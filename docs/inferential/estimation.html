<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Termeh Shafie">
<title>21&nbsp; Estimation – Foundational Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../inferential/hyp-test.html" rel="next">
<link href="../inferential/intro-inference.html" rel="prev">
<link href="../cover.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-6bb5ad484749947dbf006bb4d74c4af5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../inferential/intro-inference.html">Inferential Statistics</a></li><li class="breadcrumb-item"><a href="../inferential/estimation.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Estimation</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Foundational Statistics</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/termehs/found-stats" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../introduction/what-is-stats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">What is Statistics?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../introduction/intro-math.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">The Unavoidable Math</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../introduction/intro-surveys.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Surveys: Key Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../introduction/variable-class.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Variable Classification</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Descriptive Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../descriptive-stats/describe-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Describing a Dataset</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../descriptive-stats/central-measures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Measures of Central Tendency</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../descriptive-stats/dispersion-measures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Measures of Dispersion</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Probability Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob-theory/prob-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Probability Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob-theory/what-is-prob.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">What is Probability?</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob-theory/count-rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Counting Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../prob-theory/prob-rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probability Rules</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Random Variables and Probability Distributions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rvs-probdists/random-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rvs-probdists/discrete-dists.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Discrete Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rvs-probdists/cont-dists.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Continuous Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../rvs-probdists/jointly-dist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Jointly Distributed Random Variables</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Sampling and Sampling Distributions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling-dists/sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Sampling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling-dists/sampling-dist-mean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sampling Distributions for a Sample Mean</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling-dists/sampling-dist-prop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Sampling Distributions for a Sample Proportion</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sampling-dists/clt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Central Limit Theorem</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Inferential Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inferential/intro-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">From Probability to Statistical Inference</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inferential/estimation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inferential/hyp-test.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../inferential/chi2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Chi Square Tests</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Regression Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/reg-framework.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">The Regression Framework</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../regression/slr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Simple Linear Regression</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">References</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/normal-table.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">The Standard Normal Distribution Table</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/t-table.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">The <span class="math inline">\(t\)</span> Distribution Table</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../appendix/chi2-table.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">The <span class="math inline">\(\chi^2\)</span> Distribution Table</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#estimators-estimate-estimands" id="toc-estimators-estimate-estimands" class="nav-link active" data-scroll-target="#estimators-estimate-estimands"><span class="header-section-number">21.1</span> Estimators, Estimate, Estimands</a></li>
  <li><a href="#properties-of-estimators" id="toc-properties-of-estimators" class="nav-link" data-scroll-target="#properties-of-estimators"><span class="header-section-number">21.2</span> Properties of Estimators</a></li>
  <li><a href="#point-estimation" id="toc-point-estimation" class="nav-link" data-scroll-target="#point-estimation"><span class="header-section-number">21.3</span> Point Estimation</a></li>
  <li>
<a href="#interval-estimation" id="toc-interval-estimation" class="nav-link" data-scroll-target="#interval-estimation"><span class="header-section-number">21.4</span> Interval Estimation</a>
  <ul class="collapse">
<li><a href="#confidence-interval-for-the-population-mean" id="toc-confidence-interval-for-the-population-mean" class="nav-link" data-scroll-target="#confidence-interval-for-the-population-mean"><span class="header-section-number">21.4.1</span> Confidence Interval for the Population Mean</a></li>
  <li><a href="#confidence-interval-for-the-population-proportion" id="toc-confidence-interval-for-the-population-proportion" class="nav-link" data-scroll-target="#confidence-interval-for-the-population-proportion"><span class="header-section-number">21.4.2</span> Confidence Interval for the Population Proportion</a></li>
  <li><a href="#confidence-intervals-for-the-difference-between-two-population-means" id="toc-confidence-intervals-for-the-difference-between-two-population-means" class="nav-link" data-scroll-target="#confidence-intervals-for-the-difference-between-two-population-means"><span class="header-section-number">21.4.3</span> Confidence Intervals for the Difference Between Two Population Means</a></li>
  <li><a href="#confidence-intervals-for-differences-in-population-proportions" id="toc-confidence-intervals-for-differences-in-population-proportions" class="nav-link" data-scroll-target="#confidence-intervals-for-differences-in-population-proportions"><span class="header-section-number">21.4.4</span> Confidence Intervals for Differences in Population Proportions</a></li>
  </ul>
</li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/termehs/found-stats/edit/main/inferential/estimation.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/termehs/found-stats/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../inferential/intro-inference.html">Inferential Statistics</a></li><li class="breadcrumb-item"><a href="../inferential/estimation.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Estimation</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title"><span id="sec-est" class="quarto-section-identifier"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Estimation</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><p>When working with data, we often face the challenge of estimating unknown characteristics of a population based on a limited set of observations: a sample. These characteristics could be the population mean (<span class="math inline">\(\mu\)</span>), the population proportion (<span class="math inline">\(p\)</span>), or the population variance (<span class="math inline">\(\sigma^2\)</span>), among others. In general, we denote the unknown population parameter we wish to estimate by <span class="math inline">\(\theta\)</span>.</p>
<p>Suppose we collect a random sample consisting of <span class="math inline">\(n\)</span> independent observations, denoted by <span class="math inline">\(X_1, X_2, \dots, X_n\)</span>. Based on this sample, we compute an estimate of <span class="math inline">\(\theta\)</span>, which we denote as <span class="math inline">\(\hat{\theta}\)</span>. For instance, if the parameter of interest is the population mean <span class="math inline">\(\mu\)</span>, then the corresponding estimate is the sample mean <span class="math inline">\(\bar{X}\)</span>. If the parameter of interest is the population variance <span class="math inline">\(\sigma^2\)</span>, the estimate is the sample variance <span class="math inline">\(s^2\)</span>.</p>
<p>Because the sample is randomly drawn from the population, the estimate <span class="math inline">\(\hat{\theta}\)</span> is itself a random variable. Its value depends on the specific observations in the sample, and therefore it varies from sample to sample. The distribution of this estimate across many repeated samples is known as its sampling distribution (see <a href="../sampling-dists/sampling-dist-mean.html" class="quarto-xref"><span>Chapter 17</span></a> and <a href="../sampling-dists/sampling-dist-prop.html" class="quarto-xref"><span>Chapter 18</span></a>). Understanding the behavior of this distribution is central to inferential statistics: it allows us to assess the uncertainty in our estimates and build confidence intervals, conduct hypothesis tests, and more.</p>
<p>Naturally, we hope that the value of our estimate <span class="math inline">\(\hat{\theta}\)</span> is close to the true, unknown value of <span class="math inline">\(\theta\)</span>. However, there is always a degree of uncertainty involved. To evaluate the quality of an estimator, we study its properties, most importantly, its expected value and its variance.</p>
<section id="estimators-estimate-estimands" class="level2" data-number="21.1"><h2 data-number="21.1" class="anchored" data-anchor-id="estimators-estimate-estimands">
<span class="header-section-number">21.1</span> Estimators, Estimate, Estimands</h2>
<p>For clarity, it’s important to distinguish between three closely related but conceptually distinct terms in inferential statistics: <strong>estimand</strong>, <strong>estimator</strong>, and <strong>estimate</strong>.</p>
<ul>
<li><p><strong>Estimand</strong>: This is the <strong>target</strong> of our inference—the unknown quantity or parameter in the population we want to learn about. Examples include the population mean <span class="math inline">\(\mu\)</span>, the proportion of voters supporting a policy <span class="math inline">\(p\)</span>, or the difference in means between two groups <span class="math inline">\(\mu_1 - \mu_2\)</span>.</p></li>
<li><p><strong>Estimator</strong>: A formula or rule that we apply to sample data in order to make an informed guess about the estimand. It is a <strong>random variable</strong>, as it depends on the data, which in turn vary across samples. For instance, the sample mean <span class="math inline">\(\bar{X}\)</span> is an estimator for the population mean <span class="math inline">\(\mu\)</span>.</p></li>
<li><p><strong>Estimate</strong>: The <strong>actual numerical result</strong> obtained when we apply the estimator to a specific dataset. It is a <strong>fixed number</strong>, not a random variable. For example, if <span class="math inline">\(\bar{X} = 7.4\)</span> from our sample, then 7.4 is our estimate of the population mean.</p></li>
</ul>
<p>In simpler terms:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 46%">
<col style="width: 36%">
</colgroup>
<thead><tr class="header">
<th>Term</th>
<th>Role</th>
<th>Example</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Estimand</td>
<td>What we want to know</td>
<td>
<span class="math inline">\(\mu\)</span>, <span class="math inline">\(p\)</span>, <span class="math inline">\(\mu_1 - \mu_2\)</span>
</td>
</tr>
<tr class="even">
<td>Estimator</td>
<td>How we calculate it</td>
<td>
<span class="math inline">\(\bar{X}\)</span>, <span class="math inline">\(\hat{p}\)</span>
</td>
</tr>
<tr class="odd">
<td>Estimate</td>
<td>What we get from our data</td>
<td>7.4, 0.38</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>⚠️ While these terms are sometimes used interchangeably in casual discussion, understanding their formal distinction is crucial for clear statistical reasoning.</p>
</blockquote>
<p>In this text, we may occasionally use “estimate” loosely, but rest assured; we’ll always be clear about what we’re inferring, how we’re doing it, and what the result actually tells us.</p>
</section><section id="properties-of-estimators" class="level2" data-number="21.2"><h2 data-number="21.2" class="anchored" data-anchor-id="properties-of-estimators">
<span class="header-section-number">21.2</span> Properties of Estimators</h2>
<p>An estimator’s quality is assessed through certain desirable properties. The most fundamental ones are <strong>unbiasedness</strong>, <strong>consistency</strong>, and <strong>efficiency</strong>.</p>
<p>An estimator <span class="math inline">\(\hat{\theta}\)</span> is called <strong>unbiased</strong> if its expected value equals the true parameter:</p>
<p><span class="math display">\[
E(\hat{\theta}) = \theta.
\]</span></p>
<p>This means that, on average across many samples, the estimator hits the correct value. If this condition is not met, the estimator is said to have a <strong>bias</strong>, defined as:</p>
<p><span class="math display">\[
\text{Bias}(\hat{\theta}) = E(\hat{\theta}) - \theta.
\]</span></p>
<p>An estimator with zero bias is called unbiased. But just being correct <em>on average</em> is not enough. We also want our estimator to be <strong>reliable</strong>, that is, to give values that are close to the true parameter in most samples, not just on average.</p>
<p>This brings us to the property of <strong>consistency</strong>. An estimator is <strong>consistent</strong> if it gets arbitrarily close to the true parameter as the sample size increases. Formally, a consistent estimator <span class="math inline">\(\hat{\theta}_n\)</span> satisfies:</p>
<p><span class="math display">\[
\hat{\theta}_n \xrightarrow{p} \theta \quad \text{as } n \to \infty.
\]</span></p>
<p>That is, the probability that the estimator deviates substantially from <span class="math inline">\(\theta\)</span> goes to zero as the number of observations grows. Consistency ensures long-run accuracy with enough data.</p>
<p>Finally, among several unbiased and consistent estimators, we may prefer the one that tends to stay closest to the target in each sample. This is the idea behind <strong>efficiency</strong>. An estimator is more efficient if it has smaller variance among all unbiased estimators. In practical terms, this means it’s more <strong>precise</strong>: it fluctuates less from sample to sample, producing estimates tightly clustered around the true value. When comparing two unbiased estimators of the same parameter, the one with the smaller variance is considered more efficient.</p>
<p>To illustrate these concepts, consider the dartboard image below:</p>
<div class="center">
<div id="fig-dart" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-dart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imgs/dart.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.1: Each board illustrates a combination of estimator characteristics. The bottom-left shows an unbiased and efficient estimator (tight clustering at the center). The top-left is biased but efficient (tight clustering, but off-target). The bottom-right is unbiased but inefficient (centered but scattered). The top-right represents an inefficient and biased estimator (wide scatter, off-target). This analogy helps visualize bias, precision, and the ideal goal of consistency over repeated samples.
</figcaption></figure>
</div>
</div>
<p>Together, these properties give us a clear framework for evaluating the reliability of estimators. Ideally, we want an estimator that is unbiased and has the smallest possible variance, a combination that yields both accuracy and precision in estimation.</p>
</section><section id="point-estimation" class="level2" data-number="21.3"><h2 data-number="21.3" class="anchored" data-anchor-id="point-estimation">
<span class="header-section-number">21.3</span> Point Estimation</h2>
<p>In statistical inference, we often aim to estimate unknown characteristics of a population—such as its average income, the proportion of voters in favor of a policy, or the variance in housing prices. This process of using data from a sample to calculate a single value as a “best guess” for a population parameter is known as <strong>point estimation</strong>.</p>
<p>Let us assume we have a random sample <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> of <span class="math inline">\(n\)</span> independent observations from a population with an unknown mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. A <strong>point estimator</strong> is a function of the sample data used to estimate a population parameter.</p>
<p>For instance:</p>
<ul>
<li>The <strong>population mean</strong> <span class="math inline">\(\mu\)</span> is typically estimated by the <strong>sample mean</strong> <span class="math inline">\(\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i\)</span>
</li>
<li>The <strong>population proportion</strong> <span class="math inline">\(p\)</span> is estimated by the <strong>sample proportion</strong> <span class="math inline">\(\hat{p} = \frac{x}{n}\)</span>, where <span class="math inline">\(x\)</span> is the number of “successes”</li>
<li>The <strong>population variance</strong> <span class="math inline">\(\sigma^2\)</span> is estimated by the <strong>sample variance</strong> <span class="math inline">\(s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2\)</span>
</li>
</ul>
<p>These estimators are derived from the data and yield a specific number once we collect our sample. However, prior to observing the data, the estimator is a random variable because it depends on the randomly selected sample.</p>
<p>Since estimators are functions of random samples, they too follow a probability distribution. This distribution is known as the sampling distribution of the estimator (see <a href="../sampling-dists/sampling-dist-mean.html" class="quarto-xref"><span>Chapter 17</span></a> and <a href="../sampling-dists/sampling-dist-prop.html" class="quarto-xref"><span>Chapter 18</span></a>). It tells us how the estimator would vary if we repeatedly took samples of the same size from the same population.</p>
<p>A crucial insight here is that the larger the sample size, the less variability the estimator will show across repeated samples, leading to more <strong>reliable</strong> estimation.</p>
<p>Understanding the quality of an estimator involves examining the theoretical properties mentioned above:</p>
<ul>
<li>
<p><strong>Unbiasedness</strong>: An estimator <span class="math inline">\(\hat{\theta}\)</span> is said to be <strong>unbiased</strong> for a parameter <span class="math inline">\(\theta\)</span> if its expected value equals the true parameter:<br><span class="math display">\[ E(\hat{\theta}) = \theta \]</span></p>
<p>For example (this was shown in detail in <a href="../sampling-dists/sampling-dist-mean.html" class="quarto-xref"><span>Chapter 17</span></a>):</p>
<ul>
<li>
<span class="math inline">\(E(\bar{X}) = \mu\)</span>, so the sample mean is an unbiased estimator of the population mean.</li>
<li>
<span class="math inline">\(E(\hat{p}) = p\)</span>, meaning the sample proportion is also unbiased for the true proportion.</li>
<li>
<span class="math inline">\(E(s^2) = \sigma^2\)</span>, making <span class="math inline">\(s^2\)</span> an unbiased estimator of the population variance.</li>
</ul>
<p><em>(Note: The sample standard deviation <span class="math inline">\(s\)</span> is not an unbiased estimator of <span class="math inline">\(\sigma\)</span>.)</em></p>
</li>
<li>
<p><strong>Variance</strong>: The <strong>spread</strong> of the estimator’s sampling distribution is captured by its variance. Smaller variance means the estimator tends to be closer to the true parameter.</p>
<p>For the sample mean, this is given by:<br><span class="math display">\[ \operatorname{Var}(\bar{X}) = \frac{\sigma^2}{n} \]</span><br>
Similarly, for the sample proportion: <span class="math display">\[ \operatorname{Var}(\hat{p}) = \frac{p(1 - p)}{n} \]</span></p>
<p>These expressions show that increasing the sample size <span class="math inline">\(n\)</span> decreases the variance of the estimator.</p>
</li>
<li><p><strong>Standard Error</strong>: The <strong>standard deviation</strong> of an estimator’s sampling distribution is called the <strong>standard error</strong> (SE). It quantifies how much the estimator would vary from sample to sample: <span class="math display">\[ \text{SE}(\bar{X}) = \sqrt{\frac{\sigma^2}{n}}, \quad \text{SE}(\hat{p}) = \sqrt{\frac{p(1 - p)}{n}} \]</span></p></li>
</ul>
<p>In practice, when <span class="math inline">\(\sigma^2\)</span> or <span class="math inline">\(p\)</span> are unknown, we often substitute their estimates.</p>
<p>Point estimation provides an intuitive way to infer unknown quantities in a population using observed sample data. It’s the first essential tool in the inferential statistics toolbox, allowing us to move from descriptive summaries to educated guesses about the world beyond our data. In the coming chapters, we will build on these estimators to construct confidence intervals and perform hypothesis testing, all grounded in the probabilistic behavior of these sampling distributions.</p>
</section><section id="interval-estimation" class="level2" data-number="21.4"><h2 data-number="21.4" class="anchored" data-anchor-id="interval-estimation">
<span class="header-section-number">21.4</span> Interval Estimation</h2>
<p>In statistics, a single number, known as a point estimate, can give us an estimate of a population parameter, like the mean. But such an estimate tells us little about how precise or reliable it is. After all, due to the randomness inherent in sampling, our estimate could vary from sample to sample. That’s why we turn to <strong>interval estimation</strong>.</p>
<p>A <strong>confidence interval</strong> provides a range of plausible values for the unknown parameter. It gives a way to quantify the uncertainty of our point estimate. The general form of a confidence interval can be written as:</p>
<p><span class="math display">\[
\text{Point Estimate} \pm \text{Margin of Error}
\]</span></p>
<p>More formally, a confidence interval is constructed so that, with a specified probability known as the <strong>confidence level</strong>, contains the true value of the parameter. This probability is denoted by <span class="math inline">\(1 - \alpha\)</span>, where <span class="math inline">\(\alpha\)</span> is the <strong>significance level</strong>. Common choices are 95% confidence (<span class="math inline">\(\alpha = 0.05\)</span>) or 99% confidence (<span class="math inline">\(\alpha = 0.01\)</span>). The higher the confidence level, the wider the interval must be to ensure it covers the true parameter more frequently in repeated samples.</p>
<p>While a point estimate gives us a single best guess for the value of a population parameter, it offers no information about the uncertainty of that guess. This is visualized in <a href="#fig-fish" class="quarto-xref">Figure&nbsp;<span>21.2</span></a>. Imagine you’re trying to catch a fish (think <em>parameter</em>) you can’t quite see. Point estimation is like throwing a spear: accurate if you hit, but there’s a good chance you’ll miss. Interval estimation is more forgiving: it’s like casting a net. You may not catch the exact center, but you’re much more likely to get the fish. This is exactly what confidence intervals offer: a wider, more reliable shot at capturing the truth.</p>
<div class="center">
<div id="fig-fish" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-fish-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="imgs/point-interval-fish.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fish-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.2: An analogy for estimation methods: the top panel shows point estimation as attempting to catch a fish with a spear: precise but risky. The bottom panel illustrates interval estimation as casting a wide net: less precise but with a greater chance of capturing the true value.
</figcaption></figure>
</div>
</div>
<section id="confidence-interval-for-the-population-mean" class="level3" data-number="21.4.1"><h3 data-number="21.4.1" class="anchored" data-anchor-id="confidence-interval-for-the-population-mean">
<span class="header-section-number">21.4.1</span> Confidence Interval for the Population Mean</h3>
<p>When we talk about a <strong>confidence interval</strong> for the population mean <span class="math inline">\(\mu\)</span> with a <strong>confidence level</strong> of 95%, we mean an interval that, in the long run, will contain the true value of <span class="math inline">\(\mu\)</span> in 95% of repeated samples. In practice, we never know the true mean, but we use our sample data to construct a range where we believe the mean is likely to lie.</p>
<p>More precisely, the endpoints of the interval (called the <em>Lower Confidence Limit</em> (LCL) and <em>Upper Confidence Limit</em> (UCL)) are calculated as:</p>
<p><span class="math display">\[
\begin{aligned}
\text{LCL} &amp;= \bar{X} - z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}, \\
\text{UCL} &amp;= \bar{X} + z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}
\end{aligned}
\]</span></p>
<p>For a 95% confidence level, the critical value is <span class="math inline">\(z_{\alpha/2} \approx 1.96\)</span>.</p>
<p>Before we observe any data, the sample mean <span class="math inline">\(\bar{X}\)</span> is a random variable. If the population is <strong>normally distributed with known variance <span class="math inline">\(\sigma^2\)</span></strong>, then:</p>
<p><span class="math display">\[
\bar{X} \sim \mathcal{N}(\mu, \frac{\sigma^2}{n})
\]</span></p>
<p>Standardizing gives:</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \sim \mathcal{N}(0, 1)
\]</span></p>
<p>We know (from <a href="../appendix/normal-table.html" class="quarto-xref"><span>Appendix A</span></a>):</p>
<p><span class="math display">\[
P(-1.96 \leq Z \leq 1.96) = 0.95
\]</span></p>
<p>Rewriting this inequality in terms of <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
P\left(\underbrace{\bar{X} - 1.96 \cdot \frac{\sigma}{\sqrt{n}}}_{\text{LCL}} \leq \mu \leq  \underbrace{\bar{X} + 1.96 \cdot \frac{\sigma}{\sqrt{n}}}_{\text{UCL}}\right) = 0.95
\]</span></p>
<p>This tells us that if we repeat this sampling process many times, 95% of the resulting intervals will contain the true population mean. This is visualized in <a href="#fig-cfi" class="quarto-xref">Figure&nbsp;<span>21.3</span></a>.</p>
<div id="fig-cfi" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-cfi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="estimation_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cfi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.3: Visual comparison of a 95% confidence interval (top) and the corresponding central probability region of the standard normal distribution (bottom). The top plot shows the confidence interval expressed in terms of the sample mean <span class="math inline">\(\bar{X}\)</span> and standard error, while the bottom plot uses the standardized <span class="math inline">\(z\)</span>-values. In both cases, the central 95% of the distribution is shaded, with <span class="math inline">\(\alpha/2 = 0.025\)</span> in each tail, and the total area between the bounds representing 95% probability.
</figcaption></figure>
</div>
<p>Each time we draw a new sample from a population and construct a confidence interval for the population mean <span class="math inline">\(\mu\)</span>, the endpoints of that interval are random; they depend on the data from that specific sample. This means that the interval can change from sample to sample. However, if we use a 95% confidence level, then in the long run, 95% of those intervals will capture the true mean, and 5% will not.</p>
<p>In other words, we can’t guarantee that a single confidence interval contains the population mean, but we can say that the method used to construct it is correct 95% of the time. To show this, we perform a simulation: we simulate 100 samples from the same population, construct a 95% confidence interval for each, and visualizes which ones do and do not include the true population mean. Each vertical line in <a href="#fig-cfi-sim" class="quarto-xref">Figure&nbsp;<span>21.4</span></a> represents one confidence interval from a sample of size <span class="math inline">\(n = 30\)</span>. The blue line shows the true mean <span class="math inline">\(\mu = 5\)</span> and. The grey intervals contain the true mean, as expected 95% of the time. Red intervals are the $$5% that miss, a natural consequence of statistical variation.</p>
<div id="fig-cfi-sim" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-cfi-sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="estimation_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cfi-sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.4: Simulation of 100 confidence intervals for the population mean <span class="math inline">\(\mu = 5\)</span>. Each vertical line represents a 95% confidence interval constructed from a random sample of size <span class="math inline">\(n = 30\)</span>. Grey intervals successfully capture the true mean, while red intervals do not, illustrating the expected 5% miss rate due to sampling variability.
</figcaption></figure>
</div>
<p>So how do we interpret the confidence interval? Before we collect any data, we can say that there is a 95% probability that the interval we are about to compute will contain the true population mean, <span class="math inline">\(\mu\)</span>. This probability statement refers to the process, not the specific interval. That is, we are 95% confident in the method, not in any one result. Once a sample is drawn and the confidence interval is computed, the situation changes. The interval is now fixed, it either contains <span class="math inline">\(\mu\)</span> or it doesn’t. We no longer speak of probabilities regarding this specific interval. However, what we do know is this:</p>
<blockquote class="blockquote">
<p>The interval was calculated using a procedure that, in the long run, produces intervals that contain the true mean in 95% of all cases.</p>
</blockquote>
<p>This is the essence of the frequentist interpretation of confidence intervals. It doesn’t tell us the probability that our specific interval contains <span class="math inline">\(\mu\)</span>, but it does provide a measure of trust in the procedure we used to create it. That’s why we refer to it as a “confidence” interval — not because we are certain, but because we have reason to be confident based on the method’s performance over repeated samples.</p>
<p>So far, we have only constructed 95% confidence intervals for a population mean. This means that if we were to repeat the sampling procedure many times, approximately 95% of those intervals would contain the true population mean, <span class="math inline">\(\mu\)</span>.</p>
<p>But 95% is not a fixed rule. We can choose other confidence levels—such as 90% or 99%—depending on how certain we want to be. The trade-off is that a <em>higher level</em> of confidence results in a <em>wider interval</em>, while a <em>lower confidence level</em> gives a <em>narrower but less certain estimate</em>.</p>
<p>When the population standard deviation <span class="math inline">\(\sigma\)</span> is known and the sampling distribution of the mean is approximately normal (either by assumption or via the Central Limit Theorem), the general structure of a confidence interval for the mean is:</p>
<p><span class="math display">\[
\bar{X} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\bar{X}\)</span> is the sample mean<br>
</li>
<li>
<span class="math inline">\(\sigma\)</span> is the population standard deviation<br>
</li>
<li>
<span class="math inline">\(n\)</span> is the sample size<br>
</li>
<li>
<span class="math inline">\(z_{\alpha/2}\)</span> is the critical value from the standard normal distribution for the desired confidence level</li>
</ul>
<p>Some common confidence levels and their corresponding <span class="math inline">\(z\)</span>-values are shown in <a href="#tbl-cflevels" class="quarto-xref">Table&nbsp;<span>21.1</span></a> (see <a href="../appendix/normal-table.html" class="quarto-xref"><span>Appendix A</span></a> for the exact values):</p>
<div id="tbl-cflevels" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-cflevels-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;21.1: Commonly used confidence levels and their corresponding critical values from the standard normal distribution. The value <span class="math inline">\(z_{\alpha/2}\)</span> represents the point such that the area between <span class="math inline">\(-z_{\alpha/2}\)</span> and <span class="math inline">\(z_{\alpha/2}\)</span> under the standard normal curve equals the stated confidence level.
</figcaption><div aria-describedby="tbl-cflevels-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead><tr class="header">
<th>Confidence Level</th>
<th><span class="math inline">\(\alpha\)</span></th>
<th><span class="math inline">\(z_{\alpha/2}\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>90%</td>
<td>0.10</td>
<td>1.645</td>
</tr>
<tr class="even">
<td>95%</td>
<td>0.05</td>
<td>1.960</td>
</tr>
<tr class="odd">
<td>99%</td>
<td>0.01</td>
<td>2.576</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>As seen in <a href="#fig-cfi-2" class="quarto-xref">Figure&nbsp;<span>21.5</span></a>, a higher confidence level (e.g., 99% instead of 95%) leads to a wider interval since the <span class="math inline">\(z\)</span> value moves further away from the center towards the tails, giving us more “certainty” at the cost of less precision. A larger sample size reduces the standard error <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>, resulting in a narrower interval, i.e., better precision without sacrificing confidence.</p>
<div id="fig-cfi-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-cfi-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-confidence-interval" class="quarto-float quarto-figure quarto-figure-center anchored" width="672" data-fig-align="center">
<figure class="quarto-float quarto-subfloat-fig figure"><div aria-describedby="fig-confidence-interval-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="estimation_files/figure-html/fig-confidence-interval-1.png" id="fig-confidence-interval" class="img-fluid quarto-figure quarto-figure-center anchored figure-img" data-ref-parent="fig-cfi-2" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-confidence-interval-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a)
</figcaption></figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cfi-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.5: The confidence interval spans the central <span class="math inline">\((1 - \alpha)\)</span> area of the standard normal distribution. Each tail has area <span class="math inline">\(\alpha/2\)</span>.
</figcaption></figure>
</div>
<blockquote class="blockquote">
<p>💡 <em>A higher confidence level leads to a wider interval: you’re more confident, but less precise</em>.</p>
</blockquote>
<p>This approach provides a principled way of capturing the uncertainty in our estimation of <span class="math inline">\(\mu\)</span>. While the point estimate <span class="math inline">\(\bar{X}\)</span> gives our best guess, the confidence interval gives us a sense of how variable that estimate might be if we repeated the experiment.</p>
<p>In the following, we continue to build on this framework and explore how confidence intervals can be constructed for other types of parameters and under various assumptions.</p>
<section id="example-21.1-confidence-interval-for-a-population-mean" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="example-21.1-confidence-interval-for-a-population-mean">Example 21.1: Confidence Interval for a Population Mean</h4>
<p>Let’s consider a scenario where we take a random sample of size <span class="math inline">\(n = 25\)</span> from a normally distributed population. Suppose we know the population standard deviation to be <span class="math inline">\(\sigma = 15\)</span>, and the sample mean is <span class="math inline">\(\bar{x} = 102\)</span>.</p>
<p>We want to construct a 95% confidence interval for the population mean <span class="math inline">\(\mu\)</span>. We use the formula for a confidence interval when the population standard deviation is known:</p>
<p><span class="math display">\[
\bar{x} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}
\]</span></p>
<p>For a 95% confidence level, the critical value from the standard normal distribution is <span class="math inline">\(z_{0.025} = 1.96\)</span>.</p>
<p>Let’s plug in the values:</p>
<p><span class="math display">\[
102 \pm 1.96 \cdot \frac{15}{\sqrt{25}} = 102 \pm 1.96 \cdot 3 = 102 \pm 5.88
\]</span></p>
<p>Hence, the 95% confidence interval becomes:</p>
<p><span class="math display">\[
(96.12,\ 107.88)
\]</span></p>
<p>This interval suggests that if we were to repeat this sampling process many times, approximately 95% of the resulting intervals would contain the true population mean <span class="math inline">\(\mu\)</span>.</p>
<p><em>What if we want a 99% confidence interval?</em> A higher confidence level requires a larger critical value. For 99% confidence, we use <span class="math inline">\(z_{0.005} = 2.575\)</span>. Applying the formula:</p>
<p><span class="math display">\[
102 \pm 2.575 \cdot \frac{15}{\sqrt{25}} = 102 \pm 2.575 \cdot 3 = 102 \pm 7.725
\]</span></p>
<p>This results in a wider interval:</p>
<p><span class="math display">\[
(94.275,\ 109.725)
\]</span></p>
<p>As expected, increasing the confidence level results in a wider interval. This reflects greater certainty, more room is allowed to ensure the true mean is captured.</p>
</section><section id="confidence-intervals-with-unknown-variance" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="confidence-intervals-with-unknown-variance">Confidence Intervals with Unknown Variance</h4>
<p>In previous examples, we constructed confidence intervals assuming that the population standard deviation <span class="math inline">\(\sigma\)</span> is known and that the population is normally distributed. While this is convenient for illustrating the basic logic of confidence intervals, it is rarely the case in practice.</p>
<blockquote class="blockquote">
<p>But what if <span class="math inline">\(\sigma\)</span> is unknown?</p>
</blockquote>
<p>When <span class="math inline">\(\sigma\)</span> is <strong>unknown</strong>, we typically rely on the <strong>sample standard deviation</strong> <span class="math inline">\(s\)</span> instead. This introduces an additional source of uncertainty because we are now estimating both the center (<span class="math inline">\(\bar{X}\)</span>) and the spread (<span class="math inline">\(s\)</span>) from the sample data.</p>
<p>As a result, our confidence interval becomes wider, especially when the sample size <span class="math inline">\(n\)</span> is small. To account for this, we use the <strong><span class="math inline">\(t\)</span>-distribution</strong> rather than the standard normal distribution.</p>
<p>We distinguish between two scenarios:</p>
<p><strong>1. Large sample size (<span class="math inline">\(n \geq 30\)</span>):</strong></p>
<p>When the sample size is large, the Central Limit Theorem (<a href="../sampling-dists/clt.html" class="quarto-xref"><span>Chapter 19</span></a>) ensures that the sampling distribution of the mean is approximately normal, even if the population isn’t. In this case, substituting <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span> has little impact, and we can still use the normal approximation: <span class="math display">\[
\bar{x} \pm z_{\alpha/2} \cdot \frac{s}{\sqrt{n}}.
\]</span></p>
<p><strong>2. Small sample size (<span class="math inline">\(n &lt; 30\)</span>):</strong></p>
<p>When the sample size is small and <span class="math inline">\(\sigma\)</span> is unknown, we must use the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(\nu = n-1\)</span> degrees of freedom:</p>
<p><span class="math display">\[
\bar{x} \pm t_{\nu, \alpha/2} \cdot \frac{s}{\sqrt{n}}.
\]</span></p>
<p>Here, <span class="math inline">\(t_{\nu, \alpha/2}\)</span> is the critical value from the <span class="math inline">\(t\)</span>-distribution that corresponds to the desired confidence level. This values is obtained from <a href="../appendix/t-table.html" class="quarto-xref"><span>Appendix B</span></a> and is fully determined by the degrees of freedom <span class="math inline">\(\nu\)</span> and confidence level <span class="math inline">\(\alpha\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Introducing the <span class="math inline">\(t\)</span>-distribution
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <strong>Student’s <span class="math inline">\(t\)</span>-distribution</strong> is a fundamental tool in statistics when estimating a population mean from a small sample, especially in cases where the <strong>population standard deviation <span class="math inline">\(\sigma\)</span> is unknown</strong>. While it resembles the standard normal distribution <span class="math inline">\(N(0, 1)\)</span> in shape, the <span class="math inline">\(t\)</span>-distribution has heavier tails. These heavier tails reflect the added uncertainty introduced by estimating <span class="math inline">\(\sigma\)</span> with the sample standard deviation <span class="math inline">\(s\)</span>.</p>
<p>The exact shape of the <span class="math inline">\(t\)</span>-distribution depends on its <strong>degrees of freedom</strong>, typically <span class="math inline">\(\nu = n - 1\)</span>, where <span class="math inline">\(n\)</span> is the sample size. As the sample size increases, the estimate of <span class="math inline">\(\sigma\)</span> becomes more reliable, and the <span class="math inline">\(t\)</span>-distribution gradually approaches the normal distribution. In fact, as <span class="math inline">\(\nu \to \infty\)</span>, the <span class="math inline">\(t\)</span>-distribution converges to <span class="math inline">\(N(0, 1)\)</span> (see <a href="#fig-tz-dist" class="quarto-xref">Figure&nbsp;<span>21.6</span></a>).</p>
<p>When the population is normally distributed and we collect a random sample of size <span class="math inline">\(n\)</span>, the following standardized statistic follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n - 1\)</span> degrees of freedom:</p>
<p><span class="math display">\[
\frac{\bar{X} - \mu}{s / \sqrt{n}} \sim t(n - 1)
\]</span></p>
<p>This formulation allows us to perform valid inference about the population mean <span class="math inline">\(\mu\)</span>, even without knowing the true standard deviation <span class="math inline">\(\sigma\)</span>, as long as the population itself is assumed to be normally distributed.</p>
<div id="fig-tz-dist" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-tz-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="estimation_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tz-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;21.6: Comparison of the standard normal distribution (black) with Student’s <span class="math inline">\(t\)</span>-distributions for degrees of freedom 1, 5, and 10. As the degrees of freedom increase, the <span class="math inline">\(t\)</span>-distribution becomes more peaked and approaches the shape of the normal distribution, reflecting reduced uncertainty due to larger sample sizes.
</figcaption></figure>
</div>
</div>
</div>
</section><section id="summary-confidence-intervals-for-the-population-mean" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="summary-confidence-intervals-for-the-population-mean">Summary: Confidence Intervals for the Population Mean</h4>
<p>When constructing a confidence interval for the population mean <span class="math inline">\(\mu\)</span>, the formula depends on three key factors:</p>
<ul>
<li>whether the population standard deviation <span class="math inline">\(σ\)</span> is known,<br>
</li>
<li>the size of the sample, and<br>
</li>
<li>whether the population is normally distributed.</li>
</ul>
<p><a href="#tbl-popmean-cfi" class="quarto-xref">Table&nbsp;<span>21.2</span></a> below summarizes which distribution and formula to use in different situations:</p>
<div id="tbl-popmean-cfi" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-popmean-cfi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;21.2: Summary of conditions for constructing confidence intervals for a population mean.
</figcaption><div aria-describedby="tbl-popmean-cfi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 56%">
<col style="width: 18%">
<col style="width: 24%">
</colgroup>
<thead><tr class="header">
<th>Conditions</th>
<th>Variance Assumptions</th>
<th>Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<span class="math inline">\(n \geq 30\)</span> (any population)</td>
<td>
<span class="math inline">\(\sigma^2\)</span> known</td>
<td><span class="math inline">\(\bar{x} \pm z_{\alpha/2} \left( \frac{\sigma}{\sqrt{n}} \right)\)</span></td>
</tr>
<tr class="even">
<td></td>
<td>
<span class="math inline">\(\sigma^2\)</span> unknown</td>
<td><span class="math inline">\(\bar{x} \pm z_{\alpha/2} \left( \frac{s}{\sqrt{n}} \right)\)</span></td>
</tr>
<tr class="odd">
<td>
<span class="math inline">\(n &lt; 30\)</span>, normal population</td>
<td>
<span class="math inline">\(\sigma^2\)</span> known</td>
<td><span class="math inline">\(\bar{x} \pm z_{\alpha/2} \left( \frac{\sigma}{\sqrt{n}} \right)\)</span></td>
</tr>
<tr class="even">
<td></td>
<td>
<span class="math inline">\(\sigma^2\)</span> unknown</td>
<td><span class="math inline">\(\bar{x} \pm t_{\nu,\alpha/2} \left( \frac{s}{\sqrt{n}} \right)\)</span></td>
</tr>
<tr class="odd">
<td>
<span class="math inline">\(n &lt; 30\)</span>, population is not normally distributed</td>
<td>—</td>
<td>Confidence interval cannot be calculated</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<blockquote class="blockquote">
<p>Note: If the sample size is small (<span class="math inline">\(n &lt; 30\)</span>) and the population is <strong>not</strong> normally distributed, we cannot safely use these formulas to calculate a confidence interval for <span class="math inline">\(\mu\)</span>. In such cases, resampling methods like bootstrapping or non-parametric approaches may be more appropriate.</p>
</blockquote>
</section><section id="example-21.2-confidence-interval-for-a-population-mean-n-small-variance-unknown" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="example-21.2-confidence-interval-for-a-population-mean-n-small-variance-unknown">Example 21.2: Confidence Interval for a Population Mean, <span class="math inline">\(n\)</span> small, variance unknown</h4>
<p>In a laboratory, measurements are taken on a variable that is assumed to be normally distributed. On one occasion, 12 measurements are obtained, resulting in:</p>
<ul>
<li>
<span class="math inline">\(\bar{x} = 9.6\)</span><br>
</li>
<li><span class="math inline">\(s = 1.89\)</span></li>
</ul>
<p>We are asked to compute a 95% confidence interval for the population mean <span class="math inline">\(\mu\)</span>.</p>
<p>Since we have a small sample size (<span class="math inline">\(n = 12\)</span>) and the population variance <span class="math inline">\(\sigma^2\)</span> is unknown, we use the <strong>Student’s t-distribution</strong> with <span class="math inline">\(n - 1 = 11\)</span> degrees of freedom. The general formula for the confidence interval is:</p>
<p><span class="math display">\[
\bar{x} \pm t_{\nu, \alpha/2} \cdot \frac{s}{\sqrt{n}}
\]</span></p>
<p>For a 95% confidence level, <span class="math inline">\(\alpha = 0.05\)</span>, so <span class="math inline">\(\alpha/2 = 0.025\)</span>. From the <span class="math inline">\(t\)</span>-distribution table <a href="../appendix/t-table.html" class="quarto-xref"><span>Appendix B</span></a>, we find:</p>
<p><span class="math display">\[
t_{11, 0.025} = 2.201
\]</span></p>
<p>We can now compute the confidence interval bounds as follows.</p>
<p><span class="math display">\[
\bar{x} \pm 2.201 \cdot \frac{1.89}{\sqrt{12}} = 9.6 \pm 2.201 \cdot 0.545
\]</span></p>
<p><span class="math display">\[
9.6 \pm 1.20
\]</span></p>
<p>Thus, the 95% confidence interval for <span class="math inline">\(\mu\)</span> is:</p>
<p><span class="math display">\[
[8.40,\ 10.80]
\]</span></p>
<p>We can say that the true population mean <span class="math inline">\(\mu\)</span> lies between 8.40 and 10.80 with 95% confidence. This means that if we were to repeat this sampling process many times, approximately 95% of the constructed confidence intervals would contain the true mean.</p>
</section></section><section id="confidence-interval-for-the-population-proportion" class="level3" data-number="21.4.2"><h3 data-number="21.4.2" class="anchored" data-anchor-id="confidence-interval-for-the-population-proportion">
<span class="header-section-number">21.4.2</span> Confidence Interval for the Population Proportion</h3>
<p>Just as we can construct a confidence interval for a population mean, we can also build one for a proportion. This is particularly useful when dealing with categorical data, for instance, estimating the proportion of defective units in a production process or the share of voters supporting a candidate.</p>
<p>Let <span class="math inline">\(p\)</span> denote the <strong>population proportion</strong>, that is, the true (but unknown) share of the population with a specific characteristic. As before, we estimate <span class="math inline">\(p\)</span> using the <strong>sample proportion</strong> <span class="math inline">\(\hat{p}\)</span>, defined as:</p>
<p><span class="math display">\[
\hat{p} = \frac{\text{number of observations with the characteristic}}{n}
\]</span></p>
<p>This is the point estimate of <span class="math inline">\(p\)</span>. Under random sampling, this estimator is <strong>unbiased</strong>, meaning:</p>
<p><span class="math display">\[
E(\hat{p}) = p
\]</span></p>
<p>The <strong>variance</strong> of <span class="math inline">\(\hat{p}\)</span> is:</p>
<p><span class="math display">\[
\text{Var}(\hat{p}) = \frac{p(1 - p)}{n}
\]</span></p>
<p>This was shown in detail in <a href="../sampling-dists/sampling-dist-prop.html" class="quarto-xref"><span>Chapter 18</span></a>.</p>
<p>Since <span class="math inline">\(p\)</span> is unknown, we approximate this variance using the observed sample proportion:</p>
<p><span class="math display">\[
\widehat{\text{Var}}(\hat{p}) = \frac{\hat{p}(1 - \hat{p})}{n}
\]</span></p>
<p>When the sample size <span class="math inline">\(n\)</span> is sufficiently large, the sampling distribution of <span class="math inline">\(\hat{p}\)</span> can be approximated by a <strong>normal distribution</strong> (thanks to the Central Limit Theorem):</p>
<p><span class="math display">\[
\frac{\hat{p} - p}{\sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}} \overset{\text{apx}}{\sim} N(0, 1)
\]</span></p>
<p>This approximation holds well when the sample size satisfies the following rule of thumb: <span class="math inline">\(np(1 - p) &gt; 5\)</span>. If this condition is met, we can construct a confidence interval using the normal distribution.</p>
<p>The confidence interval for the population proportion <span class="math inline">\(p\)</span> is given by:</p>
<p><span class="math display">\[
\hat{p} \pm \underbrace{z_{\alpha/2} \cdot \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}} }_{\text{margin of error}}
\]</span> The value of <span class="math inline">\(z_{\alpha/2}\)</span> depends on the desired confidence level, just as before shown in <a href="#tbl-cflevels" class="quarto-xref">Table&nbsp;<span>21.1</span></a>.</p>
<p>To estimate a population proportion using confeidence intervals:</p>
<ol type="1">
<li>Compute the sample proportion <span class="math inline">\(\hat{p}\)</span>.</li>
<li>Calculate the standard error <span class="math inline">\(\sqrt{\hat{p}(1 - \hat{p}) / n}\)</span>.</li>
<li>Use the appropriate <span class="math inline">\(z\)</span>-value for your confidence level.</li>
<li>Construct the interval using <span class="math inline">\(\hat{p} \pm\)</span> margin of error.</li>
</ol>
<p>This method allows us to make probabilistic statements about the true population proportion, provided the sample size is sufficiently large.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note on the <em>t</em>-distribution and proportions
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <em>t</em>-distribution is <strong>not</strong> used for constructing confidence intervals for proportions, even when sample sizes are small. Proportions are based on the binomial distribution, and standard confidence intervals rely on the <strong>normal approximation</strong> when conditions are met. If these conditions aren’t satisfied, <strong>exact methods</strong> or <strong>adjusted intervals</strong> should be used instead.</p>
</div>
</div>
<section id="example-21.3-confidence-interval-for-a-proportion" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="example-21.3-confidence-interval-for-a-proportion">Example 21.3: Confidence Interval for a Proportion</h4>
<p>We take a random sample of <span class="math inline">\(n = 1200\)</span> people from a large population. Of those sampled, 43.5% report supporting a certain political party. Construct a 95% confidence interval for the true proportion <span class="math inline">\(p\)</span> of the population who support the party.</p>
<p>We are given:</p>
<ul>
<li><span class="math inline">\(\hat{p} = 0.435\)</span></li>
<li><span class="math inline">\(n = 1200\)</span></li>
<li>Confidence level = 95% <span class="math inline">\(\Rightarrow \alpha = 0.05\)</span> <span class="math inline">\(\Rightarrow z_{\alpha/2} = z_{0.025} = 1.96\)</span>
</li>
</ul>
<p>The confidence interval for a population proportion is calculated as:</p>
<p><span class="math display">\[
\hat{p} \pm z_{\alpha/2} \cdot \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}
\]</span></p>
<p>Substitute the values:</p>
<p><span class="math display">\[\begin{split}
0.435 \pm 1.96 \cdot \sqrt{\frac{0.435(1 - 0.435)}{1200}}
&amp; = 0.435 \pm 1.96 \cdot \sqrt{\frac{0.245775}{1200}} \\
&amp; = 0.435 \pm 1.96 \cdot \sqrt{0.0002048} \\
&amp; = 0.435 \pm 1.96 \cdot 0.0143  \\
&amp; = 0.435 \pm 0.028 \\
\end{split}
\]</span></p>
<p>Thus, the 95% confidence interval is:</p>
<p><span class="math display">\[
[0.407,\ 0.463]
\]</span></p>
<p>This means we are 95% confident that the true proportion of supporters in the population lies between 40.7% and 46.3%.</p>
</section></section><section id="confidence-intervals-for-the-difference-between-two-population-means" class="level3" data-number="21.4.3"><h3 data-number="21.4.3" class="anchored" data-anchor-id="confidence-intervals-for-the-difference-between-two-population-means">
<span class="header-section-number">21.4.3</span> Confidence Intervals for the Difference Between Two Population Means</h3>
<p>When comparing two groups, we often want to estimate the difference between their population means. This leads us to construct a <strong>confidence interval</strong> for <span class="math inline">\(\mu_x - \mu_y\)</span>. There are two main cases to consider here:</p>
<section id="case-1-two-independent-samples" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="case-1-two-independent-samples">Case 1: Two Independent Samples</h4>
<p>This scenario assumes we take independent random samples from two different populations. We define the populations as follows:</p>
<table class="caption-top table">
<thead><tr class="header">
<th>Population</th>
<th>Mean</th>
<th>Standard Deviation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Population 1</td>
<td><span class="math inline">\(\mu_x\)</span></td>
<td><span class="math inline">\(\sigma_x\)</span></td>
</tr>
<tr class="even">
<td>Population 2</td>
<td><span class="math inline">\(\mu_y\)</span></td>
<td><span class="math inline">\(\sigma_y\)</span></td>
</tr>
</tbody>
</table>
<p>We collect independent samples:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 16%">
<col style="width: 20%">
<col style="width: 40%">
</colgroup>
<thead><tr class="header">
<th></th>
<th>Size (<span class="math inline">\(n\)</span>)</th>
<th>Sample Mean</th>
<th>Sample Standard Deviation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Sample from 1</td>
<td><span class="math inline">\(n_x\)</span></td>
<td><span class="math inline">\(\bar{x}\)</span></td>
<td><span class="math inline">\(s_x\)</span></td>
</tr>
<tr class="even">
<td>Sample from 2</td>
<td><span class="math inline">\(n_y\)</span></td>
<td><span class="math inline">\(\bar{y}\)</span></td>
<td><span class="math inline">\(s_y\)</span></td>
</tr>
</tbody>
</table>
<p>We estimate the difference in population means using the point estimate:</p>
<p><span class="math display">\[
\bar{x} - \bar{y}
\]</span></p>
<p>This is an <strong>unbiased estimator</strong>, meaning:</p>
<p><span class="math display">\[
E(\bar{x} - \bar{y}) = E(\bar{x}) - E(\bar{y}) = \mu_x - \mu_y
\]</span></p>
<p>Assuming the samples are independent, the <strong>variance</strong> of the difference between sample means is:</p>
<p><span class="math display">\[
\text{Var}(\bar{x} - \bar{y}) = \frac{\sigma_x^2}{n_x} + \frac{\sigma_y^2}{n_y}
\]</span></p>
<p>When the population standard deviations <span class="math inline">\(\sigma_x\)</span> and <span class="math inline">\(\sigma_y\)</span> are unknown (as is usually the case), we substitute the sample standard deviations <span class="math inline">\(s_x\)</span> and <span class="math inline">\(s_y\)</span> instead.</p>
<p>The appropriate method for constructing a confidence interval depends on several factors:</p>
<ul>
<li>The sample sizes: Are they large (<span class="math inline">\(\geq 30\)</span>) or small (<span class="math inline">\(&lt; 30\)</span>)?</li>
<li>The distribution of the populations: Are they normally distributed?</li>
<li>Whether the population variances are known or unknown</li>
<li>Whether we assume the variances are equal or not</li>
</ul></section><section id="large-independent-samples-n_x-geq-30-n_y-geq-30" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="large-independent-samples-n_x-geq-30-n_y-geq-30"><strong>Large Independent Samples (<span class="math inline">\(n_x \geq 30\)</span>, <span class="math inline">\(n_y \geq 30\)</span>)</strong></h4>
<p>When both sample sizes are large, the Central Limit Theorem allows us to use the standard normal distribution (<span class="math inline">\(Z\)</span>), regardless of the population distributions.</p>
</section><section id="a-population-variances-known" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="a-population-variances-known">a) Population Variances Known</h4>
<p>Thsi is the more rare scenario in which we use the following formula: <span class="math display">\[
\bar{x} - \bar{y} \pm z_{\alpha/2} \cdot \sqrt{ \frac{\sigma_x^2}{n_x} + \frac{\sigma_y^2}{n_y} }
\]</span></p>
</section><section id="a-population-variances-unknown" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="a-population-variances-unknown">a) Population Variances Unknown</h4>
<p>This scenario is more common and we estimate the population variances using the sample variances: <span class="math display">\[
\bar{x} - \bar{y} \pm z_{\alpha/2} \cdot \sqrt{ \frac{s_x^2}{n_x} + \frac{s_y^2}{n_y} }
\]</span> The critical <span class="math inline">\(z\)</span>-value is selected to match the desired confidence level (e.g., <span class="math inline">\(z = 1.96\)</span> for 95%).</p>
</section><section id="small-independent-samples-at-least-one-of-n_x-or-n_y-30" class="level4"><h4 class="anchored" data-anchor-id="small-independent-samples-at-least-one-of-n_x-or-n_y-30"><strong>Small Independent Samples (at least one of <span class="math inline">\(n_x\)</span> or <span class="math inline">\(n_y\)</span> &lt; 30)</strong></h4>
<p>In this case, we must assume that both populations are normally distributed to proceed.</p>
</section><section id="a-population-variances-known-1" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="a-population-variances-known-1">a) Population Variances Known</h4>
<p><span class="math display">\[
\bar{x} - \bar{y} \pm z_{\alpha/2} \cdot \sqrt{ \frac{\sigma_x^2}{n_x} + \frac{\sigma_y^2}{n_y} }
\]</span></p>
</section><section id="b-population-variances-unknown-but-assumed-equal" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="b-population-variances-unknown-but-assumed-equal">b) Population Variances Unknown but Assumed Equal</h4>
<p>Then we use the <strong>pooled variance</strong> which provides a combined estimate of the common variance by weighting the sample variances according to their degrees of freedom. The formula for pooled varince is: <span class="math display">\[
s_p^2 = \frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}
\]</span> Here, <span class="math inline">\(s_x^2\)</span> and <span class="math inline">\(s_y^2\)</span> are the sample variances from the two groups, and <span class="math inline">\(n_x\)</span> and <span class="math inline">\(n_y\)</span> are the respective sample sizes. This weighted average gives a more stable estimate of variance when the equal-variance assumption is justified. Use this method only if there is reasonable evidence that the population variances are equal. The formula becomes: <span class="math display">\[
\bar{x} - \bar{y} \pm t_{\nu, \alpha/2} \cdot \sqrt{ s_p^2 \left( \frac{1}{n_x} + \frac{1}{n_y} \right) }
\]</span> where the degrees of freedom are: <span class="math display">\[
\nu = (n_x-1) + (n_y-1) = n_x + n_y - 2
\]</span></p>
</section><section id="c-population-variances-unknown-and-not-assumed-equal-welchs-t-test" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="c-population-variances-unknown-and-not-assumed-equal-welchs-t-test">c) Population Variances Unknown and Not Assumed Equal (Welch’s t-test)</h4>
<p>Here, we cannot assume equal variance, we rely on the so called <strong>Welch’s method</strong>, which is an adaptation of the standard two-sample <span class="math inline">\(t\)</span>-test that does <strong>not</strong> assume equal population variances. It is more flexible and robust, especially when sample sizes or variances differ between groups. Instead of pooling the variances, Welch’s method uses the individual sample variances to compute the standard error and an approximate degrees of freedom, denoted <span class="math inline">\(\nu\)</span>. The confidence interval is thus given by:</p>
<p><span class="math display">\[
\bar{x} - \bar{y} \pm t_{\nu, \alpha/2} \cdot \sqrt{ \frac{s_x^2}{n_x} + \frac{s_y^2}{n_y} }
\]</span> with degrees of freedom approximated by: <span class="math display">\[
\nu \approx \frac{ \left( \frac{s_x^2}{n_x} + \frac{s_y^2}{n_y} \right)^2 }{ \frac{(s_x^2 / n_x)^2}{n_x - 1} + \frac{(s_y^2 / n_y)^2}{n_y - 1} }
\]</span> This method is more robust and does not assume equal population variances, making it the preferred choice in most small-sample scenarios with unequal spread.</p>
<p>The different cases are summarized in <a href="#tbl-diffmean-cfi" class="quarto-xref">Table&nbsp;<span>21.3</span></a>.</p>
<div id="tbl-diffmean-cfi" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-diffmean-cfi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;21.3: Confidence interval formulas for the difference between two means given different sample sizes and under different variance assumptions.
</figcaption><div aria-describedby="tbl-diffmean-cfi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 61%">
<col style="width: 11%">
<col style="width: 9%">
<col style="width: 17%">
</colgroup>
<thead><tr class="header">
<th>Sample Size &amp; Variance Assumptions</th>
<th>Distribution</th>
<th>Degrees of Freedom (<span class="math inline">\(\nu\)</span>)</th>
<th>Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<span class="math inline">\(n_x, n_y \geq 30\)</span>, <span class="math inline">\(\sigma_x, \sigma_y\)</span> known</td>
<td>Standard normal <span class="math inline">\(Z\)</span>
</td>
<td></td>
<td><span class="math inline">\(\bar{x} - \bar{y} \pm z_{\alpha/2} \cdot \sqrt{ \frac{\sigma_x^2}{n_x} + \frac{\sigma_y^2}{n_y} }\)</span></td>
</tr>
<tr class="even">
<td>
<span class="math inline">\(n_x, n_y \geq 30\)</span>, <span class="math inline">\(\sigma_x, \sigma_y\)</span> unknown</td>
<td>Standard normal <span class="math inline">\(Z\)</span>
</td>
<td></td>
<td><span class="math inline">\(\bar{x} - \bar{y} \pm z_{\alpha/2} \cdot \sqrt{ \frac{s_x^2}{n_x} + \frac{s_y^2}{n_y} }\)</span></td>
</tr>
<tr class="odd">
<td>
<span class="math inline">\(n_x, n_y &lt; 30\)</span>, <span class="math inline">\(s_x = s_y\)</span>
</td>
<td>Pooled <span class="math inline">\(t\)</span>-distribution</td>
<td><span class="math inline">\(n_x + n_y - 2\)</span></td>
<td><span class="math inline">\(\bar{x} - \bar{y} \pm t_{\nu, \alpha/2} \cdot \sqrt{ s_p^2 \left( \frac{1}{n_x} + \frac{1}{n_y} \right) }\)</span></td>
</tr>
<tr class="even">
<td>
<span class="math inline">\(n_x, n_y &lt; 30\)</span>, <span class="math inline">\(s_x \neq s_y\)</span>
</td>
<td>Welch’s <span class="math inline">\(t\)</span>-distribution</td>
<td><span class="math inline">\(\displaystyle \frac{\left( \frac{s_x^2}{n_x} + \frac{s_y^2}{n_y} \right)^2}{\frac{(s_x^2 / n_x)^2}{n_x - 1} + \frac{(s_y^2 / n_y)^2}{n_y - 1}}\)</span></td>
<td><span class="math inline">\(\bar{x} - \bar{y} \pm t_{\nu, \alpha/2} \cdot \sqrt{ \frac{s_x^2}{n_x} + \frac{s_y^2}{n_y} }\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section><section id="example-21.4-confidence-interval-for-the-difference-in-means" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="example-21.4-confidence-interval-for-the-difference-in-means">Example 21.4: Confidence Interval for the Difference in Means</h4>
<p>Two independent samples were taken from two different populations:</p>
<ul>
<li>Sample 1: <span class="math inline">\(n_x = 51\)</span>, <span class="math inline">\(\bar{x} = 14.3\)</span>, <span class="math inline">\(s_x = 3.18\)</span>
</li>
<li>Sample 2: <span class="math inline">\(n_y = 52\)</span>, <span class="math inline">\(\bar{y} = 12.6\)</span>, <span class="math inline">\(s_y = 3.5\)</span>
</li>
</ul>
<p>Construct a 95% confidence interval for the difference in population means, <span class="math inline">\(\mu_x - \mu_y\)</span>.</p>
<p>Since both sample sizes are greater than 30, and population variances are unknown, we can use the <strong>standard normal approximation</strong> with sample variances substituted in. That is, we use the formula: <span class="math display">\[
\bar{x} - \bar{y} \pm z_{\alpha/2} \cdot \sqrt{ \frac{s_x^2}{n_x} + \frac{s_y^2}{n_y} }
\]</span></p>
<p>where <span class="math inline">\(z_{0.025} = 1.96\)</span> for a 95% confidence level. We plug in the values: <span class="math display">\[
\bar{x} - \bar{y} = 14.3 - 12.6 = 1.7
\]</span> <span class="math display">\[
\begin{split}
\text{Standard error} &amp; = \sqrt{ \frac{3.18^2}{51} + \frac{3.5^2}{52} } \\ &amp; \approx \sqrt{ \frac{10.1124}{51} + \frac{12.25}{52} }  \\ &amp; \approx \sqrt{0.1983 + 0.2356}  \\ &amp; \approx \sqrt{0.4339} \\ &amp; \approx 0.6588
\end{split}
\]</span> and calculate the margin of error as: <span class="math display">\[
1.96 \cdot 0.6588 \approx 1.29
\]</span> So the confidence interval is: <span class="math display">\[
1.7 \pm 1.29 = [0.41, 2.99]
\]</span></p>
</section><section id="example-21.5-confidence-interval-for-the-difference-in-means" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="example-21.5-confidence-interval-for-the-difference-in-means">Example 21.5: Confidence Interval for the Difference in Means</h4>
<p>We are given two independent random samples from normally distributed populations with <strong>equal but unknown variances</strong>:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 24%">
<col style="width: 17%">
<col style="width: 32%">
</colgroup>
<thead><tr class="header">
<th>Group</th>
<th>Sample Size</th>
<th>Mean</th>
<th>Standard Deviation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Population 1</td>
<td><span class="math inline">\(n_x = 11\)</span></td>
<td><span class="math inline">\(\bar{x} = 1.23\)</span></td>
<td>
<span class="math inline">\(s_{x}\)</span> = <span class="math inline">\(0.23\)</span>
</td>
</tr>
<tr class="even">
<td>Population 2</td>
<td><span class="math inline">\(n_y =13\)</span></td>
<td><span class="math inline">\(\bar{y} = 1.18\)</span></td>
<td><span class="math inline">\(s_y= 0.27\)</span></td>
</tr>
</tbody>
</table>
<p>We are to compute a 95% confidence interval for the difference in population means: <span class="math inline">\(\mu_x - \mu_y\)</span>.</p>
<p>Since <span class="math inline">\(n_x = 11\)</span> and <span class="math inline">\(n_y = 13\)</span> are both less than 30, and the population variances are assumed equal but unknown, we use the pooled <span class="math inline">\(t\)</span>-distribution approach. The formula to use is the following: <span class="math display">\[
\bar{x} - \bar{y} \pm t_{\nu, \alpha/2} \cdot \sqrt{ s_p^2 \left( \frac{1}{n_x} + \frac{1}{n_y} \right) }
\]</span></p>
<p>The pooled sample variance <span class="math inline">\(s_p^2\)</span> is computed as: <span class="math display">\[
s_p^2 = \frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}
= \frac{(10)(0.23^2) + (12)(0.27^2)}{22} = 0.0638
\]</span> and the degrees of freedom are given by <span class="math display">\[
\nu = n_x + n_y - 2 = 11 + 13 - 2 = 22
\]</span> At the 95% confidence level we have that (<a href="../appendix/t-table.html" class="quarto-xref"><span>Appendix B</span></a>): <span class="math display">\[
t_{22,\ 0.025} = 2.074
\]</span> We substitute values in the formula above: <span class="math display">\[\begin{split}
0.05 \pm 2.074 \cdot \sqrt{0.0638 \left( \frac{1}{11} + \frac{1}{13} \right)}
&amp; = 0.05 \pm 2.074 \cdot \sqrt{0.0638 \cdot 0.1709}
\\ &amp; = 0.05 \pm 2.074 \cdot 0.1045
\\ &amp;\approx 0.05 \pm 0.217
\end{split}
\]</span> So the 95% confidence interval is: <span class="math display">\[
[-0.167,\ 0.267]
\]</span> The 95% confidence interval for the difference in population means is <span class="math inline">\([-0.167,\ 0.267]\)</span>. This means we are 95% confident that the true difference <span class="math inline">\(\mu_x - \mu_y\)</span> lies somewhere between <span class="math inline">\(-0.167\)</span> and <span class="math inline">\(0.267\)</span>. Since this interval includes values both below and above zero, the observed difference in sample means may be due to sampling variability rather than a clear difference between the populations.</p>
</section><section id="case-2-paired-samples" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="case-2-paired-samples">Case 2: Paired Samples</h4>
<p>The second case for two group comparisons, is when we have a single sample from a population, but we take two measurements on each individual in the sample. This means we no longer have two independent samples, but instead we have <strong>paired observations</strong>.</p>
<p><strong>Paired data</strong>, that is, two measurements taken on the same individuals or on matched units is different from having two independent samples. Examples include:</p>
<ul>
<li>Measuring blood pressure <em>before and after</em> a treatment on the same patient.</li>
<li>Comparing performance on <em>two tests</em> taken by the same student.</li>
<li>Testing two teaching methods on <em>the same group of students</em>. Because the observations are <strong>not independent</strong>, we must take the dependency into account.</li>
</ul>
<p>As before, we are interested in constructing a confidence interval for the difference in means based on these paired data. Instead of comparing two separate means though, we analyze the <strong>difference within each pair</strong> defined as: <span class="math display">\[
d_i = x_i - y_i
\]</span> Now let:</p>
<ul>
<li>
<span class="math inline">\(\bar{d}\)</span> be the mean of the differences,<br>
</li>
<li>
<span class="math inline">\(s_d\)</span> the standard deviation of the differences,<br>
</li>
<li>
<span class="math inline">\(n\)</span> the number of pairs. Then, the confidence interval for the <strong>mean difference</strong> <span class="math inline">\(\mu_d\)</span> is: <span class="math display">\[
\bar{d} \pm t_{n - 1, \alpha/2} \cdot \frac{s_d}{\sqrt{n}}
\]</span>
</li>
</ul>
<p>This formula is based on the <strong>one-sample <span class="math inline">\(t\)</span>-distribution</strong> with <span class="math inline">\(n - 1\)</span> degrees of freedom.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
When to Use This Method
</div>
</div>
<div class="callout-body-container callout-body">
<p>Use the paired <span class="math inline">\(t\)</span>-method when:</p>
<ul>
<li>The <strong>same subject</strong> is measured twice (e.g., before and after),</li>
<li>The data is <strong>naturally paired</strong> (e.g., matched cases),</li>
<li>The <strong>differences <span class="math inline">\(d_i\)</span></strong> are approximately normally distributed.</li>
</ul>
</div>
</div>
<p>Suppose we are studying the effect of a blood pressure treatment. For each individual in our sample, we measure blood pressure <strong>before</strong> and <strong>after</strong> treatment as shown in the table below:</p>
<table class="caption-top table">
<thead><tr class="header">
<th>Individual</th>
<th>After (<span class="math inline">\(x\)</span>)</th>
<th>Before (<span class="math inline">\(y\)</span>)</th>
<th>Difference (<span class="math inline">\(d = x - y\)</span>)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(x_1\)</span></td>
<td><span class="math inline">\(y_1\)</span></td>
<td><span class="math inline">\(d_1 = x_1 - y_1\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td><span class="math inline">\(x_2\)</span></td>
<td><span class="math inline">\(y_2\)</span></td>
<td><span class="math inline">\(d_2 = x_2 - y_2\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(x_n\)</span></td>
<td><span class="math inline">\(y_n\)</span></td>
<td><span class="math inline">\(d_n = x_n - y_n\)</span></td>
</tr>
</tbody>
</table>
<p>These <span class="math inline">\(d_1, d_2, \dots, d_n\)</span> form a sample from a population of differences with population mean <span class="math inline">\(\mu_d\)</span> and variance <span class="math inline">\(\sigma_d^2\)</span>. We estimate the population mean difference <span class="math inline">\(\mu_d\)</span> using the sample mean of the differences: <span class="math display">\[
\bar{d} = \frac{1}{n} \sum_{i=1}^n d_i
\]</span> This is an unbiased estimator, since: <span class="math display">\[
E(\bar{d}) = \mu_d \quad \text{and} \quad \text{Var}(\bar{d}) = \frac{\sigma_d^2}{n}
\]</span> The sample variance of the differences is: <span class="math display">\[
s_d^2 = \frac{1}{n - 1} \sum_{i=1}^n (d_i - \bar{d})^2
\]</span> and the estimated standard error is: <span class="math display">\[
\text{SE} = \frac{s_d}{\sqrt{n}}
\]</span></p>
<p>There are (again) two scenarios for constructing a confidence interval:</p>
<ul>
<li><p><strong>Large sample siez</strong> (that is <span class="math inline">\(n\geq 30\)</span>)<br>
When the sample size is large (regardless of the population distribution), the confidence interval is based on the standard normal distribution: <span class="math display">\[
\bar{d} \pm z_{\alpha/2} \cdot \frac{s_d}{\sqrt{n}}
\]</span></p></li>
<li><p><strong>Small sample size and population of differences is normally distributed</strong><br>
When <span class="math inline">\(n &lt; 30\)</span> and we assume normality, we use the <span class="math inline">\(t\)</span>-distribution so the confeidence interval is given by: <span class="math display">\[
\bar{d} \pm t_{\nu,\alpha/2} \cdot \frac{s_d}{\sqrt{n}}, \quad \nu = n - 1
\]</span></p></li>
</ul>
<blockquote class="blockquote">
<p>Note: In both cases, we assume the population variance <span class="math inline">\(\sigma_d^2\)</span> is unknown, which is typically the case in practice.</p>
</blockquote>
<p>The different scenarios are summarized in <a href="#tbl-paired-cfi" class="quarto-xref">Table&nbsp;<span>21.4</span></a>.</p>
<div id="tbl-paired-cfi" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-paired-cfi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;21.4: Confidence interval formulas for paired-sample mean differences, depending on sample size and assumptions about the distribution of the population differences.
</figcaption><div aria-describedby="tbl-paired-cfi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 53%">
<col style="width: 19%">
<col style="width: 26%">
</colgroup>
<thead><tr class="header">
<th>Conditions</th>
<th>Variance Assumptions</th>
<th>Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<span class="math inline">\(n \geq 30\)</span>, any population distribution</td>
<td>
<span class="math inline">\(\sigma_d^2\)</span> known</td>
<td><span class="math inline">\(\bar{d} \pm z_{\alpha/2} \left( \frac{\sigma_d}{\sqrt{n}} \right)\)</span></td>
</tr>
<tr class="even">
<td></td>
<td>
<span class="math inline">\(\sigma_d^2\)</span> unknown</td>
<td><span class="math inline">\(\bar{d} \pm z_{\alpha/2} \left( \frac{s_d}{\sqrt{n}} \right)\)</span></td>
</tr>
<tr class="odd">
<td>
<span class="math inline">\(n &lt; 30\)</span>, population of differences is normal</td>
<td>
<span class="math inline">\(\sigma_d^2\)</span> known</td>
<td><span class="math inline">\(\bar{d} \pm z_{\alpha/2} \left( \frac{\sigma_d}{\sqrt{n}} \right)\)</span></td>
</tr>
<tr class="even">
<td></td>
<td>
<span class="math inline">\(\sigma_d^2\)</span> unknown</td>
<td><span class="math inline">\(\bar{d} \pm t_{\nu,\alpha/2} \left( \frac{s_d}{\sqrt{n}} \right)\)</span></td>
</tr>
<tr class="odd">
<td>
<span class="math inline">\(n &lt; 30\)</span>, population of differences is not normal</td>
<td>—</td>
<td>Confidence interval cannot be calculated</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section><section id="example-21.6-confidence-interval-for-paired-differences" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="example-21.6-confidence-interval-for-paired-differences">Example 21.6: Confidence Interval for Paired Differences</h4>
<p>We have a sample of 6 workers from a normally distributed population. Each worker performs the same task using Method A and Method B, and the time taken in minutes is recorded for both methods:</p>
<ul>
<li>
<span class="math inline">\(X\)</span> = time using Method A<br>
</li>
<li>
<span class="math inline">\(Y\)</span> = time using Method B</li>
</ul>
<p>We are to compute a 95% confidence interval for the average difference in time (Method A − Method B).</p>
<p>Let <span class="math inline">\(d = x - y\)</span> be the difference for each individual:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 19%">
<col style="width: 23%">
<col style="width: 27%">
</colgroup>
<thead><tr class="header">
<th>Person</th>
<th><span class="math inline">\(x\)</span></th>
<th><span class="math inline">\(y\)</span></th>
<th><span class="math inline">\(d = x - y\)</span></th>
<th><span class="math inline">\(d - \bar{d}\)</span></th>
<th><span class="math inline">\((d - \bar{d})^2\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>6.0</td>
<td>5.4</td>
<td>0.6</td>
<td>0.3</td>
<td>0.09</td>
</tr>
<tr class="even">
<td>2</td>
<td>5.0</td>
<td>5.2</td>
<td>-0.2</td>
<td>-0.5</td>
<td>0.25</td>
</tr>
<tr class="odd">
<td>3</td>
<td>7.0</td>
<td>6.5</td>
<td>0.5</td>
<td>0.2</td>
<td>0.04</td>
</tr>
<tr class="even">
<td>4</td>
<td>6.2</td>
<td>5.9</td>
<td>0.3</td>
<td>0.0</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td>5</td>
<td>6.0</td>
<td>6.0</td>
<td>0.0</td>
<td>-0.3</td>
<td>0.09</td>
</tr>
<tr class="even">
<td>6</td>
<td>6.4</td>
<td>5.8</td>
<td>0.6</td>
<td>0.3</td>
<td>0.09</td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td></td>
<td></td>
<td><strong>1.8</strong></td>
<td></td>
<td><strong>0.56</strong></td>
</tr>
</tbody>
</table>
<p>Now we can compute the sample statistics:</p>
<ul>
<li>Mean difference: <span class="math inline">\(\bar{d} = \frac{1.8}{6} = 0.3\)</span><br>
</li>
<li>Variance: <span class="math inline">\(s_d^2 = \frac{0.56}{5} = 0.112\)</span><br>
</li>
<li>Standard deviation: <span class="math inline">\(s_d = \sqrt{0.112} = 0.335\)</span>
</li>
</ul>
<p>We note that <span class="math inline">\(n &lt; 30\)</span>, <span class="math inline">\(\sigma^2\)</span> is unknown, and we have a normally distributed population. Therefore, a 95% confidence interval for <span class="math inline">\(\mu_d\)</span> is calculated as follows: <span class="math display">\[
\bar{d} \pm t_{\nu, \alpha/2} \cdot \frac{s_d}{\sqrt{n}}
\]</span> Since <span class="math inline">\(n = 6\)</span>, degrees of freedom <span class="math inline">\(\nu = 5\)</span>, and <span class="math inline">\(\alpha = 0.025\)</span>, we use (see <a href="../appendix/t-table.html" class="quarto-xref"><span>Appendix B</span></a>): <span class="math display">\[
t_{5, 0.025} = 2.571
\]</span> Substitute values in the confidence interval formula: <span class="math display">\[
0.3 \pm 2.571 \cdot \frac{0.335}{\sqrt{6}} = 0.3 \pm 0.35
\]</span> So the 95% confidence interval is: <span class="math display">\[
[-0.05,\ 0.65]
\]</span> Since the interval includes 0, we cannot rule out that the two methods are equally effective. With 95% confidence, the average difference in time could be zero.</p>
</section></section><section id="confidence-intervals-for-differences-in-population-proportions" class="level3" data-number="21.4.4"><h3 data-number="21.4.4" class="anchored" data-anchor-id="confidence-intervals-for-differences-in-population-proportions">
<span class="header-section-number">21.4.4</span> Confidence Intervals for Differences in Population Proportions</h3>
<p>When comparing two independent populations on a binary outcome (such as success/failure), we are often interested in estimating the difference between their population proportions, <span class="math inline">\(p_x - p_y\)</span>. If both <strong>samples are large</strong> enough, we can use the normal approximation to construct a confidence interval for this difference:</p>
<p><span class="math display">\[
(\hat{p}_x - \hat{p}_y) \pm z_{\alpha/2} \cdot \sqrt{ \frac{\hat{p}_x (1 - \hat{p}_x)}{n_x} + \frac{\hat{p}_y (1 - \hat{p}_y)}{n_y} }
\]</span></p>
<p>This interval provides a plausible range of values for the true difference between the proportions in the two populations. If the confidence interval includes zero, it suggests that the observed difference might be due to random sampling variability, and there may be no real difference between the groups.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Small Sample Sizes:</strong> If either sample is small, specifically, if <span class="math inline">\(n \cdot \hat{p} &lt; 5\)</span> or <span class="math inline">\(n \cdot (1 - \hat{p}) &lt; 5\)</span>, the normal approximation may not be appropriate.</p>
</div>
</div>
<section id="example-21.7-confidence-interval-for-the-difference-between-two-proportions" class="level4 unnumbered"><h4 class="unnumbered anchored" data-anchor-id="example-21.7-confidence-interval-for-the-difference-between-two-proportions">Example 21.7: Confidence Interval for the Difference Between Two Proportions</h4>
<p>We want to estimate the difference in support for a political party between two populations.</p>
<ul>
<li>Let <span class="math inline">\(p_x\)</span> = proportion in population 1 who support the party<br>
</li>
<li>Let <span class="math inline">\(p_y\)</span> = proportion in population 2 who support the party</li>
</ul>
<p>We take a simple random sample of:</p>
<ul>
<li>
<span class="math inline">\(n_x = 150\)</span> from population 1, with <span class="math inline">\(\hat{p}_x = 0.36\)</span><br>
</li>
<li>
<span class="math inline">\(n_y = 250\)</span> from population 2, with <span class="math inline">\(\hat{p}_y = 0.27\)</span>
</li>
</ul>
<p>We are to construct a 95% confidence interval for <span class="math inline">\(p_x - p_y\)</span>. Since the sample sizes are large, we use the <strong>standard normal approximation</strong> for the confidence interval: <span class="math display">\[
\hat{p}_x - \hat{p}_y \pm z_{\alpha/2} \cdot \sqrt{ \frac{ \hat{p}_x (1 - \hat{p}_x) }{n_x} + \frac{ \hat{p}_y (1 - \hat{p}_y) }{n_y} }
\]</span> With <span class="math inline">\(z_{\alpha/2} = z_{0.025} = 1.96\)</span>, we compute:</p>
<p><span class="math display">\[
0.36 - 0.27 \pm 1.96 \cdot \sqrt{ \frac{0.36(1 - 0.36)}{150} + \frac{0.27(1 - 0.27)}{250} }
\]</span> <span class="math display">\[
\begin{split} 0.09 \pm 1.96 \cdot \sqrt{ \frac{0.2304}{150} + \frac{0.1971}{250} }
&amp; = 0.09 \pm 1.96 \cdot \sqrt{0.001536 + 0.0007884}
\\ &amp; = 0.09 \pm 1.96 \cdot 0.0406
\\ &amp;= 0.09 \pm 0.0796
\end{split}
\]</span> So the 95% confidence interval is: <span class="math display">\[
[0.0104,\ 0.1696]
\]</span> We estimate that the difference in support between the two populations is between 1.0% and 17.0%, with population 1 showing more support. Since the entire interval is above 0, this suggests a real difference in proportions between the populations.</p>
</section></section></section><section id="exercises" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<ol type="1">
<li>A random sample of 120 families was drawn from a population of approximately 5000 families. The number of children in each selected family was recorded. The sample yielded <span class="math inline">\(\bar{x} = 1.28\)</span> (mean number of children) and <span class="math inline">\(s = 1.10\)</span> (sample standard deviation). Assuming the sample is drawn using simple random sampling, calculate a 99% confidence interval for the population mean <span class="math inline">\(\mu\)</span>, the average number of children per family.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We are given:</p>
<ul>
<li><span class="math inline">\(\bar{x} = 1.28\)</span></li>
<li><span class="math inline">\(s = 1.10\)</span></li>
<li><span class="math inline">\(n = 120\)</span></li>
<li>Confidence level: <span class="math inline">\(99\% \Rightarrow \alpha = 0.01 \Rightarrow \alpha/2 = 0.005\)</span>
</li>
<li>
<span class="math inline">\(z_{\alpha/2} = 2.58\)</span> (from the standard normal table)</li>
</ul>
<p>Since the sample is large (<span class="math inline">\(n = 120\)</span>), the Central Limit Theorem applies, and we can use the normal distribution.</p>
<p>The standard error is:</p>
<p><span class="math display">\[
SE = \frac{s}{\sqrt{n}} = \frac{1.10}{\sqrt{120}} \approx 0.1004
\]</span></p>
<p>Then the confidence interval is:</p>
<p><span class="math display">\[
\bar{x} \pm z_{\alpha/2} \cdot SE = 1.28 \pm 2.58 \cdot 0.1004 \approx 1.28 \pm 0.26
\]</span></p>
<p>Final interval:</p>
<p><span class="math display">\[
[1.02,\ 1.54]
\]</span></p>
<p>Interpretation: We are 99% confident that the true mean number of children per family in the population lies between 1.02 and 1.54.</p>
</div>
</div>
</div>
<ol start="2" type="1">
<li>In a small town with 8820 households, a sample of 200 households is taken. In the sample, 60 households have a smart home system installed. Construct a 95% confidence interval for the proportion of households in the entire town that have a smart home system.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We are given:</p>
<ul>
<li><span class="math inline">\(n = 200\)</span></li>
<li><span class="math inline">\(x = 60\)</span></li>
<li><span class="math inline">\(\hat{p} = \frac{60}{200} = 0.30\)</span></li>
<li>
<span class="math inline">\(z_{\alpha/2} = 1.96\)</span> for a 95% confidence level</li>
</ul>
<p>The standard error is calculated as:</p>
<p><span class="math display">\[
SE = \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}} = \sqrt{\frac{0.30(1 - 0.30)}{200}} = \sqrt{\frac{0.21}{200}} \approx 0.0324
\]</span></p>
<p>The confidence interval is:</p>
<p><span class="math display">\[
\hat{p} \pm z_{\alpha/2} \cdot SE = 0.30 \pm 1.96 \cdot 0.0324 \approx 0.30 \pm 0.0635
\]</span></p>
<p>So the 95% confidence interval is approximately:</p>
<p><span class="math display">\[
[0.24, 0.36]
\]</span></p>
<p>To interpret this in terms of number of households:</p>
<ul>
<li><span class="math inline">\(0.24 \cdot 8820 \approx 2117\)</span></li>
<li><span class="math inline">\(0.36 \cdot 8820 \approx 3175\)</span></li>
</ul>
<p>We can say, with 95% confidence, that roughly 2100 and 3200 households in the town have a smart home system installed.</p>
</div>
</div>
</div>
<ol start="3" type="1">
<li>A car manufacturer wants to compare the average fuel efficiency (in liters per 100 km) between two models of hybrid vehicles. Two random samples were taken:</li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 27%">
<col style="width: 17%">
<col style="width: 14%">
<col style="width: 41%">
</colgroup>
<thead><tr class="header">
<th>Model</th>
<th>Sample Size</th>
<th>Mean</th>
<th>Standard Deviation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Hybrid A</td>
<td>15</td>
<td><span class="math inline">\(4.8\)</span></td>
<td><span class="math inline">\(0.5\)</span></td>
</tr>
<tr class="even">
<td>Hybrid B</td>
<td>12</td>
<td><span class="math inline">\(5.1\)</span></td>
<td><span class="math inline">\(0.6\)</span></td>
</tr>
</tbody>
</table>
<p>Assume that fuel efficiency is normally distributed, and the population variances are equal but unknown. Construct a 95% confidence interval for the difference in mean fuel efficiency between the two models. What can you say about the results in terms of the difference in fuel efficiency?</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We use the <strong>pooled <span class="math inline">\(t\)</span>-distribution</strong> approach since sample sizes are small and equal variances are assumed. The pooled variance is given by: <span class="math display">\[
\begin{split}
s_p^2 = \frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}
&amp; = \frac{(14)(0.5^2) + (11)(0.6^2)}{25}
\\ &amp; = \frac{3.5 + 3.96}{25} \\ &amp; = 0.3384
\end{split}
\]</span> and we have degrees of freedom equal to <span class="math display">\[
\nu = n_x + n_y - 2 = 15 + 12 - 2 = 25
\]</span> yielding the critical <span class="math inline">\(t\)</span>-value <span class="math display">\[
t_{25,\ 0.025} = 2.060 .
\]</span></p>
<p>The 95% confidence interval to use is given by <span class="math display">\[
\bar{x} - \bar{y} \pm t_{\nu, \alpha/2} \cdot \sqrt{s_p^2 \left( \frac{1}{n_x} + \frac{1}{n_y} \right)}
\]</span> and with substituted values we get: <span class="math display">\[
\begin{split}
4.8 - 5.1 \pm 2.060 \cdot \sqrt{0.3384 \left( \frac{1}{15} + \frac{1}{12} \right)}
&amp; = -0.3 \pm 2.060 \cdot \sqrt{0.3384 \cdot 0.1528}
\\ &amp;= -0.3 \pm 2.060 \cdot 0.2273
\\ &amp;= -0.3 \pm 0.468
\end{split}
\]</span> <span class="math display">\[
\implies [-0.768,\ 0.168]
\]</span> Since this interval includes zero, the observed difference in sample means may be due to sampling variability rather than a clear difference between the two hybrid models.</p>
</div>
</div>
</div>
<ol start="3" type="1">
<li>A pedagogical study aimed to compare the learning abilities of two age groups of children. Large random samples were taken from each population. The goal is to estimate the difference in mean learning ability using a 99% confidence interval. The sample summary is shown below:</li>
</ol>
<table class="caption-top table">
<thead><tr class="header">
<th>Group</th>
<th>Sample Size</th>
<th>Mean</th>
<th>Standard Deviation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Group 1</td>
<td>89</td>
<td>42</td>
<td>6.1</td>
</tr>
<tr class="even">
<td>Group 2</td>
<td>73</td>
<td>30</td>
<td>4.5</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Since both samples are large and population variances are unknown, we use the <strong>standard normal <span class="math inline">\(z\)</span>-distribution</strong> with the formula:</p>
<p><span class="math display">\[
\bar{x} - \bar{y} \pm z_{\alpha/2} \cdot \sqrt{\frac{s_x^2}{n_x} + \frac{s_y^2}{n_y}}
\]</span> Given from sample data is the following:</p>
<ul>
<li>
<span class="math inline">\(\bar{x} = 42\)</span>, <span class="math inline">\(s_x = 6.1\)</span>, <span class="math inline">\(n_x = 89\)</span><br>
</li>
<li>
<span class="math inline">\(\bar{y} = 30\)</span>, <span class="math inline">\(s_y = 4.5\)</span>, <span class="math inline">\(n_y = 73\)</span><br>
</li>
<li><span class="math inline">\(z_{\alpha/2} = z_{0.005} = 2.58\)</span></li>
</ul>
<p>We compute the sample statistics: <span class="math display">\[
\bar{x} - \bar{y} = 42 - 30 = 12
\]</span> <span class="math display">\[
SE = \sqrt{ \frac{6.1^2}{89} + \frac{4.5^2}{73} } = \sqrt{ \frac{37.21}{89} + \frac{20.25}{73} } \approx \sqrt{0.418 + 0.277} \approx \sqrt{0.695} \approx 0.834
\]</span> Next, we can compute the confidence interval <span class="math display">\[
12 \pm 2.58 \cdot 0.834 = 12 \pm 2.15
\]</span> So the <strong>99% confidence interval</strong> is: <span class="math display">\[
[9.85,\ 14.15]
\]</span> Since this interval does not include zero, we can conclude that there is likely a meaningful difference in learning ability between the two groups.</p>
</div>
</div>
</div>
<ol start="4" type="1">
<li>At a school, students were randomly divided into two groups for English instruction. Group 1 had access to a language laboratory, while Group 2 received only traditional classroom instruction. After the instruction was completed, the goal was to examine whether there was any difference in the effectiveness of the two teaching methods. To do this, a 90% confidence interval was constructed to estimate the difference in average language proficiency between the two groups (populations). A random sample of students from each group was selected to complete a standardized language test. The investigation yielded the following results:
<ul>
<li>Group 1: <span class="math inline">\(\bar{x} = 42.4\)</span>, <span class="math inline">\(s_x^2 = 66\)</span>, <span class="math inline">\(n_x = 10\)</span><br>
</li>
<li>Group 2: <span class="math inline">\(\bar{y} = 46.6\)</span>, <span class="math inline">\(s_y^2 = 54\)</span>, <span class="math inline">\(n_y = 12\)</span>
</li>
</ul>
Construct a 90% confidence interval for <span class="math inline">\(\mu_x - \mu_y\)</span>.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The assumptions are as follows:</p>
<ul>
<li>Two independent random samples<br>
</li>
<li>Small sample sizes (<span class="math inline">\(n_x = 10\)</span>, <span class="math inline">\(n_y = 12\)</span>)<br>
</li>
<li>Assume normal populations with equal variances</li>
</ul>
<p><span class="math inline">\(\implies\)</span> Unknown population variances, use <strong>pooled <span class="math inline">\(t\)</span>-distribution</strong></p>
<p>Compute the pooled variance: <span class="math display">\[
s_p^2 = \frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}
= \frac{(9)(66) + (11)(54)}{20} = 59.4
\]</span> The degrees of freedom are given by <span class="math display">\[
\nu = n_x + n_y - 2 = 10 + 12 - 2 = 20
\]</span> and the critical <span class="math inline">\(t\)</span> value for 90% confidence, <span class="math inline">\(\alpha = 0.10\)</span> and <span class="math inline">\(\alpha/2 = 0.05\)</span> is given by <span class="math display">\[
t_{20,\,0.05} = 1.725
\]</span></p>
<p>We can now compute the confidence interval: <span class="math display">\[
\bar{x} - \bar{y} \pm t_{\nu, \alpha/2} \cdot \sqrt{s_p^2 \left( \frac{1}{n_x} + \frac{1}{n_y} \right)}
= -4.2 \pm 1.725 \cdot \sqrt{59.4 \left( \frac{1}{10} + \frac{1}{12} \right)}
= -4.2 \pm 5.7
\]</span> <span class="math display">\[
\implies [-9.9,\ 1.5]
\]</span></p>
<p>Thus, we estimate that the average English knowledge in the lab group is between 9.9 points lower and 1.5 points higher than that of the traditional group. Since the interval includes zero, the observed difference could be due to random variation in the samples, and we cannot confidently say that one teaching method leads to higher average performance than the other.</p>
</div>
</div>
</div>
<ol start="5" type="1">
<li>A new medication is believed to reduce fever. To test its effect, researchers measured the body temperature of 8 patients <strong>before</strong> and <strong>one hour after</strong> taking the medication.</li>
</ol>
<table class="caption-top table">
<thead><tr class="header">
<th>Person</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Before (°C)</td>
<td>38.2</td>
<td>38.4</td>
<td>38.5</td>
<td>38.9</td>
<td>39.0</td>
<td>39.0</td>
<td>39.3</td>
<td>39.7</td>
</tr>
<tr class="even">
<td>After (°C)</td>
<td>37.2</td>
<td>37.2</td>
<td>38.8</td>
<td>38.1</td>
<td>38.2</td>
<td>39.6</td>
<td>38.2</td>
<td>38.6</td>
</tr>
</tbody>
</table>
<p>Construct a 95% confidence interval for the mean temperature reduction due to the medication.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This is a case of <strong>paired observations</strong> (before vs.&nbsp;after on the same individuals), so we compute the differences: <span class="math display">\[
d_i = \text{Before} - \text{After}
\]</span></p>
<table class="caption-top table">
<thead><tr class="header">
<th>Person</th>
<th><span class="math inline">\(d_i\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>2</td>
<td>1.2</td>
</tr>
<tr class="odd">
<td>3</td>
<td>-0.3</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.8</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.8</td>
</tr>
<tr class="even">
<td>6</td>
<td>-0.6</td>
</tr>
<tr class="odd">
<td>7</td>
<td>1.1</td>
</tr>
<tr class="even">
<td>8</td>
<td>1.1</td>
</tr>
</tbody>
</table>
<ul>
<li>Sample mean of differences: <span class="math inline">\(\bar{d} = 0.6375\)</span>
</li>
<li>Sample standard deviation: <span class="math inline">\(s_d = 0.6907\)</span>
</li>
<li>Sample size: <span class="math inline">\(n = 8\)</span>
</li>
<li>Degrees of freedom: <span class="math inline">\(\nu = 7\)</span>
</li>
<li>Critical <span class="math inline">\(t\)</span>-value at 95%: <span class="math inline">\(t_{7, 0.025} = 2.365\)</span>
</li>
</ul>
<p>The confidence interval is given by <span class="math display">\[
\bar{d} \pm t_{\nu, \alpha/2} \cdot \frac{s_d}{\sqrt{n}} = 0.6375 \pm 2.365 \cdot \frac{0.6907}{\sqrt{8}} \approx 0.6375 \pm 0.58
\]</span> So the 95% confidence interval is: <span class="math display">\[
[0.06,\ 1.21]
\]</span> We estimate that the medication reduces fever by between 0.06 and 1.21°C on average. Since the interval does not include 0, we have evidence that the medication is likely effective in lowering body temperature.</p>
</div>
</div>
</div>
<ol start="6" type="1">
<li>A survey is conducted to compare the support for a new vaccine in two regions. In region A, 120 out of 200 people support the vaccine. In region B, 135 out of 250 support it. Construct a 95% confidence interval for the difference in population proportions, <span class="math inline">\(p_A - p_B\)</span>.</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We are given:</p>
<ul>
<li><span class="math inline">\(\hat{p}_A = \frac{120}{200} = 0.60\)</span></li>
<li><span class="math inline">\(\hat{p}_B = \frac{135}{250} = 0.54\)</span></li>
<li><span class="math inline">\(n_A = 200,\quad n_B = 250\)</span></li>
<li>
<span class="math inline">\(z_{\alpha/2} = 1.96\)</span> for 95% confidence We use the formula: <span class="math display">\[
\hat{p}_A - \hat{p}_B \pm z_{\alpha/2} \cdot \sqrt{ \frac{ \hat{p}_A (1 - \hat{p}_A) }{n_A} + \frac{ \hat{p}_B (1 - \hat{p}_B) }{n_B} }
\]</span> Substitute: <span class="math display">\[
0.60 - 0.54 \pm 1.96 \cdot \sqrt{ \frac{0.60 \cdot 0.40}{200} + \frac{0.54 \cdot 0.46}{250} }
\]</span> <span class="math display">\[ \begin{split}
&amp; = 0.06 \pm 1.96 \cdot \sqrt{0.0012 + 0.0009936}
\\ &amp; = 0.06 \pm 1.96 \cdot \sqrt{0.0021936}
\\ &amp;= 0.06 \pm 1.96 \cdot 0.0468
\\ &amp;= 0.06 \pm 0.0917
\end{split}
\]</span> So the 95% confidence interval is: <span class="math display">\[
[-0.0317,\ 0.1517]
\]</span> The interval ranges from approximately −3.2% to 15.2%. Since the interval includes 0, we cannot conclude that there is a meaningful difference in vaccine support between the two regions based on this sample.</li>
</ul>
</div>
</div>
</div>
<ol start="7" type="1">
<li>A university wants to compare the average weekly study hours between psychology and engineering students. Random samples yield the following results:</li>
</ol>
<ul>
<li>
<strong>Psychology</strong>: <span class="math inline">\(n_1 = 18\)</span>, <span class="math inline">\(\bar{x}_1 = 24.3\)</span>, <span class="math inline">\(s_1 = 4.1\)</span>
</li>
<li>
<strong>Engineering</strong>: <span class="math inline">\(n_2 = 16\)</span>, <span class="math inline">\(\bar{x}_2 = 27.8\)</span>, <span class="math inline">\(s_2 = 5.6\)</span>
</li>
</ul>
<p>Construct a 95% confidence interval for the difference in mean study hours, assuming the <strong>population variances are not equal</strong>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We use <strong>Welch’s t-interval</strong> for independent samples with unequal variances. The point estimate for the difference in means is given by <span class="math display">\[
\bar{x}_1 - \bar{x}_2 = 24.3 - 27.8 = -3.5
\]</span> and the standard error is given by <span class="math display">\[
\begin{split}SE &amp; = \sqrt{ \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} }
\\ &amp;= \sqrt{ \frac{4.1^2}{18} + \frac{5.6^2}{16} }
\\ &amp;= \sqrt{ \frac{16.81}{18} + \frac{31.36}{16} }
\\ &amp; = \sqrt{0.934 + 1.96} = \sqrt{2.894} \approx 1.702
\end{split}
\]</span></p>
<p>We find the correct degrees of freedom using Welch-Satterthwaite approximation: <span class="math display">\[
\nu \approx \frac{ \left( \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} \right)^2 }
{ \frac{ \left( \frac{s_1^2}{n_1} \right)^2 }{n_1 - 1} + \frac{ \left( \frac{s_2^2}{n_2} \right)^2 }{n_2 - 1} }
= \frac{(0.934 + 1.96)^2}{\frac{0.934^2}{17} + \frac{1.96^2}{15}} \approx \frac{8.38}{0.0513 + 0.256} \approx 25.1
\]</span> Thus, we use <span class="math inline">\(t_{25} \approx 2.060\)</span> for 95% confidence. The confidence interval is then given by <span class="math display">\[
-3.5 \pm 2.060 \cdot 1.702 = -3.5 \pm 3.508
\implies [-7.01,\ 0.01]
\]</span> The 95% confidence interval for the difference in study hours ranges from −7.01 to 0.01 hours. Since the interval includes zero, we cannot conclude that there is a difference in average study hours between the two majors.</p>
</div>
</div>
</div>


</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/termehs\.github\.io\/found-stats\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../inferential/intro-inference.html" class="pagination-link" aria-label="From Probability to Statistical Inference">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">From Probability to Statistical Inference</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../inferential/hyp-test.html" class="pagination-link" aria-label="Hypothesis Testing">
        <span class="nav-page-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Foundational Statistics by Termeh Shafie.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/termehs/found-stats/edit/main/inferential/estimation.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/termehs/found-stats/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>