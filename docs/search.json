[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Foundational Statistics",
    "section": "",
    "text": "Welcome\nThis book is work in progress.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "introduction/what-is-stats.html",
    "href": "introduction/what-is-stats.html",
    "title": "1¬† What is Statistics?",
    "section": "",
    "text": "1.1 Descriptive Statistics\nStatistics is all about making informed decisions in an uncertain world. Imagine you‚Äôre a detective piecing together clues (data) to solve a case (hypothesis testing). But instead of clear-cut evidence, you get noisy, incomplete, and sometimes misleading information.\nAt its core, statistics is the science of changing your mind under uncertainty‚Äî not because you‚Äôre indecisive, but because data has the power to prove you wrong! Making decisions without data is like guessing the weather based on your mood. Data helps us navigate randomness, update our beliefs, and make smarter choices based on evidence rather than gut feeling. You‚Äôre basically saying, we don‚Äôt know everything, but let‚Äôs make the best of what we‚Äôve got.\nUsing statistical terminology (in parenthesis) we can sunmmarize as following: Making decisions based on facts means having information about all the facts (parameters) . But most of the time we don‚Äôt have all the information, and what we know comes (sample) is often different than what we wish we knew (population). So we guess (estimate) under uncertainty.\nThe uncertainty comes from the fact that the world is messy, unpredictable, and full of unknowns. No data is perfect, randomness exist everywhere. Further to this, even if we collect tons of data, there‚Äôs always some level of error. Instead of making absolute claims, statistics helps us express how confident we are in our conclusions using quantified uncertainty. Just remember that there is no magic formula that turns uncertainty into certainty, we cannot escape it!\nStatistics has two main branches, descriptive statistics and inferential statistics, each tackling uncertainty differently.\nThis is like taking a selfie of your data. It summarizes and reports what‚Äôs there, showing us things like averages, spreads, and patterns. Think of it as data gossip ‚Äî who‚Äôs the biggest, smallest, most popular, or way off in the corner doing their own thing (yes, outliers, I‚Äôm looking at you!).\nFor example, a histogram or boxplot can reveal whether our data is skewed, normally distributed, or hiding some unexpected surprises. Without descriptive analysis, we risk making assumptions that could lead to misleading conclusions‚Äîkind of like blindly trusting a GPS without checking if the road exists!",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>What is Statistics?</span>"
    ]
  },
  {
    "objectID": "introduction/what-is-stats.html#inferential-statistics",
    "href": "introduction/what-is-stats.html#inferential-statistics",
    "title": "1¬† What is Statistics?",
    "section": "1.2 Inferential Statistics",
    "text": "1.2 Inferential Statistics\nInstead of just describing what we see, we here aim to gain insight or make predictions about the big picture based on a small sample. It‚Äôs like tasting one donut from the box and guessing if the whole batch is good üç©.\nConsider you have a hypothesis you wish to test (alternative hypothesis). Using data collected, you express the rules of the game through probabilities, distributions, and statistical models. This helps create a ‚Äútoy model‚Äù of the world based on your hypothesis. The null hypothesis is then the ‚Äúdefault world,‚Äù and your working hypothesis is literally everything else. You pretend you know how things work, and then check if reality agrees with you (hypothesis testing). Then you ask the big question: Does our data make the null hypothesis look completely ridiculous? If yes, we might just reject it and revise the null world accordingly.\nStatistics isn‚Äôt about finding the ultimate truth, but about making the best possible decisions with the information available. We estimate, test, and adjust‚Äîbecause in the end, being less wrong is the best we can do. In the words of the famous statistician George Box: ‚ÄúAll models are wrong, but some are useful‚Äù.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>What is Statistics?</span>"
    ]
  },
  {
    "objectID": "introduction/what-is-stats.html#statistical-analysis-the-process",
    "href": "introduction/what-is-stats.html#statistical-analysis-the-process",
    "title": "1¬† What is Statistics?",
    "section": "1.3 Statistical Analysis: The Process",
    "text": "1.3 Statistical Analysis: The Process\nThe diagram in Figure¬†1.1 represents the pipeline of statistical analysis, outlining the key steps in drawing insights from data:\n\nData Collection ‚Äì A sample is selected from the population to be used for the analysis and posed research questions.\nDescriptive Statistics ‚Äì The sample is analyzed to summarize patterns and trends.\nProbability Modeling ‚Äì Statistical methods establish connections between the sample and population.\nInference ‚Äì Findings from the sample are generalized to make conclusions about the population.\n\n\n\n\n\n\n\n\nFigure¬†1.1: The main branches of Statistics, together with associations between them.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>What is Statistics?</span>"
    ]
  },
  {
    "objectID": "introduction/intro-math.html",
    "href": "introduction/intro-math.html",
    "title": "2¬† The Unavoidable Math",
    "section": "",
    "text": "2.1 The Sum and The Product\nWhile some math concepts fall into the ‚Äúnice to know but not always necessary‚Äù category, others are inescapable. Whether you‚Äôre designing a survey, analyzing data, or just trying to make sense of numbers, a basic grasp of algebra, probability, and statistics is essential. Understanding fractions, percentages, and averages helps interpret results, while probability is crucial for assessing uncertainty and making predictions. Basic algebra sneaks in when solving equations or working with formulas, and statistical measures like mean, median, and standard deviation provide insight into data patterns. Even if math isn‚Äôt your favorite subject, these core concepts will save you from misinterpretations, bad decisions, and the embarrassment of wildly inaccurate estimates. So, let‚Äôs tackle the unavoidable math‚Äîquick, painless, and as useful as possible!\nWe write the sum of \\(n\\) numbers denoted \\(x_1,x_2,\\ldots,x_n\\) as \\[\\sum_{i=1}^n x_i = x_1 +x_2 + \\cdots + x_n \\] This is read as the sum of \\(x_i\\) where \\(i\\) goes from 1 to \\(n\\). The letter \\(i\\) is called the summation index and can be chosen to be any other letter.\nSimilarly, the product of \\(n\\) numbers denoted \\(x_1,x_2,\\ldots,x_n\\) is written as \\[\\prod_{i=1}^n x_i = x_1 \\times x_2 \\times  \\cdots \\times x_n \\].",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Unavoidable Math</span>"
    ]
  },
  {
    "objectID": "introduction/intro-math.html#the-sum-and-the-product",
    "href": "introduction/intro-math.html#the-sum-and-the-product",
    "title": "2¬† The Unavoidable Math",
    "section": "",
    "text": "2.1.1 Example\nAssume 5 values on \\(x\\) denoted \\(x_1,x_2,x_3,x_4,x_5\\). How can we write the sum of the squared difference of each of these values to their mean value \\(\\overline{x}\\)? \\[(x_1-\\overline{x})^2 + (x_2-\\overline{x})^2 + (x_3-\\overline{x})^2 + (x_4-\\overline{x})^2 + (x_1-\\overline{x})^5 \\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\sum_{i=1}^n (x_i-\\overline{x})^2\\]",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Unavoidable Math</span>"
    ]
  },
  {
    "objectID": "introduction/intro-math.html#combinatorics",
    "href": "introduction/intro-math.html#combinatorics",
    "title": "2¬† The Unavoidable Math",
    "section": "2.2 Combinatorics",
    "text": "2.2 Combinatorics\nThe next couple of mathematical concepts covered here are closely linked to the theory of probability which we will cover later in this book.\nCombinatorics studies different ways to count, arrange, and select objects. Essentially combinatorics helps answer questions like:\n\nIn how many ways can we arrange a set of items?\nIn how many ways can we select a group of objects?\n\nWhat are the possible ways to distribute objects into groups?\n\nThe following concepts help answer these questions.\n\n2.2.1 Counting Principles\nCombinatorics is built on two fundamental counting rules:\n\nMultiplication Principle: also known as The rule of product, is a basic counting principle. Assume that you have to perform \\(k\\) tasks in turn (one after the other). The first task can be performed in \\(n_1\\) different ways, the second in \\(n_2\\) different ways, etc. The number of possible ways to perform the \\(k\\) tasks in turn is given by \\[n_1 \\times n_2 \\times  \\cdots \\times n_k\\]\nAddition Principle: If we have mutually exclusive choices, the total number of ways they can happen is the sum of the ways each event can occur; \\(n_1 + n_2 \\cdots +  n_k\\).\n\n\nExamples\n\nIf a restaurant has 3 appetizers and 4 main courses, the total number of different meal combinations is:\n\\[3 \\times 4 = 12 \\]\nA person needs to travel from City A to City B and has the following options:\n\nBy Car: 3 different routes\n\nBy Train: 2 available train services\n\nBy Plane: 1 direct flight\nSince a person can only take one mode of transport, the number of ways to travel is: \\[3 + 2 + 1 = 6 \\]",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Unavoidable Math</span>"
    ]
  },
  {
    "objectID": "introduction/intro-math.html#permutations",
    "href": "introduction/intro-math.html#permutations",
    "title": "2¬† The Unavoidable Math",
    "section": "2.3 Permutations",
    "text": "2.3 Permutations\nPermutations refers to the mathematical calculation of the number of ways a particular set can be arranged, i.e.¬†order matters. An arrangement of \\(n\\) different objects in a specific order is called a permutation of the objects. The number of permutations that can be formed from \\(n\\) different objects is \\[n! = n\\cdot (n-1)\\cdot (n-2) \\cdots 2\\cdot 1 \\].\nIf we have \\(n\\) distinct objects and want to arrange \\(r\\) of them in a specific order, the number of ways to do so is given by the permutation formula:\n\\[ P(n,r) = \\frac{n!}{(n - r)!} \\]\nwhere:\n\n\\(n!\\) (n factorial) represents the total number of ways to arrange \\(n\\) items.\n\n\\((n - r)!\\) accounts for the unselected objects.\n\n\n\n\n\n\n\nNote\n\n\n\n\\[ 0!=1 \\]\n\n\n\nExample 2.1\nIn how many different ways can we permute the three objects \\(A\\), \\(B\\) and \\(C\\)? The asnwer is \\[3! = 3 \\cdot 2 \\cdot 1 = 6\\] namely: \\(ABC,\\  ACB, \\ BAC, \\ BCA,\\  CAB, \\ CBA\\)\n\n\n2.3.1 Combinations\nGenerally, a combination refers to a selection of objects where order does not matter. If we have \\(n\\) distinct objects and want to select \\(r\\) of them, the number of ways to do so is given by the combination formula:\n\\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n - r)!} \\]\nwhere:\n\n\\(n!\\) (read as n-factorial) represents the total number of ways to arrange \\(n\\) items.\n\n\\(r!\\) accounts for the fact that order does not matter.\n\n\\((n - r)!\\) accounts for the unselected objects.\n\n\nExample 2.2\nChoosing 3 students from a class of 10 for a group project means there are \\[ C(10,3) = \\frac{10!}{3!(10-3)!} = \\frac{10!}{3!7!} = \\frac{10 \\times 9 \\times 8}{3 \\times 2 \\times 1} = 120\\]\ndifferent combinations.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Unavoidable Math</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html",
    "href": "introduction/intro-surveys.html",
    "title": "3¬† Surveys: Key Concepts",
    "section": "",
    "text": "3.1 Census vs.¬†Sample Surveys\nSurveys are a fundamental method of gathering information in various fields, including business, social sciences, and policy making. They help us understand populations without needing to examine every individual within them.\nThe population refers to the complete set of elements (individuals, objects, or units) relevant to the study. The definition of a population can vary based on the research objective and can be finite (e.g., employees in a company) or infinite (e.g., potential customers in a market). A sample is a selected subset of the population. (inlcude figure)\nA census (or total survey) involves collecting data from every individual in a given population. This is common in national population counts but is often impractical for other types of research due to cost and time constraints. Instead, most studies rely on sample surveys which aim to generalize findings from the sample to the entire population with reasonable accuracy. The size of the sample (sample size) plays a crucial role in determining the reliability of the conclusions drawn.\nOne way to understand sampling is through the urn metaphor (Figure¬†3.1): Imagine an urn filled with different-colored balls representing different individuals in a population. Drawing balls at random with/without replacement simulates the process of selecting a sample from a population, emphasizing the role of randomness in reducing bias.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html#census-vs.-sample-surveys",
    "href": "introduction/intro-surveys.html#census-vs.-sample-surveys",
    "title": "3¬† Surveys: Key Concepts",
    "section": "",
    "text": "Figure¬†3.1: The urn metaphor.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html#characteristics-of-a-population",
    "href": "introduction/intro-surveys.html#characteristics-of-a-population",
    "title": "3¬† Surveys: Key Concepts",
    "section": "3.2 Characteristics of a Population",
    "text": "3.2 Characteristics of a Population\nEach individual in a population has measurable attributes, such as height, weight, income, or opinions. When measuring a particular characteristic, we can calculate various population metrics such as:\n\nMean (average), e.g., the average height of individuals in a population.\nProportion, e.g., the percentage of women in a population.\nTotal values, e.g., the total number of items owned by a group.\nCounts of specific attributes, e.g., the number of people with a particular qualification.\n\nThe main challenge in survey research is determining how accurately a sample represents the entire population. Statistical methods help estimate key characteristics of a population based on sample data.\nThese population characteristics are fixed parameters values which are usually unknown. Common parameters are the mean (\\(\\mu\\)) representing the true average of a characteristic in the population, or the proportion (\\(p\\)) representing the fraction of the population with a certain attribute.\nSince parameters cannot always be measured directly, they are estimated using sample statistics. For example, the sample mean (\\(\\bar{x}\\)) based on sampled observations \\(x_1,x_2,\\ldots, x_n\\) is used to estimate the population mean (\\(\\mu\\)). (include figure)\nTo distinguish between parameters and estimates, Greek letters are typically used for population parameters, while Latin letters are used for sample estimates. We will however avoid using already taken parameters, for example \\(\\pi\\) is not here used for population parameter as this already has a value assigned to it. In such cases we use the Latin letter to indicate the parameter and a ‚Äòhat‚Äô over the letter indicate the sample estimate (that is \\(\\hat{p}\\)).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html#types-of-surveys",
    "href": "introduction/intro-surveys.html#types-of-surveys",
    "title": "3¬† Surveys: Key Concepts",
    "section": "3.3 Types of Surveys",
    "text": "3.3 Types of Surveys\nThe method chosen for collecting data in a survey plays a crucial role in determining the accuracy and reliability of the results. Broadly, survey research can be classified into experimental and non-experimental approaches, each serving different research purposes.\n\n3.3.1 Experimental Surveys\nExperimental surveys are designed to explore causal relationships between variables.Here, researchers have control over certain conditions, manipulating one or more variables while keeping others constant to observe the effects. A key feature of experimental surveys is randomization, where participants are randomly assigned to different groups to eliminate bias. By ensuring that external factors do not influence the results, researchers can draw strong conclusions about cause and effect.\nOne common application of experimental surveys is in medical research, where clinical trials are conducted to test the effectiveness of a new drug. In such cases, patients might be randomly assigned to either a treatment group receiving the drug or a control group receiving a placebo. The outcomes are then compared to determine the drug‚Äôs efficacy. Similarly, in marketing, companies may experiment with different advertising strategies by exposing randomly selected groups to different promotional campaigns and then measuring their purchasing behavior.\nWhile experimental surveys provide strong evidence of causal relationships, they do have some limitations. They tend to be resource-intensive, requiring significant time and financial investment. Furthermore, ethical considerations may restrict certain types of experiments, especially in cases where withholding treatment or intervention from a control group could have serious consequences. Another challenge is that controlled settings may not fully capture real-world complexities, making it difficult to generalize findings beyond the experimental conditions.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html#non-experimental-surveys-observing-trends-and-patterns",
    "href": "introduction/intro-surveys.html#non-experimental-surveys-observing-trends-and-patterns",
    "title": "3¬† Surveys: Key Concepts",
    "section": "3.4 Non-Experimental Surveys: Observing Trends and Patterns",
    "text": "3.4 Non-Experimental Surveys: Observing Trends and Patterns\nUnlike experimental surveys, non-experimental surveys focus on observing and describing characteristics, trends, and relationships within a population without direct intervention. These surveys are widely used in fields such as social sciences, market research, and public policy analysis, where the goal is often to collect descriptive data rather than establish causality.\nOne of the most common types of non-experimental surveys is the cross-sectional survey, which captures data from a population at a single point in time. This method is frequently used in opinion polls, customer satisfaction studies, and demographic research. For example, a company might conduct a survey to understand consumer preferences for a new product just before its launch. Because cross-sectional surveys are quick and cost-effective, they are widely used.\nFor studies that require tracking changes over time, researchers may turn to longitudinal surveys, which collect data from the same subjects at multiple intervals. Longitudinal surveys are especially useful for understanding long-term trends, such as how consumer behavior evolves over the years or how health outcomes change in response to lifestyle choices. In a panel study, the same individuals are followed over time, whereas in a cohort study, a specific group‚Äîsuch as people born in a particular year‚Äîis tracked to observe changes as they age. These methods are valuable in policy research, where understanding the long-term effects of interventions, such as educational reforms or public health initiatives, is critical.\nSome non-experimental surveys rely on observational data, where researchers study behaviors and interactions without directly questioning participants. Observational studies often aim to identify associations and generate hypotheses for further research. This method is commonly used in consumer behavior research. For example, a supermarket might analyze shopping patterns by tracking how customers navigate store aisles without them being aware of the observation. Another example is web tracking which is a modern form of observational research where companies monitor users‚Äô online activities to analyze behavior, predict preferences, and personalize experiences. Unlike traditional observational studies, which are typically conducted with ethical oversight and clear participant consent, the presented examples often operates in the background without users‚Äô full awareness or control. Thus, while observational studies provide authentic behavioral insights, they raise ethical concerns about privacy and cannot establish direct cause-and-effect relationships.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/variable-class.html",
    "href": "introduction/variable-class.html",
    "title": "4¬† Variable Classification",
    "section": "",
    "text": "4.1 Types of Variables\nA variable is a property that can vary between different units in a population. Understanding the classification of variables is fundamental to selecting appropriate statistical methods and interpreting results accurately. The nature of a variable will for example determine:\nTo facilitate analysis, we focus on measurable variables, which are broadly categorized into quantitative and qualitative types. There are further sub-classes for each of these main classes, as shown in Figure¬†4.1 and exemplified further in the following.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Variable Classification</span>"
    ]
  },
  {
    "objectID": "introduction/variable-class.html#types-of-variables",
    "href": "introduction/variable-class.html#types-of-variables",
    "title": "4¬† Variable Classification",
    "section": "",
    "text": "graph TD;\n    A(Variable) --&gt; B(Qualitative);\n    A(Variable) --&gt; C(Quantitative);\n    C --&gt; D(Discrete);\n    C --&gt; E(Continuous);\n\n\n\n\n\n\n\n\nFigure¬†4.1: Variable classification.\n\n\n\n\n4.1.1 Quantitative (Numerical)\nThese variables are represented by numbers and can be measured. Depending on the type of numbers a variable takes, it can be classified as discrete or continuous.\nDiscrete variables take specific, distinct values and cannot be subdivided (natural, integer, or rational numbers). Think of these as variables holding countable values. Examples include number of children in a family, number of goals ina football match, and number of sales transactions per day.\nContinuous variables can take any value within a given range of values within an interval and can be infinitely divided (real numbers). Examples include hegiht, weight, stock price and distance.\n\n\n4.1.2 Qualitative (Categorical) Variables\nThese variables represent data that can be divided into distinct groups or categories. These values do not have a natural numerical order (except for ordinal variables) and must be coded into numerical values for statistical analysis. Examples include political affiliation, blood type, movie genre and social media platform.\nA special case of qualitative variables that take only two possible values, so called dichotomous or binary variable. Examples include smoking status (Smoker/Non-smoker) and COVID-19 test result (positive/negative).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Variable Classification</span>"
    ]
  },
  {
    "objectID": "introduction/variable-class.html#levels-of-measurement",
    "href": "introduction/variable-class.html#levels-of-measurement",
    "title": "4¬† Variable Classification",
    "section": "4.2 Levels of Measurement",
    "text": "4.2 Levels of Measurement\nThe characteristics of collected data allow us to classify them into four different measurement levels. These levels determine the statistical operations that can be performed. Table¬†4.1 summarizes the different measurement levels described in the following.\nNominal scale categorizes data without any inherent order. For example, there is no inherent ordering in the variable eye color (blue, brown, green), gender or nationality. You can only distinguish between the values nominal variables take.\nOrdinal scale is when data can be ranked in a meaningful order, but differences between values are not necessarily equal or meaningful, for example when looking at the variable fruit preference ranking or customer satisfaction levels (low, medium, high). In other words, interval lengths between one variable value and another are not of the same length.\nInterval scale is similar to the ordinal scale but with equal intervals between values. However, it lacks a true zero point. Examples include Temperature in Celsius and calendar years (the year 2000 is 100 years after 1900, but the year 0 does not represent the ‚Äúbeginning of time‚Äù).\nFinally, ratio scale has all of the above properties but also a natural zero point, allowing meaningful calculations of differences and ratios. Examples here include salary, distance traveled, height, and weight.\n\n\n\nTable¬†4.1: Summary of measurement levels.\n\n\n\nSummary of measurement levels.\n\n\n\n\n\n\n\n\n\n\n\nDistinguish\nRank\nEqual Step Length\nAbsolute Zero Point\nExample\n\n\n\n\nNominal\nYes\nNo\nNo\nNo\ngender, city, religion\n\n\nOrdinal\nYes\nYes\nNo\nNo\ngrades, preference, customer satisfaction ratings\n\n\nInterval\nYes\nYes\nYes\nNo\ntemperature in Celsius. credit scores, calender years\n\n\nRatio\nYes\nYes\nYes\nYes\nlength, weight, time, salary",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Variable Classification</span>"
    ]
  },
  {
    "objectID": "introduction/variable-class.html#types-of-numbers",
    "href": "introduction/variable-class.html#types-of-numbers",
    "title": "4¬† Variable Classification",
    "section": "4.3 Types of Numbers",
    "text": "4.3 Types of Numbers\nUnderstanding the nature of numbers is crucial when classifying variables because it directly influences statistical analysis, measurement accuracy, and the interpretation of data. The classification of numbers into natural, whole, integer, rational, irrational, and real numbers helps in determining which mathematical operations and statistical techniques are valid for a given data set:\n\nNatural Numbers: \\(0, 1, 2, 3, \\ldots\\)\nIntegers: \\(\\dots , -3, -2, -1, 0, 1, 2, 3, \\ldots\\)\nRational Numbers: Numbers that can be expressed as a fraction \\(\\frac{a}{b}\\) , where \\(a\\) and \\(b\\) are integers. Examples include:\n\n\\(-14 = \\frac{-14}{1}\\)\n\\(\\frac{3}{4} = 0.75\\)\n\\(\\frac{2}{7} = 0.285714285714 \\dots\\)\n\nReal Numbers: Non-repeating decimal numbers, such as:\n\n\\(\\pi = 3.14159265358979 \\dots\\)\n\n\nFor example you cannot calculate an average zip code (nominal) or say that ‚Äúa temperature of 20¬∞C is twice as hot as 10¬∞C‚Äù (interval), but you can say ‚Äúa person earning ‚Ç¨50,000 earns twice as much as someone earning ‚Ç¨25,000‚Äù (ratio). An another example, you cannot consider the mean of a categorical variable like ‚Äúfavorite color,‚Äù but you can analyze the frequency distribution.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Variable Classification</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html",
    "href": "descriptive-stats/describe-data.html",
    "title": "\n5¬† Describing a Dataset\n",
    "section": "",
    "text": "5.1 Describing Qualitative Variables\nDescriptive statistics is the foundation of data analysis, helping us summarize, visualize, and interpret data before diving into deeper statistical methods. This section explores how to describe datasets using tables, charts, and frequency distributions for both qualitative and quantitative variables.\nBefore analyzing data, it‚Äôs essential to understand its nature. The choice of tables, charts, or summary statistics depends on:\nQualitative (categorical) variables represent data grouped into distinct categories, such as gender, marital status, or election participation. These variables are best summarized using frequency tables and graphs such as bar charts and pie charts.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html#describing-qualitative-variables",
    "href": "descriptive-stats/describe-data.html#describing-qualitative-variables",
    "title": "\n5¬† Describing a Dataset\n",
    "section": "",
    "text": "5.1.1 Frequency Tables for Qualitative Data\nA frequency table lists the categories of a variable along with their corresponding counts (absolute frequency) and percentages (relative frequency). Assume we surveyed 300 people about their favorite hot beverage and found that 60% prefer coffee and 40% prefer tea. This preference distribution, also presented in the table below, will be used as a running example in the following.\n\n\nPreference\nCount (\\(f_i\\))\nPercentage (\\(f_i\\) in %)\n\n\n\nTea\n120\n40%\n\n\nCoffee\n180\n60%\n\n\nTotal\n300\n100%\n\n\n\nThe relative frequency is calculated as:\n\\[\\frac{120}{300} \\times 100 = 40\\%\\]\nand shown in the third column.\n\n5.1.2 Pie Chart\nPie charts are one of the most commonly used tools for representing categorical data in a simple, visual format. They break down a whole into proportional slices, making it easy to see relative differences between categories at a glance. Whether you‚Äôre comparing sales across different product categories, analyzing survey responses, or breaking down a budget, a well-made pie chart provides an intuitive way to present proportions.\nEach slice represents a category‚Äôs percentage of the total, with the entire pie equaling 100%. The size of each slice is determined by the proportion of the category it represents. For example, if 60% of survey respondents prefer coffee over tea, that category would take up 60% of the pie chart, or 60% of 360¬∞, that is \\(0.60 √ó 360¬∞ = 216¬∞\\) of the full circle. Pie charts are particularly effective when comparing a few distinct categories but lose clarity when too many slices are included.\n\n\n\n\n\n\n\n\nWhile a standard pie chart is a great way to visualize data, 3D pie charts are the dark side of data visualization. They may look fancy, but they distort proportions, making it difficult to accurately compare slice sizes. Due to the perspective effect, some slices appear larger or smaller than they actually are, leading to misleading interpretations. In short: if you want your data to be clear and not just flashy, stick to 2D pies - your audience will thank you.\n\n5.1.3 Bar Chart\nBar charts are a great way to visualize qualitative data, making it easy to compare different categories. Each category is represented by a bar, with the height corresponding to its frequency or percentage. For example, a bar chart would clearly display the difference between coffee and tea lovers, making it easy to interpret at a glance. Unlike pie charts, bar charts work well even when multiple categories are involved, ensuring your audience can quickly grasp the data - without any risk of 3D chart-induced confusion!\n\n\n\n\n\n\n\n\n\n5.1.4 Contingency Tables\nWhen we have observations on two qualitative variables, we can create two separate frequency tables. However, if we want to study the relationship between the two variables, we use a contingency table.\nA contingency table organizes paired observations, showing the frequency distribution across the two categorical variables.\nFor example, consider the following data where individuals are classified into two groups based on their marital status (Married (M) or Not Married (NM)) and their voting behavior (Voted (1) or Did Not Vote (0)). This results in four possible outcome combinations:\n\n(M, 0) - Married, Did Not Vote\n(M, 1) - Married, Voted\n(NM, 0) - Not Married, Did Not Vote\n(NM, 1) - Not Married, Voted\n\nAssume the first four observations are: (G, 0), (EG, 1), (G, 1), (G, 1) Which we create the following table over:\n\n\n\n0 (Did Not Vote)\n1 (Voted)\n\n\n\nM (Married)\n‚úîÔ∏è\n‚úîÔ∏è‚úîÔ∏è\n\n\nNM (Not Married)\n\n‚úîÔ∏è\n\n\n\nOnce all observations have been recorded, we can create the following contingency table:\n\n\n\nDid Not Vote\nVoted\nTotal\n\n\n\nMarried\n54\n1496\n1550\n\n\nNot Married\n85\n628\n713\n\n\nTotal\n139\n2124\n2263\n\n\n\nThis table displays the distribution of voting behavior by marital status, where we can analyze differences between the groups.\nMarginal Distributions\nA marginal distribution summarizes the totals for each row and column in a contingency table. This helps us understand the overall distribution of each variable separately.\nFor example, the absolute and relative marginal distributions for marital status is shown below:\n\n\nMarital Status\nCount\nPercentage (%)\n\n\n\nMarried\n1550\n68.5%\n\n\nNot Married\n713\n31.5%\n\n\nTotal\n2263\n100%\n\n\n\nSimilarly, the absolute and relative marginal distributions for voting behvaior is shown below:\n\n\nVoting Behavior\nCount\nPercentage (%)\n\n\n\nDid Not Vote\n139\n6.1%\n\n\nVoted\n2124\n93.9%\n\n\nTotal\n2263\n100%\n\n\n\nThese tables summarize how many people are in each category without considering the second variable.\nConditional Distributions\nTo compare voting behavior between married and non-married individuals, we calculate row percentages.\n\n\n\nDid Not Vote (%)\nVoted (%)\nTotal (%)\n\n\n\nMarried\n3.5%\n96.5%\n100%\n\n\nNot Married\n11.9%\n88.1%\n100%\n\n\n\nThis table shows the conditional distribution of voting behavior, given marital status.\n\nAmong married individuals, 1496 √ó 100 = 0.965= 96.5% voted while 54 √ó 100 = 0.035 =3.5% did not.\nAmong non-married individuals, 88.1% voted, while 11.9% did not.\n\nBy comparing these row percentages, we can see that married individuals were more likely to vote compared to non-married individuals. We have calculated the percentages horizontally but compare the percentage values in the vertical columns. We can also compute column percentages instead of row percentages if needed.\nTo determine whether a relationship exists between voting behavior and marital status, we compare conditional distributions. Since the voting percentages differ between married and non-married groups, we conclude that marital status influences voting behavior. If the two variables were independent, the percentages in the columns would be nearly the same. The fact that they differ suggests an association between the two variables.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html#describing-quantitative-variables",
    "href": "descriptive-stats/describe-data.html#describing-quantitative-variables",
    "title": "\n5¬† Describing a Dataset\n",
    "section": "\n5.2 Describing Quantitative Variables",
    "text": "5.2 Describing Quantitative Variables\nUnlike qualitative data, which can be subjective and harder to categorize, quantitative data enables direct comparisons, making it easier to identify patterns, test hypotheses, and make data-driven decisions.\nQuantitative variables are numeric and can be either discrete (specific values, such as test scores) or continuous (measured on a scale, such as weight). These variables are best summarized using frequency tables, histograms, and cumulative distributions.\n\n5.2.1 Frequency and Cumulative Frequency Tables\nExample 5.1: Mathematics Grade\nWe begin by examining a discrete variable with a small number of observations. Assume the mathematics grades (ranging from 1-5) of 25 students are:\n5 4 1 4 4 3 2 3 3 3 4 2 3 1 3 3 5 4 2 2 2 4 3 5 3\nWhen data is presented in this way, it is referred to as ungrouped data. Let:\n\n\n\\(x_i\\) = observed values, where \\(i = 1, \\ldots , n\\)\n\n\n\\(f_i\\) = frequency of the \\(i\\)-th variable value, where \\(i = 1, 2, \\ldots, k\\).\n\nFor our example here, \\(n = 25\\) (total observations) and \\(k = 5\\) (five distinct values of the variable ‚ÄúMathematics Grades‚Äù).\nLet‚Äôs summarize this data by counting how many we have in each grade category:\n\n\nGrade (\\(x_i\\))\nCount\nFrequency (\\(f_i\\))\n\n\n\n1\n‚úîÔ∏è‚úîÔ∏è\n2\n\n\n2\n‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è\n5\n\n\n3\n‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úî\n9\n\n\n4\n‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è\n6\n\n\n5\n‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è\n3\n\n\nTotal\n\n25\n\n\n\nThe sum of all frequencies equals the total number of observations: \\(\\sum_{i=1}^{k} f_i = n\\).\nWe have created a frequency table by grouping the data into categories which can be visualized using a bar chart:\n\n\n\n\n\n\n\n\nThe cumulative frequency tells us how many observations are less than or equal to a given value.\n\n\n\n\n\n\n\nScore (\\(x_i\\))\nAbsolute Frequency (\\(f_i\\))\nCumulative Frequency (\\(F_i\\))\n\n\n\n1\n2\n2\n\n\n2\n5\n7\n\n\n3\n9\n16\n\n\n4\n6\n22\n\n\n5\n3\n25\n\n\n\nCumulative frequencies are often displayed using a cumulative step graph:",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html#histograms",
    "href": "descriptive-stats/describe-data.html#histograms",
    "title": "\n5¬† Describing a Dataset\n",
    "section": "\n5.3 Histograms",
    "text": "5.3 Histograms\nWhen dealing with a continuous variable or a discrete variable with many values, it is common to create class intervals and then display frequencies in a frequency table or graph.\nExample 5.2: Candy Bar Weights\n\n\n\n\nWe have observed 40 candy bars of a specific brand and recorded their weighs which are given in the following in ascending order:\n20.5 20.7 20.8 21.0 21.0 21.4 21.5 22.0 22.1 22.5\n22.6 22.6 22.7 22.7 22.9 22.9 23.1 23.3 23.4 23.5\n23.6 23.6 23.6 23.9 24.1 24.3 24.5 24.5 24.8 24.8\n24.9 24.9 25.1 25.1 25.2 25.6 25.8 25.9 26.1 26.7\nSince weight is a continuous variable, we must group the observations into classes. We choose five class intervals, each with a width of 1.3 grams, starting from 20.4 grams:\n\n\nClass 1: 20.4 - 21.6\n\nClass 2: 21.7 - 22.9\n\nClass 3: 23.0 - 24.2\n\nClass 4: 24.3 - 25.5\n\nClass 5: 25.6 - 26.9\n\nWe can then create a frequency table as before:\n\n\nWeight Range (grams)\nFrequency (\\(f_i\\))\n\n\n\n20.4 - 21.6\n7\n\n\n21.7 - 22.9\n9\n\n\n23.0 - 24.2\n9\n\n\n24.3 - 25.5\n10\n\n\n25.6 - 26.9\n5\n\n\nTotal\n40\n\n\n\nWe then can visualize the frequency distribution using a histogram:\n\n\n\n\n\n\n\n\nGenerally, A histogram represents continuous data by grouping values into intervals, with bar heights corresponding to frequencies.\nTo determine how many observations fall below a given value, we calculate the cumulative frequencies as before and visualize using a step chart.\n\n\n\n\n\n\n\n\n\nWeight Range (grams)\nAbsolute Frequency (fi)\nCumulative Frequency (Fi)\nRelative Frequency (%)\nCumulative Relative Frequency (%)\n\n\n\n20.4 - 21.6\n7\n7\n17.5\n17.5\n\n\n21.7 - 22.9\n9\n16\n22.5\n40.0\n\n\n23.0 - 24.2\n9\n25\n22.5\n62.5\n\n\n24.3 - 25.5\n10\n35\n25.0\n87.5\n\n\n25.6 - 26.9\n5\n40\n12.5\n100\n\n\nTotal\n40\n40\n100%\n100%",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html#stem-and-leaf-plot",
    "href": "descriptive-stats/describe-data.html#stem-and-leaf-plot",
    "title": "\n5¬† Describing a Dataset\n",
    "section": "\n5.4 Stem-and-Leaf Plot",
    "text": "5.4 Stem-and-Leaf Plot\nA Stem-and-leaf plot is a compact way to display numerical data while preserving individual values. It organizes data into stems (representing the leading digits) and leaves (the following digits), providing a good display of the distribution.\nFor example, in the dataset of candy bar weights, a stem-and-leaf plot can show whether weights cluster around a certain value and help identify any inconsistencies. This is shown in the follwing.\nWe split each value from our candy bar weight dataset into - Stem (e.g., 20, 21, 22, etc.) - Leaf (the decimal part, such as .1, .2, .3, etc.)\nThe Stem-and-Leaf Table is then given as:\n\n\nStem\nLeaf\n\n\n\n20\n5 7 8\n\n\n21\n0 0 4 5\n\n\n22\n0 1 5 6 6 7 7 9 9\n\n\n23\n1 3 4 5 6 6 6 9\n\n\n24\n1 3 5 5 8 8 9 9\n\n\n25\n1 1 2 6 8 9\n\n\n26\n1 7\n\n\n\nIf you tilt your head to the right or rotate the table 90¬∞ you get a fairly good view on the distribution of the data. The distribution appears fairly symmetric, with a slight skew toward the higher weights. Overall, the data is well distributed across the entire range, but there is a higher density of observations between 22.0 g and 24.9 g, indicating that the most frequent range appears to be 22 to 24 grams, with many values concentrated in these stems. The least frequent weights occur at the lower (20-21 g) and higher (25-26 g) ends. In a quality control one might check this distribution and note whether a large amount of candy bars end up in the tails of the distribution, thus indicating inconsistent production of candy bars.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html",
    "href": "descriptive-stats/central-measures.html",
    "title": "\n6¬† Measures of Central Tendency\n",
    "section": "",
    "text": "Example 6.1: Income\nMeasures of central tendency are numerical indicators that describe a ‚Äútypical‚Äù observation within a data set. These measures help summarize data and provide insight into the distribution. The three most commonly used central measures are:\nWe will use the follwing running example in this chapter.\nWe have income data (in thousands of ‚Ç¨) for 18 individuals:\nWe will in the following show how we compute each of the shown measure of central tendency in the follwing.\nWe will see that for this example, the median income is the most representative value, as it is less affected by high-income extreme values.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html#arithmetic-mean",
    "href": "descriptive-stats/central-measures.html#arithmetic-mean",
    "title": "\n6¬† Measures of Central Tendency\n",
    "section": "\n6.1 Arithmetic Mean",
    "text": "6.1 Arithmetic Mean\nThe mean is calculated by summing all values and dividing by the number of observations. It is often used as a measure of central tendency because it incorporates all data points, making it a valuable summary statistic. However, the mean is sensitive to outliers, meaning that extreme values can pull it higher or lower, potentially misrepresenting the typical value in a skewed distribution. Despite this, in normally distributed data, the mean is a reliable and widely used indicator of the data set‚Äôs center.\nThe mean is calculated differently depending on whether we are working with an entire population or a sample: For a population, the mean (\\(\\mu\\), just a fancy Greek way of saying ‚Äúthe mean of \\(X\\)‚Äù) is given by: \\[\n\\mu = \\frac{\\sum_{i=1}^{N} x_i}{N}\n\\]\nwhere \\(N\\) is the population size. For a sample, the mean (\\(\\bar{x}\\)) is an estimate of \\(\\mu\\) and is calculated as: \\[\n\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n\\] where \\(n\\) is the sample size.\nExample 6.1: Income\nThe mean income is: \\[\\bar{x} = \\frac{20 + 22 + 24 + 24 + \\cdots + 85 + 90}{18} = 44.7 \\] Thus, the mean income is 44 700 ‚Ç¨.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html#median",
    "href": "descriptive-stats/central-measures.html#median",
    "title": "\n6¬† Measures of Central Tendency\n",
    "section": "\n6.2 Median",
    "text": "6.2 Median\nThe median is the middle value of a dataset when arranged in ascending order. It represents the point where half of the observations are below and half are above, making it a useful measure of central tendency for skewed distributions. Unlike the mean, the median is not affected by outliers, making it a more robust indicator of typical values in cases where extreme values exist. For example, in income data, the median often provides a better reflection of the typical salary than the mean, which can be skewed by very high incomes. If there is an even number of observations, the median is the average of the two middle values. The median position is found using: \\[\n\\frac{n + 1}{2}\n\\]\nExample 6.1: Income\nFor our sorted income data we get that the median is located at the position \\[\n\\frac{19}{2} = 9.5\n\\] The median is then the average of the 9th and 10th values (40 and 44):** \\[\n\\frac{40 + 44}{2} =42\n\\] Thus, the median income is 42 000 ‚Ç¨.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html#mode",
    "href": "descriptive-stats/central-measures.html#mode",
    "title": "\n6¬† Measures of Central Tendency\n",
    "section": "\n6.3 Mode",
    "text": "6.3 Mode\nThe mode is the most frequently occurring value in a data set. A data set can have one mode (unimodal), multiple modes (multimodal), or no mode at all if all values are unique. The mode is particularly useful for categorical data, such as identifying the most popular product in a sales dataset or the most common salary range in a workforce. In a histogram, the mode corresponds to the peak of the distribution, highlighting where data points concentrate the most.\nExample 6.1: Income\nThe most frequently occurring values in the income example is 24.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html#which-measure-should-you-choose",
    "href": "descriptive-stats/central-measures.html#which-measure-should-you-choose",
    "title": "\n6¬† Measures of Central Tendency\n",
    "section": "\n6.4 Which Measure Should You Choose?",
    "text": "6.4 Which Measure Should You Choose?\nThe appropriate measure of central tendency depends on the data type:\n\n\nData Type\nSuitable Measure(s)\n\n\n\n\nNominal Data (categories)\nMode\n\n\n\nOrdinal Data (ranked categories)\nMode, Median\n\n\n\nInterval Data (e.g., temperature)\nMode, Median, Mean\n\n\n\nRatio Data (e.g., income, weight)\nMode, Median, Mean\n\n\n\nWhen deciding between the mean and median, the mean is preferred for normally distributed data without outliers, while the median is better suited for skewed distributions or data sets with extreme values since it is not influenced by outliers. The mode, while useful for categorical and multimodal data, may not always provide meaningful insights in numerical data sets.\nIn our example, the median income (42 thousand euros) is a better representation of a ‚Äútypical‚Äù income than the mean (44.7 thousand euros) due to high-income values skewing the mean upward.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html",
    "href": "descriptive-stats/dispersion-measures.html",
    "title": "\n7¬† Measures of Dispersion\n",
    "section": "",
    "text": "Example: Test Scores\nWhile measures of central tendency, such as the mean or median, provide valuable insight into the typical value in a data set, they often do not tell the whole story. Two data sets can have the same mean but exhibit vastly different distributions. This is where measures of dispersion become crucial, as they describe the spread or variability in a data set.\nMeasures of dispersion quantify how much the observations in a data set differ from each other. They help answer questions such as:\nDispersion measures require numerical data and are essential for understanding the reliability and consistency of a data set.\nConsider two sets of scores from two different groups of students. Each data set contains eight observations, representing the scores students received on a test:\nData A\nData B\nBoth data sets have the same mean: \\[\\bar{x}_A = \\frac{4 + 4 + 5 + 5 + 5 + 6 + 6 + 7}{8} = 5.25\\] \\[\\bar{x}_B = \\frac{0+1+4+5+6+7+8+11}{8} = 5.25\\]\nHowever, data set B has a much wider spread of values, ranging from 0 to 11, while data set A is more compact, with values between 4 and 7. The greater spread in data set B suggests higher variability in scores, meaning individual performances were less consistent compared to data set A. In contrast, data set A shows more uniform performance, suggesting students‚Äô scores were relatively close to each other. The two data set distributions are visualized below:\nSeveral statistical measures help quantify dispersion in a dataset, some of which are covered in the following.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#quartiles-and-percentiles",
    "href": "descriptive-stats/dispersion-measures.html#quartiles-and-percentiles",
    "title": "\n7¬† Measures of Dispersion\n",
    "section": "\n7.1 Quartiles and Percentiles",
    "text": "7.1 Quartiles and Percentiles\nQuartiles and percentiles divide data into sections, helping us understand the distribution more effectively. The most commonly used quartiles are the first quartile (Q1), median (Q2), and third quartile (Q3).\nFirst Quartile (Q1) - 25th Percentile\nThe first quartile (Q1) marks the value below which 25% of the observations fall. It helps us understand the lower range of the dataset and is computed as: \\[\nQ1 = \\text{value at position } 0.25(n+1)\n\\] where \\(n\\) is the total number of observations.\nSecond Quartile (Q2) ‚Äì 50th Percentile (Median)\nThe second quartile (Q2) is simply the median, dividing the dataset into two equal halves. This is calculated as: \\[\nQ2 = \\text{value at position } 0.50(n+1)\n\\] Since 50% of values are below this point, the median represents the central value in the distribution.\nThird Quartile (Q3) - 75th Percentile\nThe third quartile (Q3) is the value below which 75% of the observations fall. This is particularly useful for understanding the upper range of the dataset and is calculated as: \\[\nQ3 = \\text{value at position } 0.75(n+1)\n\\]\nQuartiles provide valuable information about how data is spread across different sections. They allow us to:\n\nIdentify skewness: If Q1 and Q3 are unevenly spaced around Q2 (the median), the data may be skewed.\nDetect outliers: Any value that is significantly lower than Q1 or higher than Q3 can be considered an outlier.\nCalculate the Interquartile Range (\\(IQR\\)), which is the difference between Q3 and Q1, providing a robust measure of spread that is less sensitive to extreme values (not to be confused with range which is the difference between minimum and maximum observation values \\(x_{max}-x_{min}\\)).\nCalculate the Quartile Deviation which is another measure that is robust against extreme values and defined as half the difference between the third quartile (Q3) and the first quartile (Q1): \\[\\frac{Q3-Q1}{2} .\\]",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#five-number-summary-and-boxplot",
    "href": "descriptive-stats/dispersion-measures.html#five-number-summary-and-boxplot",
    "title": "\n7¬† Measures of Dispersion\n",
    "section": "\n7.2 Five-Number Summary and Boxplot",
    "text": "7.2 Five-Number Summary and Boxplot\nA Five-Number Summary is a set of five descriptive statistics that provide insights into the distribution of a data set. These include:\n\n\nMinimum ‚Äì The smallest observed value.\n\nFirst Quartile (Q1) ‚Äì The 25th percentile, below which 25% of the data falls.\n\nSecond Quartile (Median, Q2) ‚Äì The 50th percentile, the middle value of the data set.\n\nThird Quartile (Q3) ‚Äì The 75th percentile, below which 75% of the data falls.\n\nMaximum ‚Äì The largest observed value.\n\nThe Five-Number Summary helps in constructing a boxplot, which visually represents the spread and skewness of the data, as well as potential outliers. An example is shown in Figure¬†7.1.\nThe boxplot visually represents the distribution and spread of the data using the five-number summary. The minimum and maximum values mark the range of the data, while the first quartile (Q1), median (Q2), and third quartile (Q3) divide the data into four equal parts. The interquartile range (IQR), which spans from Q1 to Q3, highlights the middle 50% of the data, giving insights into variability.\nThe median (Q2) represents the central value, while outliers (if any) are shown as red points beyond the whiskers of the box. This boxplot effectively summarizes the data set, making it easy to identify skewness, dispersion, and potential outliers at a glance.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.1: Boxplot with labels for each component of the Five-Number Summary\n\n\nExample: Test Scores\nWe compute the Five-Number Summary for the two datasets, A and B, representing test scores.\nData A\n4 4 5 5 5 6 6 7\nData B\n0 1 4 5 6 7 8 11\n1 and 5: The range is the difference between the maximum and minimum values (thus allowig us to see the minimum and maximum as well):\n\nA: (7 - 4 = 3)\nB: (11 - 0 = 11)\n\n2: The first quartile is found at position:\\[\nQ1 = 0.25(n+1) = 0.25(9) = 2.25\n\\]\n\nA: \\(Q1 = 4 + 0.25(5-4) = 4.25\\)\n\nB: \\(Q1 = 1 + 0.25(4-1) = 1.75\\)\n\n\n3: The median is found at position:\\[\nQ2 = 0.50(n+1) = 0.50(9) = 4.5\n\\]\n\nA: \\(Q2 = 5\\)\n\nB: \\(Q2 = 5.5\\)\n\n\n4: The third quartile is found at position:\\[\nQ3 = 0.75(n+1) = 0.75(9) = 6.75\n\\]\n\nA: \\(Q3 = 6 + 0.75(6-6) = 6\\)\n\nB: \\(Q3 = 7 + 0.75(8-7) = 7.75\\)\n\n\nFinal Five-Number Summaries\n\n\nDataset\nMinimum\nQ1\nMedian (Q2)\nQ3\nMaximum\n\n\n\nA\n4\n4.25\n5\n6\n7\n\n\nB\n0\n1.75\n5.5\n7.75\n11\n\n\n\nTo better understand the distribution of the two datasets, we use a boxplot to visualize the Five-Number Summary.\n\n\n\n\n\n\n\n\nThe boxplot visually highlights key aspects of dispersion, skewness, and potential outliers. In our example:\n\nDataset A has a smaller range (3) and is more compact.\nDataset B has a wider range (11), indicating greater variability in scores.\n\nBy using these descriptive statistics, we can better interpret datasets and make informed comparisons in various fields, including education, business, and research.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#variance-and-standard-deviation",
    "href": "descriptive-stats/dispersion-measures.html#variance-and-standard-deviation",
    "title": "\n7¬† Measures of Dispersion\n",
    "section": "\n7.3 Variance and Standard Deviation",
    "text": "7.3 Variance and Standard Deviation\nWhen analyzing data, calculating the mean provides insight into the average value of a dataset. However, to understand how spread out the data is, we need to measure its variability. This is where variance and standard deviation become essential.\nVariance quantifies the average squared deviation of each data point from the mean. It provides a measure of how much the data points differ from the central value. For an entire population, the variance (\\(\\sigma^2\\)) is calculated as: \\[\nœÉ^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\n\\] where:\n\n\n\\(N\\) = total number of data points in the population,\n\n\\(x_i\\) = individual data points,\n\n\\(\\mu\\) = population mean.\n\nWhen working with a sample instead of an entire population, we use the sample variance (\\(s^2\\)): \\[\ns^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\n\\] where:\n\n\n\\(n\\) = sample size,\n\n\\(x_i\\) = individual data points,\n\n\\(\\bar{x}\\)= sample mean.\n\nThe denominator \\((n-1)\\) instead of \\(n\\) accounts for the loss of one degree of freedom, making it an unbiased estimator of population variance (we‚Äôll return to this later).\nAn alternative formula for calculating sample variance can be found by noting that the sum of all deviations from the mean is zero: \\(\\sum_{i=1}^{n} x_i = n\\bar{x}\\) so that we get \\[\n\\sum_{i=1}^{n} x_i \\bar{x} = \\bar{x} \\sum_{i=1}^{n} x_i = n \\bar{x}^2.\n\\] Substituting this back into original equation yields: \\[\ns^2 = \\frac{\\sum_{i=1}^{n} x_i^2 - 2n\\bar{x}^2 + n\\bar{x}^2}{n-1}\n= \\frac{\\sum_{i=1}^{n} x_i^2 - n\\bar{x}^2}{n-1}\n\\] Rewriting using summation notation: \\[\ns^2 = \\frac{n \\sum_{i=1}^{n} x_i^2 - (\\sum_{i=1}^{n} x_i)^2}{n(n-1)}\n\\] This formulation simplifies calculations by hand when working with moderately large data sets.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#standard-deviation",
    "href": "descriptive-stats/dispersion-measures.html#standard-deviation",
    "title": "\n7¬† Measures of Dispersion\n",
    "section": "\n7.4 Standard Deviation",
    "text": "7.4 Standard Deviation\nThe standard deviation is the square root of variance, bringing it back to the same units as the data, for example if measuring weight in kg, standard deviation is in kg as well. Thus, it is better to use when you need an intuitive, practical measure of data spread in real-world scenarios.\nFor a population, the standard deviation (\\(\\sigma\\)) is: \\[\n\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}}\n\\] For a sample, the standard deviation (\\(s\\)) is: \\[\ns = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}}\n\\] which can also be rewritten as: \\[\ns = \\sqrt{\\frac{n \\sum_{i=1}^{n} x_i^2 - (\\sum_{i=1}^{n} x_i)^2}{n(n-1)}}\n\\] following the alternative variance formula shown above.\nTo better understand the concept of standard deviation, we visualize the distribution of a data set in Figure¬†7.2 where the mean (blue) and standard deviation bands (red) are overlayed.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.2: Histogram of data set of 100 0bservations with standard deviation bands included.\n\n\nExample: Test Scores\nReturning to our example on test scores, we previously calculated the sample mean as \\(\\bar{x} = 5.25\\). Now, we compute the variance (\\(s^2\\)) for each data set: \\[\ns^2_A = \\frac{(4‚àí5.25)^2 + (4‚àí5.25)^2 + \\dots + (7‚àí5.25)^2}{8-1}  \\approx 1.074\n\\] \\[\ns^2_B = \\frac{(0‚àí5.25)^2 + (1‚àí5.25)^2 + \\dots + (11‚àí5.25)^2}{8-1} \\approx 13.071\n\\]\nThe standard deviation (\\(s\\)) is then simply the square root of the variance: \\[\ns_A = \\sqrt{1.071} \\approx 1.035\n\\] and \\[\ns_B = \\sqrt{13.071} \\approx 3.615\n\\] We see that for data set A, the standard deviation is 1.035, indicating that most scores are relatively close to the mean (5.25), while for data set B, the standard deviation is 3.615, suggesting a wider spread of scores and greater variability. This comparison shows that data set B has a significantly higher variability than data set A, meaning the scores are more dispersed from the average.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#the-empirical-rule",
    "href": "descriptive-stats/dispersion-measures.html#the-empirical-rule",
    "title": "\n7¬† Measures of Dispersion\n",
    "section": "\n7.5 The Empirical Rule",
    "text": "7.5 The Empirical Rule\nThe Empirical Rule, also known as the 68-95-99.7 Rule, describes how data is distributed in a normal (bell-shaped) distribution. It states that for a large population following a normal distribution:\n\n\nApproximately 68% of all observations lie within one standard deviation from the mean (\\(\\mu ¬± 1\\sigma\\)).\n\nApproximately 95% of all observations lie within two standard deviations from the mean (\\(\\mu ¬± 2\\sigma\\)).\n\nNearly all observations (99.7%) lie within three standard deviations from the mean (\\(\\mu ¬± 3\\sigma\\)).\n\nThis rule helps us understand the probability of an observation falling within a given range and is widely used in quality control, finance, and science to assess variability and expected outcomes. It is particularly useful when analyzing data distributions. If data follows a normal distribution most values cluster around the mean, and extreme values are rare. This also means that outliers can be identified if they fall beyond 3 standard deviations from the mean.\nThe empricial rule is visualized in Figure¬†7.3 showing the percentages of data falling within each standard deviation range.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.3: The Empirical Rule: Normal Distribution.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#sec-descriptives-cov",
    "href": "descriptive-stats/dispersion-measures.html#sec-descriptives-cov",
    "title": "\n7¬† Measures of Dispersion\n",
    "section": "\n7.6 Covariance and Correlation",
    "text": "7.6 Covariance and Correlation\nWhen analyzing data, it is often important to understand the relationship between two variables. Measures such as covariance and correlation help quantify the degree to which two variables change together, allowing us to assess their association.\nCovariance measures the direction of the linear relationship between two variables, \\(X\\) and \\(Y\\). It tells us whether an increase in one variable is associated with an increase or decrease in the other. For an entire population, the covariance is calculated as: \\[\n\\operatorname{Cov}(x, y) = \\sigma_{xy} = \\frac{\\sum_{i=1}^{N} (x_i - \\mu_x)(y_i - \\mu_y)}{N}\n\\] where:\n\n\n\\(N\\) = total number of observations,\n\n\\(x_i, y_i\\) = individual data points,\n\n\\(\\mu_x \\mu_y\\) = means of \\(x\\) and \\(y\\).\n\nFor a sample, we estimate covariance using: \\[\n\\operatorname{Cov}(x, y) = s_{xy} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{n - 1}\n\\] where:\n\n\n\\(n\\) = sample size,\n\n\\(\\bar{x} ,\\bar{y}\\) = sample means of \\(x\\) and \\(y\\).\n\nHow do we interpret the covariance?\n\nIf we have positive covariance it means that when \\(x\\) increases, then \\(y\\) also tends to increase (e.g., study time and exam scores).\nIf we have negative covariance it means that when \\(x\\) increases, then \\(y\\) tends to decrease (e.g., speed and time taken to reach a destination).\nIf we have near zero covariance, then this indicates no significant linear relationship between \\(x\\) and \\(y\\) (note however that it does not detect patterns where variables are related in a non-linear way e.g., quadratic or exponential relationships).\n\nOne limitation of covariance is that it depends on the units of measurement (same as for variance), making it difficult to interpret. This is where correlation comes in as it standardizes covariance by adjusting for the scales of the variables, providing a dimensionless measure that is easier to interpret. The population correlation (\\(\\rho\\)) is given by \\[\n\\rho = \\frac{\\operatorname{Cov}(x, y)}{\\sigma_x \\sigma_y}\n\\] where \\(\\sigma_x,\\sigma_y\\) are the standard deviations of \\(x\\) and \\(y\\). The sample correlation (\\(r\\)) \\[\nr = \\frac{\\operatorname{Cov}(x, y)}{s_x s_y}\n\\] where \\(s_x, s_y\\) are the sample standard deviations. Correlation values fall within the range -1 to 1, with the following interpretations (we use sample correlation as example):\n\n\n\\(r = 1\\): perfect positive correlation; \\(x\\) and \\(y\\) move together exactly in a straight line.\n\n\\(0.8 \\leq r &lt; 1\\): strong positive correlation; \\(x\\) and \\(y\\) tend to increase together.\n\n\\(0.5 \\leq r &lt; 0.8\\): moderate positive correlation; \\(x\\) and \\(y\\) show a noticeable increasing relationship.\n\n\\(0 &lt; r &lt; 0.5\\): weak positive correlation; \\(x\\) and \\(y\\) tend to increase together, but with variability.\n\n\\(r = 0\\): no linear relationship; \\(x\\) and \\(y\\) are not linearly related (but might be non-linearly associated).\n\n\\(-0.5 &lt; r &lt; 0\\): weak negative correlation; as \\(x\\) increases, \\(y\\) tends to decrease slightly.\n\n\\(-0.8 &lt; r \\leq -0.5\\): moderate negative correlation; \\(x\\) and \\(y\\) shown an inverse relationship.\n\n\\(-1 ‚â§ r ‚â§ -0.8\\): strong negative correlation; \\(x\\) and \\(y\\) move in opposite directions strongly.\n\n\\(r = -1\\): perfect negative correlation; \\(x\\) and \\(y\\) move in exactly opposite directions in a straight line.\n\nA few examples are shown in Figure¬†7.4.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.4: Simulated data showing different correlations.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html",
    "href": "prob-theory/prob-concepts.html",
    "title": "8¬† Probability Concepts",
    "section": "",
    "text": "8.1 Random Experiments\nWe now focus on the middle part of Figure¬†8.1, where we transition from simply summarizing data to drawing broader conclusions. Probability theory serves as the bridge between descriptive statistics, which tells us ‚Äúhow it is,‚Äù and inferential statistics, which helps us predict ‚Äúhow it will be.‚Äù By understanding why certain patterns appear in our sample data and combining that with probabilistic assumptions, we can move toward generalizing from the sample to the entire population.\nProbability theory is the branch of mathematics that deals with random experiments, where the outcome of each trial is uncertain and cannot be determined in advance. These experiments can be repeated under similar conditions, but due to inherent randomness, different trials may produce different results. No matter how hard you stare at a die before rolling, you won‚Äôt magically force it to land on a 6 (unless you‚Äôre a magician‚Ä¶ or cheating).\nA random experiment is an event or process that, when performed, leads to one of several possible outcomes, but the exact outcome is not known beforehand. The key characteristic of a random experiment is that even though individual outcomes are unpredictable, patterns may emerge when the experiment is repeated multiple times. This allows us to quantify uncertainty and make probabilistic predictions.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html#random-experiments",
    "href": "prob-theory/prob-concepts.html#random-experiments",
    "title": "8¬† Probability Concepts",
    "section": "",
    "text": "8.1.1 Properties of Random Experiments\n\nUncertainty in Individual Outcomes: The result of a single trial is unpredictable. You never really know what‚Äôs coming (just like your WiFi signal when you really need it).\nReproducibility Under Similar Conditions: The experiment can be performed multiple times under the same setup but the result may change every time (kind of like baking‚Äîyou follow the same recipe, yet somehow, things go wrong).\nPatterns in the Long Run: While single outcomes are uncertain, probability theory helps reveal long-term statistical regularities. In other words, while each trial is a mystery, repeat something enough times, and trends start to emerge (like realizing your cat will always knock things off the table).\n\nExamples of random experiments include:\n\nRolling a die (What number will appear: 1, 2, 3, 4, 5, or 6?)\nDrawing a lottery ticket (Win or no win?)\nRandom sampling from a population (Who will be selected?)\nFertilization of an egg (Boy or girl?)\nRadioactive decay (Number of particles decayed in a given time?)\nManufacturing of a product (Defective or non-defective?)\n\nWhile randomness may seem chaotic, probability theory helps us bring order to the madness. It allows us to assign mathematical probabilities to outcomes, making it possible to predict patterns, measure risk, and, if you‚Äôre lucky, win at poker.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html#outcomes-sample-space-and-events",
    "href": "prob-theory/prob-concepts.html#outcomes-sample-space-and-events",
    "title": "8¬† Probability Concepts",
    "section": "8.2 Outcomes, Sample Space and Events",
    "text": "8.2 Outcomes, Sample Space and Events\nThe result of a random experiment is called an outcome, and the set of all possible outcomes is known as the sample space, denoted as \\(\\Omega\\). A couple of examples are shown below:\nExperiment: Rolling a six-sided die\nSample Space: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\)\nExperiment: Flipping a coin twice\nSample Space: \\(\\Omega = \\{\\text{heads, tails}), (\\text{heads, heads}), (\\text{tails, heads}), (\\text{tails, tails})\\}\\)\nIn probability theory, we are often more interested in the characteristics of outcomes rather than the individual outcomes themselves. An event is a collection of outcomes that share a common feature, allowing us to analyze probabilities more efficiently and identify meaningful patterns within the data. Events are typically denoted by uppercase letters such as \\(A, B, C, \\ldots\\) and are formally defined as subsets of the sample space \\(\\Omega\\) Each event is characterized by the set of outcomes for which it occurs, meaning that an event is said to happen if and only if at least one of its associated outcomes is observed.\nConsider the follwing example. In a standard six-sided die roll üé≤, the sample space is given by: \\[\n\\Omega =\\{1, 2, 3, 4, 5, 6\\}\n\\]\nDifferent events can be defined as subsets of the sample space:\n\n\n\nEvent\nSubset of Sample Space\n\n\n\n\n\\(A\\) = Rolling an odd number\n\\(A = \\{1, 3, 5\\}\\)\n\n\n\\(B\\) = Rolling at most three\n\\(B = \\{1, 2, 3\\}\\)\n\n\n\\(C\\) = Rolling a six\n\\(C = \\{6\\}\\)\n\n\n\\(D\\) = Not rolling a six\n\\(D = \\{1, 2, 3, 4, 5\\}\\)\n\n\n\\(E\\) = Rolling a seven\n\\(E = \\emptyset\\) (empty set)\n\n\n\nIn this table, event \\(E\\) represents an impossible event since rolling a seven is not possible with a six-sided die, making its subset the empty set \\(\\emptyset\\).\n\nExample 8.1\nImagine randomly selecting a person from a lecture room. The sample space consists of all individuals present in the room. However, we are often more interested in certain characteristics rather than the specific individuals themselves.\nLet‚Äôs define the following events:\n\n\\(A\\) = The selected person wears glasses\n\n\\(B\\) = The selected person cycled to the university\n\nEach event consists of all outcomes where the selected individual satisfies the given condition. Suppose the randomly chosen person is Alex. If Alex wears glasses, then event \\(A\\) has occurred. If Alex also cycled to the university, then both events \\(A\\) and \\(B\\) have occurred simultaneously.\nNote that we here only considered one random experiment. In many real-world situations, random experiments are repeated multiple times instead of occurring just once. In such cases, each possible sample drawn represents an individual outcome.\nFor example, suppose we randomly select three students from the lecture room and ask them: ‚ÄúDid you cycle to today‚Äôs lecture?‚Äù.\nIf we let \\(Y\\) represent ‚ÄúYes‚Äù and \\(N\\) represent ‚ÄúNo‚Äù, the sample space consists of all possible sequences of answers: \\[\n\\Omega = \\{YYY, YYN, YNY, NYY, YNN, NYN, NNY, NNN\\}\n\\]\nand each outcome represents a specific combination of answers from the three selected students.\nRather than focusing on individual outcomes, we may be interested in how many of the selected students cycled to the lecture. This allows us to define events based on counts. For example, let‚Äôs define:\n\n\\(B_2\\) = Exactly two students cycled to the lecture\n\nThis event consists of all sequences where two of the three selected students answered ‚ÄúYes‚Äù, i.e.¬†\\[\nB_2 = \\{YYN, YNY, NYY\\}\n\\] Similarly, we can define:\n\n\\(B_0\\) = No students cycled to the lecture\n\n\\(B_1\\) = Exactly one student cycled to the lecture\n\n\\(B_3\\) = All three students cycled to the lecture\n\nSince one and only one of these events must occur, they are considered:\n\nExhaustive ‚Äì Together, they cover the entire sample space.\n\nMutually Exclusive ‚Äì No two of these events can occur at the same time.\n\nBy structuring probability problems in this way, we can analyze patterns in data and make probability calculations more intuitive.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html#venn-diagram",
    "href": "prob-theory/prob-concepts.html#venn-diagram",
    "title": "8¬† Probability Concepts",
    "section": "8.3 Venn Diagram",
    "text": "8.3 Venn Diagram\nProbability theory frequently utilizes conecpts from set theory to describe relationships between events. Venn diagrams provide a visual representation of these concepts and illustrate how different events relate to one another within the sample space. By using set operations, we can define and show new events effectively.\nThe sample space \\(\\Omega\\) is often represented as a rectangle, where individual outcomes may be shown as dots inside. However, for simplicity, the dots are usually omitted (and sometimes even the rectangle is omitted).\nAn event is typically represented as a circle within the rectangle. If multiple events are considered, their circles may overlap, reflecting cases where both events can occur simultaneously.\nReturning to our previous example, imagine we again randomly select a student from a lecture hall. We define the following events:\n\n\\(A\\) = The selected student wears glasses\n\\(B\\) = The selected student cycled to the university\n\nThese events can be visualized in a Venn diagram, where each event is a circle, as shown in Figure¬†8.2. Their overlap represents students who meet both conditions. These is called the intersection of events \\(A\\) and \\(B\\) and is one of three interesting areas that are of particular interest. We will cover each fo these in the following with reference to Figure¬†8.3 below.\n\n\n\n\n\n\n\nFigure¬†8.2: Events \\(A\\) and \\(B\\) in sample space \\(\\Omega\\).\n\n\n\n\n\n8.3.1 The Intersection of Events\nHere we look for outcomes that belong to both events \\(A\\) and \\(B\\). The intersection of two events \\(A\\) and \\(B\\) is denoted as: \\[A \\cap B\\]\nand represents the set of all outcomes where both events occur simultaneously. This is shown in top-left diagram of Figure¬†8.3.\n\nExample 8.2\nConsider a standard six-sided die where the sample space is: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) Define the following events:\n\n\\(A\\) = Rolling an odd number; \\(A = \\{1, 3, 5\\}\\)\n\\(B\\) = Rolling a number that is at most 3; \\(B = \\{1, 2, 3\\}\\)\n\nThe intersection of \\(A\\) and \\(B\\) includes only the numbers that appear in both sets: \\[\nA \\cap B = \\{1, 3\\}\n\\] Thus, the intersection contains only the numbers 1 and 3, since these are the only values present in both events.\n\n\n\n8.3.2 The Union of Events\nWe now look for outcomes that belong to at least one of the two events \\(A\\) and \\(B\\). The union of events, denoted as: \\[ A \\cup B \\] and represents the event that either \\(A\\), \\(B\\), or both occur. This is shown in bottom-left diagram of Figure¬†8.3.\n\nExample 8.3\nConsider a standard six-sided die where the sample space is: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) Define the following events:\n\n\\(A\\) = Rolling an odd number; \\(A = \\{1, 3, 5\\}\\)\n\\(B\\) = Rolling a number that is at most 3; \\(B = \\{1, 2, 3\\}\\)\n\nThe union of \\(A\\) and \\(B\\) includes all outcomes that belong to either event or both:\n\\[A \\cup B = \\{1, 2, 3, 5\\}\\]\nThus, the union contains the numbers 1, 2, 3, and 5, since at least one of the events \\(A\\) or \\(B\\) includes each of these numbers.\n\n\n\n8.3.3 Complement of an Event\nFor every event \\(A\\), there exists a complement event, which consists of all outcomes that do not belong to event \\(A\\).\nThe complement of \\(A\\) is denoted as: \\[ \\overline{A} \\] and represents the event that \\(A\\) does not occur. This is shown in bottom-right diagram of Figure¬†8.3.\n\nExample 8.4\nConsider rolling a standard six-sided die, where the sample space is: \\[S=\\{1,2,3,4,5,6\\}\\] Define the following event:\n\n\\(A\\) = Rolling an odd number; \\(A=\\{1,3,5\\}\\)\n\nThe complement of \\(A\\) consists of all outcomes not included in \\(A\\): \\[\\overline{A}=\\{2,4,6\\}\\] Thus, the complement of rolling an odd number is rolling an even number.\n\n\n\n8.3.4 Mutually Exclusive Events\nIn some cases, events \\(A\\) and \\(B\\) do not share any outcomes. Such events are called disjoint events, meaning they cannot occur simultaneously. Mathematically, this is written as: \\[A \\cap B = \\emptyset\\] where \\(\\emptyset\\) represents the empty set, meaning a set with no elements. This is shown in top-right diagram of Figure¬†8.3.\n\nExample 8.4\nConsider rolling a standard six-sided die, where the sample space is: \\[S=\\{1,2,3,4,5,6\\}\\]\nDefine the following events:\n\n\\(A\\) = Rolling an odd number; \\(A=\\{1,3,5\\}\\)\n\\(B\\) = Rolling an even number; \\(B=\\{2,4,6\\}\\)\n\nSince \\(A\\) and \\(B\\) do not have any numbers in common, we conclude: \\[A \\cap B = \\emptyset\\]\nThus, rolling an odd number and rolling an even number are mutually exclusive events.\n\n\n\n\n\n\n\nFigure¬†8.3: The intersection of events \\(A\\) and \\(B\\) (top-left), mutually exhaustive events (top-right), the union of events \\(A\\) and \\(B\\) (bottom-left) and the complement of event \\(A\\) (bottom-right).",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html#exercises",
    "href": "prob-theory/prob-concepts.html#exercises",
    "title": "8¬† Probability Concepts",
    "section": "Exercises",
    "text": "Exercises\nLet the sample space be: \\[\\Omega = {1,2,3,4,5,6} \\] Define the following events:\n\n\\(A\\) = ‚ÄúOdd numbers‚Äù; \\(A = {1,3,5}\\)\n\\(B\\) = ‚ÄúAt most three‚Äù; \\(B = {1,2,3}\\)\n\nDraw Venn diagrams to verify that the following statements hold:\n\n\\(\\overline{A \\cup B} = {4,6}\\)\n\\(\\overline{A} \\cap \\overline{B} = {4,6}\\)\n\\(A \\cup \\overline{A} = {1,2,3,4,5,6} = \\Omega\\)\n\\(A \\cap \\overline{A} = \\emptyset\\)",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html",
    "href": "prob-theory/what-is-prob.html",
    "title": "\n9¬† What is Probability?\n",
    "section": "",
    "text": "9.1 Fundamental Assumptions of Probability\nNow that we have explored fundamental probability concepts, such as unions, intersections, complements, and mutually exclusive events, we can use these ideas to formally define probability itself.\nUsing the relationships between events that we have discussed, we can also establish the formal rules of probability and see how these concepts help in calculating probabilities for different types of events.\nProbability theory provides a framework for modeling randomness and quantifying uncertainty. At its core, it relies on three fundamental assumptions that define how probabilities are assigned to different outcomes in a random experiment.\n\\[P(O_1) + P(O_2) + \\dots + P(O_n) = \\sum_{i=1}^{n} P(O_i) = 1\\]\nThese fundamental principles form the backbone of probability theory, ensuring a structured and consistent way to reason about uncertain events. By defining probabilities within these constraints, we can build models that capture real-world randomness and variability in a mathematically rigorous way.\nThe probability of an event \\(A\\), denoted as \\(P(A)\\), is determined by summing the probabilities of all individual outcomes that make up \\(A\\): \\[ P(A) = \\sum_{O_i \\in A} P(O_i) \\]\nThis rule ensures that if an event consists of multiple possible outcomes, its probability is found by adding up the probabilities of each contributing outcome.\nSince probability values must be assigned consistently, we require a formal system that ensures logical coherence in probability calculations. This leads us to Kolmogorov axioms, which form the foundation of modern probability theory.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#fundamental-assumptions-of-probability",
    "href": "prob-theory/what-is-prob.html#fundamental-assumptions-of-probability",
    "title": "\n9¬† What is Probability?\n",
    "section": "",
    "text": "First, every probability calculation begins with a random experiment that has a well-defined sample space, denoted as \\(\\Omega = \\{O_1, O_2, \\dots, O_n\\}\\). This sample space represents all possible outcomes of the experiment, ensuring that every event of interest is accounted for.\nSecond, once the sample space is established, each outcome \\(O_i\\) is assigned a probability \\(P(O_i)\\) for \\(i = 1,2,\\ldots, n\\), representing the likelihood of that specific event occurring. These probabilities must follow\n\n\n\nnon-negativity, meaning that probabilities must always fall within the range \\(0 \\leq P(O_i) \\leq 1\\) for all outcomes. This ensures that an event can never have a negative probability, and the probability of a certain event is at most 1.\n\nand the total probability principle, stating that the sum of all assigned probabilities must equal 1:",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#kolmogorovs-axioms",
    "href": "prob-theory/what-is-prob.html#kolmogorovs-axioms",
    "title": "\n9¬† What is Probability?\n",
    "section": "\n9.2 Kolmogorov‚Äôs Axioms",
    "text": "9.2 Kolmogorov‚Äôs Axioms\nTo maintain consistency in probability assignments, Andrey Kolmogorov formulated three fundamental axioms:\n\nNon-Negativity: The probability of any event \\(A\\) is always greater than or equal to zero:\\[P(A) \\geq 0\\]\nThis ensures that probabilities are never negative.\nTotal Probability: The probability of the entire sample space \\(\\Omega\\) (i.e., the event that some outcome must occur) is exactly 1:\\[P(\\Omega) = 1\\]\nThis guarantees that probability is correctly distributed among all possible outcomes.\nAdditivity for Mutually Exclusive Events: If two events \\(A\\) and \\(B\\) cannot occur at the same time (i.e., they are mutually exclusive), then the probability of either occurring is the sum of their individual probabilities:\\[P(A \\cup B) = P(A) + P(B)\\]\nThis principle extends to any finite or countable number of mutually exclusive events. If \\(A_1, A_2, \\dots, A_k\\) are pairwise disjoint events, then the probability of their union is the sum of their individual probabilities: \\[P(A_1 \\cup A_2 \\cup \\dots \\cup A_k) = P(A_1) + P(A_2) + \\dots + P(A_k)\\]\n\nThese axioms are not just abstract rules; they provide the backbone for all probability calculations, from simple games of chance to risk assessments in finance, medicine, and machine learning. By defining probability through outcome summation and enforcing consistency through these axioms, we build a powerful and reliable framework for understanding and modeling uncertainty, thus allowing for meaningful calculations and predictions about uncertain events.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#defining-probability",
    "href": "prob-theory/what-is-prob.html#defining-probability",
    "title": "\n9¬† What is Probability?\n",
    "section": "\n9.3 Defining Probability",
    "text": "9.3 Defining Probability\nThe probability of an event \\(A\\), denoted as \\(P(A)\\), is a measure of how likely it is that the event will occur. Different interpretations of probability exist, leading to various probability definitions.\n\n9.3.1 The Classical Definition\nThe classical definition of probability, derived from basic counting principles, states that if a random experiment has \\(N\\) possible outcomes, and exactly \\(N_A\\) of these correspond to event \\(A\\) occurring, then the probability of \\(A\\) is given by: \\[P(A) = \\frac{N_A}{N}\\] This is known as a theoretical probability assignment, as it assumes that all outcomes are equally likely.\n\n9.3.2 The Frequentist Definition\nAn alternative way to define probability is through relative frequency. In the frequentist interpretation, the probability of an event \\(A\\) is understood as the proportion of times \\(A\\) occurs in a very long sequence of repeated random experiments. This can be expressed mathematically as: \\[P(A) \\approx \\frac{n_A}{n}\\] where:\n\n\n\\(n_A\\) is the number of times event \\(A\\) occurs.\n\n\\(n\\) is the total number of trials.\n\nAs the number of trials \\(n\\) increases, the relative frequency of event \\(A\\) stabilizes and approaches its probability \\(P(A)\\), aligning with the classical probability definition. In other words, if we repeat an experiment an extremely large number of times, the empirical probability we observe will converge toward a fixed value. This phenomenon is known as the stability of relative frequencies and serves as the empirical foundation of probability theory. It explains why probabilities can be estimated by repeated experimentation, as observed frequencies tend to settle around a fixed value over a large number of trials. AN example of this is shown below in Example 9.1.\nThis probability defintion is known as the empirical probability assignment, meaning that probabilities are assigned based on observed data rather than theoretical assumptions.\n\n9.3.3 The Subjective Definition\nAnother way to interpret probability is through subjective probability, where probability is understood as a*measure of personal belief in the occurrence of an event. Formally, the probability of an event \\(A\\) in this interpretation is given by:\n\\[P(A) = \\text{a measure of how strongly a person believes that } A \\text{ will occur}\\] For example, one might estimate the probability of rain tomorrow as 30%, or believe that the chance of Germany winning the next Eurovision Song Contest is 70%. These probabilities are not derived from mathematical models or repeated experiments but instead reflect an individual‚Äôs degree of confidence in a given outcome.\nThis approach known as the subjective probability assignment is commonly used in decision-making under uncertainty, such as betting, economics, and risk assessment, where probabilities are assigned based on available information, intuition, or expert judgment rather than empirical frequency or formal statistical models.\nExample 9.1: Stability of Relative Frequencies\nHow many sixes can we expect if we roll a die 10 times? 1000 times? 10,000 times?\nLet event \\(A\\) represent rolling a six when tossing a fair die. The theoretical probability of rolling a six is:\n\\[P(A) = \\frac{1}{6} \\approx 0.167\\]\nThis suggests that in 10 rolls, we should expect approximately 1 to 2 sixes.\nTo illustrate this, nine people each rolled a die 10 times, producing the following results for the number of sixes obtained: \\(1, 3, 1, 2, 2, 5, 4, 0, 2\\)\nIn total, there were 90 rolls, with a total of: \\(1+3+1+2+2+5+4+0+2 = 20\\) occurrences of a six. The relative frequency of rolling a six in this experiment was: \\[\\frac{n_A}{n} = \\frac{20}{90} = 0.22\\]\nWhat happens if we roll the die many more times? Using a computer simulation, the die was rolled 1000, 10 000 and 100 000 times, resulting in 140, 1726, and 16 745 sixes. The results are summarized in Table¬†9.1.\n\n\nTable¬†9.1: Summary of rolling a fair six-sided die multiple times, showing how the relative frequency of rolling a six approaches the theoretical probability 0.167 (16.7%) as the number of trials increases.\n\n\n\nNumber of üé≤ Rolls\nNumber of Sixes\nRelative Frequency\n\n\n\n10\n2\n0.20 (20%)\n\n\n90\n20\n0.22 (22%)\n\n\n1,000\n140\n0.14 (14%)\n\n\n10,000\n1,726\n0.173 (17.3%)\n\n\n100,000\n16,745\n0.167 (16.75%)\n\n\n\n\n\n\nAs the number of trials increases, the observed relative frequency tends to stabilize around the theoretical probability. This illustrates the law of large numbers, which states that the empirical probability of an event converges to its theoretical probability as the number of trials increases. We‚Äôll return to this later on.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#uniform-probabilitis",
    "href": "prob-theory/what-is-prob.html#uniform-probabilitis",
    "title": "\n9¬† What is Probability?\n",
    "section": "\n9.4 Uniform Probabilitis",
    "text": "9.4 Uniform Probabilitis\nIn many practical situations, it is reasonable to assume that all outcomes of a random experiment are equally likely. This is known as a uniform probability model.\nFor an experiment where each outcome occurs with equal probability, the probability of an event \\(A\\) can be calculated as:\n\\[P(A) = \\frac{N_A}{N}\\]\nwhere:\n\n\n\\(N\\) is the total number of possible outcomes.\n\n\\(N_A\\) is the number of favorable outcomes (i.e., outcomes where event \\(A\\) occurs).\n\nThis applies to all situations where each outcome has the same probability of occurring.\nExample 9.2: Rolling Two Dice üé≤üé≤\nConsider rolling two fair six-sided dice. Since each die has six faces, there are a total of:\n\\[6 \\times 6 = 36\\]\npossible outcomes, all of which are assumed to be equally likely. This is illustrated below where each star represents a possible combination of each roll of the two dice:\n\n\n\n\n\n\n\n\nWhat is the probability of rolling two sixes?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nDefine event \\(A\\) as the event of rolling a six on both dice. Since there is only one way to get this outcome \\((6,6)\\) among the 36 possible outcomes, the probability of \\(A\\) is: \\[P(A) = \\frac{1}{36} \\]\nThus, the likelihood of rolling double sixes in a single roll is 1 in 36, or approximately 2.78%.\nBelow in Table¬†9.2, all possible outcome combinations and their corresponding probaiblitis are given. The probability of rolling double sixes in a single roll is given the last row of this table.\n\n\nTable¬†9.2: The probability distribution of sums when rolling two six-sided dice.\n\n\n\nSum\nNumber of Outcomes\nProbability\n\n\n\n2\n1\n1/36 (2.78%)\n\n\n3\n2\n2/36 (5.56%)\n\n\n4\n3\n3/36 (8.33%)\n\n\n5\n4\n4/36 (11.11%)\n\n\n6\n5\n5/36 (13.89%)\n\n\n7\n6\n6/36 (16.67%)\n\n\n8\n5\n5/36 (13.89%)\n\n\n9\n4\n4/36 (11.11%)\n\n\n10\n3\n3/36 (8.33%)\n\n\n11\n2\n2/36 (5.56%)\n\n\n12\n1\n1/36 (2.78%)",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#exercises",
    "href": "prob-theory/what-is-prob.html#exercises",
    "title": "\n9¬† What is Probability?\n",
    "section": "Exercises",
    "text": "Exercises\n\nConsider rolling two fair six-sided dice. What is the probability of rolling doubles (both dice show the same number)?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFrom earlier we know that the dice rolling follows a uniform probability model with \\(6 \\times 6 = 36\\) total possible outcomes.\nThe event ‚ÄòDoubles‚Äô occur when both dice show the same number:(1,1), (2,2), (3,3), (4,4), (5,5), (6,6), implying we have 6 outcomes of interest and the probability of this event is given by \\[P(\\text{doubles}) = \\frac{6}{36} = \\frac{1}{6} \\approx 0.167 \\text{ (16.7\\%)} \\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/count-rules.html",
    "href": "prob-theory/count-rules.html",
    "title": "10¬† Counting Rules",
    "section": "",
    "text": "10.1 With/Without Replacement? Order Matters or Not?\nNow that we have established the definition of probability, the next step is to determine how to count the number of possible outcomes in a structured way.\nIn many probability problems, we need to calculate the likelihood of an event occurring based on the number of favorable outcomes relative to the total number of possible outcomes. However, when dealing with large or complex sample spaces, manually listing all possible outcomes is impractical.\nTo efficiently compute probabilities, we rely on counting rules from combinatorics, which provide systematic methods to count possible outcomes. These include (see Chapter 2):\nOne key distinction in counting problems is whether selection is with or without replacement.\nAnother important factor is whether the order of selection matters when counting possibilities.\nBy understanding whether we are dealing with replacement or no replacement and ordered or unordered selection, we can use combinatorial techniques to systematically count possible outcomes in probability problems.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Counting Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/count-rules.html#withwithout-replacement-order-matters-or-not",
    "href": "prob-theory/count-rules.html#withwithout-replacement-order-matters-or-not",
    "title": "10¬† Counting Rules",
    "section": "",
    "text": "If a ball is drawn from an urn and returned before the next draw, then every selection remains independent, and the number of available choices does not change. This is known as drawing with replacement. For example, if an urn contains six balls, each ball has a \\(1/6\\) probability of being chosen, and this probability remains the same for every draw.\nIn contrast, drawing without replacement means that once a ball is selected, it is not returned to the urn. This affects the probability of subsequent draws. A common example is a lottery draw, where seven winning numbers are selected from a total of 35 balls. Since each number can only appear once, this is an example of drawing without replacement.\n\n\n\nIn some cases, order does matter. For example, imagine that a company requires employees to create five-letter security codes using the letters A, B, C, D, and E. Here the order of the letters celarly matters since password ABCDE is different from password ACBDE. This means the number of possible passwords availbale to choose from is determined by permutations, where order plays a role.\nIn other cases, order does not matter. Returning to the lottery example, suppose the machine selects the balls in the order 1,2,3,4,5,6,7. This sequence represents the same lottery result as if the balls had been drawn in the order 7,6,5,4,3,2,1. Since the order of selection does not change the outcome, this scenario follows combinations, where only the chosen numbers matter, not their sequence.\n\n\n\n10.1.1 Drawing with Replacement, Order Matters\n\nExample 9.3: PIN Code Generation\nConsider a four-digit PIN code, where each digit can be any number from 0 to 9. Since each digit is chosen independently and can be repeated, every unique sequence forms a distinct PIN code.\nThis is an example of permutations with repetition, where the total number of possible PIN codes is given by: \\[N^n\\] where:\n\n\\(N\\) is the number of available choices for each digit (10 digits: 0‚Äì9).\n\\(n\\) is the number of digits in the PIN code (4-digit code). Applying the formula: \\[10^4 = 10,000 \\]\n\nThis means there are 10,000 unique PIN codes that can be generated under these conditions.\n\n\nExample 9.4: Vehicle Registration Numbers in Sweden\nHow many possible vehicle registration numbers exist in Sweden? In Swedish license plates, a registration number consists of three letters followed by three digits. Since letters and digits can be repeated, this follows the rule of permutations with repetition.\nTo calculate the total number of possible license plates, we consider:\n\nThe first three characters are letters, chosen from 26 available options.\n\nThe last three characters are digits, chosen from 10 available options (0‚Äì9).\n\nUsing the multiplication principle, the total number of possible registration numbers is:\n\\[ 26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3 = 17,576,000 \\]\nThis means that Sweden can issue up to 17.58 million unique vehicle registration numbers under this system. The formaula is generally written as \\(N_1^{n_1} \\times N_2^{n_2}\\) where:\n\n\\(N_1 = 26\\) (number of available letters), \\(n_1 = 3\\) (three letters chosen).\n\n\\(N_2 = 10\\) (number of available digits), \\(n_2 = 3\\) (three digits chosen).\n\n\n\n\n10.1.2 Drawing with Replacement, Ignoring Order\n\nExample 9.5: Selecting Ice Cream Flavors üç¶\nImagine an ice cream shop that offers six different flavors. A customer selects three scoops of ice cream, where:\n\nThe same flavor can be chosen multiple times (replacement).\n\nThe order of the scoops does not matter‚Äî choosing (vanilla, chocolate, vanilla) is the same as (chocolate, vanilla, vanilla).\n\nSince order is ignored, but repetition is allowed, we calculate the number of possible selections using combinations with replacement, given by the formula: \\[\\binom{N + n - 1}{n} = \\frac{(N + n - 1)!}{n!(N - 1)!} \\]\nwhere:\n\n\\(N = 6\\) (number of available flavors).\n\n\\(n = 3\\) (number of scoops selected).\n\nApplying the formula:\n\\[ \\binom{6+3-1}{3} = \\binom{8}{3} = \\frac{8!}{3!(5!)} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56 \\]\nThus, there are 56 different ways to choose three scoops of ice cream when order does not matter, but flavors can be repeated.\n\n\n\n10.1.3 Drawing without Replacement, Order Matters\n\nExample 9.6: Finalist Selection in ESC üé§üé∂\nIn the semi-final rounds of the Eurovision Song Contest, five countries have reached the last stage. The final ranking must be determined, where each country is assigned a unique position from 1st place to 5th place.\nSince the order of ranking is important, we need to determine how many different ways the top five positions can be arranged. This follows the permutation rule, as once a country‚Äôs submission is assigned a position, it cannot be placed elsewhere. The total number of possible rankings is calculated as: \\[5 \\times 4 \\times 3 \\times 2 \\times 1 = 5! = 120 \\]\nThus, there are 120 possible ways to assign the final rankings to the five finalists.\nThis follows the principle of permutations without replacement, meaning that each finalist is placed in a unique ranking, and no two countries can hold the same position.\n\n\n\n10.1.4 Drawing without Replacement, Ignoring Order\n\nExample 9.7: Poker Hands üé¥\nIn a standard game of five-card poker, a player is dealt five random cards from a standard deck of 52 playing cards. Since:\n\nThe order of the cards does not matter (a hand with A‚ô† K‚ô† Q‚ô† J‚ô† 10‚ô† is the same regardless of the order drawn).\nCards are drawn without replacement (once a card is drawn, it cannot be selected again), we calculate the total number of different poker hands using combinations without replacement: \\[\\binom{52}{5} = \\frac{52!}{(52-5)!5!} = \\frac{52 \\times 51 \\times 50 \\times 49 \\times 48}{5!} = 2 598 960 \\]\nThus, there are 2 598 960 unique five-card poker hands in a standard deck.\n\nWhat is the probability of getting a flush on the first draw?\nA flush in poker means that all five cards in the hand belong to the same suit (‚ô†, ‚ô•, ‚ô¶, or ‚ô£). We define event \\(A\\) as the event of being dealt a flush directly, meaning that all five cards in the hand belong to the same suit (‚ô†, ‚ô•, ‚ô¶, or ‚ô£).\nTo compute the probability \\(A\\), consider that:\n\nIf we focus on only hearts, there are 13 hearts in the deck, and we need to choose 5 of them: \\[\\binom{13}{5} = \\frac{13!}{(13-5)!5!} = 1287 \\]\nThe same calculation applies for the other three suits (spades, diamonds, and clubs), so the total number of flush hands is: \\[4 \\times 1287 = 5148 \\]\n\nSince all poker hands are equally likely, the probability of being dealt a flush is: \\[P(A) = \\frac{5148}{2598960} \\approx 0.00198\\]\nThis means that the probability of being dealt a flush on the first draw is approximately 0.198%.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Counting Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/count-rules.html#exercises",
    "href": "prob-theory/count-rules.html#exercises",
    "title": "10¬† Counting Rules",
    "section": "Exercises",
    "text": "Exercises\n\nA full house in poker consists of three cards of one rank and two cards of another (e.g., Q‚ô† Q‚ô• Q‚ô¶ 7‚ô£ 7‚ô¶). What is the probability of getting a full house on the first draw?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSince the order does not matter, and cards are drawn without replacement, we use combinations to determine the number of possible full house hands.\nSelecting one of 13 ranks for the three-of-a-kind: \\(\\binom{13}{1} = 13\\). Choosing three suits out of four for that rank: \\(\\binom{4}{3} = 4\\).\nTotal ways to select the three-of-a-kind: \\[13 \\times 4 = 52 \\]\nSelecting one of 12 remaining ranks for the pair: \\(\\binom{12}{1} = 12\\). Choosing two suits out of four for that rank: \\(\\binom{4}{2} = 6\\). Total ways to select the pair: \\[12 \\times 6 = 72 \\]\nMultiplying both parts together we get: \\[52 \\times 72 = 3 744 \\]\nThus, there are 3 744 unique full house hands in a standard deck.\nSince we already know that there are 2 598 960 total poker hands, the probability of being dealt a full house is (defined as event \\(A\\)):\n\\[P(A) = \\frac{3744}{2598960} \\approx 0.00144\\]\nThis means the probability of being dealt a full house on the first draw is 0.144%.\n\n\n\n\nA teacher randomly arranges 6 students in a line for a class photo. Each student is assigned a unique position.\n\n\n\nHow many different ways can the 6 students be arranged in a line?\nWhat is the probability that a specific student (A) is in the first position?\nWhat is the probability that student A is first and student B is second in the lineup?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThere are \\(P(6,6) = 6! = 6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1 = 720\\) different ways to arrange the students in a line (see Chapter 2 exercises for more details)\nSince all arrangements are equally likely, student A can be in any of the 6 positions. If we fix A in the first position, the remaining 5 students can be arranged freely: \\[5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\]\nThe probability of A being first is then given by \\[P(A)  = \\frac{120}{720} = \\frac{1}{6} \\approx 0.167 \\text{ (16.7\\%)}\\]\nIf A is fixed in the first position, there are 5 students remaining. If B is fixed in the second position, there are 4 students left to be arranged: \\[4! = 4 \\times 3 \\times 2 \\times 1 = 24\\]\nThe probability of A being first and B being second is then given by: \\[P(B) = \\frac{24}{720} = \\frac{1}{30} \\approx 0.0333 \\text{ (3.33\\%)}\\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Counting Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html",
    "href": "prob-theory/prob-rules.html",
    "title": "\n11¬† Probability Rules\n",
    "section": "",
    "text": "11.1 The Complement Rule\nWhile some probabilities can be determined directly from counting outcomes, others require probability rules that help us break down complex situations. Several fundamental rules govern probability calculations, ensuring consistency and logical reasoning:\nWe‚Äôll cover these in more details and examples in the following.\nhe complement rule states that if an event \\(A\\) has probability \\(P(A)\\), then the probability that \\(A\\) does not occur is:\\[P(\\overline{A}) = 1 - P(A)\\]\nThis rule is particularly useful when calculating the probability of ‚Äúat least one‚Äù occurrences by considering the opposite event. See Figure¬†11.1.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#the-complement-rule",
    "href": "prob-theory/prob-rules.html#the-complement-rule",
    "title": "\n11¬† Probability Rules\n",
    "section": "",
    "text": "Figure¬†11.1: The complement of event \\(A\\).\n\n\n\nExample 11.1: Deck of Cards\nDetermine the probability of drawing a ‚ô¶ (diamond), ‚ô• (heart), or ‚ô† (spade) when randomly selecting a card from a standard deck of 52 cards.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe sample space consists of all 52 cards, so: \\(\\Omega = \\{1, 2, 3, \\dots, 52\\}\\)\nLet \\(A\\) be the event of drawing a ‚ô¶, ‚ô•, or ‚ô†. The complement of \\(A\\), denoted as \\(\\overline{A}\\), is the event of drawing a ‚ô£ (club). Since there are 13 clubs in a deck, the probability of \\(\\overline{A}\\) is:\\[P(\\overline{A}) = \\frac{13}{52}\\]\nUsing the complement rule we get that: \\[P(A) = 1 - P(\\overline{A}) = 1 - \\frac{13}{52} = \\frac{39}{52} = \\frac{3}{4}\\] Thus, the probability of drawing a ‚ô¶, ‚ô•, or ‚ô† is 3/4 (75%).",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#the-addition-rule",
    "href": "prob-theory/prob-rules.html#the-addition-rule",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.2 The Addition Rule",
    "text": "11.2 The Addition Rule\nThe addition rule helps compute the probability of the union of two events (see Figure¬†11.2):\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\n\n\n\n\nFigure¬†11.2: The union of events \\(A\\) and \\(B\\).\n\n\n\nIf \\(A\\) and \\(B\\) are mutually exclusive (disjoint), then it follows that \\[P(A \\cup B) = P(A) + P(B)\\] since there is no intersection between the two events.\nExample 11.2: Dice Roll üé≤\nDetermine the probability of rolling an even number or a number greater than three when rolling a fair six-sided die.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe sample space consists of all possible outcomes of a die roll:\\[\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\]\nDefine the events:\n\n\n\\(A\\) = rolling an even number: \\(A = \\{2, 4, 6\\}\\)\n\n\n\\(B\\) = rolling a number greater than three: \\(B = \\{4, 5, 6\\}\\)\n\nThe intersection of these events (\\(A \\cap B\\)) = numbers that are both even and greater than three: \\[A \\cap B = \\{4, 6\\}\\]\n\n\nThe probabilities are \\[P(A) = \\frac{3}{6}, \\quad P(B) = \\frac{3}{6}, \\quad P(A \\cap B) = \\frac{2}{6}\\]\nUsing the addition rule \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\] we get that \\[P(A \\cup B) = \\frac{3}{6} + \\frac{3}{6} - \\frac{2}{6} = \\frac{4}{6} \\]\nThus, the probability of rolling either an even number or a number greater than three is \\(\\frac{4}{6}\\) or approximately 0.667 (66.7%).\n\n\n\nExample 11.2: Product Defects\nIn the manufacturing process of a product, two types of defects, \\(A\\) and \\(B\\), can occur. Sometimes both defects appear together. We are given the probabilities:\\[P(A) = 0.01, \\quad P(B) = 0.02, \\quad P(A \\cap B) = 0.005\\]\na. Determine the probability that a product has at least one of the two defects.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are looking for the union of the events \\(A\\) and \\(B\\): \\[P (A \\cup  B) = 0.01 + 0.02 ‚àí 0.005 = 0.025 = 2.5\\%\\]\n\n\n\n\nWhat is the probability that a product will be defect-free?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are looking for the complement of the union of the events \\(A\\) and \\(B\\): \\[P (\\overline{A \\cup B}) = 1 ‚àí P (A \\cup B) = 1 ‚àí 0.025 = 0.975 = 97.5\\%\\]\n\n\n\n\nWhat is the probability that a product will have exactly one defect?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are looking for the shaded area in Figure¬†11.3 which is given by \\[P(A \\cup  B) ‚àí P (A \\cap B) = 0.025 ‚àí 0.005 = 0.02 = 2\\%\\]\n\n\n\n\n\n\nFigure¬†11.3: The area shaded corresponds to exactly one defect.\n\n\n\n\n\n\n\n11.2.1 The Union of Three or More Events\nTo compute the probability of the union of three events \\(A\\), \\(B\\), and \\(C\\) as shown in Figure¬†11.4 we use the generalized addition rule:\n\\(\\qquad \\qquad \\qquad  P(A \\cup B \\cup C) = P(A) + P(B) + P(C)\\)\n\\[\\quad \\qquad \\qquad  - P(A \\cap B) - P(A \\cap C) - P(B \\cap C)\\]\n\\[+P(A \\cap B \\cap C)\\]\nThis formula ensures that overlapping probabilities are not double-counted when summing individual event probabilities.\n\n\n\n\n\n\nFigure¬†11.4: The union of three events.\n\n\n\nTo generalize it even further for \\(n\\) events \\(A_1, A_2, \\ldots, A_n\\), the probability of their union follows the principle of inclusion-exclusion:\n\\(P\\left(\\bigcup_{i=1}^{n} A_i \\right) =\n\\sum_{i=1}^{n} P(A_i) -\n\\sum_{1 \\leq i &lt; j \\leq n} P(A_i \\cap A_j)\\)\n\\[\n\\qquad + \\sum_{1 \\leq i &lt; j &lt; k \\leq n} P(A_i \\cap A_j \\cap A_k)\n- \\dots + (-1)^{n+1} P(A_1 \\cap A_2 \\cap \\dots \\cap A_n)  \n\\] This pattern continues, alternating between adding and subtracting intersections of increasing size.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#conditional-probability",
    "href": "prob-theory/prob-rules.html#conditional-probability",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.3 Conditional Probability",
    "text": "11.3 Conditional Probability\nImagine you‚Äôre waiting for a pizza delivery. Normally, the probability of the delivery driver being on time (event \\(B\\)) might not be great. But then you receive a text message saying, ‚ÄúYour order is on the way!‚Äù (event \\(A\\) has occurred). Now that you have extra information, your estimate of \\(P(B)\\) should change, right? That‚Äôs the essence of conditional probability; updating what we know when we gain new insight.\nWe originally wanted to find the probability of \\(B\\) happening, i.e., \\(P(B)\\). But now we‚Äôve been given a game-changing update: \\(A\\) has happened. That means our world is now limited to the subset of outcomes where \\(A\\) is true. In other words, we‚Äôre no longer looking at the whole sample space \\(\\Omega\\) - our new reality is just \\(A\\)!\nSo, the updated probability of \\(B\\) given that \\(A\\) has occurred, the so called conditional probability of \\(B\\) given \\(A\\), written as \\(P(B \\mid A)\\), is calculated using:\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)}\n\\]\nwhere \\(P(A) &gt; 0\\) (because if \\(A\\) didn‚Äôt happen, there‚Äôs no reason to update anything). This formula quantifies how the probability of \\(B\\) changes when we have additional information that \\(A\\) has occurred.\nConditional probability is like getting insider information:\n\nDid your team win the game? If they were leading at halftime, the probability changes.\n\nIs your package arriving today? If it was shipped yesterday, chances are better.\n\nAre you likely to pass your exam? If you‚Äôve studied, your odds are much higher!\n\nExample 11.3: Conditional Probability\nWe are given a population of individuals where:\n\n40% are men\n\n60% are women\n\nFurthermore, we know that:\n\n28% of the population are smokers, of which 8% are male and 20% are female\n\nA person is randomly selected from the population.\nWe are interested in finding the following conditional probabilities:\n\nWhat is the probability that the person is a smoker, given that the person is male?\nWhat is the probability that the person is a smoker, given that the person is female?\nWhat is the probability that the person is female, given that the person is a smoker?\n\nWe define the following events:\n\n\n\\(A\\): the person is a woman\n\n\n\\(\\bar{A}\\): the person is a man\n\n\n\\(B\\): the person is a smoker\n\n\n\\(\\bar{B}\\): the person is a non-smoker\n\nand the probabilities given for the events:\n\n\\(P(A) = 0.6\\)\n\\(P(\\bar{A}) = 0.4\\)\n\\(P(B) = 0.28\\)\n\\(P(\\bar{B}) = 0.72\\)\n\\(P(A \\cap B) = 0.20\\)\n\\(P(\\bar{A} \\cap B) = 0.08\\)\n\nTo help us calculate conditional probabilities, we construct a contingency table that shows joint and marginal probabilities. We fill in the parts given to us:\n\n\n\nWoman (\\(A\\))\nMan (\\(\\bar{A}\\))\nTotal\n\n\n\nSmoker (\\(B\\))\n0.20\n0.08\n0.28\n\n\nNon-smoker (\\(\\bar{B}\\))\n?\n?\n0.72\n\n\nTotal\n0.60\n0.40\n1.00\n\n\n\nTo fill in the remaining cells, we use subtraction: \\[P(A \\cap \\bar{B}) = P(A) - P(A \\cap B) = 0.60 - 0.20 = 0.40\\] \\[P(\\bar{A} \\cap \\bar{B}) = P(\\bar{A}) - P(\\bar{A} \\cap B) = 0.40 - 0.08 = 0.32\\]\nThe complete table is then given below:\n\n\n\n\n\n\n\n\n\nWoman (\\(A\\))\nMan (\\(\\bar{A}\\))\nTotal\n\n\n\nSmoker (\\(B\\))\n0.20\n0.08\n0.28\n\n\nNon-smoker (\\(\\bar{B}\\))\n0.40\n0.32\n0.72\n\n\nTotal\n0.60\n0.40\n1.00\n\n\n\nWith the help of this table, and the equation for conditional probability above, we can now find the asked probabilities (a)‚Äì(c).\n\n\n\n\n\n\nSolution (a)\n\n\n\n\n\n\nSmoker given man:\\[P(B \\mid \\bar{A}) = \\frac{P(B \\cap \\bar{A})}{P(\\bar{A})}\n= \\frac{0.08}{0.40} = 0.2\\] So, the probability that a person is a smoker given that he is a man is 20%.\n\n\n\n\n\n\n\n\n\n\nSolution (b)\n\n\n\n\n\nSmoker given woman: \\[\n   P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{0.20}{0.60} = \\frac{1}{3} \\approx 0.333\n\\]\n\n\n\n\n\n\n\n\n\nSolution (c)\n\n\n\n\n\nWoman given smoker: \\[\n   P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{0.20}{0.28} \\approx 0.714\n\\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#the-multiplication-rule",
    "href": "prob-theory/prob-rules.html#the-multiplication-rule",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.4 The Multiplication Rule",
    "text": "11.4 The Multiplication Rule\nFrom the definition of conditional probability, we can derive what is known as the multiplication rule.\nFor two events \\(A\\) and \\(B\\), the following holds:\\[\nP(A \\cap B) = P(A) \\cdot P(B \\mid A)\n\\]\nThis rule is particularly useful when determining the joint probability of two events that are not independent.\nExample 11.4: Defective Items\nConsider a batch of 100 items, out of which 5 are defective.\nWe randomly select one item from the 100. Then, without replacing the first, we randomly select another from the remaining 99 items.\nWe want to find the probability that both selected items are defective.\nDefine the events:\n\n\n\\(A\\): ‚ÄúThe first selected item is defective‚Äù\n\n\n\\(B\\): ‚ÄúThe second selected item is defective‚Äù\n\nWe are interested in computing \\(P(A \\cap B)\\) and we know that \\(P(A) = \\frac{5}{100}\\) and \\(P(B \\mid A) = \\frac{4}{99}\\) (since one defective item has been removed, 4 defective remain out of 99 items.) Now we apply the multiplication rule: \\[P(A \\cap B) = P(A) \\cdot P(B \\mid A) = \\frac{5}{100} \\cdot \\frac{4}{99} = \\frac{20}{9900} = \\frac{1}{495}\\] Alternatively, we could have used combinatorics to solve the problem. Can you see how?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe want the probability of choosing 2 defective items out of 5, from a total of 100:\n\\[P(\\text{both defective}) = \\frac{\\binom{5}{2} \\cdot \\binom{95}{0}}{\\binom{100}{2}} = \\frac{10 \\cdot 1}{4950} = \\frac{1}{495}\\]\nSo, both the multiplication rule and combinatorics give us the same result: the probability is \\(\\frac{1}{495}\\)",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#independence",
    "href": "prob-theory/prob-rules.html#independence",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.5 Independence",
    "text": "11.5 Independence\nTwo events \\(A\\) and \\(B\\) are said to be independent if:\n\\[P(A \\cap B) = P(A) \\cdot P(B)\\]\nThis also implies:\n\\[P(A \\mid B) = P(A \\mid \\bar{B}) = P(A)\\]\nIn other words, knowing that \\(B\\) has occurred (or not) tells us nothing about whether \\(A\\) will happen. This follows from the definition of conditional probability:\n\\[P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A) \\cdot P(B)}{P(B)} = P(A)\\]\n\nIntuition: If you‚Äôre flipping a coin, the result of the second flip doesn‚Äôt care what happened on the first flip!\n\nExample 11.5: Rolling Dice üé≤\nLet‚Äôs roll a standard die twice.\n\nLet \\(A\\) be ‚Äúgetting a 6 on the first roll‚Äù\nLet \\(B\\) be ‚Äúgetting a 6 on the second roll‚Äù\n\nThese events are independent, because one roll doesn‚Äôt affect the other. This means that \\[P(A) = \\frac{1}{6} \\ \\textrm{ and } \\ P(B) = \\frac{1}{6}\\]\nTherefore: \\[P(\\text{6 on both rolls}) = P(A \\cap B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36}\\] Note that if \\(A\\) and \\(B\\) are independent, then the following events are also indepndent:\n\n\n\\(A\\) and \\(\\bar{B}\\)\n\n\n\\(\\bar{A}\\) and \\(B\\)\n\n\n\\(\\bar{A}\\) and \\(\\bar{B}\\)\n\n\nIn other words, independence spreads across complements!\nLet‚Äôs calculate the probability of not getting a 6 in either roll.\n\n\n\\(\\bar{A}\\): Not getting a 6 on the first roll with probability \\(P(\\bar{A}) = \\frac{5}{6}\\)\n\n\n\\(\\bar{B}\\): Not getting a 6 on the second roll with probability \\(P(\\bar{B}) = \\frac{5}{6}\\)\n\n\nSince they are independent events, the probability of their intersection is given by\n\\[P(\\bar{A} \\cap \\bar{B}) = \\frac{5}{6} \\cdot \\frac{5}{6} = \\frac{25}{36}\\]\n\n\n\n\n\n\nNote\n\n\n\nDon‚Äôt confuse independence with mutual exclusivity ‚Äî they‚Äôre very different! Exercises 1 and 2 below illlutrate this.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#the-law-of-total-probability",
    "href": "prob-theory/prob-rules.html#the-law-of-total-probability",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.6 The Law of Total Probability",
    "text": "11.6 The Law of Total Probability\nSometimes, we want to calculate the probability of a complex event \\(B\\), but it‚Äôs hard to compute directly. However, we might know the conditional probabilities of \\(B\\) given simpler events: \\(P(B \\mid A_1), P(B \\mid A_2), ..., P(B \\mid A_k)\\)\nIf \\(A_1, A_2, ..., A_k\\) are:\n\n\nmutually exclusive: \\(A_i \\cap A_j = \\emptyset\\) for \\(i \\ne j\\)\n\n\ncollectively exhaustive: \\(A_1 \\cup A_2 \\cup \\dots \\cup A_k = S\\)\n\n\nThen we can piece things together with the Law of Total Probability.\nLet \\(A_1, A_2, ..., A_k\\) be mutually exclusive and collectively exhaustive events. Then:\n\\[\nP(B) = \\sum_{i=1}^{k} P(A_i) \\cdot P(B \\mid A_i)\n\\]\nWe break down \\(B\\) based on each case \\(A_i\\), multiply by the probability of that case, then add them all up. Think of it like calculating total outcomes across different ‚Äúpaths‚Äù or scenarios. This is illustrated in Figure¬†11.5 for \\(k=7\\).\n\n\n\n\n\n\nFigure¬†11.5: Venn diagram of the law of total. probability\n\n\n\nExample 11.6: Picking Pupils\nThere are 3 school classes:\n\nClass 1: 10 boys, 10 girls\n\nClass 2: 8 boys, 12 girls\n\nClass 3: 6 boys, 14 girls\n\nA class is chosen at random, then a pupil is picked randomly from that class. What‚Äôs the probability the pupil is a girl?\nTo solve this, we define the following events:\n\n\n\\(A_1\\) = Class 1\n\n\n\\(A_2\\) = Class 2\n\n\n\\(A_3\\) = Class 3\n\n\n\\(B\\) = Student is a girl\n\nSince all classes are equally likely we get the following: \\[P(A_1) = P(A_2) = P(A_3) = \\frac{1}{3}\\]\\[P(B \\mid A_1) = \\frac{10}{20} = 0.5\\] \\[P(B \\mid A_2) = \\frac{12}{20} = 0.6\\] \\[P(B \\mid A_3) = \\frac{14}{20} = 0.7\\]\nNow we apply the law of total probability:\n\\[\nP(B) = \\frac{1}{3} \\cdot 0.5 + \\frac{1}{3} \\cdot 0.6 + \\frac{1}{3} \\cdot 0.7 = \\frac{0.5 + 0.6 + 0.7}{3} = \\frac{1.8}{3} = 0.6\n\\]\nThus, there‚Äôs a 60% chance the selected pupil is a girl.\nExample 11.7: Drawing Balls ‚ö´‚ö™\nYou can also illustrate the law of total probability using tree diagrams, which is used in this example. Assume draw two balls without replacement from a box of 7 black and 10 white balls.\nThe tree below illustrates the four possible outcomes of the two draws, along with their probabilities.\n\n\n\nTree\nStart\nStartA\nAP(A) = 7/17Start-&gt;A\n7/17Abar\nAÃÑP(AÃÑ) = 10/17Start-&gt;Abar\n10/17AB\nBP(B|A) = 6/16A-&gt;AB\n6/16ABarB\nBÃÑP(BÃÑ|A) = 10/16A-&gt;ABarB\n10/16AbarB\nBP(B|AÃÑ) = 7/16Abar-&gt;AbarB\n7/16AbarBarB\nBÃÑP(BÃÑ|AÃÑ) = 9/16Abar-&gt;AbarBarB\n9/16AB_lbl\nP(A)¬∑P(B|A)ABarB_lbl\nP(A)¬∑P(BÃÑ|A)AbarB_lbl\nP(AÃÑ)¬∑P(B|AÃÑ)AbarBarB_lbl\nP(AÃÑ)¬∑P(BÃÑ|AÃÑ)\n\n\n\nWe clarify each step now. Let:\n\n\n\\(A\\) = First ball is black\n\n\n\\(\\bar{A}\\) = First ball is white\n\n\n\\(B\\) = Second ball is black\n\nWe want to compute \\(P(B)\\) using total probability. First, we calculate each part:\n\\[P(A) = \\frac{7}{17}\\] since 7 out of 17 are black, and the complement is thus \\[P(\\bar{A}) = \\frac{10}{17}\\]\nIf the first is black we have that \\(P(B \\mid A) = \\frac{6}{16}\\), and one black is removed. If the first is white \\(P(B \\mid \\bar{A}) = \\frac{7}{16}\\), and all black balls are still there.\nNow apply the law of total probability:\n\\[\nP(B) = P(A) \\cdot P(B \\mid A) + P(\\bar{A}) \\cdot P(B \\mid \\bar{A})\n\\]\n\\[\nP(B) = \\frac{7}{17} \\cdot \\frac{6}{16} + \\frac{10}{17} \\cdot \\frac{7}{16}\n\\]\nSome simplifying leads to: \\[\nP(B) = \\frac{42}{272} + \\frac{70}{272} = \\frac{112}{272} = \\frac{7}{17}\n\\]\nThe probability of the second ball being black is again \\(\\frac{7}{17}\\); the same as the original proportion of black balls!",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#bayes-theorem",
    "href": "prob-theory/prob-rules.html#bayes-theorem",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.7 Bayes‚Äô Theorem",
    "text": "11.7 Bayes‚Äô Theorem\nBayes‚Äô Theorem is a fundamental tool in probability theory, especially when we want to reverse the direction of a conditional probability. Suppose we have a collection of events \\(A_1, A_2, ..., A_n\\) that are mutually exclusive; no two can happen at the same time, and together these events cover the entire sample space. That means one and only one of these events will occur.\nNow assume we know the probability of each of these events, \\(P(A_1), P(A_2), ..., P(A_n)\\), and we also know the conditional probabilities of another event \\(B\\) given each \\(A_i\\), that is, \\(P(B \\mid A_1), ..., P(B \\mid A_n)\\). Our goal is to compute the probability that \\(A_i\\) is true given that \\(B\\) has occurred, written as \\(P(A_i \\mid B)\\).\nBayes‚Äô Theorem gives us exactly this:\n\\[\nP(A_i \\mid B) = \\frac{P(A_i) \\cdot P(B \\mid A_i)}{P(B)}\n\\]\nThe denominator, \\(P(B)\\), is calculated using the law of total probability:\n\\[\nP(B) = \\sum_{i=1}^{k} P(A_i) \\cdot P(B \\mid A_i)\n\\]\nExample 11.8: Genetics and Thumb Length\nImagine a person may or may not carry a certain gene that causes a disease to develop before the age of 40. However, we cannot directly observe whether someone carries the gene. What we can observe is whether they have long thumbs; a trait which appears more often in people who do have the gene.\nLet us define the events as follows:\\(A\\) is the event that the person has the gene (and will eventually develop the disease), and \\(\\bar{A}\\) is the event that they do not. Let \\(B\\) be the event that the person has long thumbs, and \\(\\bar{B}\\) that they have short thumbs.\nWe are given the following probabilities:\nThe probability that someone carries the gene is \\(P(A) = 0.01\\). Among those who carry the gene, 90% have long thumbs, so \\(P(B \\mid A) = 0.9\\). For those who do not carry the gene, 40% have long thumbs, meaning \\(P(B \\mid \\bar{A}) = 0.4\\).\nNow, imagine someone is 16 years old and notices they have long thumbs. What is the probability that they carry the gene for the disease?\nWe want to compute \\(P(A \\mid B)\\), the probability that someone has the gene, given they have long thumbs. Using Bayes‚Äô Theorem, we write:\n\\[\nP(A \\mid B) = \\frac{P(A) \\cdot P(B \\mid A)}{P(A) \\cdot P(B \\mid A) + P(\\bar{A}) \\cdot P(B \\mid \\bar{A})}\n\\]\nSubstituting the known values:\n\n\\(P(A) \\cdot P(B \\mid A) = 0.01 \\cdot 0.9 = 0.009\\)\n\\(P(\\bar{A}) \\cdot P(B \\mid \\bar{A}) = 0.99 \\cdot 0.4 = 0.396\\)\n\\(P(B) = 0.009 + 0.396 = 0.405\\)\n\nThus,\n\\[\nP(A \\mid B) = \\frac{0.009}{0.405} \\approx 0.0222\n\\]\nThis tells us that the probability a person with long thumbs carries the disease gene is about 2.2%.\nExample 11.9: Finding the Toilet\nNow let‚Äôs turn to a more lighthearted but equally instructive example. Imagine you are at a party in a large, unfamiliar house. You‚Äôre searching for the toilet, which we‚Äôll call \\(T\\). You see three doors in front of you, each leading to a different room: \\(R_1\\), \\(R_2\\), and \\(R_3\\). You don‚Äôt know which one to pick, so you choose randomly.\nOnce inside one of these rooms, you find several doors. In room \\(R_1\\), there are two more doors, one of which leads to the bathroom. In \\(R_2\\), there are four doors, again only one of which leads to \\(T\\). In \\(R_3\\), three doors are present, and two of them lead to \\(T\\).\nYou may only move forward, that is, you pick one of the three initial rooms and then try one of its doors.\n\nWhat is the probability that you reach the bathroom?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSince you choose one of the three rooms at random, the probability of entering any specific room is \\(1/3\\). Given the room, the conditional probabilities of finding the bathroom are:\n\n\n\\(P(T \\mid R_1) = 1/2\\)\n\n\n\\(P(T \\mid R_2) = 1/4\\)\n\n\\(P(T \\mid R_3) = 2/3\\)\n\nUsing the law of total probability, we compute:\n\\[\nP(T) = \\frac{1}{3} \\cdot \\frac{1}{2} + \\frac{1}{3} \\cdot \\frac{1}{4} + \\frac{1}{3} \\cdot \\frac{2}{3}\n= \\frac{1}{6} + \\frac{1}{12} + \\frac{2}{9}\n= \\frac{6}{36} + \\frac{3}{36} + \\frac{8}{36} = \\frac{17}{36} \\approx 0.472\n\\]\nSo you have approximately a 47.2% chance of finding the bathroom.\n\n\n\n\nYou found the bathroom, but which room did you use?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet‚Äôs now suppose you did find the bathroom but forgot which room you entered first. What‚Äôs the probability you entered through say room \\(R_2\\)?\nThis is another great application of Bayes‚Äô Theorem. We now want \\(P(R_2 \\mid T)\\), the probability that you passed through \\(R_2\\) given that you found the bathroom.\nAccording to Bayes‚Äô Theorem:\n\\[\nP(R_2 \\mid T) = \\frac{P(R_2) \\cdot P(T \\mid R_2)}{P(T)} = \\frac{\\frac{1}{3} \\cdot \\frac{1}{4}}{\\frac{17}{36}} = \\frac{1}{12} \\cdot \\frac{36}{17} = \\frac{3}{17} \\approx 0.176\n\\]\nSo there‚Äôs about a 17.6% chance that your successful journey to the bathroom started through \\(R_2\\). Similarly: \\[\nP(R_1 \\mid T) =  \\frac{P(R_1) \\cdot P(T \\mid R_1)}{P(T)} = \\frac{\\frac{1}{3} \\cdot \\frac{1}{2}}{\\frac{17}{36}} = \\frac{1}{6} \\cdot \\frac{36}{17} = \\frac{6}{17} \\approx 0.353\n\\] and \\[\nP(R_3 \\mid T) = \\frac{P(R_3) \\cdot P(T \\mid R_3)}{P(T)} = \\frac{\\frac{1}{3} \\cdot \\frac{2}{3}}{\\frac{17}{36}} = \\frac{2}{9} \\cdot \\frac{36}{17} = \\frac{8}{17} \\approx 0.471\n\\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#exercises",
    "href": "prob-theory/prob-rules.html#exercises",
    "title": "\n11¬† Probability Rules\n",
    "section": "Exercises",
    "text": "Exercises\n\nThe probability of two events \\(A\\) and \\(B\\) are given by \\(P(A) = 0.5\\) and \\(P(B) = 0.2\\). What‚Äôs \\(P(A \\cap B)\\) if\n\n\n\\(A\\) and \\(B\\) are mutually exclusive events\n\\(A\\) and \\(B\\) are independent events\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nIf \\(A\\) and \\(B\\) can‚Äôt happen together, then \\(P(A \\cap B) = \\emptyset = 0\\).\nIf \\(A\\) and \\(B\\) are independent, then \\(P(A \\cap B) = P(A) \\cdot P(B) = 0.5 \\cdot 0.2 = 0.1\\).\n\n\n\n\n\nThe probability of two events \\(A\\) and \\(B\\) are given by \\(P(A) = 0.5\\) and \\(P(B) = 0.2\\). What is \\(P(A \\cup B)\\), the probability that at least one happens, if\n\n\n\\(A\\) and \\(B\\) are mutually exclusive events\n\\(A\\) and \\(B\\) are independent events\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nIf \\(A\\) and \\(B\\) are mutually exclusive events, then \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B) = 0.5 + 0.2 - 0 = 0.7\\).\nIf \\(A\\) and \\(B\\) are independent, then \\(P(A \\cup B) = 0.5 + 0.2 - 0.1 = 0.6\\).\n\n\n\n\n\nAssume we know the following: \\(P(A) = 0.6\\), \\(P(A \\mid B) = 0.75\\), \\(P(B \\mid A) = 0.5\\). What is the probability that \\(B\\) will happen?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFind \\(P(A \\cap B)\\) using the conditional probability rule:\n\\[P(A \\cap B) = P(A) \\cdot P(B \\mid A) = 0.6 \\cdot 0.5 = 0.3\\]\nThen use the definition of conditional probability:\n\\[P(B) = \\frac{P(A \\cap B)}{P(A \\mid B)} = \\frac{0.3}{0.75} = 0.4\\]\n\n\n\n\nAnna and Bob go downhill skiing. The probability that Anna falls is \\(1/2\\), while the probability that Bob falls is \\(1/3\\). The probability that both fall is \\(1/4\\). What is the probability that both make it safely down the slope?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet:\n\n\n\\(A\\) = Anna falls\n\n\\(B\\) = Bob falls\n\nWe want the probability that both Anna and Bob make it down the slope safely \\[P(\\bar{A} \\cap \\bar{B}) = P(\\overline{A \\cup B}) =  1 - P(A \\cup B)\\]\n\\[P(\\bar{A} \\cap \\bar{B})  = 1 - P(A \\cup B)\n= 1 - [P(A) + P(B) - P(A \\cap B)] \\] \\[ = 1 - \\left(\\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4}\\right) = \\frac{5}{12}\\]\n\n\n\n\nA tech company has found that:\n\n\n40% of its users are premium members (\\(P(M) = 0.4\\))\n80% of premium users log in daily (\\(P(D \\mid M) = 0.8\\))\n\nWhat is the probability that a randomly chosen user is a premium member who logs in daily?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the mnultiplication rule, we get that\n\\[\nP(M \\cap D) = P(M) \\cdot P(D \\mid M)\n\\]\nSubstitute the values:\n\\[\nP(M \\cap D) = 0.4 \\cdot 0.8 = 0.32\n\\]\nThus 32% of users are both premium and daily-active.\n\n\n\n\nIn a survey of 300 students:\n\n\n180 said they drink coffee\n\n150 said they drink tea\n\n60 said they drink both coffee and tea\n\nWhat is the probability that a randomly chosen student drinks coffee (\\(C\\)) or tea (\\(T\\))?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are seeking \\(P(C \\cup T)\\): the probability that a student drinks coffee OR tea. We can use the addition rule:\n\\[\nP(C \\cup T) = P(C) + P(T) - P(C \\cap T)\n\\]\nFirst we convert counts into probabilities:\n\n\n\\(P(C) = \\frac{180}{300} = 0.6\\)\n\n\n\\(P(T) = \\frac{150}{300} = 0.5\\)\n\n\\(P(C \\cap T) = \\frac{60}{300} = 0.2\\)\n\nThen apply the rule:\n\\[\nP(C \\cup T) = 0.6 + 0.5 - 0.2 = 0.9\n\\]\nThus 90% of students drink either coffee, tea, or both.\n\n\n\n\nA machine learning model classifies emails as spam or not spam. Based on past data we know the following:\n\n\n10% of all emails are actually spam: \\(P(S) = 0.10\\)\n\n90% of emails are not spam: \\(P(\\bar{S}) = 0.90\\)\n\nThe model correctly detects spam 95% of the time: \\(P(D \\mid S) = 0.95\\)\n\nThe model incorrectly flags 5% of non-spam as spam: \\(P(D \\mid \\bar{S}) = 0.05\\)\n\n\nYou receive an email that was flagged by the model as spam (i.e., it was detected as spam).\nWhat is the probability that it is actually spam?\nThat is, compute \\(P(S \\mid D)\\), where:\n\n\n\\(S\\): Email is spam\n\n\\(D\\): Email was detected as spam by the filter\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe apply Bayes‚Äô Theorem: \\[\nP(S \\mid D) = \\frac{P(S) \\cdot P(D \\mid S)}{P(S) \\cdot P(D \\mid S) + P(\\bar{S}) \\cdot P(D \\mid \\bar{S})}\n\\]\nPlug in the values to get\n\nNumerator: \\(0.10 \\cdot 0.95 = 0.095\\)\n\nDenominator: \\(0.10 \\cdot 0.95 + 0.90 \\cdot 0.05 = 0.095 + 0.045 = 0.14\\)\n\n\nThus: \\[\nP(S \\mid D) = \\frac{0.095}{0.14} \\approx 0.679\n\\] There is a 67.9% chance the email is actually spam.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html",
    "href": "rvs-probdists/random-variables.html",
    "title": "12¬† Random Variables",
    "section": "",
    "text": "12.1 What is a Random Variable?\nIn many real-world situations, from rolling a die to measuring rainfall, we deal with outcomes that are inherently uncertain. To make sense of this uncertainty, we use random variables: mathematical tools that assign numerical values to the outcomes of random processes. They allow us to translate chance into structure, giving us a way to analyze and predict patterns in uncertain environments.\nThis section introduces the concept of random variables and the probability distributions that describe their behavior. A probability distribution not only lists the possible values a random variable can take, but also tells us how likely each value is to occur. Whether the variable counts discrete outcomes or measures continuous quantities, understanding its distribution is key to interpreting the role of randomness in data, decisions, and models.\nIn statistics, sampling should always be done randomly. This means that before the sampling occurs, we do not know who will be selected; it‚Äôs a random experiment where all individuals in the population are possible outcomes.\nTo introduce the idea of a random variable (also called a stochastic variable), imagine a small population of six individuals: Anna, Bob, Carol, David, Erin, Finn. This is shown in Figure¬†12.1 (a).\nWe are not primarily interested in the individuals themselves, but in the values they hold on some variable. For example, suppose we want to study whether each person has a driver‚Äôs license. Let‚Äôs assign a value of 1 to those who have a license and 0 to those who don‚Äôt. Now, instead of thinking about names, our outcome space transforms into a set of 1‚Äôs and 0‚Äôs, depending on the presence or absence of a driver‚Äôs license. This is shown in Figure¬†12.1 (b).\nIn probability theory, we often want to describe a random experiment using a variable before the experiment is carried out. Because we do not know in advance what the outcome will be, we use a random variable to represent the result. This variable is typically denoted by a capital letter, such as \\(X\\), \\(Y\\), or \\(Z\\), often chosen from the end of the alphabet.\nFor example, we might define the variable \\(X\\) as:\n\\(X\\) = Number of people with a driver‚Äôs license\nThis variable can take on different values depending on who is selected during the sampling process. By grouping all individuals who share the same outcome value for our variable, we divide the outcome space into disjoint events. Suppose we define the event \\(A\\) as: ‚ÄúA randomly selected individual has a driver‚Äôs license.‚Äù\nThis allows us to split the outcome space into two distinct parts: those with \\(X = 1\\) (event \\(A\\)), and those with \\(X = 0\\) (event \\(\\bar{A}\\)), as shown in Figure¬†12.2.\nIf three of the six individuals in the population have a license, then the probability of selecting a person with a license is:\n\\[\nP(X = 1) = \\frac{3}{6} = 0.5\n\\]\nAnd the probability of selecting someone without a license is:\n\\[\nP(X = 0) = \\frac{3}{6} = 0.5\n\\]\nThis defines the probability distribution of the variable \\(X\\). Note that we can construct an infinite number of random variables for the same random experiment. For instance, if we use the same group of six people, we could define a new variable \\(X\\) to represent vaccination instead of license status. Then we would need to specify what values the variable takes (e.g., 1 = vaccinated, 0 = not vaccinated), define the corresponding event \\(A\\), and determine the resulting probability distribution for this new version of \\(X\\).\nOnce the random event has occurred and the experiment is completed, the stochastic variable will have assumed a specific value. At that point, we switch notation and use lowercase letters (such as \\(x\\), \\(y\\), or \\(z\\)) to refer to the observed values. We write \\(P(x) = P(X = x)\\), which defines the probability function for the variable \\(X\\). This function tells us the likelihood that \\(X\\) takes on specific values \\(x\\).\nIn summary, a random variable is a numerical variable whose value is determined by the outcome of a random experiment. Before the experiment is performed, we don‚Äôt know what value the variable will take, but we do know the set of possible values it may assume. Once the experiment is conducted, the variable takes on a definite value, and we can analyze its behavior using its probability distribution.\nWe use uppercase letters like \\(X\\) to denote random variables, and the corresponding lowercase letters (like \\(x\\)) to represent actual outcomes. Depending on the context, random variables may be discrete or continuous, and each has its own type of probability model.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#what-is-a-random-variable",
    "href": "rvs-probdists/random-variables.html#what-is-a-random-variable",
    "title": "12¬† Random Variables",
    "section": "",
    "text": "(a) Sample space with names.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Sample space with coded variable of interest.\n\n\n\n\n\n\n\nFigure¬†12.1: Random variables in sample space.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†12.2: Outcome space divided into disjoint events.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#discrete-vs.-continuous-random-variables",
    "href": "rvs-probdists/random-variables.html#discrete-vs.-continuous-random-variables",
    "title": "12¬† Random Variables",
    "section": "12.2 Discrete vs.¬†Continuous Random Variables",
    "text": "12.2 Discrete vs.¬†Continuous Random Variables\nA discrete stochastic variable is one that can only take on a countable number of values. This might be a finite set, or it could be an infinite but countable one. Common examples include:\n\nThe number of dots shown when rolling a die\nThe sum of two dice rolls\nThe number of trials needed to roll a six\nThe number of girls in a randomly selected family with three children\n\nOn the other hand, a continuous stochastic variable can take on any value within an interval of the real number line. These variables are useful for modeling quantities that are measured rather than counted. Some examples include:\n\nThe length of a randomly selected newborn child\nThe lifespan of a randomly chosen light bulb\nThe annual income of a randomly chosen household",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#expected-value-and-variance",
    "href": "rvs-probdists/random-variables.html#expected-value-and-variance",
    "title": "12¬† Random Variables",
    "section": "12.3 Expected Value and Variance",
    "text": "12.3 Expected Value and Variance\nA random variable‚Äôs probability distribution can, much like an empirical data set, be described using measures of central tendency and spread.\nThe expected value of a random variable, often denoted as \\(E(X)\\) or \\(\\mu\\), represents the long-run average outcome of a random process if it were repeated many times. It‚Äôs a kind of ‚Äúcenter of gravity‚Äù for the distribution ‚Äî where the outcomes tend to balance out.\nWhile the expected value tells us the average, the variance of a random variable, denoted \\(\\operatorname{Var}(X)\\), tells us how spread out the values are around the mean. A small variance means values cluster tightly around the mean; a large variance means they are more widely scattered.\nSo even if we don‚Äôt yet know the outcome of a random process, we can describe how it typically behaves: where it centers (expected value) and how much it varies (standard deviation). This way, we can summarize the behavior of randomness in both location and consistency ‚Äî a powerful way to make sense of uncertainty. We explore these concepts further in the next chapter.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#sec-rvrules",
    "href": "rvs-probdists/random-variables.html#sec-rvrules",
    "title": "12¬† Random Variables",
    "section": "12.4 Linear Transformations of Random Variables",
    "text": "12.4 Linear Transformations of Random Variables\nSuppose we know the expected value and variance of a random variable \\(X\\), and we define a new variable \\(Y\\) as a linear transformation. FOr example, maybe you‚Äôre adding a flat fee to a cost, or scaling everything up because of inflation.\nMathematically, you‚Äôve created:\n\\[\nY = a + bX\n\\]\nNow you‚Äôre probably wondering: How does this change the average and the spread? In other words, we are interested in how this affects the expectation and variance. The following rules apply:\n\nThe expected value of \\(Y\\) is:\n\n\\[\nE(Y) = E(a + bX) = a + bE(X)\n\\]\n\nThe variance of \\(Y\\) is:\n\n\\[\n\\operatorname{Var}(Y) = \\operatorname{Var}(a + bX) = b^2 \\operatorname{Var}(X)\n\\]\nAdding a constant (\\(a\\)) does not affect variability, but scaling by a constant (\\(b\\)) affects the spread by a factor of \\(b^2\\).\nIf \\(c\\) is a constant (i.e., not a random variable):\n\nThe expected value of a constant is the constant itself:\n\n\\[\nE(c) = c\n\\]\n\nThe variance of a constant is zero:\n\n\\[\n\\operatorname{Var}(c) = 0\n\\]\nWhy zero variance? Because there‚Äôs nothing to vary ‚Äî it‚Äôs always the same.\nWe will see a practiccal example of these rukes of in the next chapter.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#standardizing-a-random-variable",
    "href": "rvs-probdists/random-variables.html#standardizing-a-random-variable",
    "title": "12¬† Random Variables",
    "section": "12.5 Standardizing a Random Variable",
    "text": "12.5 Standardizing a Random Variable\nTo compare random variables on a common scale, we often standardize them. Given a random variable \\(X\\) with expected value \\(\\mu_X\\) and standard deviation \\(\\sigma_X\\), we define:\n\\[\nZ = \\frac{X - \\mu_X}{\\sigma_X}\n\\]\nThis transformation creates a standardized variable \\(Z\\) with mean derived as follows using the rules shown in Section 12.4.\n\\[\nE(Z) = E\\left( \\frac{X - \\mu_X}{\\sigma_X} \\right)\n\\]\nSince \\(\\frac{1}{\\sigma_X}\\) is a constant, we can factor it out:\n\\[\nE(Z) = \\frac{1}{\\sigma_X} \\cdot E(X - \\mu_X)\n\\]\nUsing the linearity of expectation:\n\\[\nE(X - \\mu_X) = E(X) - \\mu_X = \\mu_X - \\mu_X = 0\n\\]\nSo:\n\\[\nE(Z) = \\frac{1}{\\sigma_X} \\cdot 0 = 0\n\\]\nThus, the standardized variable \\(Z\\) has mean 0. \\[\n  E(Z) = 0\n\\]\nNow we derive the variance of \\(Z\\):\n\\[\n\\operatorname{Var}(Z) = \\operatorname{Var}\\left( \\frac{X - \\mu_X}{\\sigma_X} \\right)\n\\]\nWe apply the rule for scaling a random variable:\n\\[\n\\operatorname{Var}\\left( \\frac{X - \\mu_X}{\\sigma_X} \\right) = \\left( \\frac{1}{\\sigma_X} \\right)^2 \\cdot \\operatorname{Var}(X - \\mu_X)\n\\]\nSince subtracting a constant does not change variance:\n\\[\n\\operatorname{Var}(X - \\mu_X) = \\operatorname{Var}(X) = \\sigma_X^2\n\\]\nSo:\n\\[\n\\operatorname{Var}(Z) = \\frac{1}{\\sigma_X^2} \\cdot \\sigma_X^2 = 1\n\\]\nThus, the standardized variable \\(Z\\) has variance 1.\n\\[\n  \\operatorname{Var}(Z) = 1\n\\]\nTo summarize, by standardizing a random variable using\n\\[\nZ = \\frac{X - \\mu_X}{\\sigma_X}\n\\]\nwe obtained a new variable \\(Z\\) with the following properties:\n\n\\(E(Z) = 0\\)\n\\(\\operatorname{Var}(Z) = 1\\)\n\nThis makes \\(Z\\) easier to work with and allows comparisons between different variables, regardless of their original scale or units.\nStandardized variables are especially useful when:\n\nComparing two variables measured in different units\nWorking with standard distributions (like the standard normal)\nSimplifying statistical formulas and derivations\n\nStandardization ensures that the new variable \\(Z\\) has no unit, zero mean, and unit variance ‚Äî a common baseline in probability and statistics.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#exercises",
    "href": "rvs-probdists/random-variables.html#exercises",
    "title": "12¬† Random Variables",
    "section": "12.6 Exercises",
    "text": "12.6 Exercises\nFor each of the random variables below, decide whether it is discrete or continuous:\n\nThe number of books a student checked out from the library this week\n\nThe time (in minutes) it takes a person to run 5 kilometers\n\nThe number of heads in 10 coin tosses\n\nA person‚Äôs height (in centimeters)\n\nThe number of emails received in one day\n\nThe daily average temperature in a city (in ¬∞C)\n\nWhether a person owns a smartphone (yes = 1, no = 0)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDiscrete ‚Äì counts books, can only be whole numbers\n\nContinuous ‚Äì time can be measured with decimals (e.g., 23.75 minutes)\n\nDiscrete ‚Äì number of heads is a count between 0 and 10\n\nContinuous ‚Äì height is measurable and can take any value in a range\n\nDiscrete ‚Äì number of emails is countable\n\nContinuous ‚Äì temperature is measured on a continuous scale\n\nDiscrete ‚Äì binary variable (yes/no)\n\n\n\n\n\nTwo workers, Alice and Bob, work independently on a task. The time (in hours) it takes each of them to complete their part is modeled as discrete random variables:\n\\(X\\) is Alice‚Äôs completion time, with \\(E(X) = 5\\) and \\(\\operatorname{Var}(X) = 1.5\\)\n\\(Y\\) is Bob‚Äôs completion time, with \\(E(Y) = 6\\) and \\(\\operatorname{Var}(Y) = 2\\)\nAssume \\(X\\) and \\(Y\\) are independent. Now define:\n\n\\(T = X + Y\\) as the total time they spend\n\\(D = Y - X\\) as the difference between their times\n\nCompute \\(E(T)\\), \\(\\operatorname{Var}(T)\\), \\(E(D)\\) and \\(\\operatorname{Var}(D)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTotal time: \\(T = X + Y\\). Using linearity of expectation:\n\\[\nE(T) = E(X) + E(Y) = 5 + 6 = 11\n\\]\nSince \\(X\\) and \\(Y\\) are independent:\n\\[\n\\operatorname{Var}(T) = \\operatorname{Var}(X) + \\operatorname{Var}(Y) = 1.5 + 2 = 3.5\n\\]\nTime difference: \\(D = Y - X\\). Again, using linearity:\n\\[\nE(D) = E(Y - X) = E(Y) - E(X) = 6 - 5 = 1\n\\]\nVariance of the difference (since \\(X\\) and \\(Y\\) are independent):\n\\[\n\\operatorname{Var}(D) = \\operatorname{Var}(Y) + \\operatorname{Var}(X) = 2 + 1.5 = 3.5\n\\]",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html",
    "href": "rvs-probdists/discrete-dists.html",
    "title": "13¬† Discrete Probability Distributions",
    "section": "",
    "text": "13.1 Probability Mass Function (PMF)\nA discrete probability distribution describes how the values of a variable are associated with probabilities. It applies when a variable can take on a limited or countable set of values, like 0, 1, 2, and so on, and we know how likely each value is. Note that we use uppercase letter to denote random variables and lowercase letters for the values they take on.\nThe probability function \\(P(x)\\) assigns a probability to each possible value \\(x\\) that the variable can take. These probabilities must all lie between 0 and 1, and together they must sum to exactly 1.\nWe use the expected value, \\(E(X)\\), to summarize the typical or central value of the distribution. It gives us a sense of where the values tend to cluster. Think of it as a kind of weighted average, where more probable outcomes count more heavily in the calculation.\nThe variance, \\(\\operatorname{Var}(X)\\), describes how much the values of the variable differ from this central value. A small variance means most values are close to the expected value, while a large variance means the values are more spread out.\nWhen dealing with discrete random variables, we are interested in how likely it is that the variable takes on specific values. This relationship, the link between possible values and their associated probabilities, is described by the probability distribution of the random variable.\nThe probability mass function (PMF) is a mathematical function that assigns a probability to each value the variable can take. In other words, the PMF is the mathematical expression of the probability distribution. The distribution is the overall concept; the PMF is the function that specifies the details.\nWe usually denote the PMF as \\(P(x)\\), where:\n\\[\nP(x) = P(X = x)\n\\] This gives the probability that the random variable \\(X\\) equals a specific value \\(x\\).\nFor the PMF to describe a valid distribution, it must satisfy two conditions:\nIf we know \\(P(x)\\) for all values \\(x\\) that \\(X\\) can take, we say we know the probability distribution of \\(X\\). We can present a probability distribution in several forms: as a table, a bar chart, or through a formula.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#probability-mass-function-pmf",
    "href": "rvs-probdists/discrete-dists.html#probability-mass-function-pmf",
    "title": "13¬† Discrete Probability Distributions",
    "section": "",
    "text": "Each probability must be between 0 and 1: \\[\n0 \\leq P(x) \\leq 1\n\\]\nThe total probability across all values must sum to 1: \\[\n\\sum_x P(x) = 1\n\\]\n\n\nExample 12.1: Coin Toss\nSuppose we toss a fair coin two times. Let the random variable \\(X\\) represent the number of heads observed. The sample space consists of four equally likely outcomes:\n\nHead, Head ‚Üí \\(X = 2\\)\n\nHead, Tail ‚Üí \\(X = 1\\)\n\nTail, Head ‚Üí \\(X = 1\\)\n\nTail, Tail ‚Üí \\(X = 0\\)\n\n\nEach of these outcomes has probability 0.25. From this, we can define the probability mass function (PMF) of \\(X\\) as:\n\\[\nP(x) =\n\\begin{cases}\n0.25 & \\text{if } x = 0 \\\\\n0.50 & \\text{if } x = 1 \\\\\n0.25 & \\text{if } x = 2 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nThe table below presents a representation of the PMF; showing the values of \\(P(x)\\) for each value in the support of \\(X\\):\n\n\nOutcomes\n\n\\(x\\) (Number of heads)\n\\(P(x)\\)\n\n\n\n(Tail, Tail)\n0\n0.25\n\n\n(Head, Tail), (Tail, Head)\n1\n0.50\n\n\n(Head, Head)\n2\n0.25\n\n\n\nWe can confirm that this satisfies the requirement:\n\\[\n\\sum_x P(x) = 0.25 + 0.5 + 0.25 = 1\n\\]\nThis confirms that \\(P(x)\\) defines a valid probability distribution.\nThis table is one way of representing the probability distribution of \\(X\\). Another way to represent it is by using bar plot:",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#the-cumulative-distribution-function-cdf",
    "href": "rvs-probdists/discrete-dists.html#the-cumulative-distribution-function-cdf",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.2 The Cumulative Distribution Function (CDF)",
    "text": "13.2 The Cumulative Distribution Function (CDF)\nFor a discrete random variable \\(X\\), we can describe its probability distribution not only using the probability mass function, but also through its cumulative distribution function, denoted \\(F(x)\\).\nThe CDF gives the probability that \\(X\\) takes on a value less than or equal to a given number \\(x\\):\n\\[\nF(x) = P(X \\leq x)\n\\]\nThis function grows step by step as we move through the possible values of \\(X\\), accumulating the total probability up to each point.\nExample 12.1: Coin Toss (continued)\nWe continue here with the example abive, where \\(X\\) is the number of heads in two tosses of a fair coin. The PMF and corresponding CDF values are:\n\n\n\\(x\\)\n\\(P(x)\\)\n\\(F(x)\\)\n\n\n\n0\n0.25\n0.25\n\n\n1\n0.50\n0.75\n\n\n2\n0.25\n1.00\n\n\n\nThe last value of \\(F(x)\\) must always equal 1, since the total probability must sum to 1.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#expected-value-of-a-discrete-random-variable",
    "href": "rvs-probdists/discrete-dists.html#expected-value-of-a-discrete-random-variable",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.3 Expected Value of a Discrete Random Variable",
    "text": "13.3 Expected Value of a Discrete Random Variable\nJust like empirical data can be summarized with averages and standard deviations, a discrete probability distribution can also be described using corresponding statistical measures. These include measures of central tendency, such as the expected value, and measures of variability, such as the standard deviation.\nThe expected value plays the role of a mean or average. But because the possible outcomes may occur with different probabilities, we must take this into account by assigning more weight to more likely outcomes. This means the values are weighted by their associated probabilities.\nTo find the expected value of a discrete random variable, we do not simply average the outcomes. Instead, we compute a weighted average where the weights are given by the probability mass function.\nThe expected value of a discrete random variable \\(X\\) is denoted by \\(E(X)\\), where \\(E\\) stands for expectation. It is defined as:\n\\[\nE(X) = \\sum_{x} x \\cdot P(x) = \\mu_X\n\\]\nThis formula tells us to multiply each value \\(x\\) by its probability \\(P(x)\\) and then sum the results over all possible values of \\(X\\). The result, \\(E(X)\\), gives us the value we expect to observe on average in the long run, if we were to randomly select a value of \\(X\\) according to its probability distribution.\nThe expected value represents the ‚Äúcenter‚Äù of the distribution ‚Äî the point where the values balance, considering how often each one occurs. For example, if a random variable has most of its probability mass near 1, its expected value will be close to 1.\nIt‚Äôs important to note that expected value doesn‚Äôt predict what will happen* ‚Äî it predicts what happens on average. It‚Äôs like asking, ‚ÄúWhat would I get if the universe reran this scenario a million times?‚Äù\nExample 12.1: Coin Toss (continued)\nIf you revisit the coin-toss example where \\(X\\) counts the number of heads in two tosses, you would compute the expected value as:\n\\[\nE(X) = \\sum_{x} x \\cdot P(x) = 0 \\cdot 0.25 + 1 \\cdot 0.5 + 2 \\cdot 0.25 = 1\n\\]\nThis confirms that we expect to get 1 head on average when tossing a coin twice.\nExample 12.2: Lottery - A Risky Business\nLet‚Äôs say you‚Äôre eyeing a lottery with 100 tickets. Each ticket costs 1‚Ç¨, and you‚Äôre feeling lucky. The prize setup is:\n\nOne lucky winner gets 50‚Ç¨\n\nThree people win 10‚Ç¨\n\nFive folks get 2‚Ç¨\n\nAnd‚Ä¶ the remaining 91 get absolutely nothing\n\nLet‚Äôs define a random variable \\(X\\) as the payout of a randomly selected ticket.\nSo what values can \\(X\\) take?\n\\[\nX \\in \\{0, 2, 10, 50\\}\n\\]\nBut ‚Äî and here‚Äôs the key ‚Äî just averaging those values like this:\n\\[\n\\frac{0 + 2 + 10 + 50}{4} = 15.5\n\\]\n‚Ä¶makes no sense! That would only be correct if all outcomes were equally likely, which they‚Äôre definitely not. Most people walk away with nothing. So we need to weight each value by how often it actually happens.\nLet‚Äôs build a table to show how many tickets correspond to each prize:\n\n\nPayout (‚Ç¨)\nNumber of tickets\nProbability \\(P(x)\\)\n\n\n\n\n0\n91\n0.91\n\n\n2\n5\n0.05\n\n\n10\n3\n0.03\n\n\n50\n1\n0.01\n\n\n\nSo now we have a complete probability distribution for \\(X\\) which is visualized below:\n\n\n\n\n\n\n\n\nLet‚Äôs compute the expected value \\(E(X)\\) using the PMF:\n\\[\nE(X) = \\sum_x x \\cdot P(x) = 0 \\cdot 0.91 + 2 \\cdot 0.05 + 10 \\cdot 0.03 + 50 \\cdot 0.01 = 0.90\n\\]\nSo even though one person might win 50‚Ç¨, the average payout per ticket is just 90 cents. That means if you pay 1‚Ç¨ per ticket, you‚Äôre losing 10 cents on average.\nMost of the time, lottery isn‚Äôt just random ‚Äî it‚Äôs rigged (in favor of the organizers)",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#variance-and-standard-deviation-of-a-discrete-random-variable",
    "href": "rvs-probdists/discrete-dists.html#variance-and-standard-deviation-of-a-discrete-random-variable",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.4 Variance and Standard Deviation of a Discrete Random Variable",
    "text": "13.4 Variance and Standard Deviation of a Discrete Random Variable\nJust as sample variance measures the average squared deviation from the sample mean, the variance of a random variable measures the average squared deviation from its expected value, weighted by the probability mass function.\nLet \\(X\\) be a discrete random variable with expected value \\(\\mu_X = E(X)\\). The variance of \\(X\\) is defined as:\n\\[\n\\text{Var}(X) = E[(X - \\mu_X)^2] = \\sum_x (x - \\mu_X)^2 \\cdot P(x)\n\\]\nAlternatively, variance can also be calculated using:\n\\[\n\\text{Var}(X) = E(X^2) - (E(X))^2\n\\]\nThe standard deviation is the square root of the variance:\n\\[\n\\sigma_X = \\sqrt{\\text{Var}(X)}\n\\]\nThese measures provide information about how much variability there is in the possible values of \\(X\\).\nExample 12.1: Coin Toss (continued)\nConsider again the random variable \\(X =\\) number of heads in two tosses of a fair coin. We previously found the expected value:\n\\[\nE(X) = 1\n\\]\nWe now calculate the variance by constructing the following table:\n\n\n\\(x\\)\n\\(P(x)\\)\n\\((x - \\mu_X)^2\\)\n\\((x - \\mu_X)^2 \\cdot P(x)\\)\n\n\n\n0\n0.25\n1\n0.25\n\n\n1\n0.50\n0\n0\n\n\n2\n0.25\n1\n0.25\n\n\n\n\n\n0.50\n\n\n\nSo,\n\\[\n\\text{Var}(X) = 0.50 \\quad \\text{and} \\quad \\sigma_X = \\sqrt{0.50} \\approx 0.7071\n\\]\nThis tells us that the number of heads in two tosses typically deviates by about 0.71 from the expected value.\nExample 12.2: Lottery - A Risky Business\nLet \\(X\\) denote the payout from a randomly selected lottery ticket. From earlier, we know the expected value is:\n\\[\n\\mu_X = E(X) = 0.9\n\\]\nTo compute the variance, we first calculate the squared deviations from the mean for each possible payout:\n\n\n\\(x\\)\n\\(P(x)\\)\n\\((x - \\mu_X)^2\\)\n\n\n\n0\n0.91\n\\((0 - 0.9)^2 = 0.81\\)\n\n\n2\n0.05\n\\((2 - 0.9)^2 = 1.21\\)\n\n\n10\n0.03\n\\((10 - 0.9)^2 = 82.81\\)\n\n\n50\n0.01\n\\((50 - 0.9)^2 = 2410.81\\)\n\n\n\nNow multiply by probabilities:\n\\[\n\\text{Var}(X) = 0.91 \\cdot 0.81 + 0.05 \\cdot 1.21 + 0.03 \\cdot 82.81 + 0.01 \\cdot 2410.81 = 27.39\n\\]\nSo the standard deviation is:\n\\[\n\\sigma_X = \\sqrt{27.39} \\approx 5.23\n\\]\nSo in summary, the expected payout of 0.9‚Ç¨ indicated that on average, each ticket returns 90cents. However, no single ticket actually pays exactly 0.9‚Ç¨. This value is theoretical ‚Äî it describes the average over many repetitions.\nThe standard deviation of 5.23‚Ç¨ tells us that the actual payout from a randomly chosen ticket typically deviates from the expected value by about 5‚Ç¨. This large spread reflects the presence of a few large prizes and many losing tickets.\nAlthough the possibility of winning a large amount may seem appealing, the large variance masks the fact that the expected return is less than the ticket price, ensuring profit for the lottery organizers over time.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#rules-for-expectation-and-variance",
    "href": "rvs-probdists/discrete-dists.html#rules-for-expectation-and-variance",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.5 Rules for Expectation and Variance",
    "text": "13.5 Rules for Expectation and Variance\nRecall from previous chapter and section Section 12.4 that for any random variable \\(X\\), and constants \\(a\\) and \\(b\\), we always have that the expected value is given by \\[\nE(a + bX) = a + bE(X)\n\\] and the variance by \\[\n\\operatorname{Var}(a + bX) = b^2 \\operatorname{Var}(X).\n\\] Let‚Äôs look at an exmaple of this in the discrete case.\nExample 12.3: The Project Budget\nYou‚Äôre managing a project. The number of workdays to finish the project, denoted by random variable \\(X\\), is a bit uncertain. Its distribution looks like this:\n\n\n\\(x\\)\n10\n11\n12\n13\n14\n\n\n\\(P(x)\\)\n0.1\n0.3\n0.3\n0.2\n0.1\n\n\nYou know a few things:\n\nFixed cost: ‚Ç¨25,000\n\nDaily cost: ‚Ç¨900\n\nSo the total cost denoted by \\(Y\\) is:\\[\nY = 25000 + 900X\n\\]\n\n\nLet‚Äôs use the rules above to find the expected value and variance of \\(Y\\).\nFirst we use similar technique as earlier to find\n\\[\nE(X) = 11.9 \\quad \\text{and} \\quad \\operatorname{Var}(X) = 1.29\n\\]\nUsing the rules of linear transformation we then can find the expected value of \\(Y\\) \\[\nE(Y) = 25000 + 900 \\cdot E(X) = 25000 + 900 \\cdot 11.9 = 35710\n\\]\nand the variance of \\(Y\\) as\n\\[\n\\operatorname{Var}(Y) = 900^2 \\cdot \\operatorname{Var}(X) = 810000 \\cdot 1.29 = 1044900\n\\]\nFinally we find the standarc deviaiton as \\[\n\\sqrt{\\operatorname{Var}(Y)} = \\sqrt{1044900} \\approx 1022.20\n\\]\nThis gives a total expected project cost of ‚Ç¨35,710, with a standard deviation of about ‚Ç¨1,022.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#sec-binom",
    "href": "rvs-probdists/discrete-dists.html#sec-binom",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.6 The Bernoulli and Binomial Distribution",
    "text": "13.6 The Bernoulli and Binomial Distribution\nIn probability theory, many random variables arise in contexts that follow well-known and well-studied distributions. For example, a variable that takes the value 1 when an event occurs and 0 otherwise ‚Äî such as flipping a coin or checking if a customer buys a product ‚Äî follows a Bernoulli distribution. When this type of binary trial is repeated independently a fixed number of times, and we count the number of successes, the resulting variable follows a Binomial distribution. These distributions not only help us describe real-world phenomena succinctly but also allow us to use established formulas to compute probabilities, expectations, variances, and more.\nA random variable \\(X\\) is said to follow a Bernoulli distribution if it takes on only two possible values: \\(0\\) and \\(1\\). These values typically represent the outcomes of a binary trial ‚Äî such as failure or success ‚Äî with probabilities \\(1 - p\\) and \\(p\\) respectively. The distribution is written as:\n\\[\nX \\sim \\text{Bernoulli}(p)\n\\]\nThis means that \\(X = 1\\) with probability \\(p\\), and \\(X = 0\\) with probability \\(1 - p\\). The expected value of a Bernoulli variable is given by \\(E(X) = p\\), and the variance is \\(\\operatorname{Var}(X) = p(1 - p)\\).\nA common use of Bernoulli variables is as indicator variables, which simply record whether or not a particular event occurs. For example, suppose \\(A\\) is an event. Then we define the indicator variable \\(X\\) as:\n\\[\nX =\n\\begin{cases}\n1 & \\text{if event } A \\text{ occurs} \\\\\n0 & \\text{if event } A \\text{ does not occur}\n\\end{cases}\n\\]\nIn this case, \\(X \\sim \\text{Bernoulli}(p)\\), where \\(p = P(A)\\). This also implies that \\(E(X) = P(A)\\). In other words, the expected value of an indicator variable is simply the probability of the event it represents.\nAs an example, consider rolling a fair six-sided die. Let \\(X\\) be the indicator variable for the event ‚Äúrolling a six.‚Äù Then:\n\\[\nX =\n\\begin{cases}\n1 & \\text{if we roll a six} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nSince the probability of rolling a six is \\(p = \\frac{1}{6}\\), we can say \\(X \\sim \\text{Bernoulli}(1/6)\\). The expected value of \\(X\\) is then \\(E(X) = \\frac{1}{6}\\), and the variance is:\n\\[\n\\operatorname{Var}(X) = \\frac{1}{6} \\left(1 - \\frac{1}{6} \\right) = \\frac{5}{36}\n\\]\nThis illustrates how Bernoulli variables can model simple binary outcomes and provide useful measures like mean and variability.\nBernoulli variables are also the building blocks of the Binomial distribution. When a Bernoulli trial is repeated independently \\(n\\) times, and we define a variable \\(X\\) to count the number of times the event (success) occurs, then \\(X\\) follows a Binomial distribution. More precisely, if each trial has success probability \\(p\\), and the trials are independent, then\n\\[\nX \\sim \\text{Bin}(n, p).\n\\]\nIn this case, \\(X\\) can take values \\(x = 0, 1, 2, \\dots, n\\), and the probability mass function is given by the formula\n\\[\nP(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x},\n\\]\nwhere \\(\\binom{n}{x}\\) is the binomial coefficient, which counts the number of ways to choose \\(x\\) successes from \\(n\\) trials. The expected value and variance of a binomially distributed random variable are\n\\[\nE(X) = np \\quad \\text{and} \\quad \\operatorname{Var}(X) = np(1 - p).\n\\]\nExample 12.4: Flipping a Coin 3 Times\nAs an example, consider tossing a fair coin three times and let \\(X\\) be the number of heads obtained. Each toss is a Bernoulli trial with \\(p = 0.5\\), and there are three independent trials, so\n\\[\nX \\sim \\text{Bin}(3, 0.5).\n\\]\nWe can compute the probabilities for each possible value of \\(X\\) using the binomial formula:\n\\[\nP(X = x) = \\binom{3}{x}(0.5)^x(1 - 0.5)^{3 - x}.\n\\]\nFor example, to compute the probability of getting no heads at all, that is \\(X = 0\\), we use the binomial formula: \\[\nP(X = 0) = \\binom{3}{0}(0.5)^0(1 - 0.5)^3 = 1 \\cdot 1 \\cdot 0.125 = 0.125.\n\\]\nHere, \\(\\binom{3}{0} = 3\\) means the number of ways we can draw exactly 0 heads in 3 tosses and the answer is exactly 1 since there is only one outcome correposndin to this: \\(\\{(T,T,T)\\}\\).\nFor \\(X = 2\\) however, which corresponds to getting exactly two heads, the calculation is:\n\\[\nP(X = 2) = \\binom{3}{2}(0.5)^2(1 - 0.5)^1 = 3 \\cdot 0.25 \\cdot 0.5 = 0.375.\n\\]\nHere, \\(\\binom{3}{2} = 3\\) reflects the number of different ways to get two heads and one tail in three tosses. The specific outcomes are: \\(\\{(H,H,T), (H,T,H), (T,H,H)\\}\\). Each of these outcomes has the same probability, and the binomial coefficient counts how many such arrangements contribute to the total.\nDoing this for all possible outcomes provides the results in the following table:\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(F(x) = P(X \\leq x)\\)\n\n\n\n0\n0.125\n0.125\n\n\n1\n0.375\n0.500\n\n\n2\n0.375\n0.875\n\n\n3\n0.125\n1.000\n\n\n\nWe can verify that the total probability sums to 1, as expected. This example illustrates how the binomial distribution models the number of successes in a fixed number of independent trials, and how it extends naturally from the simpler Bernoulli setting.\nExample 12.5: 12 Independent Trials with Binary Outcomes\nIn this example, we consider a sequence of 12 independent trials, where the probability of success on each trial is 0.8. Let \\(X\\) be the random variable representing the total number of successful trials.\nWe begin by identifying the distribution of \\(X\\). Since the trials are independent and each has the same probability of success, \\(X\\) follows a binomial distribution with parameters \\(n = 12\\) and \\(P = 0.8\\). We can write:\n\\[\nX \\sim \\text{Bin}(12, 0.8)\n\\]\nWe are asked to compute:\n\n\n\\(P(X = 10)\\)\n\n\\(P(X \\leq 10)\\)\n\nThe first is straightforward to compute using our binomial formula: \\[\n\\begin{split}\nP(X = 10) = \\binom{12}{10}(0.8)^{10}(0.2)^2 &  = \\frac{12!}{10!(12 - 10)!} (0.8)^{10}(0.2)^2 \\\\ &  =  66 \\cdot 0.1074 \\cdot 0.04 \\approx 66 \\cdot 0.004296 \\\\ &  = 0.2835\n\\end{split}\n\\]\nHowever, for the second task of computing \\(P(X \\leq 10)\\), it can be very tedious to compute the binomial formula 11 times and then add them. Here‚Äôs the trick! We consider the number of failures instead. Define \\(Y\\) as the number of unsuccessful trials. Then \\(Y = 12 - X\\), and it also follows a binomial distribution, but with with \\(p = 0.2\\), that is \\[\nY \\sim \\text{Bin}(12, 0.2)\n\\]\nSo the probability of exactly 10 successes is approximately 0.2835.\nHowever, because \\(p = 0.8 &gt; 0.5\\), we cannot use the standard binomial tables in the textbook, which only go up to \\(P = 0.5\\). To get around this, we consider the number of failures instead. Define \\(Y\\) as the number of unsuccessful trials. Then \\(Y = 12 - X\\), and it also follows a binomial distribution, but with \\(P = 0.2\\). So:\n\\[\nY \\sim \\text{Bin}(12, 0.2)\n\\]\nNow to compute \\(P(X \\leq 10)\\) we see that it corresponds to \\(P(Y \\geq 2)\\), since if \\(X \\leq 10\\), then the number of failures \\(Y \\geq 2\\).\nWe use the complement: \\[\n\\begin{split} P(X \\leq 10) = P(Y \\geq 2) &  = 1 - P(Y \\leq 1) =  \\\\ &\n= 1 - [P(Y = 0) + P(Y = 1)]\n\\end{split}\n\\]\nand use the binomial formula as before: \\[\nP(Y = 0) = \\binom{12}{0}(0.2)^0(0.8)^{12} = 1 \\cdot 1 \\cdot (0.8)^{12} \\approx 0.0687\n\\]\n\\[\nP(Y = 1) = \\binom{12}{1}(0.2)^1(0.8)^{11} = 12 \\cdot 0.2 \\cdot (0.8)^{11} \\approx 0.2062\n\\] Add these two probabilities \\[\nP(Y \\leq 1) = P(Y = 0) + P(Y = 1) \\approx 0.0687 + 0.2062 = 0.2749\n\\]\nand finally, subtract from 1 to get the desired result:\n\\[\nP(Y \\geq 2) = 1 - 0.2749 = 0.7251\n\\]\nSo, the probability that \\(Y\\) is greater than or equal to 2 is approximately 0.7251. This is the same probability as \\(X\\) being less than or equal to 10.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#exercises",
    "href": "rvs-probdists/discrete-dists.html#exercises",
    "title": "13¬† Discrete Probability Distributions",
    "section": "Exercises",
    "text": "Exercises\n\nLet \\(X\\) be a discrete random variable with the following probability distribution:\n\n\n\n\\(x\\)\n1\n2\n3\n4\n\n\n\\(P(x)\\)\n0.1\n0.3\n0.4\n0.2\n\n\n\nVerify that this is a valid probability distribution.\n\nCompute the expected value \\(E(X)\\).\n\nCompute the variance \\(\\operatorname{Var}(X)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nValidity check We check that the sum of the probabilities is 1:\n\n\\[\n0.1 + 0.3 + 0.4 + 0.2 = 1.0\n\\]\n\nExpected value\n\n\\[\nE(X) = \\sum x \\cdot P(x) = 1 \\cdot 0.1 + 2 \\cdot 0.3 + 3 \\cdot 0.4 + 4 \\cdot 0.2 = 0.1 + 0.6 + 1.2 + 0.8 = 2.7\n\\]\n\nVariance\n\nWe first compute \\(E(X^2)\\): \\[\nE(X^2) = 1^2 \\cdot 0.1 + 2^2 \\cdot 0.3 + 3^2 \\cdot 0.4 + 4^2 \\cdot 0.2 = 0.1 + 1.2 + 3.6 + 3.2 = 8.1\n\\]\nThen:\n\\[\n\\operatorname{Var}(X) = E(X^2) - (E(X))^2 = 8.1 - (2.7)^2 = 8.1 - 7.29 = 0.81\n\\]\n\n\n\n\nSuppose a quality control inspector checks whether products are defective. Each item has a 10% chance of being defective, and tests are independent.\n\n\nLet \\(X\\) be a Bernoulli random variable indicating whether a single item is defective. What are the mean and variance of \\(X\\)?\nLet \\(Y \\sim \\text{Bin}(10, 0.1)\\) represent the number of defective items in a sample of 10. Compute:\n\n\n\n\\(E(Y)\\) and \\(\\operatorname{Var}(Y)\\)\n\n\n\\(P(Y = 0)\\)\n\n\\(P(Y \\geq 2)\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\nBernoulli Variable \\(X\\): \\(X \\sim \\text{Bernoulli}(0.1)\\) \\[E(X) = 0.1\\]\n\\[\\operatorname{Var}(X) = 0.1 \\cdot (1 - 0.1) = 0.09\\]\n\n\n\n\n\nBinomial Variable \\(Y\\): \\(Y \\sim \\text{Bin}(10, 0.1)\\)\n\\(E(Y) = 10 \\cdot 0.1 = 1\\)\n\\(\\operatorname{Var}(Y) = 10 \\cdot 0.1 \\cdot 0.9 = 0.9\\)\n\n\\(P(Y = 0)\\)\n\n\\[\nP(Y = 0) = \\binom{10}{0}(0.1)^0(0.9)^{10} = 1 \\cdot 1 \\cdot (0.9)^{10} \\approx 0.3487\n\\]\n\n\n\\(P(Y \\geq 2)\\) We use the complement: \\[\nP(Y \\geq 2) = 1 - P(Y = 0) - P(Y = 1)\n\\] Already have \\(P(Y = 0) \\approx 0.3487\\). Now compute: \\[\nP(Y = 1) = \\binom{10}{1}(0.1)^1(0.9)^9 = 10 \\cdot 0.1 \\cdot (0.9)^9 \\approx 0.3874\n\\] Then: \\[\nP(Y \\geq 2) = 1 - 0.3487 - 0.3874 = 0.2639\n\\]",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html",
    "href": "rvs-probdists/cont-dists.html",
    "title": "14¬† Continuous Probability Distributions",
    "section": "",
    "text": "14.1 Probability Density Function (PDF)\nUntil now, we have mainly worked with discrete random variables, meaning variables that can only take on a finite or countably infinite number of possible values. For instance, the number of heads when tossing coins or the number of defective items in a sample are all discrete.\nHowever, not all random phenomena can be described in this way. A continuous random variable is a variable that can take on any value within an interval on the real number line. Rather than jumping between isolated values, a continuous variable can assume an infinite continuum of possible outcomes.\nBecause a continuous random variable can take any value within an interval, it is practically impossible to guess the exact value that a randomly selected observation will have. In fact, the probability that the variable exactly equals any specific value is zero. Consequently, for continuous random variables, we do not measure probabilities at single points. Instead, we consider the probability that the variable falls within a given interval.\nTo handle continuous random variables, we develop continuous analogues of the probability mass functions used for discrete variables. These continuous probability distributions are described using probability density functions, which allow us to calculate the probability that the variable lies within a specified range.\nTo summarize visually:\nIn discrete settings, probabilities are assigned to individual points. For continuous random variables, we instead measure the ‚Äúarea under the curve‚Äù of the density function across an interval.\nAs we move forward, we will develop the tools needed to work with continuous distributions, starting with probability density functions and moving toward important continuous models such as the uniform and normal distributions.\nA continuous random variable can take on all possible values within some interval on the real number line. The interval may be bounded or extend to infinity in one or both directions.\nThe probability distribution of a continuous random variable \\(X\\) is described by a so-called probability density function \\(f(x)\\). The density function represents how the values of \\(X\\) are distributed across the real line.\nA typical shape of a probability density function might look like the following:\nIn contrast to discrete random variables, continuous variables do not assign positive probability to specific points. Instead, the probability that \\(X\\) falls within a particular interval \\([a, b]\\) is given by the area under the curve of the density function between \\(a\\) and \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\text{area under } f(x) \\text{ from } a \\text{ to } b\n\\]\nThe properties that every valid probability density function must satisfy are: - \\(f(x) \\geq 0\\) for all \\(x\\) (the function must be non-negative everywhere) - The total area under \\(f(x)\\) over the entire real line equals 1:\n\\[\n\\int_{-\\infty}^{\\infty} f(x) , dx = 1\n\\]\nThis ensures that the random variable must take on some value in the real numbers with total probability one.\nWe can also visually highlight the probability over a specific interval by shading the area between two points \\(a\\) and \\(b\\):\nIn this plot, the shaded area between \\(a = 3\\) and \\(b = 7\\) represents \\(P(3 \\leq X \\leq 7)\\); the probability that the random variable falls within this interval.\nThis concept, relating probabilities to areas under a curve, is a fundamental idea when working with continuous random variables, and it distinguishes them clearly from the discrete case where we sum probabilities at isolated points.\nWhen working with continuous random variables, we are always interested in the probability that a value falls within an interval, never at a single point. This is because the area under the curve at a single value is zero, which means:\n\\[\nP(X = a) = 0\n\\]\nWhether we specify the interval as open, closed, or half-open does not affect the probability. For example, the following expressions are all equivalent:\n\\[\nP(a \\leq X \\leq b) = P(a \\leq X &lt; b) = P(a &lt; X \\leq b) = P(a &lt; X &lt; b)\n\\]\nThey all describe the same shaded region under the curve between \\(a\\) and \\(b\\).\nFormally, the probability that \\(X\\) falls within an interval \\([a, b]\\) is given by integrating the probability density function:\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx\n\\]\nHowever, in this course, we do not require formal calculations using integrals.\nWe can work with the cumulative distribution function (CDF), which is defined as:\n\\[\nF(x) = P(X \\leq x)\n\\]\nThis function gives the total probability accumulated up to the value \\(x\\), that is, the area under the density curve from the lower bound of the distribution up to \\(x\\).\nUsing the CDF, we can express interval probabilities as the difference of cumulative values:\n\\[\nP(a \\leq X \\leq b) = P(X \\leq b) - P(X \\leq a) = F(b) - F(a)\n\\]\nThis relationship is especially useful when we don‚Äôt have access to the density function itself but can look up or compute values of the cumulative distribution. It also reinforces the idea that probability for continuous variables is tied to the area between two points, not the height at a point.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#expectation-and-variance-for-continuous-variables",
    "href": "rvs-probdists/cont-dists.html#expectation-and-variance-for-continuous-variables",
    "title": "14¬† Continuous Probability Distributions",
    "section": "\n14.2 Expectation and Variance for Continuous Variables",
    "text": "14.2 Expectation and Variance for Continuous Variables\nJust as we did with discrete random variables, we can define the expected value and variance for continuous random variables. These two quantities serve as important measures of central tendency and spread, respectively.\nThe expected value of a continuous random variable \\(X\\) with density function \\(f(x)\\) is given by:\n\\[\nE(X) = \\mu_X = \\int_{-\\infty}^{\\infty} x f(x) \\, dx\n\\]\nThis can be interpreted as a kind of weighted average, where the values of \\(x\\) are weighted by their relative likelihood ‚Äî in this case, the density function \\(f(x)\\).\nThe variance is defined as:\n\\[\n\\operatorname{Var}(X) = \\sigma_X^2 = \\int_{-\\infty}^{\\infty} (x - \\mu)^2 f(x) \\, dx\n\\]\nJust like in the discrete case, this measures how spread out the values of \\(X\\) are around the mean \\(\\mu\\).\nIntuitively, the expected value can be thought of as the balance point of the distribution, the point at which the density function would balance perfectly if it were a physical object. The variance, as before, describes how tightly or widely the values of \\(X\\) tend to cluster around this center.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#the-normal-distribution",
    "href": "rvs-probdists/cont-dists.html#the-normal-distribution",
    "title": "14¬† Continuous Probability Distributions",
    "section": "\n14.3 The Normal Distribution",
    "text": "14.3 The Normal Distribution\nAmong all continuous probability distributions, none is more important or more widely used than the normal distribution. This may seem strange, since very few real-world quantities are exactly normally distributed. Nevertheless, the normal distribution plays a central role in probability theory and statistics, especially as a powerful approximation tool.\nMathematically, a random variable \\(X\\) is said to follow a normal distribution if its probability density function is given by:\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\, e^{- \\frac{1}{2} \\left( \\frac{x - \\mu}{\\sigma} \\right)^2}, \\quad \\text{for } -\\infty &lt; x &lt; \\infty\n\\]\nWe denote this by writing:\n\\[\nX \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\nHere, \\(\\mu\\) is the mean of the distribution, and \\(\\sigma^2\\) is the variance (with \\(\\sigma\\) being the standard deviation).\nThis density function has a characteristic bell shape: it is symmetric about the mean \\(\\mu\\), and the spread of the curve is determined by \\(\\sigma\\). The larger the value of \\(\\sigma\\), the more spread out the distribution becomes.\nDespite its somewhat complicated appearance, the normal distribution is incredibly useful because many phenomena in practice, especially sums and averages of random variables, tend to follow a distribution that closely resembles the normal. This fact is supported by the central limit theorem, which guarantees that under mild conditions, the sum of a large number of independent random variables tends toward a normal distribution, regardless of the original distributions. We will return to this in more details later.\nMoreover, the probabilities associated with the normal distribution have already been computed and tabulated. These tables allow us to quickly look up values without performing integrals manually, making the normal distribution not only powerful in theory but also very practical in application.\nIt is this combination of mathematical elegance, approximation power, and computational convenience that explains the normal distribution‚Äôs central role in both theoretical and applied statistics.\nLet us now look at a concrete example. Suppose \\(X\\) is a normally distributed random variable with mean \\(\\mu = 10\\) and standard deviation \\(\\sigma = 2\\):\n\\[\nX \\sim \\mathcal{N}(10, 2)\n\\]\nThe density function of \\(X\\) is bell-shaped and symmetric around the mean, with most of its probability mass concentrated within a few standard deviations from the center.\nBelow is the probability density function for this distribution:\n\n\n\n\n\n\n\n\nIn practice, there are a few key characteristics of the normal distribution that are particularly important to understand.\nFirst, the shape of the normal distribution is completely determined by two parameters: the mean \\(\\mu\\) and the standard deviation \\(\\sigma\\). These control the center and the spread of the distribution, respectively.\nThe sample space of a normal distribution is the entire real number line, meaning that the variable can take on any real value, both positive and negative.\nGraphically, the density function of a normal distribution always has the same bell-shaped curve, regardless of the specific values of \\(\\mu\\) and \\(\\sigma\\). The mean \\(\\mu\\) determines the central location of the curve, while the standard deviation \\(\\sigma\\) determines how wide or narrow the curve appears.\nA key feature of the normal distribution is that it is symmetric around the mean \\(\\mu\\). This symmetry implies that probabilities on either side of the mean are equal for equally sized intervals. In addition, as \\(x \\to \\pm\\infty\\), the density function \\(f(x)\\) approaches zero, meaning that extremely large or small values are increasingly unlikely, but not impossible.\nThe shape of a normal distribution is fully determined by its mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Changing either of these parameters modifies the appearance of the distribution in predictable ways. This is shown in Figure¬†14.1.\nIn (a), we compare two normal distributions with different means but the same standard deviation. This results in curves with identical shapes, but centered at different locations. Shifting \\(\\mu\\) translates the curve horizontally without altering its height or spread.\nIn (b), we hold the mean constant and vary the standard deviation. This causes the curve to either compress or stretch. A smaller \\(\\sigma\\) yields a sharper, narrower peak, while a larger \\(\\sigma\\) produces a flatter, wider distribution.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†14.1: Effects of changing parameters in the normal distribution (a) Changing the mean shifts the curve horizontally. (b) Changing the standard deviation alters the width and height of the curve\n\n\nBut first, we will learn how to calculate probabilities using normal distribution tables.\n\n14.3.1 Area under curve\nWhen using a normal distribution curve to model probability, the logic is as follows: we want to determine the probability that a randomly selected individual falls within a certain interval, say \\((a, b)\\). This is equivalent to finding the proportion of individuals in the population whose values lie between \\(a\\) and \\(b\\).\nIn a normal distribution, this probability corresponds to the area under the curve between \\(a\\) and \\(b\\). Since the total area under the entire curve is equal to 1 (or 100%), the shaded region gives us the desired probability.\nThis relationship between area and probability allows us to calculate how likely it is to observe values within specific ranges ‚Äî and by symmetry, how unusual values far from the mean are.\nLet us visualize this with the previously mentioned empirical rule in Figure¬†7.3, which summarizes how the area is distributed across standard deviations from the mean. This is shown in Figure¬†14.2.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†14.2: Empirical rule for the normal distribution. Shaded areas show typical probabilities for values within 1, 2, and 3 standard deviations of the mean.\n\n\nIn practice, the most important takeaway is this:\n\nApproximately 68% of values lie within one standard deviation from the mean (\\(\\mu \\pm \\sigma\\))\nAbout 95% lie within two standard deviations (\\(\\mu \\pm 2\\sigma\\))\nNearly 99.7% lie within three standard deviations (\\(\\mu \\pm 3\\sigma\\))\n\nThis is known as the empirical rule, and it forms the basis for many practical applications of the normal distribution. It also shows that values far from the mean are rare, making them candidates for being considered ‚Äúunusual‚Äù or outliers in statistical reasoning.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#the-standard-normal-distribution",
    "href": "rvs-probdists/cont-dists.html#the-standard-normal-distribution",
    "title": "14¬† Continuous Probability Distributions",
    "section": "\n14.4 The Standard Normal Distribution",
    "text": "14.4 The Standard Normal Distribution\nIn practice, the values for which we want to calculate probabilities do not always align with the specific values shown in a table. Fortunately, thanks to the properties of the normal distribution, we don‚Äôt need a separate table for every possible mean and standard deviation.\nInstead, we make use of a powerful idea: that any normal distribution can be converted into a standard normal distribution, and this makes calculating probabilities far simpler.\nThe standard normal distribution is the special case where the mean is 0 and the standard deviation is 1. That is:\n\\[\nZ \\sim \\mathcal{N}(0, 1)\n\\]\nThis is our reference distribution. Because it measures distances in units of standard deviation from the mean, we can interpret a value like \\(z = 1.5\\) as ‚Äú1.5 standard deviations above the mean‚Äù.\nSince the normal distribution is symmetric around the mean, values less than 0 represent outcomes below average, and values greater than 0 are above average. Below is the standard normal curve:\n\n\n\n\n\n\n\n\nThe plot shows the familiar bell shape, now centered at 0. By using the standard normal distribution, we only need to consult a single probability table, shown in Appendix A, to find probabilities for a wide range of problems. The transformation is done through standardization, which we‚Äôll explore in the next section.\nWe denote the cumulative probability function of the standard normal by \\(F(z)\\) or \\(P(Z \\leq z)\\), and for values of \\(z\\) between 0.00 and 3.00, these values are commonly found in standard Z-tables. Because of symmetry, we can compute probabilities for both tails of the distribution (and for negative values of \\(z\\)), i.e.\n\\[\nP(Z \\leq -z) = 1 - P(Z \\leq z)\n\\]\nThis is the foundation for calculating probabilities with normal distributions; we convert our variable to a Z-score and then read the probability directly from this reference distribution.\nExample 14.1: Standard Normal Distribution\nLet \\(Z \\sim \\mathcal{N}(0,1)\\) be a standard normal variable. We‚Äôll now walk through several examples of calculating probabilities using the standard normal distribution, visualizing the corresponding areas under the curve in each case.\n\n\\(P(Z \\leq 0)\\)\n\nBy symmetry, the probability that \\(Z\\) is less than or equal to 0 is:\n\\[\nP(Z \\leq 0) = F(0) = 0.5\n\\]\n\n\n\n\n\n\n\n\n\n\\(P(Z \\leq 1)\\)\n\nWe use the standard normal table:\n\\[\nP(Z \\leq 1) = F(1) = 0.8413\n\\]\n\n\n\n\n\n\n\n\n\n\\(P(0 \\leq Z \\leq 1)\\)\n\nThis is the difference between two cumulative probabilities:\n\\[\nP(0 \\leq Z \\leq 1) = F(1) - F(0) = 0.8413 - 0.5000 = 0.3413\n\\]\n\n\n\n\n\n\n\n\n\n\\(P(Z \\geq 0.73)\\)\n\nWe use the complement rule:\n\\[\nP(Z \\geq 0.73) = 1 - P(Z \\leq 0.73) = 1 - 0.7673 = 0.2327\n\\]\n\n\n\n\n\n\n\n\n\n\\(P(Z \\geq -1.59)\\)\n\nUsing symmetry:\n\\[\nP(Z \\geq -1.59) = P(Z \\leq 1.59) = F(1.59) = 0.9441\n\\]\n\n\n\n\n\n\n\n\n\n\\(P(-1.59 \\leq Z \\leq 0.73)\\)\n\nWe combine cumulative values:\n\\[\n\\begin{split}\nP(-1.59 \\leq Z \\leq 0.73) & = F(0.73) - (1 - F(1.59)) \\\\ &\n= 0.7673 - (1 - 0.9441) \\\\ & = 0.7114\n\\end{split}\n\\]",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#from-normal-to-standard-normal-distribution",
    "href": "rvs-probdists/cont-dists.html#from-normal-to-standard-normal-distribution",
    "title": "14¬† Continuous Probability Distributions",
    "section": "\n14.5 From Normal to Standard Normal Distribution",
    "text": "14.5 From Normal to Standard Normal Distribution\nSuppose a random variable \\(X\\) follows a normal distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), written:\n\\[\nX \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\nWe often want to compute the probability \\(P(X \\leq x)\\) for some value \\(x\\). While this can‚Äôt be calculated directly from \\(X\\) without integration, we can convert the problem to one involving the standard normal distribution using the transformation:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\nThis transformation maps \\(X\\) to a standard normal variable \\(Z \\sim \\mathcal{N}(0,1)\\). The beauty of this is that we can now use our standard normal table in Appendix A to calculate:\n\\[\nP(X \\leq x) = P\\left(Z \\leq \\frac{x - \\mu}{\\sigma} \\right)\n\\]\nExample 14.2: \\(X \\sim \\mathcal{N}(170, 10)\\)\n\nWe want to compute:\n\n\\(P(X \\leq 190)\\)\n\nWe begin by standardizing:\n\\[\nZ = \\frac{X - 170}{10}, \\quad \\text{so} \\quad \\frac{190 - 170}{10} = 2\n\\]\nThen use the standard normal table to find the correpsondign probability area:\n\\[\nP(X \\leq 190) = P(Z \\leq 2) = 0.9772\n\\]\nThis is shown below in Figure¬†14.3 where both shaded areas are exactly the same.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†14.3: Top: Probability under the original normal distribution \\(X \\sim \\mathcal{N}(170, 10)\\). Bottom: Corresponding probability under the standard normal distribution \\(Z \\sim \\mathcal{N}(0, 1)\\). The shaded areas are equivalent, since \\(Z = \\frac{X - \\mu}{\\sigma}\\).",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#normal-approximation-to-the-binomial-distribution",
    "href": "rvs-probdists/cont-dists.html#normal-approximation-to-the-binomial-distribution",
    "title": "14¬† Continuous Probability Distributions",
    "section": "\n14.6 Normal Approximation to the Binomial Distribution",
    "text": "14.6 Normal Approximation to the Binomial Distribution\nAs hinted before, one of the normal distribution‚Äôs greatest superpowers is its flexibility; it‚Äôs like the Swiss Army knife of probability! Why? Because it can be used to approximate probabilities in many important situations, especially when working with other discrete distributions.\nAs seen in Figure¬†14.4, the binomial distribution becomes increasingly symmetric and bell-shaped as the sample size grows. When the number of trials is large enough, the distribution of a binomially distributed variable begins to closely resemble that of a normal distribution. In such cases, it becomes not only possible but also practical to use the normal distribution as an approximation.\nThe normal approximation is particularly helpful when exact binomial probabilities are cumbersome to calculate.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†14.4: Binomial Distribution with \\(p = 0.3\\) approaching Normal as \\(n\\) increases.\n\n\n\n14.6.1 When can we approximate?\nA common rule of thumb is:\n\\[\nnp(1 - p) &gt; 5\n\\]\nIf this condition is met, the binomial distribution can be reasonably approximated by a normal distribution that shares the same mean and variance.\n\n14.6.2 How is the approximation performed?\nWell, suppose \\(X \\sim \\text{Bin}(n, p)\\) and the above condition is satisfied. Then we can approximate \\(X\\) using a normal distribution:\n\\[\nX \\overset{\\text{apx}}{\\sim} \\mathcal{N}(\\mu, \\sigma)\n\\]\nwhere\n\\[\n\\mu = E(X) = np \\quad \\text{and} \\qquad \\sigma = \\sqrt{\\operatorname{Var}(X)} = \\sqrt{np(1 - p)}\n\\]\nTo compute a probability such as \\(P(X \\leq c)\\), where \\(c\\) is an integer, we use the standard normal distribution:\n\\[\nP(X \\leq c) \\approx P\\left(Z \\leq \\frac{c - \\mu}{\\sigma} \\right)\n\\]\nThis gives us an approximate value by translating the binomial question into a standard normal one.\nExample 14.3: Binomial to Normal\nLet \\(X \\sim \\text{Bin}(44, 0.45)\\). We wish to approximate the probability:\n\\[\nP(X \\leq 26)\n\\]\nFirst, compute the mean and variance of \\(X\\):\n\\[\nE(X) = 44 \\cdot 0.45 = 19.8 \\\\\n\\operatorname{Var}(X) = 44 \\cdot 0.45 \\cdot 0.55 = 10.89\n\\]\nSince \\(nP(1 - P) = 10.89 &gt; 5\\), the normal approximation is applicable.\nNow standardize:\n\\[\nZ = \\frac{26 - 19.8}{\\sqrt{10.89}} \\approx \\frac{6.2}{3.3} \\approx 1.88\n\\]\nUsing the standard normal distribution:\n\\[\nP(X \\leq 26) \\approx P(Z \\leq 1.88) = 0.9699\n\\]\nFor comparison, the exact binomial value is:\n\\[\nP(X \\leq 26) = 0.9786\n\\]\nSo the normal approximation is quite close, especially useful when exact computation is difficult.\n\n14.6.3 Continuity Correction\nWhen using a normal distribution to approximate a binomial, it‚Äôs important to remember that we are replacing a discrete distribution (which only takes whole number values) with a continuous one (which takes all real values). To improve the accuracy of this approximation, we use a technique called the continuity correction.\nThe idea is simple: when we compute a probability such as \\(P(X \\leq c)\\) for a binomial variable, we approximate it not with \\(P(Z \\leq z)\\) but with a slightly adjusted value:\n\\[\nP(X \\leq c) \\approx P\\left(Z \\leq \\frac{c + 0.5 - \\mu}{\\sigma} \\right)\n\\]\nThe addition of \\(0.5\\) shifts the cutoff slightly to the right, accounting for the fact that we‚Äôre now working with an area under a continuous curve rather than summing discrete spikes.\nExample 14.3: Binomial to Normal (cont‚Äôd)\nRecall from earlier that:\n\\[\nX \\sim \\text{Bin}(44, 0.45), \\quad \\mu = 19.8, \\quad \\sigma = \\sqrt{10.89} \\approx 3.3\n\\]\nWe want to compute:\n\\[\nP(X \\leq 26)\n\\]\nUsing the continuity correction, we calculate:\n\\[\nP(X \\leq 26) \\approx P\\left(Z \\leq \\frac{26 + 0.5 - 19.8}{3.3} \\right)\n= P(Z \\leq 2.0)\n= 0.9772\n\\]\nThis is a better approximation than the earlier uncorrected value of \\(P(Z \\leq 1.88) = 0.9699\\).\nThe table below summarizes and compraes the results:\n\n\n\nValue\n\n\n\nExact binomial\n0.9786\n\n\nNormal approximation\n0.9699\n\n\nWith continuity correction\n0.9772\n\n\n\nAs shown above, the continuity correction significantly improves the accuracy of the approximation and is highly recommended when using the normal distribution to approximate binomial probabilities.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#exercises",
    "href": "rvs-probdists/cont-dists.html#exercises",
    "title": "14¬† Continuous Probability Distributions",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose human reaction times to a specific stimulus are normally distributed with a mean of 300 milliseconds and a standard deviation of 50 milliseconds. You randomly select one person. What is the probability that their reaction time is between 237.5 ms and 325 ms?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe standardize both endpoints:\n\\[\nZ_1 = \\frac{237.5 - 300}{50} = -1.25 \\quad\\text{and}\\quad Z_2 = \\frac{325 - 300}{50} = 0.5\n\\]\nFrom the standard normal table:\n\n\\(P(Z \\leq 0.5) = 0.6915\\)\n\\(P(Z \\leq -1.25) = 0.1056\\)\n\nSo:\n\\[\nP(237.5 \\leq X \\leq 325) = 0.6915 - 0.1056 = \\boxed{0.5859}\n\\]\nThis means there‚Äôs about a 59% chance a person reacts within this interval.\n\n\n\n\nAn economic survey estimates that 35% of a certain population is underemployed. In a sample of 100 individuals, let \\(X\\) be the number who are underemployed. What is the probability that at most 42 people are underemployed? Use the normal approximation with continuity correction.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe model \\(X \\sim \\text{Bin}(100, 0.35)\\)\n\nMean: \\(\\mu = 100 \\cdot 0.35 = 35\\)\n\nStandard deviation: \\(\\sigma = \\sqrt{100 \\cdot 0.35 \\cdot 0.65} = \\sqrt{22.75} \\approx 4.77\\)\n\n\nUsing continuity correction:\n\\[\nP(X \\leq 42) \\approx P\\left(Z \\leq \\frac{42 + 0.5 - 35}{4.77} \\right) = P(Z \\leq 1.57)\n\\]\nFrom Z-table:\n\\[\nP(Z \\leq 1.57) = \\boxed{0.9418}\n\\]\nSo there‚Äôs a 94% chance that 42 or fewer people in the sample are underemployed.\n\n\n\n\nIn a national voter turnout study, the probability that an eligible person votes is estimated to be 65%. Suppose a researcher surveys 200 randomly selected citizens. Let \\(X\\) be the number of individuals in the sample who actually voted. What is the probability that between 120 and 140 people (inclusive) voted, using a normal approximation with continuity correction?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe model \\(X \\sim \\text{Bin}(n = 200, p = 0.65)\\).\n\nMean: \\(\\mu = 200 \\cdot 0.65 = 130\\)\n\nStandard deviation: \\(\\sigma = \\sqrt{200 \\cdot 0.65 \\cdot 0.35} = \\sqrt{45.5} \\approx 6.74\\)\n\n\nWe apply continuity correction to the bounds:\n\nLower bound: \\(X = 120 \\Rightarrow Z = \\frac{119.5 - 130}{6.74} \\approx -1.56\\)\n\nUpper bound: \\(X = 140 \\Rightarrow Z = \\frac{140.5 - 130}{6.74} \\approx 1.56\\)\n\n\nSo:\n\\[\nP(120 \\leq X \\leq 140) \\approx P(-1.56 \\leq Z \\leq 1.56)\n\\]\nFrom standard normal tables:\n\n\\(P(Z \\leq 1.56) = 0.9406\\)\n\\(P(Z \\leq -1.56) = 1 - 0.9406 = 0.0594\\)\n\nTherefore:\n\\[\nP(-1.56 \\leq Z \\leq 1.56) = 0.9406 - 0.0594 = \\boxed{0.8812}\n\\]\nThere‚Äôs an 88.1% chance that between 120 and 140 people in the sample voted.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html",
    "href": "rvs-probdists/jointly-dist.html",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "",
    "text": "15.1 Multivariate Random Variables\nUp to this point, we‚Äôve focused primarily on single random variables, for example, the number of heads in a series of coin flips or the height of a randomly selected person. But in many real-world scenarios, we are interested in studying multiple random variables at the same time.\nIn this chapter we take a close look on jointly distributed random variables and explore their joint, marginal, and conditional behavior, then we introduce the concepts of independence and correlation, and learn how to work with sums and differences.\nSome variables may emerge from the same underlying random experiment, and they might be related or not. Our goal is to understand their individual behaviors, and more importantly, how they interact with each other.\nFor instance:\nWhen we analyze such situations, we say that the variables \\(X\\) and \\(Y\\) are jointly distributed. That is, we consider their distributions together, not in isolation.\nThe concept extends naturally beyond just two variables. We may consider \\(n\\) random variables \\(X_1, X_2, \\dots, X_n\\) that are all jointly distributed, meaning they are defined from a single experiment and may or may not be dependent on each other.\nConsider the experiment of rolling a die 10 times. We can define a sequence of variables:\n\\[\nX_1 = \\text{dots on roll 1}, \\quad X_2 = \\text{dots on roll 2}, \\quad \\dots, \\quad X_{10} = \\text{dots on roll 10}\n\\]\nTogether, these form 10 jointly distributed random variables. In this case, each variable reflects a distinct outcome from a shared process (a sequence of rolls) and is naturally treated as part of a multivariate random structure.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#multivariate-random-variables",
    "href": "rvs-probdists/jointly-dist.html#multivariate-random-variables",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "",
    "text": "Suppose we randomly select one person from a population.\nLet \\(X\\) be their weight and \\(Y\\) be his height. These two measurements clearly relate to the same individual and may show some correlation, taller people tend to weigh more, on average.\nOr imagine rolling a die twice.\nLet \\(X\\) be the number of dots on the first roll, and \\(Y\\) the number of dots on the second. Here, the two values result from separate events within the same experiment, and in this case, may be independent.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#joint-probability-distribution-discrete-case",
    "href": "rvs-probdists/jointly-dist.html#joint-probability-distribution-discrete-case",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "\n15.2 Joint Probability Distribution (Discrete Case)",
    "text": "15.2 Joint Probability Distribution (Discrete Case)\nLet \\(X\\) and \\(Y\\) be two discrete random variables observed together. Then we define their joint probability mass function (joint PMF) as:\n\\[\nP(x, y) = P(X = x \\text{ and } Y = y) = P(X = x \\cap Y = y)\n\\]\nThis function gives the probability of every possible pair of outcomes \\((x, y)\\). It‚Äôs essentially a table (or function) that assigns a probability to each combination of values that \\(X\\) and \\(Y\\) might jointly take.\nWhen we refer to the joint distribution of \\(X\\) and \\(Y\\), we mean the complete collection of these probabilities, i.e.¬†the full map of how the two variables behave together.\nIn the next sections, we‚Äôll explore how to work with joint distributions, derive marginal and conditional probabilities, and investigate whether or not the variables are independent.\nExample 15.1: Family Composition\nLet‚Äôs consider a practical example. Suppose we randomly select a family from a large population. Let:\n\n\n\\(X\\) = number of boys in the family\n\n\n\\(Y\\) = number of girls in the family\n\nBelow is the joint probability distribution for \\(X\\) and \\(Y\\), represented in table form. Table¬†15.1 tells us how likely it is to observe each specific combination of boys and girls.\n\n\nTable¬†15.1: Joint Probability Table for Number of Boys (\\(X\\)) and Girls (\\(Y\\)).\n\n\n\n\nJoint Probability Table for Number of Boys (X) and Girls (Y)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of girls (Y)\n\n\n\n\nNumber of boys (X)\n0\n1\n2\n3\n4\nP(X = x)\n\n\n\n\n0\n0.38\n0.16\n0.04\n0.01\n0.01\n0.60\n\n\n1\n0.17\n0.08\n0.02\n‚Äì\n‚Äì\n0.27\n\n\n2\n0.05\n0.02\n0.01\n‚Äì\n‚Äì\n0.08\n\n\n3\n0.02\n0.01\n‚Äì\n‚Äì\n‚Äì\n0.03\n\n\n4\n0.02\n‚Äì\n‚Äì\n‚Äì\n‚Äì\n0.02\n\n\nP(Y = y)\n0.64\n0.27\n0.07\n0.01\n0.01\n1.00\n\n\n\n\n\n\n\n\nTable¬†15.1 above shows the full joint probability distribution of the number of boys (\\(X\\)) and girls (\\(Y\\)) in a randomly selected family. Each cell in the main body of the table gives the probability that a family has a specific combination of boys and girls. For example, the probability of having 1 boy and 2 girls is 0.02.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#marginal-distributions",
    "href": "rvs-probdists/jointly-dist.html#marginal-distributions",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "\n15.3 Marginal Distributions",
    "text": "15.3 Marginal Distributions\nFrom the joint distribution, we can compute the marginal distributions for \\(X\\) and \\(Y\\). These represent the individual behavior of each variable, ignoring the other.\nThe marginal probability distribution for \\(X\\) is obtained by summing each row across all \\(y\\) values:\n\\[\nP(X = x) = \\sum_y P(x, y)\n\\]\nSimilarly, the marginal distribution for \\(Y\\) comes from summing each column across all \\(x\\) values:\n\\[\nP(Y = y) = \\sum_x P(x, y)\n\\]\nThe row and column totals in the table reflect these marginal probabilities.\nExample 15.1: Family Composition (cont‚Äôd)\nAt the end of each row in Table¬†15.1, we see the marginal distribution of \\(X\\), denoted \\(P(X = x)\\). These values are computed by summing the probabilities across each row, that is, over all values of \\(Y\\) for a fixed \\(X\\). The interpretation is simple: \\(P(X = 1) = 0.27\\) means that 27% of the families have exactly one boy, regardless of how many girls they have.\nSimilarly, the bottom row contains the marginal distribution of \\(Y\\), labeled \\(P(Y = y)\\). These probabilities are calculated by summing down each column ‚Äî over all values of \\(X\\) for a fixed number of girls \\(Y = y\\). For instance, \\(P(Y = 0) = 0.64\\) indicates that 64% of the families have no girls, irrespective of how many boys they have.\nThese marginal distributions summarize the overall behavior of each variable independently, while the joint distribution reflects how the variables interact.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#conditional-distributions",
    "href": "rvs-probdists/jointly-dist.html#conditional-distributions",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "\n15.4 Conditional Distributions",
    "text": "15.4 Conditional Distributions\nWith the joint and marginal distributions in hand, we can now define and compute conditional probabilities. These allow us to ask more nuanced questions, such as:\n\n‚ÄúWhat is the probability a family has two boys given that it has no girls?‚Äù\n‚ÄúHow does the number of boys vary given that the family has two girls?‚Äù\n\nTo compute a conditional distribution, we use the definition:\n\\[\nP(X = x \\mid Y = y) = \\frac{P(X = x \\cap Y = y)}{P(Y = y)}\n\\]\nThis gives us the probability of a specific \\(X\\) value, assuming we know the value of \\(Y\\). We calculate this by dividing each entry in a given column by the total at the bottom of that column.\nExample 15.1: Family Composition (cont‚Äôd)\nUsing the formula:\n\\[\nP(X = x \\mid Y = y) = \\frac{P(X = x, Y = y)}{P(Y = y)}\n\\]\nWe divide each cell in a column (fixed \\(Y = y\\)) by the column total to obtain the conditional distribution of \\(X\\) given \\(Y = y\\).\nFor example, to compute \\(P(X = 0 \\mid Y = 1)\\): \\[\nP(X = 0 \\mid Y = 1) = \\frac{P(X = 0 \\cap Y = 1)}{P(Y = 1)} = \\frac{0.16}{0.27} \\approx 0.59\n\\]\nThis tells us that among families with exactly one girl, 59% of them have no boys.\nTable¬†15.2 is the conditional distribution of \\(X\\) given various values of \\(Y\\):\n\n\nTable¬†15.2: Conditional Probabilities \\(P(X = x | Y = y)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of girls (Y)\n\n\n\n\nNumber of boys (X)\n0\n1\n2\n3\n4\nP(X = x)\n\n\n\n\n0\n0.59\n0.59\n0.57\n1.00\n1.00\n0.60\n\n\n1\n0.27\n0.30\n0.29\n‚Äì\n‚Äì\n0.27\n\n\n2\n0.08\n0.07\n0.14\n‚Äì\n‚Äì\n0.08\n\n\n3\n0.03\n0.04\n‚Äì\n‚Äì\n‚Äì\n0.03\n\n\n4\n0.02\n‚Äì\n‚Äì\n‚Äì\n‚Äì\n0.02\n\n\n\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\nNote that each column now sums to 1, since we‚Äôre conditioning on a fixed \\(Y = y\\). In other words Each such column-normalized set of values gives the conditional distribution of \\(X\\) given \\(Y = y\\). These distributions allow us to examine how the number of boys is influenced by the known number of girls. We can also reverse the roles and analyze \\(P(Y = y \\mid X = x)\\) by normalizing each row.\nThis approach allows us to analyze how knowledge of one variable informs us about the likely values of the other, a key idea that leads naturally into concepts like independence, correlation, and covariance, which we‚Äôll explore next.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#independence-of-random-variables",
    "href": "rvs-probdists/jointly-dist.html#independence-of-random-variables",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "\n15.5 Independence of Random Variables",
    "text": "15.5 Independence of Random Variables\nWhen working with two or more random variables defined on the same experiment, an important question is whether they are independent ‚Äî that is, whether the value of one gives us any information about the other.\nTwo discrete random variables \\(X\\) and \\(Y\\) are said to be independent if and only if:\n\\[\nP(X = x, Y = y) = P(X = x) \\cdot P(Y = y)\n\\]\nfor all combinations of values \\(x\\) and \\(y\\).\nThis definition mirrors what we‚Äôve already seen for independence between events:\nIf \\(A\\) and \\(B\\) are events, then they are independent if:\n\\[\nP(A \\cap B) = P(A) \\cdot P(B)\n\\]\nIn this setting, each event \\(X = x\\) and \\(Y = y\\) can be thought of as a particular outcome ‚Äî and we require that every pair of outcomes satisfies the multiplicative rule to call \\(X\\) and \\(Y\\) independent.\nIn applied settings, we often use prior experience or domain knowledge to assume independence between variables when it‚Äôs reasonable. For instance, if two numerical quantities are measured in such a way that one could not possibly influence the other, we usually model them as independent.\nExample 15.2: Rolling Dice Twice\nLet:\n\n\n\\(X\\) = number of dots on the first die roll\n\n\n\\(Y\\) = number of dots on the second die roll\n\nIf the dice rolls are fair and separate, then the outcome of the first roll has no effect on the second. Therefore, we assume that \\(X\\) and \\(Y\\) are independent random variables.\nThe joint probability of both rolls resulting in a six is:\n\\[\nP(X = 6, Y = 6) = P(X = 6) \\cdot P(Y = 6) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36}\n\\]\nExample 15.1: Family Composition (cont‚Äôd)\nLet‚Äôs revisit the earlier example with the joint probability distribution of the number of boys (\\(X\\)) and girls (\\(Y\\)) in a family and ask: are number of boys and girls independent?\nTo test for independence, we compare:\n\\[\nP(X = x, Y = y) \\stackrel{?}{=} P(X = x) \\cdot P(Y = y)\n\\]\nFor example:\n\nFrom Table¬†15.1 we get that \\(P(X = 1, Y = 1) = 0.08\\)\n\nMarginals: \\(P(X = 1) = 0.27\\), \\(P(Y = 1) = 0.27\\)\n\n\nSo:\n\\[\nP(X = 1) \\cdot P(Y = 1) = 0.27 \\cdot 0.27 = 0.0729\n\\]\nSince \\(0.0729 \\neq 0.08\\), the condition does not hold. Therefore, \\(X\\) and \\(Y\\) are not independent. This implies that the number of boys in a family is somewhat related to the number of girls, not surprising, as both are constrained by total family size.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#constructing-a-joint-distribution-under-independence",
    "href": "rvs-probdists/jointly-dist.html#constructing-a-joint-distribution-under-independence",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "\n15.6 Constructing a Joint Distribution Under Independence",
    "text": "15.6 Constructing a Joint Distribution Under Independence\nSuppose \\(X\\) and \\(Y\\) are two independent random variables defined as follows:\n\n\n\\(X\\) takes values 1 and 2 with probabilities 0.4 and 0.6\n\n\\(Y\\) takes values 1, 2, and 3 with probabilities 0.2, 0.5, and 0.3\n\nSince \\(X\\) and \\(Y\\) are independent, the joint probability is obtained by multiplying the marginal probabilities for each combination of \\(x\\) and \\(y\\). Doing so leads to Table¬†15.3.\n\n\nTable¬†15.3: Joint Probability Table for Independent Random Variables X and Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nY\n\n\n\n\nX\n1\n2\n3\nP(X = x)\n\n\n\n\n1\n0.08\n0.20\n0.12\n0.40\n\n\n2\n0.12\n0.30\n0.18\n0.60\n\n\nP(Y = y)\n0.20\n0.50\n0.30\n1.00\n\n\n\n\n\n\n\n\nEach cell is computed as:\n\\[\nP(X = x, Y = y) = P(X = x) \\cdot P(Y = y)\n\\]\nFor example:\n\n\\(P(X = 1, Y = 1) = 0.4 \\cdot 0.2 = 0.08\\)\n\\(P(X = 2, Y = 2) = 0.6 \\cdot 0.5 = 0.30\\)\n\nTable¬†15.3 reflects the idea that independent random variables ‚Äúdon‚Äôt talk to each other‚Äù ‚Äî knowing the value of one gives no information about the other.\nThe definition of independence extends beyond just two variables. A set of random variables \\(X_1, X_2, \\dots, X_n\\) is said to be mutually independent if and only if:\n\\[\nP(X_1 = x_1, X_2 = x_2, \\dots, X_n = x_n) = P(X_1 = x_1) \\cdot P(X_2 = x_2) \\cdots P(X_n = x_n)\n\\]\nfor all combinations of values \\(x_1, x_2, \\dots, x_n\\).\nThis definition guarantees that knowing the value of one variable gives us no information about the values of the others ‚Äî all outcomes occur independently of one another.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#covariance-and-correlation-observed-data",
    "href": "rvs-probdists/jointly-dist.html#covariance-and-correlation-observed-data",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "\n15.7 Covariance and Correlation: Observed Data",
    "text": "15.7 Covariance and Correlation: Observed Data\nNow, suppose we have a data set with two measured variables \\(x\\) and \\(y\\):\n\n\nObs.\n\\(x_i\\)\n\\(y_i\\)\n\n\n\n1\n\\(x_1\\)\n\\(y_1\\)\n\n\n2\n\\(x_2\\)\n\\(y_2\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\n\\(x_n\\)\n\\(y_n\\)\n\n\n\nThe sample covariance between \\(x\\) and \\(y\\) is defined as:\n\\[\ns_{xy} = \\frac{1}{n - 1} \\sum_{i = 1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n\\]\n\nIf \\(s_{xy} &gt; 0\\), \\(x\\) and \\(y\\) tend to increase together (positive linear relationship).\nIf \\(s_{xy} &lt; 0\\), one tends to increase as the other decreases (negative relationship).\n\nA more standardized measure is the sample correlation coefficient \\(r_{xy}\\):\n\\[\nr_{xy} = \\frac{s_{xy}}{s_x s_y}\n\\]\nwhere \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\) respectively.\nAlternatively, this can be computed as:\n\\[\nr_{xy} =\n\\frac{\\sum_{i = 1}^n (x_i - \\bar{x})(y_i - \\bar{y})}\n{\\sqrt{\\sum_{i = 1}^n (x_i - \\bar{x})^2} \\cdot \\sqrt{\\sum_{i = 1}^n (y_i - \\bar{y})^2}}\n\\]\nThis formula provides a unitless measure of linear association, bounded by \\(-1 \\leq r_{xy} \\leq 1\\).\n\n\n\\(r_{xy} = 1\\) means perfect positive linear correlation\n\n\\(r_{xy} = -1\\) means perfect negative linear correlation\n\n\\(r_{xy} = 0\\) means no linear correlation (but nonlinear relationships may still exist)\n\nFor more details see Section 7.6.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#covariance-and-correlation-for-random-variables",
    "href": "rvs-probdists/jointly-dist.html#covariance-and-correlation-for-random-variables",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "\n15.8 Covariance and Correlation for Random Variables",
    "text": "15.8 Covariance and Correlation for Random Variables\nWe now extend these ideas to random variables.\nThe theoretical covariance of two random variables \\(X\\) and \\(Y\\) is defined as:\n\\[\n\\operatorname{Cov}(X, Y) = \\sigma_{XY} = E[(X - \\mu_X)(Y - \\mu_Y)]\n\\]\nIn discrete form:\n\\[\n\\operatorname{Cov}(X, Y) =\n\\sum_x \\sum_y (x - \\mu_X)(y - \\mu_Y) P(x, y)\n\\]\nWe also use a computational shortcut:\n\\[\n\\operatorname{Cov}(X, Y) = E(XY) - \\mu_X \\mu_Y\n\\]\nThe correlation coefficient between two random variables \\(X\\) and \\(Y\\) is:\n\\[\n\\rho_{XY} = \\frac{\\operatorname{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n\\]\nThis is a standardized version of covariance, ranging between \\(-1\\) and \\(1\\), and easier to interpret.\nJust like with sample data:\n\n\n\\(\\rho = 1\\) implies perfect positive linear association\n\n\\(\\rho = -1\\) implies perfect negative linear association\n\n\\(\\rho = 0\\) means \\(X\\) and \\(Y\\) are uncorrelated\n\n\nThe correlation coefficient always shares the same sign as the covariance, that is, if the covariance is positive, the correlation is positive, and vice versa.\nThis makes correlation a useful, unitless summary of the strength and direction of the linear association between two variables ‚Äî especially when comparing across different data sets or variables with different units.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#expected-value-and-variance-of-sums-and-differences",
    "href": "rvs-probdists/jointly-dist.html#expected-value-and-variance-of-sums-and-differences",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "\n15.9 Expected Value and Variance of Sums and Differences",
    "text": "15.9 Expected Value and Variance of Sums and Differences\nWe now wrap up this chapter with a powerful and commonly used set of results: how to compute the expected value and variance of a sum or difference of two random variables. This is realted to what we covered in Section 12.4.\nLet \\(X\\) and \\(Y\\) be two random variables. Suppose we are interested in the distribution of their sum \\(X + Y\\) or difference \\(X - Y\\). The following rules apply:\nThe expected value behaves linearly, meaning:\n\\[\nE(X + Y) = E(X) + E(Y)\n\\]\nand\n\\[\nE(X - Y) = E(X) - E(Y)\n\\]\nThis rule is always true, regardless of whether \\(X\\) and \\(Y\\) are independent.\nVariance, however, is not generally linear. The formula involves the covariance between \\(X\\) and \\(Y\\):\n\\[\n\\begin{aligned}\n\\operatorname{Var}(X + Y) &= \\operatorname{Var}(X) + \\operatorname{Var}(Y) + 2 \\cdot \\operatorname{Cov}(X, Y) \\\\\n\\operatorname{Var}(X - Y) &= \\operatorname{Var}(X) + \\operatorname{Var}(Y) - 2 \\cdot \\operatorname{Cov}(X, Y)\n\\end{aligned}\n\\]\nSo when variables are positively correlated, the variance of their sum increases. When they‚Äôre negatively correlated, the variance of the sum decreases.\nA special case concerns uncorrelated variables.If \\(X\\) and \\(Y\\) are uncorrelated, that is:\n\\[\n\\operatorname{Cov}(X, Y) = 0\n\\]\nThen the formulas simplify to:\n\\[\n\\begin{aligned}\n\\operatorname{Var}(X + Y) &= \\operatorname{Var}(X) + \\operatorname{Var}(Y) \\\\\n\\operatorname{Var}(X - Y) &= \\operatorname{Var}(X) + \\operatorname{Var}(Y)\n\\end{aligned}\n\\]\nIt‚Äôs important to note:\n\nIf \\(X\\) and \\(Y\\) are independent, then they are also uncorrelated.\n\n\\[\n\\text{If } X \\perp Y \\Rightarrow \\rho_{XY} = 0\n\\]\nHowever, the converse is not true: uncorrelated variables may still be dependent, just not in a linear way. For example, \\(Y = X^2\\) is nonlinearly related to \\(X\\) but could have \\(\\rho = 0\\).\nThat is, independence implies zero covariance:\n\\[\nX \\perp Y \\quad \\Rightarrow \\quad \\operatorname{Cov}(X, Y) = 0\n\\]\nBut the reverse is not necessarily true. Two variables can have zero covariance (i.e., be uncorrelated) and still be dependent in a nonlinear way. This is further illustrated in Exercise 2 below.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/jointly-dist.html#exercises",
    "href": "rvs-probdists/jointly-dist.html#exercises",
    "title": "15¬† Jointly Distributed Random Variables",
    "section": "Exercises",
    "text": "Exercises\n\nGiven the joint distribution below:\n\n\n\n\n\\(x\\) \\ \\(y\\)\n\n0\n1\n2\n\\(P(x)\\)\n\n\n\n1\n0.08\n0.12\n0.30\n0.50\n\n\n2\n0.12\n0.18\n0.20\n0.50\n\n\n\\(P(y)\\)\n0.20\n0.30\n0.50\n1.00\n\n\n\nCalculate the correlation \\(\\rho_{XY}\\) between \\(X\\) and \\(Y\\).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst, use marginal distributions to compute all relevant expected values: \\[\nE(X) = 1 \\cdot 0.50 + 2 \\cdot 0.50 = 0.50 + 1.00 = 1.50\n\\] \\[\nE(Y) = 0 \\cdot 0.20 + 1 \\cdot 0.30 + 2 \\cdot 0.50 = 0 + 0.30 + 1.00 = 1.30\n\\]\nWe multiply each \\((x, y)\\) pair by its joint probability:\n\\[\n\\begin{aligned}\nE(XY) &= 1 \\cdot 0 \\cdot 0.08 + 1 \\cdot 1 \\cdot 0.12 + 1 \\cdot 2 \\cdot 0.30 \\\\\n      &+ 2 \\cdot 0 \\cdot 0.12 + 2 \\cdot 1 \\cdot 0.18 + 2 \\cdot 2 \\cdot 0.20 \\\\\n&= 0 + 0.12 + 0.60 + 0 + 0.36 + 0.80 = 1.88\n\\end{aligned}\n\\]\nUse the shortcut formula:\n\\[\n\\operatorname{Cov}(X, Y) = E(XY) - E(X)E(Y) = 1.88 - (1.50)(1.30) = 1.88 - 1.95 = -0.07\n\\] Use the marginal distributions again to compute variances: \\[\n\\begin{aligned}\nE(X^2) &= 1^2 \\cdot 0.50 + 2^2 \\cdot 0.50 = 0.50 + 2.00 = 2.50 \\\\\n\\operatorname{Var}(X) &= E(X^2) - [E(X)]^2 = 2.50 - 1.50^2 = 2.50 - 2.25 = 0.25 \\\\\n\\sigma_X &= \\sqrt{0.25} = 0.50\n\\end{aligned}\n\\] \\[\n\\begin{aligned}\nE(Y^2) &= 0^2 \\cdot 0.20 + 1^2 \\cdot 0.30 + 2^2 \\cdot 0.50 = 0 + 0.30 + 2.00 = 2.30 \\\\\n\\operatorname{Var}(Y) &= E(Y^2) - [E(Y)]^2 = 2.30 - 1.30^2 = 2.30 - 1.69 = 0.61 \\\\\n\\sigma_Y &= \\sqrt{0.61} \\approx 0.78\n\\end{aligned}\n\\]\nNow we hjave evrything needed to cmopute the correlation: \\[\n\\rho_{XY} = \\frac{\\operatorname{Cov}(X, Y)}{\\sigma_X \\sigma_Y} = \\frac{-0.07}{0.50 \\cdot 0.78} \\approx \\boxed{-0.18}\n\\]\nThis indicates a weak negative linear relationship between \\(X\\) and \\(Y\\).\n\n\n\n\nLet \\(X\\) be a discrete random variable taking the values \\(-1\\), \\(0\\), and \\(1\\), each with equal probability:\n\n\n\n\\(X\\)\n\\(P(X)\\)\n\n\n\n-1\n1/3\n\n\n0\n1/3\n\n\n1\n1/3\n\n\n\nDefine a new random variable \\(Y = X^2\\).\n\nAre \\(X\\) and \\(Y\\) dependent or independent?\nCompute \\(\\operatorname{Cov}(X, Y)\\) and determine whether they are correlated.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSince \\(Y = X^2\\), the value of \\(Y\\) is entirely determined by \\(X\\). So \\(X\\) and \\(Y\\) are clearly dependent.\nNex compute \\(E(X)\\) and \\(E(Y)\\) \\[\nE(X) = (-1) \\cdot \\frac{1}{3} + 0 \\cdot \\frac{1}{3} + 1 \\cdot \\frac{1}{3} = 0\n\\]\n\\[\nE(Y) = 1 \\cdot \\frac{1}{3} + 0 \\cdot \\frac{1}{3} + 1 \\cdot \\frac{1}{3} = \\frac{2}{3}\n\\]\nTo compute \\(E(XY)\\) we compute \\(XY\\) for each pair:\n\n\n\\(X = -1\\), \\(Y = 1\\) ‚Üí \\(XY = -1\\)\n\n\n\\(X = 0\\), \\(Y = 0\\) ‚Üí \\(XY = 0\\)\n\n\n\\(X = 1\\), \\(Y = 1\\) ‚Üí \\(XY = 1\\)\n\n\nThen: \\[\nE(XY) = (-1) \\cdot \\frac{1}{3} + 0 + 1 \\cdot \\frac{1}{3} = 0\n\\]\nNext we compute the covariance:\n\\[\n\\operatorname{Cov}(X, Y) = E(XY) - E(X)E(Y) = 0 - (0 \\cdot \\tfrac{2}{3}) = 0\n\\]\nThis means: \\[\n\\operatorname{Cov}(X, Y) = 0 \\quad \\text{and} \\quad \\rho_{XY} = 0\n\\] We see here that even though \\(X\\) and \\(Y\\) are clearly dependent, their covariance and correlation are zero. This is an illustration of that uncorrelated does not imply independence.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Jointly Distributed Random Variables</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling.html",
    "href": "sampling-dists/sampling.html",
    "title": "16¬† Sampling",
    "section": "",
    "text": "16.1 Populations and Samples\nStatistics is built on the bridge between the theoretical and the observable ‚Äî between the population we aim to understand and the sample data we actually have in hand. In other words, it is about learning from data ‚Äî but data never comes from thin air. It always originates from some underlying group, system, or process, which we refer to as the population. Yet, we almost never observe the whole population. Instead, we work with a sample.\nThis chapter introduces fundamental ideas that underpin all of statistical inference: the concept of a population, a sample, and the assumptions we make when drawing conclusions from one to the other. Here, we lay the groundwork for how we conceptualize data: where it comes from, what it represents, and what assumptions are reasonable when we try to generalize from sample to population.\nWe also explore different ways of selecting a sample from a population. How we draw the sample affects both the validity of our conclusions and the precision of our estimates. We distinguish between probability sampling methods, where each unit in the population has a known chance of being selected, and non-probability sampling, where that probability is unknown or ignored.\nIn statistics, the population refers to the entire group we‚Äôre interested in studying. This can be tangible and finite, like all employees in a company, or conceptual and infinite, like all possible future outcomes of a coin flip.\nThe sample is the data we actually observe. It‚Äôs a (usually small) subset of the population and forms the basis of all our statistical conclusions.\nWe often say that data represents a sample drawn from a population. But what exactly do we mean by a ‚Äúpopulation‚Äù? And how is a sample chosen? We‚Äôll explore two main scenarios depending on the nature of the population:",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Sampling</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling.html#populations-and-samples",
    "href": "sampling-dists/sampling.html#populations-and-samples",
    "title": "16¬† Sampling",
    "section": "",
    "text": "1. Sampling from a Finite Population\nThis sampling model applies when the population is a fixed set of identifiable units. In such cases, the sample is typically selected via simple random sampling meaning each unit has an equal chance of being included. Below a few examples are listed:\n\nA polling agency selects 1000 individuals at random from the national electoral register to estimate national voting preferences.\nA municipality selects 15 schools at random from all schools in the region to evaluate average class size.\nOut of a day‚Äôs production of 10,000 light bulbs, a factory randomly selects 50 to test for defects.\n\nIn all these cases, the population is finite and real, but often large enough that we treat it as practically infinite.\n\n\n2. Sampling from an Infinite Population\nThis model applies when data comes from a repeating process or an idealized model, such as physical measurements with noise or simulated outcomes of random experiments.\nThe key assumption is that each observed value is drawn independently from the same probability distribution ‚Äî an idea formalized as an i.i.d. sample (independent and identically distributed). We list a few examples below:\n\nYou flip a fair coin 100 times. Each result is treated as an independent sample from the theoretical population of all possible flips.\nYou roll a die 60 times and record each outcome. Although the sample is finite, it reflects draws from the conceptual population of all future die rolls.\nYou measure the same distance repeatedly with the same device. Each result is slightly different due to random error. These outcomes are modeled as a random sample from a normal distribution representing all possible measurements.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Sampling</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling.html#our-framework",
    "href": "sampling-dists/sampling.html#our-framework",
    "title": "16¬† Sampling",
    "section": "16.2 Our Framework",
    "text": "16.2 Our Framework\nIn this course, we will consistently treat both types of sampling ‚Äî from large finite populations and from infinite populations ‚Äî in the same way.\n\nRegardless of the origin, we will assume our sample is drawn from an infinite population, where each observation is independent of the others and follows the same probability distribution.\n\nThis is a powerful simplifying assumption. It lets us use the same mathematical tools whether we‚Äôre dealing with people in a city or points on a graph from a simulated process.\nIn both cases, we say we have a random sample from a population.\nThis unified framework allows us to:\n\nDefine and compute sampling distributions,\nConstruct confidence intervals and hypothesis tests,\nEstimate parameters of the underlying population model using methods like the sample mean, variance, and proportion.\n\nThese tools form the backbone of modern inferential statistics, and everything that follows will build on this core idea:\n\nWe observe a random sample from a population.\nWhether that population is large and real, or infinite and theoretical, the principles are the same.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Sampling</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling.html#some-terminology",
    "href": "sampling-dists/sampling.html#some-terminology",
    "title": "16¬† Sampling",
    "section": "16.3 Some Terminology",
    "text": "16.3 Some Terminology\nWhen performing a statistical survey, it‚Äôs essential to distinguish between different types of populations and the sampling frame. Here are the key concepts.\nThe target population is the group we ultimately want to draw conclusions about. It is the ideal population relevant to our research question or hypothesis.\n\nExample: All adults living in Germany in 2025.\n\nThe part of the target population, for which we have a list or registry of identifiable unit is called a sampling frame. This is often a subset of the target population, due to practical limitations. Examples: - Registered residents in the national tax agency‚Äôs population database. - A census list - A school enrollment database - A phone number registry.\nA good sampling frame should be complete, accurate, and current.\nDiscrepancies between the target population and the sampling frame can introduce coverage errors. These occur when some groups are:\n\nExcluded from the sampling frame (e.g., unregistered residents),\nOr overrepresented due to duplications or outdated records.\n\n\nA well-designed study explicitly states and justifies how the sampling frame relates to the ideal target population.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Sampling</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling.html#probability-sampling",
    "href": "sampling-dists/sampling.html#probability-sampling",
    "title": "16¬† Sampling",
    "section": "16.4 Probability Sampling",
    "text": "16.4 Probability Sampling\nA sampling method is considered probabilistic if every element in the population has a known, non-zero probability of being selected. This inclusion probability is what allows us to make valid inferences from the sample to the population.\nExamples include:\n\nSimple random sampling (SRS)\nStratified sampling\nSystematic sampling\nCluster sampling (single or multi-stage)\n\n\n1. Simple Random Sampling (SRS)\nThis is the simplest form of probability sampling: we randomly select \\(n\\) units from a population of \\(N\\) such that each unit has equal probability of being chosen.\nLet \\(x_1, x_2, ..., x_n\\) denote the observed salaries. Then the sample mean\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n\\]\nis an unbiased estimator of the population mean \\(\\mu\\) (we will return to this concept later).\nTo estimate the variance of \\(\\bar{x}\\), we use:\n\\[\n\\widehat{\\text{Var}}(\\bar{x}) = \\left(1 - \\frac{n}{N}\\right) \\frac{s^2}{n}\n\\]\nwhere:\n\n\\(s^2\\) is the sample variance,\nThe term \\(\\left(1 - \\frac{n}{N}\\right)\\) is a finite population correction.\n\nThe correction factor \\(\\left(1 - \\frac{n}{N}\\right)\\) reduces the estimated variance because we are not replacing observations. The more of the population we sample (larger \\(n/N\\)), the smaller this variance becomes. If the sample is small relative to the population (i.e., \\(n \\ll N\\)), this correction is approximately 1 and may be omitted, simplifying the formula to:\n\\[\n\\widehat{\\operatorname{Var}}(\\bar{x}) \\approx \\frac{s^2}{n}\n\\]\n\nExample: 16.1: Company Salary\nWe wish to estimate the average salary in a company. You have a full list (frame) of all 70 employees. You use a random number generator to select 30 employees. Each has the same probability \\(1/70\\) of being selected.\nThe variable of interest is a numeric one, such as income, age, or any measurable quantity. From the sample, we obtain the following:\n\nSample mean: \\(\\bar{x} = 176.20\\)\nSample variance: \\(s^2 = 20.00\\)\n\nWe now want to estimate the variance of the sample mean \\(\\bar{x}\\). Since the sample is drawn without replacement from a finite population, we apply the finite population correction:\n\\[\n\\widehat{\\operatorname{Var}}(\\bar{x}) = \\left(1 - \\frac{n}{N}\\right) \\cdot \\frac{s^2}{n}\n\\] Plugging in the values:\n\\[\n\\widehat{\\operatorname{Var}}(\\bar{x}) = \\left(1 - \\frac{30}{70}\\right) \\cdot \\frac{20.00}{30}\n= \\left(\\frac{40}{70}\\right) \\cdot \\frac{20.00}{30}\n= 0.38095\n\\]\nThis estimate tells us how much variability we might expect in the sample mean if we repeatedly took samples of size 30 from this population. But in this case, with \\(n = 30\\) and \\(N = 70\\), the correction still makes a meaningful difference.\n\n\n\n2. Stratified Sampling\nStratified sampling is a method used to increase precision by dividing the population into homogeneous subgroups, or strata, and drawing a random sample from each. This approach ensures that all relevant sub-populations are represented and that within-group variation is minimized.\nThe idea is to reduce variance by organizing the population into strata that are internally homogeneous but different from each other with respect to the study variable.\nStratification can improve estimation accuracy if the variable of interest differs between groups (e.g., income between age groups) and if the stratification variable (like age, gender, region) is known and available for the full population.\nStratification is most effective when:\n\nThe within-stratum variance is low, and\nThe between-stratum variance is high\n\nThis occurs when the stratification variable (e.g., gender, age) is strongly related to the outcome variable (e.g., income). Choosing appropriate strata isn‚Äôt always straightforward, e.g.:\n\nStratification based on gender is easy.\nFor age or income, it may be necessary to define strata using cutoff values, such as:\n\nAges 20‚Äì29, 30‚Äì39, etc.\nSalary bands: low, medium, high\n\n\nThe goal is to make each stratum internally homogeneous with respect to the variable being studied.\n‚ö†Ô∏è You must have a sampling frame sorted by the stratifying variable to apply this effectively.\nSo how do we actually allocate units to each strata? One method is Proportional Allocation where each stratum contributes to the sample in proportion to its size:\n\\[\n\\frac{n_i}{n} = \\frac{N_i}{N}\n\\]\nThis method is self-weighting and simple. Note however that we sometimes are interested in group comparisons, not overall estimation. Then we can use Equal Allocation and sample the same number of units from each group, even if groups are different sizes. This is useful for comparing averages between, say, men and women.\nTo minimize total variance, one can also use Optimal Allocation (Neyman Allocation) and allocate more sample units to strata with higher variability. Thus, sample size per stratum is proportional to:\n\\[\nn_i \\propto N_i \\cdot s_i\n\\] More units are drawn from more varying strata, improving overall precision.\nWhen using stratified sampling, we combine sample means from each stratum into a single overall estimate:\n\\[\n\\bar{X}_{\\text{str}} = \\sum_{i=1}^L W_i \\bar{X}_i\n\\] where\n\n\\(\\bar{X}_{\\text{str}}\\) is the stratified sample mean,\n\\(W_i = \\frac{N_i}{N}\\) is the weight (proportion of the population in stratum \\(i\\)),\n\\(\\bar{X}_i\\) is the sample mean in stratum \\(i\\),\n\\(L\\) is the number of strata.\n\nSince each stratum‚Äôs sample is drawn independently, the corresponding stratum sample means \\(\\bar{X}_i\\) are independent random variables. The weights \\(W_i\\) are constants (not random), so the variance of the weighted sum is simply:\n\\[\n\\operatorname{Var}(\\bar{X}_{\\text{str}}) = \\sum_{i=1}^L W_i^2 \\cdot \\operatorname{Var}(\\bar{X}_i)\n\\]\nThink of it this way: \\[\n\\operatorname{Var}(\\bar{X}_{\\text{str}}) = \\operatorname{Var}\\left(\\sum_{i=1}^L W_i \\bar{X}_i\\right)\n\\]\nSince each \\(W_i\\) is a constant and the \\(\\bar{X}_i\\) are independent, the variance of the sum equals the sum of the variances, each scaled by the square of the corresponding weight.\n\nExample: 16.1: Company Salary (Cont‚Äôd)\nSuppose we know the company consists of:\n\n20 women, labeled 01‚Äì20\n50 men, labeled 21‚Äì70\n\nWe decide to draw a total sample of \\(n = 30\\) individuals using proportional allocation, so each group is sampled proportionally to its size.\n\\[\nn_1 = \\frac{N_1}{N} \\cdot n = \\frac{20}{70} \\cdot 30 \\approx 9\n\\] \\[\nn_2 = \\frac{N_2}{N} \\cdot n = \\frac{50}{70} \\cdot 30 \\approx 21\n\\]\nAfter sampling and collecting incomes, we compute the sample means and standard deviations within each group:\n\n\n\nStratum\n\\(N_i\\)\n\\(n_i\\)\n\\(\\bar{x}_i\\)\n\\(s_i\\)\n\n\n\n\nWomen\n20\n9\n106.87\n1.052\n\n\nMen\n50\n21\n110.45\n0.789\n\n\nTotal\n70\n30\n\n\n\n\n\nWe calculate the stratified mean as:\n\\[\n\\bar{x}_{\\text{str}} = W_1 \\bar{x}_1 + W_2 \\bar{x}_2\n\\]\nwhere:\n\\[\nW_1 = \\frac{20}{70}, \\quad W_2 = \\frac{50}{70}\n\\]\nThen: \\[\n\\bar{x}_{\\text{str}} = \\frac{20}{70} \\cdot 106.87 + \\frac{50}{70} \\cdot 110.45 = 109.43\n\\] Each stratum sample is independent, so:\n\\[\n\\operatorname{Var}(\\bar{x}_{\\text{str}}) = W_1^2 \\cdot \\operatorname{Var}(\\bar{x}_1) + W_2^2 \\cdot \\operatorname{Var}(\\bar{x}_2)\n\\]\nFor each group, the variance is estimated using the finite population correction (since we‚Äôre sampling without replacement):\n\\[\n\\operatorname{Var}(\\bar{x}_i) = \\left(1 - \\frac{n_i}{N_i}\\right) \\cdot \\frac{s_i^2}{n_i}\n\\]\nPlugging in: \\[\n\\operatorname{Var}(\\bar{x}_{\\text{str}}) =\n\\left(\\frac{20}{70}\\right)^2 \\left(1 - \\frac{9}{20}\\right) \\cdot \\frac{1.052^2}{9} +\n\\left(\\frac{50}{70}\\right)^2 \\left(1 - \\frac{21}{50}\\right) \\cdot \\frac{0.789^2}{21}\n\\] Which yields: \\[\n\\widehat{\\operatorname{Var}}(\\bar{x}_{\\text{str}}) = 0.014293\n\\]\nNow let‚Äôs compare this result with what we‚Äôd get from a simple random sample of \\(n = 30\\) without stratification:\n\n\n\nMethod\nMean\nVariance\n\n\n\n\nSimple Random Sample (SRS)\n176.20\n0.38095\n\n\nStratified Sample\n109.43\n0.01429\n\n\n\nThe stratified sample gives much lower variance, showing how stratification can improve precision when strata are well chosen.\n\n\n\n3. Systematic Sampling\nSystematic sampling is a method where we select elements at regular intervals from a list (the sampling frame), after first choosing a random starting point.\nSuppose we want to estimate the average salary in a company with \\(N = 1000\\) employees. We plan to draw a sample of \\(n = 100\\). Assume the sampling frame is sorted by personal ID number (which correlates with age). We compute the sampling interval:\n\\[\nr = \\frac{N}{n} = \\frac{1000}{100} = 10\n\\] We then randomly select a starting number between 1 and 10 ‚Äî say we pick 4. Our sample will include the following individuals (based on their position in the list):\n\\[\n4,\\ 14,\\ 24,\\ 34,\\ \\dots,\\ 994\n\\]\nThat is, we include every 10th individual starting at position 4.\nLet‚Äôs fomralize the process of systematic sampling: Let \\(N\\) be the total number of elements and \\(n\\) the number of desired samples.\n\nCompute the sampling interval:\n\\[\nr = \\left\\lfloor \\frac{N}{n} \\right\\rfloor\n\\]\n(Round down to the nearest whole number)\nRandomly choose a number \\(s\\) between 1 and \\(r\\).\nSelect elements at positions:\n\\[\ns,\\ s + r,\\ s + 2r,\\ \\dots\n\\]\nContinue until you‚Äôve passed through the entire list.\n\nNote that it‚Äôs important to go through the entire list, or risk introducing systematic bias. Because we round \\(r\\) down, it is possible to end up with more than \\(n\\) elements.\nIf that happens youou can simply keep the extra observations,\nor randomly remove some observations to reduce to the intended sample size.\nThis method is efficient and easy to implement, especially when dealing with large, ordered datasets.\n‚ö†Ô∏è Beware of periodicity in the lis: if the sorting follows a cycle, the results may be biased. For Example, suppose you‚Äôre studying newspaper ads and want to select every 7th day. If ads tend to follow a weekly cycle (e.g., most appear on Sundays), your sample could:\n\nMiss certain types of ads,\nOverrepresent others,\nLead to systematic bias and increased variance in estimates.\n\n\nExample: 16.1: Company Salary (Cont‚Äôd)\nSuppose we wish to select a systematic sample of size \\(n = 30\\) from the population of size \\(N = 70\\) here. Fir we compute the sampling interval \\[\nr = \\frac{N}{n} = \\frac{70}{30} \\approx 2.333 \\quad \\text{(rounded down to } r = 2 \\text{)}\n\\] This means we plan to take every second person from the sampling frame. Then randomly select a starting position from among the first \\(r = 2\\) units. Draw a random number between 1 and 2 (say 2), then select every 2nd person:\n\\[\n2,\\ 4,\\ 6,\\ 8,\\ \\dots,\\ 70\n\\]\nThis gives us: \\[\n\\frac{70 - 2}{2} + 1 = 35 \\text{ individuals}\n\\]\nSo our actual sample size is 35, which is larger than intended.\n\n\n\n4. Cluster Sampling\nUsed when sampling individuals directly is impractical (e.g., geographical spread or missing frame).\n\nIn single-stage cluster sampling, groups (e.g., schools, buildings) are selected randomly, and all elements within them are surveyed.\nIn two-stage cluster sampling, we randomly select both clusters and elements within them.\n\nFor example, consider a housing association who wants feedback on apartment quality. Instead of mailing all tenants, they randomly select 5 buildings and visit every apartment in each.\nOr, in a two-stage approach, they visit a subset of apartments in each selected building.\n\nCluster sampling is cost-effective but usually has lower precision than simple or stratified sampling.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Sampling</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling.html#non-probability-sampling",
    "href": "sampling-dists/sampling.html#non-probability-sampling",
    "title": "16¬† Sampling",
    "section": "16.5 Non-Probability Sampling",
    "text": "16.5 Non-Probability Sampling\nSometimes, we cannot or do not use a probability-based method, for example if no register over all population elements exist. While easier or more practical, these designs do not guarantee unbiased or generalizable results.\nExamples include:\n\nQuota sampling ‚Äì Fill quotas based on traits like age or gender, but allow interviewer discretion.\nVoluntary response ‚Äì Participants opt in (e.g., online polls).\nConvenience sampling ‚Äì Survey whoever is nearby.\nJudgment sampling ‚Äì Select ‚Äútypical‚Äù individuals based on expert opinion.\nSnowball sampling ‚Äì Ask members of a hidden population (e.g., drug users) to recruit others.\n\n\nThese methods may lead to systematic errors and hidden biases. Always interpret results cautiously and never generalize to the full population without disclaimers.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Sampling</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-mean.html",
    "href": "sampling-dists/sampling-dist-mean.html",
    "title": "17¬† Sampling Distributions for a Sample Mean",
    "section": "",
    "text": "17.1 The Sample Mean as a Random Variable\nThe sample mean \\(\\bar{X}\\), when calculated from a random sample, is itself a random variable whose distribution reflects the variability inherent in the sampling process. This distribution, the sampling distribution of the sample mean, has an expected value equal to the true population mean \\(\\mu\\), and its variance is given by \\(\\sigma^2 / n\\), where \\(\\sigma^2\\) is the population variance and \\(n\\) is the sample size. Consequently, the standard error of the mean, defined as \\(\\sigma / \\sqrt{n}\\), quantifies the typical deviation of the sample mean from the population mean across repeated samples. Understanding this sampling distribution is essential for inferential statistics, whether we are constructing confidence intervals, performing hypothesis tests, or quantifying the uncertainty associated with point estimates.\nSuppose we plan to collect a random sample of size \\(n\\) from a population with mean \\(\\mu\\) and variance: \\(\\sigma^2\\). Let \\(X_1, X_2, \\dots, X_n\\) represent the values we observe in that sample. We assume independent and identically distributed (i.i.d.) random variables, that is:\nThe sample mean \\(\\bar{X}\\) is defined as: \\[\n\\bar{X} = \\frac{X_1 + X_2 + \\cdots + X_n}{n} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nAlthough we treat \\(\\bar{X}\\) as a numerical quantity once the sample is collected, in theory it is itself a random variable; its value depends on which sample we happen to get and the observations within the sample.\nThe distribution of \\(\\bar{X}\\) across all possible random samples is called the sampling distribution of the sample mean. Each time we take a random sample from the population, we compute a sample mean. If we were to repeat the sampling process many times, we would get different values of \\(\\bar{X}\\). The distribution of these values, one for each possible sample, forms the sampling distribution of the sample mean.\nThis distribution tells us:",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Mean</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-mean.html#the-sample-mean-as-a-random-variable",
    "href": "sampling-dists/sampling-dist-mean.html#the-sample-mean-as-a-random-variable",
    "title": "17¬† Sampling Distributions for a Sample Mean",
    "section": "",
    "text": "The variables \\(X_1, X_2, \\dots, X_n\\) are independent,\nEach \\(X_i\\) follows the same distribution (i.e., they are identically distributed)\n\n\n\n\n\n\nWhat values the sample mean might take,\nHow much it tends to vary from sample to sample,\nHow close we can expect it to be to the population mean.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Mean</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-mean.html#properties-of-the-sampling-distribution",
    "href": "sampling-dists/sampling-dist-mean.html#properties-of-the-sampling-distribution",
    "title": "17¬† Sampling Distributions for a Sample Mean",
    "section": "\n17.2 Properties of the Sampling Distribution",
    "text": "17.2 Properties of the Sampling Distribution\nLet \\(X_1, \\dots, X_n\\) be an i.i.d. sample from a population with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Then the sample mean \\(\\bar{X}\\) has:\n\nExpected value (mean):\n\n\\[\nE(\\bar{X}) = \\mu\n\\]\n\nVariance: \\[\n\\operatorname{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\nStandard deviation:\n\n\\[\n\\operatorname{SD}(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nThis standard deviation is known as the standard error of the mean.\nThe more observations we average together, the less variability we expect in the result. A single observation \\(X\\) has variance \\(\\sigma^2\\), but the mean of \\(n\\) i.i.d. observations spreads out less, its variance shrinks by a factor of \\(1/n\\). This is why increasing the sample size gives more precise estimates of the population mean. This is illustrated in Figure¬†17.1 where a simulation of the sampling distribution of the mean shown for a population with mean 50 and variance 100. The plot shows how the distribution evolves as the number of repeated samples of size \\(n = 30\\) goes from 10 to 1000.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†17.1: Simulation of the sampling distribution of the mean for a population with mean 50 and variance 100. The plot shows how the distribution evolves as the number of repeated samples of size \\(n = 30\\) increases from 10 to 1000.\n\n\nWhy does this happen? Since the sample mean is a linear combination of independent, identically distributed random variables:\n\nIndependence means the variances add.\nIdentical distribution means they each have the same mean and variance.\n\nUsing the linearity of expectation, we find:\n\\[\n\\begin{split}\nE(\\bar{X}) &= E\\left( \\frac{1}{n} \\sum_{i=1}^n X_i \\right) \\\\\n&= \\frac{1}{n} E\\left( \\sum_{i=1}^n X_i \\right) \\\\\n&= \\frac{1}{n} \\sum_{i=1}^n E(X_i) \\\\\n&= \\frac{1}{n} \\sum_{i=1}^n \\mu_X \\\\\n&= \\frac{n \\cdot \\mu_X}{n} \\\\\n&= \\mu_X\n\\end{split}\n\\]\nThis confirms that \\(\\bar{X}\\) is an unbiased estimator of the population mean \\(\\mu_X\\) (in the long run, we hit the target). Assuming independence, the variance of the sum is the sum of the variances. Therefore:\n\\[\n\\begin{split}\n\\operatorname{Var}(\\bar{X}) &= \\operatorname{Var} \\left( \\frac{1}{n} \\sum_{i=1}^n X_i \\right) \\\\\n&= \\frac{1}{n^2} \\operatorname{Var} \\left( \\sum_{i=1}^n X_i \\right) \\\\\n&= \\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}(X_i) \\quad \\text{(independence)} \\\\\n&= \\frac{1}{n^2} \\sum_{i=1}^n \\sigma_X^2 \\\\\n&= \\frac{1}{n^2} \\cdot n \\cdot \\sigma_X^2 \\\\\n&= \\frac{\\sigma_X^2}{n}\n\\end{split}\n\\]\nThe variance of the sample mean thus shrinks with larger sample sizes, reflecting increased precision. The square root of the variance of the sample mean is known as the standard error of the mean:\n\\[\n\\text{SE}(\\bar{X}) = \\frac{\\sigma_X}{\\sqrt{n}}\n\\]\nThis measures how much the sample mean is expected to vary from sample to sample. It decreases as \\(n\\) increases, giving tighter estimates of the population mean with larger samples. Together, these results imply that \\(\\bar{X}\\) is not only unbiased, but also a consistent estimator of \\(\\mu_X\\). That is: \\[\n\\bar{X} \\xrightarrow{P} \\mu_X \\quad \\text{as } n \\to \\infty\n\\]\nThis convergence in probability follows from the Law of Large Numbers: as the sample size grows, the probability that the sample mean deviates significantly from the true mean approaches zero. We will return to these concepts in mroe detail later in the book.\nExample 17.1: Which Sampling Method Gives a More Accurate Total?\nIn the production of construction elements, the lengths of individual parts vary slightly due to randomness in the manufacturing process. These variations can be modeled as outcomes from independent and identically distributed random variables with:\n\nMean (expected length): \\(\\mu = 2\\) meters\n\nStandard deviation: \\(\\sigma = 0.005\\) meters (i.e., 5 mm)\n\nSuppose we need ten elements that together should sum to exactly 20 meters. We consider two alternative methods to select these:\nMethod 1: Randomly select one element, then cut or grind the remaining nine so that all ten elements match the length of the first.\nMethod 2: Randomly select ten elements independently from the production line.\nThe question is: Which method gives a total length closer to the desired 20 meters on average?\nLet‚Äôs analyze the variance of the total length under each method:\nMethod 1\nAll ten elements are set to the same length, which is a single random realization of one element \\(X\\). So the total length is: \\[\nL_1 = 10X\n\\]\nThen the variance of the total length is: \\[\n\\operatorname{Var}(L_1) = \\operatorname{Var}(10X) = 100 \\cdot \\operatorname{Var}(X) = 100 \\sigma^2\n\\]\nMethod 2\nEach element is chosen independently: \\(X_1, X_2, \\dots, X_{10}\\). The total length is:\n\\[\nL_2 = X_1 + X_2 + \\dots + X_{10}\n\\]\nThen the variance of the total length is:\n\\[\n\\operatorname{Var}(L_2) = \\sum_{i=1}^{10} \\operatorname{Var}(X_i) = 10 \\sigma^2\n\\]\nBoth methods are unbiased: in expectation, the total length is \\(E(L) = 10 \\cdot \\mu = 20\\) meters.\nHowever, Method 2 has significantly lower variance (the total variance is ten times smaller under Method 2 than Method 1), meaning the total length will more reliably fall close to 20 meters. This is visulalized in Figure¬†17.2.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†17.2: Simulation of total length under the two sampling methods in example 17.1.\n\n\nThe general insight from above example is as follows. If we randomly select a single unit from a population, its expected value is \\(\\mu\\), and it deviates from the mean on average by \\(\\sigma\\). If we instead select a sample of \\(n\\) units, the sample mean \\(\\bar{X}\\) is still centered around \\(\\mu\\), but the deviations tend to cancel out. Thus:\n\\[\n\\text{Standard deviation of } \\bar{X} = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nThis demonstrates the variance-reducing power of averaging, and illustrates why using independent samples yields more reliable estimates; a key motivation behind the sampling distribution of the mean.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Mean</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-mean.html#normal-distribution-of-the-sample-mean",
    "href": "sampling-dists/sampling-dist-mean.html#normal-distribution-of-the-sample-mean",
    "title": "17¬† Sampling Distributions for a Sample Mean",
    "section": "\n17.3 Normal Distribution of the Sample Mean",
    "text": "17.3 Normal Distribution of the Sample Mean\nIf the variable of interest \\(X\\) is itself normally distributed, then the sample mean \\(\\bar{X}\\) is also normally distributed, regardless of the sample size. Formally, if:\n\\[\nX \\sim \\mathcal{N}(\\mu_X, \\sigma_X)\n\\]\nthen for any sample size \\(n\\), the sample mean follows:\n\\[\n\\bar{X} \\sim \\mathcal{N} \\left( \\mu_X, \\frac{\\sigma_X}{\\sqrt{n}} \\right)\n\\]\nTo calculate probabilities involving a sample mean, we often need to standardize it ‚Äî that is, convert it to a standard normal variable. If the sample mean \\(\\bar{X}\\) is normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma / \\sqrt{n}\\), we can transform it using the formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n\\]\nThis transformation yields a new variable \\(Z\\) that follows the standard normal distribution \\(\\mathcal{N}(0, 1)\\). Once in this form, we can use standard normal tables or software to compute probabilities and percentiles, just as done before in Chapter 14.\nBut what happens if \\(X\\) is not normally distributed? Can we still use these kinds of probability calculations? Later in this part, we‚Äôll explore the Central Limit Theorem (Chapter 19), which shows that the sample mean \\(\\bar{X}\\) still tends to follow a normal distribution as long as the sample size is sufficiently large, even if the original data are not normally distributed.\nExample: 17.2: Lightbulb Lifespans\nThe lifespan of a particular brand of lightbulb is known to follow a normal distribution with a mean of \\(\\mu = 1200\\) hours and a standard deviation of \\(\\sigma = 50\\) hours. A quality control engineer takes a random sample of \\(n = 25\\) lightbulbs. What is the probability that the average lifespan of the sampled bulbs is less than 1180 hours?\nWe are asked to calculate:\n\\[\nP(\\bar{X} \\leq 1180)\n\\]\nSince the sample comes from a normally distributed population, the sample mean \\(\\bar{X}\\) also follows a normal distribution: \\[\n\\bar{X} \\sim \\mathcal{N} \\left(1200, \\frac{50}{\\sqrt{25}} \\right) = \\mathcal{N}(1200, 10)\n\\] We standardize the problem using the \\(Z\\)-score formula:\n\\[\n\\begin{split}\nZ &= \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} = \\frac{1180 - 1200}{10} = -2\n\\end{split}\n\\]\nNow, using the standard normal distribution table or a calculator: \\[\nP(\\bar{X} \\leq 1180) = P(Z \\leq -2) = 0.022\n\\]\nThere is a 2.28% chance that the sample mean is less than 1180 hours, even though the expected mean is 1200 hours.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Mean</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-mean.html#exercises",
    "href": "sampling-dists/sampling-dist-mean.html#exercises",
    "title": "17¬† Sampling Distributions for a Sample Mean",
    "section": "Exercises",
    "text": "Exercises\n\nA city reports that the daily commute time for its residents is normally distributed with a mean of \\(\\mu = 42\\) minutes and a standard deviation of \\(\\sigma = 12\\) minutes. A researcher takes a random sample of \\(n = 36\\) residents. What is the probability that the average commute time in the sample is more than 45 minutes?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are asked to compute: \\[\nP(\\bar{X} &gt; 45)\n\\]\nSince \\(X \\sim \\mathcal{N}(42, 12)\\) and \\(n = 36\\), the sampling distribution of the mean is:\n\\[\n\\bar{X} \\sim \\mathcal{N}\\left(42, \\frac{12}{\\sqrt{36}}\\right) = \\mathcal{N}(42, 2)\n\\] Now standardize: \\[\nZ = \\frac{45 - 42}{2} = 1.5\n\\]\nUsing the standard normal table: \\[\nP(\\bar{X} &gt; 45) = P(Z &gt; 1.5) = 1 - 0.933 = 0.067\n\\]\nThere is a 6.68% chance that the sample mean is greater than 45 minutes.\n\n\n\n\nThe battery life of a type of smartphone is normally distributed with a mean of 10 hours and a standard deviation of 1.5 hours. An engineer selects a random sample of 49 phones. What is the probability that their average battery life is between 9.7 and 10.2 hours?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe want: \\[\nP(9.7 \\leq \\bar{X} \\leq 10.2)\n\\]\nThe sampling distribution is: \\[\n\\bar{X} \\sim \\mathcal{N}\\left(10, \\frac{1.5}{\\sqrt{49}}\\right) = \\mathcal{N}(10, 0.214)\n\\] Standardize both bounds: \\[\nZ_1 = \\frac{9.7 - 10}{0.214} \\approx -1.40 \\\\\nZ_2 = \\frac{10.2 - 10}{0.214} \\approx 0.93\n\\]\nUsing the standard normal table: \\[\nP(-1.40 \\leq Z \\leq 0.93) = \\Phi(0.93) - \\Phi(-1.40) \\approx 0.8238 - 0.0808 = 0.743\n\\]\nThere is a 74.3% chance that the average battery life lies between 9.7 and 10.2 hours.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Mean</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-prop.html",
    "href": "sampling-dists/sampling-dist-prop.html",
    "title": "18¬† Sampling Distributions for a Sample Proportion",
    "section": "",
    "text": "18.1 The Proportion as a Random Variable\nIn many applications, we are interested not in the mean of a variable, but in the proportion of units in a population that possess a certain characteristic ‚Äî for example, the proportion of voters who support a candidate, or the proportion of products that are defective.\nLet \\(p\\) denote the true proportion in the population of units with a characteristic \\(A\\). We consider two equivalent situations:\nIn both cases, we define the sample proportion as:\n\\[\n\\hat{p} = \\frac{X}{n}\n\\]\nwhere \\(X\\) is the number of observed ‚Äúsuccesses‚Äù in the sample.\nIn fact, the sample proportion \\(\\hat{p}\\) can be viewed as a sample mean of 0/1 variables, where each observation equals 1 if the characteristic is present and 0 otherwise.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Proportion</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-prop.html#the-proportion-as-a-random-variable",
    "href": "sampling-dists/sampling-dist-prop.html#the-proportion-as-a-random-variable",
    "title": "18¬† Sampling Distributions for a Sample Proportion",
    "section": "",
    "text": "A random sample of size \\(n\\) is drawn from a large (finite) population, where \\(p\\) is the proportion of \\(A\\)-units.\nWe perform \\(n\\) independent trials, each with probability \\(p\\) of ‚Äúsuccess‚Äù (i.e., observing \\(A\\)). In this case, \\(X \\sim \\text{Bin}(n, p)\\).",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Proportion</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-prop.html#properties-of-the-sampling-distribution",
    "href": "sampling-dists/sampling-dist-prop.html#properties-of-the-sampling-distribution",
    "title": "18¬† Sampling Distributions for a Sample Proportion",
    "section": "\n18.2 Properties of the Sampling Distribution",
    "text": "18.2 Properties of the Sampling Distribution\nBecause \\(\\hat{p}\\) depends on the outcomes of a random process, it is itself a random variable. Its distribution is called the sampling distribution of the sample proportion.\nThis distribution describes how the sample proportion \\(\\hat{p}\\) would vary from sample to sample due to randomness. Just like the sample mean, the sample proportion has a mean and variance:\n\nExpected value: \\[\nE(\\hat{p}) = p\n\\]\nVariance: \\[\n\\operatorname{Var}(\\hat{p}) = \\frac{p(1 - p)}{n}\n\\]\n\nThese results follow from properties of the binomial distribution (see Section 13.6). If \\(X \\sim \\text{Bin}(n, p)\\), then: \\[\nE(X) = np \\quad \\text{and} \\quad \\operatorname{Var}(X) = np(1 - p)\n\\]\nThen: \\[\nE\\left(\\frac{X}{n}\\right) = \\frac{E(X)}{n} = \\frac{np}{n} =  p\n\\] \\[\n\\operatorname{Var}\\left(\\frac{X}{n}\\right) = \\frac{\\operatorname{Var}(X)}{n^2} = \\frac{np(1 - p)}{n^2} = \\frac{p(1 - p)}{n}\n\\]",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Proportion</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-prop.html#normal-approximation-of-the-sample-proportion",
    "href": "sampling-dists/sampling-dist-prop.html#normal-approximation-of-the-sample-proportion",
    "title": "18¬† Sampling Distributions for a Sample Proportion",
    "section": "\n18.3 Normal Approximation of the Sample Proportion",
    "text": "18.3 Normal Approximation of the Sample Proportion\nUnder certain conditions, the distribution of \\(\\hat{p}\\) can be approximated by a normal distribution. This is particularly useful for calculating probabilities.\nThe approximation holds when the sample is sufficiently large. A common rule of thumb is:\n\\[\nnp(1 - p) &gt; 5\n\\]\nIf this holds, we can write:\n\\[\n\\hat{p}\\overset{\\text{apx}}{\\sim} \\mathcal{N}\\left(p, \\frac{p(1 - p)}{n}\\right)\n\\] This follows from the fact that the sample proportion \\(\\hat{p}\\) can be viewed as a sample mean of binary variables, justifying the use of Central Limit Theorem covered in the next chapter Chapter 19.\nExample: 18.1: Electrical Installations in Old Houses\nIn a large population of older houses, 30% are known to have faulty electrical installations. We take a simple random sample of \\(n = 250\\) houses. What is the probability that the sample proportion \\(\\hat{p}\\) falls between 0.25 and 0.35? Let‚Äôs have a look at the given:\n\nTrue population proportion: \\(p = 0.30\\)\n\nSample size: \\(n = 250\\)\n\nTarget interval: \\(0.25 \\leq \\hat{p} \\leq 0.35\\)\n\n\nSince we‚Äôre dealing with a sample proportion, the random variable \\(\\hat{p} = X/n\\) has:\n\nExpected value: \\(E(\\hat{p}) = p = 0.30\\)\n\nVariance: \\(\\operatorname{Var}(\\hat{p}) = \\frac{p(1 - p)}{n} = \\frac{0.3 \\cdot 0.7}{250} = 0.00084\\)\n\nStandard deviation (standard error): \\(\\sqrt{0.00084} \\approx 0.029\\) We check:\n\n\\[\nnp(1 - p) = 250 \\cdot 0.3 \\cdot 0.7 = 52.5 &gt; 5\n\\]\nThis confirms that we can approximate the sampling distribution of \\(\\hat{p}\\) using a normal distribution. Next, we standardize the bounds and convert 0.25 and 0.35 to \\(Z\\)-scores:\n\\[\nZ_1 = \\frac{0.25 - 0.30}{0.029} \\approx -1.72 \\\\\nZ_2 = \\frac{0.35 - 0.30}{0.029} \\approx 1.72\n\\]\nNow the probaiblity area we seek is given by as shown in the plot below: \\[\nP(0.25 \\leq \\hat{p} \\leq 0.35) = P(-1.72 \\leq Z \\leq 1.72)\n\\]\n\n\n\n\n\n\n\n\nFrom the standard normal table (Appendix A) we get \\[\n\\Phi(1.72) \\approx 0.957,\\quad \\Phi(-1.72) \\approx  1-\\Phi(1.72)  = 0.043\n\\]\nwhich implies that \\[\nP(-1.72 \\leq Z \\leq 1.72) = 0.957 - 0.043 = 0.914\n\\] In conclusion, there is about a 91% probability that the sample proportion will fall between 25% and 35%. This reflects the natural variability of proportions in random samples, and highlights how the sampling distribution of \\(\\hat{p}\\) allows us to make probabilistic statements about sample outcomes.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Proportion</span>"
    ]
  },
  {
    "objectID": "sampling-dists/sampling-dist-prop.html#exercises",
    "href": "sampling-dists/sampling-dist-prop.html#exercises",
    "title": "18¬† Sampling Distributions for a Sample Proportion",
    "section": "Exercises",
    "text": "Exercises\n\nA political poll finds that 55% of voters in a population support a new environmental policy. A journalist takes a random sample of 200 people from the population. What is the probability that fewer than the majority in the sample supports the policy?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe seek the probability that the sample proportion is less than 0.5, that is \\(P(\\hat{p} \\leq 0.5)\\). We are given:\n\n\\(p = 0.55\\)\n\\(n = 200\\)\n\nCheck conditions: \\[\nnp(1 - p) = 200 \\cdot 0.55 \\cdot 0.45 = 49.5 &gt; 5 \\quad \\text{so we can use normal approx.}\n\\]\nStandard error: \\[\n\\text{SE} = \\sqrt{ \\frac{0.55 \\cdot 0.45}{200} } \\approx 0.035\n\\]\nStandardize: \\[\nZ = \\frac{0.50 - 0.55}{0.035} \\approx -1.43\n\\]\n\\[\nP(\\hat{p} \\leq 0.50) = P(\\hat{p} &lt; 0.50) = P(Z &lt; -1.43) \\approx 0.0764\n\\]\nThere‚Äôs about a 7.6% chance the sample shows less than 50% support.\n\n\n\n\nIn a large batch of manufactured items, 4% are defective. An inspector takes a sample of 100 items. What is the probability that more than 5% of the sample is defective?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGiven:\n\n\\(p = 0.04\\)\n\\(n = 100\\)\n\nCheck: \\[\nnp(1 - p) = 100 \\cdot 0.04 \\cdot 0.96 = 3.84 \\lt 5 \\quad \\text{not large enough for normal approx.}\n\\]\nThe normal approximation should not be used here. Use exact binomial calculation instead:\n\\[\nP(X &gt; 5) = 1 - P(X \\leq 5)=  1 - \\sum_{k=0}^{5} P(X = k), \\qquad X \\sim \\text{Bin}(100, 0.04)\n\\] Recall the binomial probability formula: \\[\nP(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k} = \\binom{100}{k} (0.04)^k (0.96)^{100 - k}\n\\] Compute each term from \\(k = 0\\) to \\(k = 5\\) using this formula: \\[\n\\begin{aligned}\nP(X = 0) &= \\binom{100}{0} \\cdot (0.04)^0 \\cdot (0.96)^{100}\n= 1 \\cdot 1 \\cdot 0.0166 = \\mathbf{0.0166} \\\\\\\\\nP(X = 1) &= \\binom{100}{1} \\cdot (0.04)^1 \\cdot (0.96)^{99}\n= 100 \\cdot 0.04 \\cdot 0.0173 = \\mathbf{0.0692} \\\\\\\\\nP(X = 2) &= \\binom{100}{2} \\cdot (0.04)^2 \\cdot (0.96)^{98}\n= 4950 \\cdot 0.0016 \\cdot 0.0180 = \\mathbf{0.1426} \\\\\\\\\nP(X = 3) &= \\binom{100}{3} \\cdot (0.04)^3 \\cdot (0.96)^{97}\n= 161700 \\cdot 0.000064 \\cdot 0.0187 = \\mathbf{0.1952} \\\\\\\\\nP(X = 4) &= \\binom{100}{4} \\cdot (0.04)^4 \\cdot (0.96)^{96}\n= 3921225 \\cdot 0.00000256 \\cdot 0.0195 = \\mathbf{0.1797} \\\\\\\\\nP(X = 5) &= \\binom{100}{5} \\cdot (0.04)^5 \\cdot (0.96)^{95}\n= 75287520 \\cdot 0.00000102 \\cdot 0.0203 = \\mathbf{0.1234}\n\\end{aligned}\n\\]\nNow we sum these:\n\\[\n\\begin{aligned}\nP(X \\leq 5) &= 0.0166 + 0.0692 + 0.1426 + 0.1952 + 0.1797 + 0.1234 \\\\\n&=  0.7267\n\\end{aligned}\n\\] Final answer is then: \\[\nP(X &gt; 5) = 1 - P(X \\leq 5) = 1-0.7267 = \\boxed{0.2733}\n\\]\nThere is approximately a 27.33% chance of observing more than 5 defective items in a random sample of 100 when the defect rate is 4%.\nWith normal approximation the answer would be \\(P(X &gt; 5) \\approx 0.2206\\) (double check this by yourselves). So the normal approximation underestimates the true probability in this case, not surprising since the sample size is modest and \\(np\\) is close to the lower cutoff for using normal approximation reliably.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Sampling Distributions for a Sample Proportion</span>"
    ]
  },
  {
    "objectID": "sampling-dists/clt.html",
    "href": "sampling-dists/clt.html",
    "title": "19¬† Central Limit Theorem",
    "section": "",
    "text": "19.1 A Universal Pattern\nImagine you‚Äôre running around collecting sample means ‚Äî one sample here, another there, all from the same population. At first, your collection looks messy: skewed, bumpy, unpredictable. But as your sample size grows, something magical happens. No matter how weird or wonky the original data is, the distribution of your sample means starts to smooth out. And before long, it begins to look suspiciously bell-shaped ‚Äî that‚Äôs the Central Limit Theorem at work. It tells us that if your sample size is large enough, the sampling distribution of the mean will be approximately normal, with a mean equal to the population mean and a standard deviation (called the standard error) that shrinks as \\(n\\) grows. This makes it the statistical superhero behind confidence intervals, hypothesis tests, and your ability to make meaningful conclusions from messy real-world data.\nUp until now, we‚Äôve seen that when the population distribution is normal, the sampling distribution of the mean \\(\\bar{X}\\) is also normally distributed ‚Äî regardless of sample size. But what happens when the population isn‚Äôt normally distributed at all?\nThis is where the Central Limit Theorem (CLT) enters like the hero of probability theory. It answers the following question:\nThe short answer: approximately normal, as long as the sample size is large enough. The CLT intuitively states: If we take a large enough random sample of size \\(n\\) from any population (with finite mean \\(\\mu\\) and variance \\(\\sigma^2\\)), then the sampling distribution of the sample mean \\(\\bar{X}\\) will be approximately normal: \\[\\bar{X} \\sim \\mathcal{N} \\left( \\mu, \\frac{\\sigma^2}{n} \\right)\\]\nThis approximation becomes better as \\(n\\) increases. But what does large enough actually mean? There‚Äôs no hard rule, but a common rule of thumb is that \\(n \\geq 30\\) is usually sufficient, especially if the population distribution is moderately skewed. For extremely skewed or heavy-tailed distributions, a larger sample may be needed for the approximation to hold well. A visual inspection of the distribution may therefore be necessary to determine if normal approximation is appropriate.\nOne of the most powerful outcomes of the Central Limit Theorem is that it allows us to approximate probabilities involving the sample mean \\(\\bar{X}\\), even when we do not know the distribution of the population, as long as the sample size \\(n\\) is sufficiently large.\nSuppose we want to compute the probability: \\[\nP(\\bar{X} \\leq c)\n\\]\nwhere \\(c\\) is some value. Thanks to the CLT, we can standardize the sample mean and relate this probability to the standard normal distribution:\n\\[\nP(\\bar{X} \\leq c) \\approx P\\left(Z \\leq \\frac{c - \\mu_{\\bar{X}}}{\\sigma_{\\bar{X}}} \\right)\n\\]\nSince \\(\\bar{X}\\) has mean \\(\\mu_X\\) and standard deviation \\(\\sigma_X / \\sqrt{n}\\), we substitute:\n\\[\nP(\\bar{X} \\leq c) \\approx P\\left(Z \\leq \\frac{c - \\mu_X}{\\sigma_X / \\sqrt{n}} \\right)\n\\]\nwhere\nThis approximation is foundational in statistics. It simplifies problems involving averages and enables the use of standard normal tables or software tools to answer probability questions.\nFigure¬†19.1 show an animation on how the distribution of sample means evolves as we draw one sample from increasingly larger sample sizes from a highly skewed population (chi-squared with 2 degrees of freedom). As the number of sample means accumulates, and as each mean is based on more data, the distribution of those means becomes increasingly symmetric and bell-shaped; demonstrating the Central Limit Theorem in action. Even though the original population is far from normal, the sample means tend toward a normal distribution as \\(n\\) increases.",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "sampling-dists/clt.html#a-universal-pattern",
    "href": "sampling-dists/clt.html#a-universal-pattern",
    "title": "19¬† Central Limit Theorem",
    "section": "",
    "text": "What does the sampling distribution of \\(\\bar{X}\\) look like if the population itself is not normal?\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mu_X\\): population mean\n\n\n\\(\\sigma_X\\): population standard deviation\n\n\n\\(n\\): sample size\n\n\n\\(Z\\): standard normal variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†19.1: Illustration of the Central Limit Theorem (CLT).",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "sampling-dists/clt.html#the-formal-statement-of-clt",
    "href": "sampling-dists/clt.html#the-formal-statement-of-clt",
    "title": "19¬† Central Limit Theorem",
    "section": "\n19.2 The Formal Statement of CLT",
    "text": "19.2 The Formal Statement of CLT\nLet \\(X_1, X_2, \\dots, X_n\\) be a sequence of independent and identically distributed (i.i.d.) random variables with:\n\nMean: \\(\\mu = E(X_i)\\)\n\nVariance: \\(\\sigma^2 = \\operatorname{Var}(X_i) &lt; \\infty\\)\n\n\nDefine the sample mean:\n\\[\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nThen the Central Limit Theorem states:\n\\[\n\\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0, 1) \\quad \\text{as } n \\to \\infty\n\\]\nIn words: As the sample size increases, the standardized sample mean converges in distribution to a standard normal distribution, regardless of the shape of the original distribution (as long as the mean and variance are finite).\nThe proof of this theorem is rather long and beyond the scope of this course.\nExample 19.1: Applying the CLT\nSuppose we draw a random sample of size \\(n = 100\\) from a population with:\n\nMean \\(\\mu = 65\\)\n\nVariance \\(\\sigma^2 = 64\\)\n\n\nWhat is the probability that the sample mean \\(\\bar{X}\\) is less than 63?\nFrom the CLT, since \\(n \\geq 30\\), we can assume: \\[\n\\bar{X} \\sim \\mathcal{N}\\left(65, \\frac{64}{100}\\right) = \\mathcal{N}(65, 0.64)\n\\]\nWe want to calculate: \\[\nP(\\bar{X} \\leq 63)\n\\]\nWe standardize the sample mean: \\[\nZ = \\frac{63 - 65}{\\sqrt{0.64}} = \\frac{-2}{0.8} = -2.5\n\\]\nand find \\[\nP(\\bar{X} \\leq 63) = P(Z \\leq -2.5)\n\\]\nUsing the standard normal distribution (Appendix A): \\[\nP(Z \\leq -2.5) = 1 - P(Z \\leq 2.5) = 1 - 0.994 = 0.006\n\\]",
    "crumbs": [
      "Sampling and Sampling Distributions",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Central Limit Theorem</span>"
    ]
  },
  {
    "objectID": "inferential/intro-inference.html",
    "href": "inferential/intro-inference.html",
    "title": "20¬† From Probability to Statistical Inference",
    "section": "",
    "text": "Most statistical journeys begin with descriptive statistics; calculating averages, medians, spreads, and trends to summarize what we see in our data. But knowing how it is only gets us partway. At some point, we want to go further. We ask:\n\nIs this result just a fluke? Will it happen again? Can we generalize it?*\n\nTo answer these questions, we need more than summaries. We need a framework to quantify uncertainty, and that‚Äôs where probability theory does its magic. It helps us model randomness and variation in data, turning questions about how things are into questions about how things might be.\nEnter inferential statistics: the part of statistics that uses sample data, guided by probability, to draw conclusions about the larger population. This is where we estimate unknown values, test hypotheses, and make data-driven decisions, even when we can‚Äôt see the whole picture.\nIn the coming sections, we‚Äôll explore the key tools of inference, and how they allow us to move thoughtfully from what we observe to what we believe about the world. In the following section, we‚Äôll begin exploring the methods and logic behind inferential statistics, starting with estimation techniques and building toward hypothesis testing. Let‚Äôs dive into how we can responsibly and rigorously make sense of the unknown.\n\n\n\n\n\n\n\nFigure¬†20.1: Inferential statistics builds on descriptive summaries and probability theory to predict and generalize beyond the data at hand.\n\n\n\n\nUp until now, our focus has been on the domain of probability theory. This has allowed us to answer questions like:\n\nWhat is the probability that a certain outcome will occur?\n\nFor instance, imagine we know that 30% of a population of 1000 people own a car. If we randomly select a sample of 100 individuals, we can calculate the probability that 50 or more of them are car owners using tools from probability.\nBut now, we turn the tables.\nInstead of starting with known population characteristics and predicting sample behavior, we enter the world of statistical inference ‚Äî where we begin with a sample and aim to draw conclusions about the larger population. Inference flips the problem around:\n\nGiven data from a sample, what can we say about the population it came from?\n\nLet‚Äôs revisit the earlier example but from a different angle. Suppose we randomly select 100 people from a population of 1000 but this time, we don‚Äôt know what percentage of the population owns a car. We observe that 40 out of the 100 in our sample are car owners. The central question becomes:\n\nWhat can we infer about the proportion of car owners in the entire population?\n\nThis, in essence, is what statistical inference is about: using data from a sample to make educated guesses about unknown parameters in a population distribution. While probability theory helps us determine the behavior of a sample given known population traits, statistical inference works in reverse; aiming to uncover population-level truths from sample-level evidence.\nIn practice, statistical inference involves several important techniques, including:\n\nPoint estimation, where we use sample data to provide a single best guess of a population parameter.\nInterval estimation, where we compute confidence intervals to express the uncertainty around our estimates.\nHypothesis testing, where we formally assess claims about population characteristics using sample evidence.\n\nThis shift, from description and theory to inference and decision-making, marks a crucial transition in the statistical journey. It enables us to go beyond the data at hand and make broader conclusions about the world.\nIn the chapters ahead, we‚Äôll explore each of these methods; learning how to estimate, quantify uncertainty, and test ideas using the powerful tools of inferential statistics.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>From Probability to Statistical Inference</span>"
    ]
  },
  {
    "objectID": "inferential/estimation.html",
    "href": "inferential/estimation.html",
    "title": "21¬† Estimation",
    "section": "",
    "text": "21.1 Estimators, Estimate, Estimands\nWhen working with data, we often face the challenge of estimating unknown characteristics of a population based on a limited set of observations: a sample. These characteristics could be the population mean (\\(\\mu\\)), the population proportion (\\(p\\)), or the population variance (\\(\\sigma^2\\)), among others. In general, we denote the unknown population parameter we wish to estimate by \\(\\theta\\).\nSuppose we collect a random sample consisting of \\(n\\) independent observations, denoted by \\(X_1, X_2, \\dots, X_n\\). Based on this sample, we compute an estimate of \\(\\theta\\), which we denote as \\(\\hat{\\theta}\\). For instance, if the parameter of interest is the population mean \\(\\mu\\), then the corresponding estimate is the sample mean \\(\\bar{X}\\). If the parameter of interest is the population variance \\(\\sigma^2\\), the estimate is the sample variance \\(s^2\\).\nBecause the sample is randomly drawn from the population, the estimate \\(\\hat{\\theta}\\) is itself a random variable. Its value depends on the specific observations in the sample, and therefore it varies from sample to sample. The distribution of this estimate across many repeated samples is known as its sampling distribution (see Chapter 17 and Chapter 18). Understanding the behavior of this distribution is central to inferential statistics: it allows us to assess the uncertainty in our estimates and build confidence intervals, conduct hypothesis tests, and more.\nNaturally, we hope that the value of our estimate \\(\\hat{\\theta}\\) is close to the true, unknown value of \\(\\theta\\). However, there is always a degree of uncertainty involved. To evaluate the quality of an estimator, we study its properties, most importantly, its expected value and its variance.\nFor clarity, it‚Äôs important to distinguish between three closely related but conceptually distinct terms in inferential statistics: estimand, estimator, and estimate.\nIn simpler terms:\nIn this text, we may occasionally use ‚Äúestimate‚Äù loosely, but rest assured; we‚Äôll always be clear about what we‚Äôre inferring, how we‚Äôre doing it, and what the result actually tells us.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "inferential/estimation.html#estimators-estimate-estimands",
    "href": "inferential/estimation.html#estimators-estimate-estimands",
    "title": "21¬† Estimation",
    "section": "",
    "text": "Estimand: This is the target of our inference‚Äîthe unknown quantity or parameter in the population we want to learn about. Examples include the population mean \\(\\mu\\), the proportion of voters supporting a policy \\(p\\), or the difference in means between two groups \\(\\mu_1 - \\mu_2\\).\nEstimator: A formula or rule that we apply to sample data in order to make an informed guess about the estimand. It is a random variable, as it depends on the data, which in turn vary across samples. For instance, the sample mean \\(\\bar{X}\\) is an estimator for the population mean \\(\\mu\\).\nEstimate: The actual numerical result obtained when we apply the estimator to a specific dataset. It is a fixed number, not a random variable. For example, if \\(\\bar{X} = 7.4\\) from our sample, then 7.4 is our estimate of the population mean.\n\n\n\n\n\n\n\n\n\nTerm\nRole\nExample\n\n\n\nEstimand\nWhat we want to know\n\n\\(\\mu\\), \\(p\\), \\(\\mu_1 - \\mu_2\\)\n\n\n\nEstimator\nHow we calculate it\n\n\\(\\bar{X}\\), \\(\\hat{p}\\)\n\n\n\nEstimate\nWhat we get from our data\n7.4, 0.38\n\n\n\n\n‚ö†Ô∏è While these terms are sometimes used interchangeably in casual discussion, understanding their formal distinction is crucial for clear statistical reasoning.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "inferential/estimation.html#properties-of-estimators",
    "href": "inferential/estimation.html#properties-of-estimators",
    "title": "21¬† Estimation",
    "section": "\n21.2 Properties of Estimators",
    "text": "21.2 Properties of Estimators\nAn estimator‚Äôs quality is assessed through certain desirable properties. The most fundamental ones are unbiasedness, consistency, and efficiency.\nAn estimator \\(\\hat{\\theta}\\) is called unbiased if its expected value equals the true parameter:\n\\[\nE(\\hat{\\theta}) = \\theta.\n\\]\nThis means that, on average across many samples, the estimator hits the correct value. If this condition is not met, the estimator is said to have a bias, defined as:\n\\[\n\\text{Bias}(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta.\n\\]\nAn estimator with zero bias is called unbiased. But just being correct on average is not enough. We also want our estimator to be reliable, that is, to give values that are close to the true parameter in most samples, not just on average.\nThis brings us to the property of consistency. An estimator is consistent if it gets arbitrarily close to the true parameter as the sample size increases. Formally, a consistent estimator \\(\\hat{\\theta}_n\\) satisfies:\n\\[\n\\hat{\\theta}_n \\xrightarrow{p} \\theta \\quad \\text{as } n \\to \\infty.\n\\]\nThat is, the probability that the estimator deviates substantially from \\(\\theta\\) goes to zero as the number of observations grows. Consistency ensures long-run accuracy with enough data.\nFinally, among several unbiased and consistent estimators, we may prefer the one that tends to stay closest to the target in each sample. This is the idea behind efficiency. An estimator is more efficient if it has smaller variance among all unbiased estimators. In practical terms, this means it‚Äôs more precise: it fluctuates less from sample to sample, producing estimates tightly clustered around the true value. When comparing two unbiased estimators of the same parameter, the one with the smaller variance is considered more efficient.\nTo illustrate these concepts, consider the dartboard image below:\n\n\n\n\n\n\nFigure¬†21.1: Each board illustrates a combination of estimator characteristics. The bottom-left shows an unbiased and efficient estimator (tight clustering at the center). The top-left is biased but efficient (tight clustering, but off-target). The bottom-right is unbiased but inefficient (centered but scattered). The top-right represents an inefficient and biased estimator (wide scatter, off-target). This analogy helps visualize bias, precision, and the ideal goal of consistency over repeated samples.\n\n\n\nTogether, these properties give us a clear framework for evaluating the reliability of estimators. Ideally, we want an estimator that is unbiased and has the smallest possible variance, a combination that yields both accuracy and precision in estimation.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "inferential/estimation.html#point-estimation",
    "href": "inferential/estimation.html#point-estimation",
    "title": "21¬† Estimation",
    "section": "\n21.3 Point Estimation",
    "text": "21.3 Point Estimation\nIn statistical inference, we often aim to estimate unknown characteristics of a population‚Äîsuch as its average income, the proportion of voters in favor of a policy, or the variance in housing prices. This process of using data from a sample to calculate a single value as a ‚Äúbest guess‚Äù for a population parameter is known as point estimation.\nLet us assume we have a random sample \\(X_1, X_2, \\ldots, X_n\\) of \\(n\\) independent observations from a population with an unknown mean \\(\\mu\\) and variance \\(\\sigma^2\\). A point estimator is a function of the sample data used to estimate a population parameter.\nFor instance:\n\nThe population mean \\(\\mu\\) is typically estimated by the sample mean \\(\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i\\)\n\nThe population proportion \\(p\\) is estimated by the sample proportion \\(\\hat{p} = \\frac{x}{n}\\), where \\(x\\) is the number of ‚Äúsuccesses‚Äù\nThe population variance \\(\\sigma^2\\) is estimated by the sample variance \\(s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2\\)\n\n\nThese estimators are derived from the data and yield a specific number once we collect our sample. However, prior to observing the data, the estimator is a random variable because it depends on the randomly selected sample.\nSince estimators are functions of random samples, they too follow a probability distribution. This distribution is known as the sampling distribution of the estimator (see Chapter 17 and Chapter 18). It tells us how the estimator would vary if we repeatedly took samples of the same size from the same population.\nA crucial insight here is that the larger the sample size, the less variability the estimator will show across repeated samples, leading to more reliable estimation.\nUnderstanding the quality of an estimator involves examining the theoretical properties mentioned above:\n\n\nUnbiasedness: An estimator \\(\\hat{\\theta}\\) is said to be unbiased for a parameter \\(\\theta\\) if its expected value equals the true parameter:\\[ E(\\hat{\\theta}) = \\theta \\]\nFor example (this was shown in detail in Chapter 17):\n\n\n\\(E(\\bar{X}) = \\mu\\), so the sample mean is an unbiased estimator of the population mean.\n\n\\(E(\\hat{p}) = p\\), meaning the sample proportion is also unbiased for the true proportion.\n\n\\(E(s^2) = \\sigma^2\\), making \\(s^2\\) an unbiased estimator of the population variance.\n\n(Note: The sample standard deviation \\(s\\) is not an unbiased estimator of \\(\\sigma\\).)\n\n\nVariance: The spread of the estimator‚Äôs sampling distribution is captured by its variance. Smaller variance means the estimator tends to be closer to the true parameter.\nFor the sample mean, this is given by:\\[ \\operatorname{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} \\]\nSimilarly, for the sample proportion: \\[ \\operatorname{Var}(\\hat{p}) = \\frac{p(1 - p)}{n} \\]\nThese expressions show that increasing the sample size \\(n\\) decreases the variance of the estimator.\n\nStandard Error: The standard deviation of an estimator‚Äôs sampling distribution is called the standard error (SE). It quantifies how much the estimator would vary from sample to sample: \\[ \\text{SE}(\\bar{X}) = \\sqrt{\\frac{\\sigma^2}{n}}, \\quad \\text{SE}(\\hat{p}) = \\sqrt{\\frac{p(1 - p)}{n}} \\]\n\nIn practice, when \\(\\sigma^2\\) or \\(p\\) are unknown, we often substitute their estimates.\nPoint estimation provides an intuitive way to infer unknown quantities in a population using observed sample data. It‚Äôs the first essential tool in the inferential statistics toolbox, allowing us to move from descriptive summaries to educated guesses about the world beyond our data. In the coming chapters, we will build on these estimators to construct confidence intervals and perform hypothesis testing, all grounded in the probabilistic behavior of these sampling distributions.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "inferential/estimation.html#interval-estimation",
    "href": "inferential/estimation.html#interval-estimation",
    "title": "21¬† Estimation",
    "section": "\n21.4 Interval Estimation",
    "text": "21.4 Interval Estimation\nIn statistics, a single number, known as a point estimate, can give us an estimate of a population parameter, like the mean. But such an estimate tells us little about how precise or reliable it is. After all, due to the randomness inherent in sampling, our estimate could vary from sample to sample. That‚Äôs why we turn to interval estimation.\nA confidence interval provides a range of plausible values for the unknown parameter. It gives a way to quantify the uncertainty of our point estimate. The general form of a confidence interval can be written as:\n\\[\n\\text{Point Estimate} \\pm \\text{Margin of Error}\n\\]\nMore formally, a confidence interval is constructed so that, with a specified probability known as the confidence level, contains the true value of the parameter. This probability is denoted by \\(1 - \\alpha\\), where \\(\\alpha\\) is the significance level. Common choices are 95% confidence (\\(\\alpha = 0.05\\)) or 99% confidence (\\(\\alpha = 0.01\\)). The higher the confidence level, the wider the interval must be to ensure it covers the true parameter more frequently in repeated samples.\nWhile a point estimate gives us a single best guess for the value of a population parameter, it offers no information about the uncertainty of that guess. This is visualized in Figure¬†21.2. Imagine you‚Äôre trying to catch a fish (think parameter) you can‚Äôt quite see. Point estimation is like throwing a spear: accurate if you hit, but there‚Äôs a good chance you‚Äôll miss. Interval estimation is more forgiving: it‚Äôs like casting a net. You may not catch the exact center, but you‚Äôre much more likely to get the fish. This is exactly what confidence intervals offer: a wider, more reliable shot at capturing the truth.\n\n\n\n\n\n\nFigure¬†21.2: An analogy for estimation methods: the top panel shows point estimation as attempting to catch a fish with a spear: precise but risky. The bottom panel illustrates interval estimation as casting a wide net: less precise but with a greater chance of capturing the true value.\n\n\n\n\n21.4.1 Confidence Interval for the Population Mean\nWhen we talk about a confidence interval for the population mean \\(\\mu\\) with a confidence level of 95%, we mean an interval that, in the long run, will contain the true value of \\(\\mu\\) in 95% of repeated samples. In practice, we never know the true mean, but we use our sample data to construct a range where we believe the mean is likely to lie.\nMore precisely, the endpoints of the interval (called the Lower Confidence Limit (LCL) and Upper Confidence Limit (UCL)) are calculated as:\n\\[\n\\begin{aligned}\n\\text{LCL} &= \\bar{X} - z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}, \\\\\n\\text{UCL} &= \\bar{X} + z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n\\end{aligned}\n\\]\nFor a 95% confidence level, the critical value is \\(z_{\\alpha/2} \\approx 1.96\\).\nBefore we observe any data, the sample mean \\(\\bar{X}\\) is a random variable. If the population is normally distributed with known variance \\(\\sigma^2\\), then:\n\\[\n\\bar{X} \\sim \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n})\n\\]\nStandardizing gives:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim \\mathcal{N}(0, 1)\n\\]\nWe know (from Appendix A):\n\\[\nP(-1.96 \\leq Z \\leq 1.96) = 0.95\n\\]\nRewriting this inequality in terms of \\(\\mu\\):\n\\[\nP\\left(\\underbrace{\\bar{X} - 1.96 \\cdot \\frac{\\sigma}{\\sqrt{n}}}_{\\text{LCL}} \\leq \\mu \\leq  \\underbrace{\\bar{X} + 1.96 \\cdot \\frac{\\sigma}{\\sqrt{n}}}_{\\text{UCL}}\\right) = 0.95\n\\]\nThis tells us that if we repeat this sampling process many times, 95% of the resulting intervals will contain the true population mean. This is visualized in Figure¬†21.3.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†21.3: Visual comparison of a 95% confidence interval (top) and the corresponding central probability region of the standard normal distribution (bottom). The top plot shows the confidence interval expressed in terms of the sample mean \\(\\bar{X}\\) and standard error, while the bottom plot uses the standardized \\(z\\)-values. In both cases, the central 95% of the distribution is shaded, with \\(\\alpha/2 = 0.025\\) in each tail, and the total area between the bounds representing 95% probability.\n\n\nEach time we draw a new sample from a population and construct a confidence interval for the population mean \\(\\mu\\), the endpoints of that interval are random; they depend on the data from that specific sample. This means that the interval can change from sample to sample. However, if we use a 95% confidence level, then in the long run, 95% of those intervals will capture the true mean, and 5% will not.\nIn other words, we can‚Äôt guarantee that a single confidence interval contains the population mean, but we can say that the method used to construct it is correct 95% of the time. To show this, we perform a simulation: we simulate 100 samples from the same population, construct a 95% confidence interval for each, and visualizes which ones do and do not include the true population mean. Each vertical line in Figure¬†21.4 represents one confidence interval from a sample of size \\(n = 30\\). The blue line shows the true mean \\(\\mu = 5\\) and. The grey intervals contain the true mean, as expected 95% of the time. Red intervals are the $$5% that miss, a natural consequence of statistical variation.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†21.4: Simulation of 100 confidence intervals for the population mean \\(\\mu = 5\\). Each vertical line represents a 95% confidence interval constructed from a random sample of size \\(n = 30\\). Grey intervals successfully capture the true mean, while red intervals do not, illustrating the expected 5% miss rate due to sampling variability.\n\n\nSo how do we interpret the confidence interval? Before we collect any data, we can say that there is a 95% probability that the interval we are about to compute will contain the true population mean, \\(\\mu\\). This probability statement refers to the process, not the specific interval. That is, we are 95% confident in the method, not in any one result. Once a sample is drawn and the confidence interval is computed, the situation changes. The interval is now fixed, it either contains \\(\\mu\\) or it doesn‚Äôt. We no longer speak of probabilities regarding this specific interval. However, what we do know is this:\n\nThe interval was calculated using a procedure that, in the long run, produces intervals that contain the true mean in 95% of all cases.\n\nThis is the essence of the frequentist interpretation of confidence intervals. It doesn‚Äôt tell us the probability that our specific interval contains \\(\\mu\\), but it does provide a measure of trust in the procedure we used to create it. That‚Äôs why we refer to it as a ‚Äúconfidence‚Äù interval ‚Äî not because we are certain, but because we have reason to be confident based on the method‚Äôs performance over repeated samples.\nSo far, we have only constructed 95% confidence intervals for a population mean. This means that if we were to repeat the sampling procedure many times, approximately 95% of those intervals would contain the true population mean, \\(\\mu\\).\nBut 95% is not a fixed rule. We can choose other confidence levels‚Äîsuch as 90% or 99%‚Äîdepending on how certain we want to be. The trade-off is that a higher level of confidence results in a wider interval, while a lower confidence level gives a narrower but less certain estimate.\nWhen the population standard deviation \\(\\sigma\\) is known and the sampling distribution of the mean is approximately normal (either by assumption or via the Central Limit Theorem), the general structure of a confidence interval for the mean is:\n\\[\n\\bar{X} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n\\]\nwhere:\n\n\n\\(\\bar{X}\\) is the sample mean\n\n\n\\(\\sigma\\) is the population standard deviation\n\n\n\\(n\\) is the sample size\n\n\n\\(z_{\\alpha/2}\\) is the critical value from the standard normal distribution for the desired confidence level\n\nSome common confidence levels and their corresponding \\(z\\)-values are shown in Table¬†21.1 (see Appendix A for the exact values):\n\n\nTable¬†21.1: Commonly used confidence levels and their corresponding critical values from the standard normal distribution. The value \\(z_{\\alpha/2}\\) represents the point such that the area between \\(-z_{\\alpha/2}\\) and \\(z_{\\alpha/2}\\) under the standard normal curve equals the stated confidence level.\n\n\n\nConfidence Level\n\\(\\alpha\\)\n\\(z_{\\alpha/2}\\)\n\n\n\n90%\n0.10\n1.645\n\n\n95%\n0.05\n1.960\n\n\n99%\n0.01\n2.576\n\n\n\n\n\n\nAs seen in Figure¬†21.5, a higher confidence level (e.g., 99% instead of 95%) leads to a wider interval since the \\(z\\) value moves further away from the center towards the tails, giving us more ‚Äúcertainty‚Äù at the cost of less precision. A larger sample size reduces the standard error \\(\\frac{\\sigma}{\\sqrt{n}}\\), resulting in a narrower interval, i.e., better precision without sacrificing confidence.\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\nFigure¬†21.5: The confidence interval spans the central \\((1 - \\alpha)\\) area of the standard normal distribution. Each tail has area \\(\\alpha/2\\).\n\n\n\nüí° A higher confidence level leads to a wider interval: you‚Äôre more confident, but less precise.\n\nThis approach provides a principled way of capturing the uncertainty in our estimation of \\(\\mu\\). While the point estimate \\(\\bar{X}\\) gives our best guess, the confidence interval gives us a sense of how variable that estimate might be if we repeated the experiment.\nIn the following, we continue to build on this framework and explore how confidence intervals can be constructed for other types of parameters and under various assumptions.\nExample 21.1: Confidence Interval for a Population Mean\nLet‚Äôs consider a scenario where we take a random sample of size \\(n = 25\\) from a normally distributed population. Suppose we know the population standard deviation to be \\(\\sigma = 15\\), and the sample mean is \\(\\bar{x} = 102\\).\nWe want to construct a 95% confidence interval for the population mean \\(\\mu\\). We use the formula for a confidence interval when the population standard deviation is known:\n\\[\n\\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\n\\]\nFor a 95% confidence level, the critical value from the standard normal distribution is \\(z_{0.025} = 1.96\\).\nLet‚Äôs plug in the values:\n\\[\n102 \\pm 1.96 \\cdot \\frac{15}{\\sqrt{25}} = 102 \\pm 1.96 \\cdot 3 = 102 \\pm 5.88\n\\]\nHence, the 95% confidence interval becomes:\n\\[\n(96.12,\\ 107.88)\n\\]\nThis interval suggests that if we were to repeat this sampling process many times, approximately 95% of the resulting intervals would contain the true population mean \\(\\mu\\).\nWhat if we want a 99% confidence interval? A higher confidence level requires a larger critical value. For 99% confidence, we use \\(z_{0.005} = 2.575\\). Applying the formula:\n\\[\n102 \\pm 2.575 \\cdot \\frac{15}{\\sqrt{25}} = 102 \\pm 2.575 \\cdot 3 = 102 \\pm 7.725\n\\]\nThis results in a wider interval:\n\\[\n(94.275,\\ 109.725)\n\\]\nAs expected, increasing the confidence level results in a wider interval. This reflects greater certainty, more room is allowed to ensure the true mean is captured.\nConfidence Intervals with Unknown Variance\nIn previous examples, we constructed confidence intervals assuming that the population standard deviation \\(\\sigma\\) is known and that the population is normally distributed. While this is convenient for illustrating the basic logic of confidence intervals, it is rarely the case in practice.\n\nBut what if \\(\\sigma\\) is unknown?\n\nWhen \\(\\sigma\\) is unknown, we typically rely on the sample standard deviation \\(s\\) instead. This introduces an additional source of uncertainty because we are now estimating both the center (\\(\\bar{X}\\)) and the spread (\\(s\\)) from the sample data.\nAs a result, our confidence interval becomes wider, especially when the sample size \\(n\\) is small. To account for this, we use the \\(t\\)-distribution rather than the standard normal distribution.\nWe distinguish between two scenarios:\n1. Large sample size (\\(n \\geq 30\\)):\nWhen the sample size is large, the Central Limit Theorem (Chapter 19) ensures that the sampling distribution of the mean is approximately normal, even if the population isn‚Äôt. In this case, substituting \\(s\\) for \\(\\sigma\\) has little impact, and we can still use the normal approximation: \\[\n\\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\n2. Small sample size (\\(n &lt; 30\\)):\nWhen the sample size is small and \\(\\sigma\\) is unknown, we must use the \\(t\\)-distribution with \\(\\nu = n-1\\) degrees of freedom:\n\\[\n\\bar{x} \\pm t_{\\nu, \\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}.\n\\]\nHere, \\(t_{\\nu, \\alpha/2}\\) is the critical value from the \\(t\\)-distribution that corresponds to the desired confidence level. This values is obtained from Appendix B and is fully determined by the degrees of freedom \\(\\nu\\) and confidence level \\(\\alpha\\).\n\n\n\n\n\n\nIntroducing the \\(t\\)-distribution\n\n\n\nThe Student‚Äôs \\(t\\)-distribution is a fundamental tool in statistics when estimating a population mean from a small sample, especially in cases where the population standard deviation \\(\\sigma\\) is unknown. While it resembles the standard normal distribution \\(N(0, 1)\\) in shape, the \\(t\\)-distribution has heavier tails. These heavier tails reflect the added uncertainty introduced by estimating \\(\\sigma\\) with the sample standard deviation \\(s\\).\nThe exact shape of the \\(t\\)-distribution depends on its degrees of freedom, typically \\(\\nu = n - 1\\), where \\(n\\) is the sample size. As the sample size increases, the estimate of \\(\\sigma\\) becomes more reliable, and the \\(t\\)-distribution gradually approaches the normal distribution. In fact, as \\(\\nu \\to \\infty\\), the \\(t\\)-distribution converges to \\(N(0, 1)\\) (see Figure¬†21.6).\nWhen the population is normally distributed and we collect a random sample of size \\(n\\), the following standardized statistic follows a \\(t\\)-distribution with \\(n - 1\\) degrees of freedom:\n\\[\n\\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} \\sim t(n - 1)\n\\]\nThis formulation allows us to perform valid inference about the population mean \\(\\mu\\), even without knowing the true standard deviation \\(\\sigma\\), as long as the population itself is assumed to be normally distributed.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†21.6: Comparison of the standard normal distribution (black) with Student‚Äôs \\(t\\)-distributions for degrees of freedom 1, 5, and 10. As the degrees of freedom increase, the \\(t\\)-distribution becomes more peaked and approaches the shape of the normal distribution, reflecting reduced uncertainty due to larger sample sizes.\n\n\n\n\nSummary: Confidence Intervals for the Population Mean\nWhen constructing a confidence interval for the population mean \\(\\mu\\), the formula depends on three key factors:\n\nwhether the population standard deviation \\(œÉ\\) is known,\n\nthe size of the sample, and\n\nwhether the population is normally distributed.\n\nTable¬†21.2 below summarizes which distribution and formula to use in different situations:\n\n\nTable¬†21.2: Summary of conditions for constructing confidence intervals for a population mean.\n\n\n\n\n\n\n\n\nConditions\nVariance Assumptions\nFormula\n\n\n\n\n\\(n \\geq 30\\) (any population)\n\n\\(\\sigma^2\\) known\n\\(\\bar{x} \\pm z_{\\alpha/2} \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)\\)\n\n\n\n\n\\(\\sigma^2\\) unknown\n\\(\\bar{x} \\pm z_{\\alpha/2} \\left( \\frac{s}{\\sqrt{n}} \\right)\\)\n\n\n\n\\(n &lt; 30\\), normal population\n\n\\(\\sigma^2\\) known\n\\(\\bar{x} \\pm z_{\\alpha/2} \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)\\)\n\n\n\n\n\\(\\sigma^2\\) unknown\n\\(\\bar{x} \\pm t_{\\nu,\\alpha/2} \\left( \\frac{s}{\\sqrt{n}} \\right)\\)\n\n\n\n\\(n &lt; 30\\), population is not normally distributed\n‚Äî\nConfidence interval cannot be calculated\n\n\n\n\n\n\n\nNote: If the sample size is small (\\(n &lt; 30\\)) and the population is not normally distributed, we cannot safely use these formulas to calculate a confidence interval for \\(\\mu\\). In such cases, resampling methods like bootstrapping or non-parametric approaches may be more appropriate.\n\nExample 21.2: Confidence Interval for a Population Mean, \\(n\\) small, variance unknown\nIn a laboratory, measurements are taken on a variable that is assumed to be normally distributed. On one occasion, 12 measurements are obtained, resulting in:\n\n\n\\(\\bar{x} = 9.6\\)\n\n\\(s = 1.89\\)\n\nWe are asked to compute a 95% confidence interval for the population mean \\(\\mu\\).\nSince we have a small sample size (\\(n = 12\\)) and the population variance \\(\\sigma^2\\) is unknown, we use the Student‚Äôs t-distribution with \\(n - 1 = 11\\) degrees of freedom. The general formula for the confidence interval is:\n\\[\n\\bar{x} \\pm t_{\\nu, \\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}\n\\]\nFor a 95% confidence level, \\(\\alpha = 0.05\\), so \\(\\alpha/2 = 0.025\\). From the \\(t\\)-distribution table Appendix B, we find:\n\\[\nt_{11, 0.025} = 2.201\n\\]\nWe can now compute the confidence interval bounds as follows.\n\\[\n\\bar{x} \\pm 2.201 \\cdot \\frac{1.89}{\\sqrt{12}} = 9.6 \\pm 2.201 \\cdot 0.545\n\\]\n\\[\n9.6 \\pm 1.20\n\\]\nThus, the 95% confidence interval for \\(\\mu\\) is:\n\\[\n[8.40,\\ 10.80]\n\\]\nWe can say that the true population mean \\(\\mu\\) lies between 8.40 and 10.80 with 95% confidence. This means that if we were to repeat this sampling process many times, approximately 95% of the constructed confidence intervals would contain the true mean.\n\n21.4.2 Confidence Interval for the Population Proportion\nJust as we can construct a confidence interval for a population mean, we can also build one for a proportion. This is particularly useful when dealing with categorical data, for instance, estimating the proportion of defective units in a production process or the share of voters supporting a candidate.\nLet \\(p\\) denote the population proportion, that is, the true (but unknown) share of the population with a specific characteristic. As before, we estimate \\(p\\) using the sample proportion \\(\\hat{p}\\), defined as:\n\\[\n\\hat{p} = \\frac{\\text{number of observations with the characteristic}}{n}\n\\]\nThis is the point estimate of \\(p\\). Under random sampling, this estimator is unbiased, meaning:\n\\[\nE(\\hat{p}) = p\n\\]\nThe variance of \\(\\hat{p}\\) is:\n\\[\n\\text{Var}(\\hat{p}) = \\frac{p(1 - p)}{n}\n\\]\nThis was shown in detail in Chapter 18.\nSince \\(p\\) is unknown, we approximate this variance using the observed sample proportion:\n\\[\n\\widehat{\\text{Var}}(\\hat{p}) = \\frac{\\hat{p}(1 - \\hat{p})}{n}\n\\]\nWhen the sample size \\(n\\) is sufficiently large, the sampling distribution of \\(\\hat{p}\\) can be approximated by a normal distribution (thanks to the Central Limit Theorem):\n\\[\n\\frac{\\hat{p} - p}{\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}} \\overset{\\text{apx}}{\\sim} N(0, 1)\n\\]\nThis approximation holds well when the sample size satisfies the following rule of thumb: \\(np(1 - p) &gt; 5\\). If this condition is met, we can construct a confidence interval using the normal distribution.\nThe confidence interval for the population proportion \\(p\\) is given by:\n\\[\n\\hat{p} \\pm \\underbrace{z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} }_{\\text{margin of error}}\n\\] The value of \\(z_{\\alpha/2}\\) depends on the desired confidence level, just as before shown in Table¬†21.1.\nTo estimate a population proportion using confeidence intervals:\n\nCompute the sample proportion \\(\\hat{p}\\).\nCalculate the standard error \\(\\sqrt{\\hat{p}(1 - \\hat{p}) / n}\\).\nUse the appropriate \\(z\\)-value for your confidence level.\nConstruct the interval using \\(\\hat{p} \\pm\\) margin of error.\n\nThis method allows us to make probabilistic statements about the true population proportion, provided the sample size is sufficiently large.\n\n\n\n\n\n\nNote on the t-distribution and proportions\n\n\n\nThe t-distribution is not used for constructing confidence intervals for proportions, even when sample sizes are small. Proportions are based on the binomial distribution, and standard confidence intervals rely on the normal approximation when conditions are met. If these conditions aren‚Äôt satisfied, exact methods or adjusted intervals should be used instead.\n\n\nExample 21.3: Confidence Interval for a Proportion\nWe take a random sample of \\(n = 1200\\) people from a large population. Of those sampled, 43.5% report supporting a certain political party. Construct a 95% confidence interval for the true proportion \\(p\\) of the population who support the party.\nWe are given:\n\n\\(\\hat{p} = 0.435\\)\n\\(n = 1200\\)\nConfidence level = 95% \\(\\Rightarrow \\alpha = 0.05\\) \\(\\Rightarrow z_{\\alpha/2} = z_{0.025} = 1.96\\)\n\n\nThe confidence interval for a population proportion is calculated as:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nSubstitute the values:\n\\[\\begin{split}\n0.435 \\pm 1.96 \\cdot \\sqrt{\\frac{0.435(1 - 0.435)}{1200}}\n& = 0.435 \\pm 1.96 \\cdot \\sqrt{\\frac{0.245775}{1200}} \\\\\n& = 0.435 \\pm 1.96 \\cdot \\sqrt{0.0002048} \\\\\n& = 0.435 \\pm 1.96 \\cdot 0.0143  \\\\\n& = 0.435 \\pm 0.028 \\\\\n\\end{split}\n\\]\nThus, the 95% confidence interval is:\n\\[\n[0.407,\\ 0.463]\n\\]\nThis means we are 95% confident that the true proportion of supporters in the population lies between 40.7% and 46.3%.\n\n21.4.3 Confidence Intervals for the Difference Between Two Population Means\nWhen comparing two groups, we often want to estimate the difference between their population means. This leads us to construct a confidence interval for \\(\\mu_x - \\mu_y\\). There are two main cases to consider here:\nCase 1: Two Independent Samples\nThis scenario assumes we take independent random samples from two different populations. We define the populations as follows:\n\n\nPopulation\nMean\nStandard Deviation\n\n\n\nPopulation 1\n\\(\\mu_x\\)\n\\(\\sigma_x\\)\n\n\nPopulation 2\n\\(\\mu_y\\)\n\\(\\sigma_y\\)\n\n\n\nWe collect independent samples:\n\n\n\n\n\n\n\n\n\nSize (\\(n\\))\nSample Mean\nSample Standard Deviation\n\n\n\nSample from 1\n\\(n_x\\)\n\\(\\bar{x}\\)\n\\(s_x\\)\n\n\nSample from 2\n\\(n_y\\)\n\\(\\bar{y}\\)\n\\(s_y\\)\n\n\n\nWe estimate the difference in population means using the point estimate:\n\\[\n\\bar{x} - \\bar{y}\n\\]\nThis is an unbiased estimator, meaning:\n\\[\nE(\\bar{x} - \\bar{y}) = E(\\bar{x}) - E(\\bar{y}) = \\mu_x - \\mu_y\n\\]\nAssuming the samples are independent, the variance of the difference between sample means is:\n\\[\n\\text{Var}(\\bar{x} - \\bar{y}) = \\frac{\\sigma_x^2}{n_x} + \\frac{\\sigma_y^2}{n_y}\n\\]\nWhen the population standard deviations \\(\\sigma_x\\) and \\(\\sigma_y\\) are unknown (as is usually the case), we substitute the sample standard deviations \\(s_x\\) and \\(s_y\\) instead.\nThe appropriate method for constructing a confidence interval depends on several factors:\n\nThe sample sizes: Are they large (\\(\\geq 30\\)) or small (\\(&lt; 30\\))?\nThe distribution of the populations: Are they normally distributed?\nWhether the population variances are known or unknown\nWhether we assume the variances are equal or not\n\nLarge Independent Samples (\\(n_x \\geq 30\\), \\(n_y \\geq 30\\))\nWhen both sample sizes are large, the Central Limit Theorem allows us to use the standard normal distribution (\\(Z\\)), regardless of the population distributions.\n\n\nIf the population variances are known (rare):\n\n\\[\n\\bar{x} - \\bar{y} \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{\\sigma_x^2}{n_x} + \\frac{\\sigma_y^2}{n_y} }\n\\]\n\n\nIf the population variances are unknown (more common), we estimate them with sample variances:\n\n\\[\n\\bar{x} - \\bar{y} \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y} }\n\\]\nThe critical \\(z\\)-value is selected to match the desired confidence level (e.g., \\(z = 1.96\\) for 95%).\nSmall Independent Samples (at least one of \\(n_x\\) or \\(n_y\\) &lt; 30)\nIn this case, we must assume that both populations are normally distributed to proceed.\n\n\nIf the population variances are known (uncommon):\n\n\\[\n\\bar{x} - \\bar{y} \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{\\sigma_x^2}{n_x} + \\frac{\\sigma_y^2}{n_y} }\n\\]\n\nIf the variances are unknown but assumed equal, we use the pooled variance which provides a combined estimate of the common variance by weighting the sample variances according to their degrees of freedom. The formula for pooled varince is: \\[\ns_p^2 = \\frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}\n\\] Here, \\(s_x^2\\) and \\(s_y^2\\) are the sample variances from the two groups, and \\(n_x\\) and \\(n_y\\) are the respective sample sizes. This weighted average gives a more stable estimate of variance when the equal-variance assumption is justified. Use this method only if there is reasonable evidence that the population variances are equal. The formula becomes: \\[\n\\bar{x} - \\bar{y} \\pm t_{\\nu, \\alpha/2} \\cdot \\sqrt{ s_p^2 \\left( \\frac{1}{n_x} + \\frac{1}{n_y} \\right) }\n\\] where the degrees of freedom are: \\[\n\\nu = (n_x-1) + (n_y-1) = n_x + n_y - 2\n\\]\nIf the variances are unknown and cannot be assumed equal, we cannot assume equal variance, we rely on the so called Welch‚Äôs method, which is an adaptation of the standard two-sample \\(t\\)-test that does not assume equal population variances. It is more flexible and robust, especially when sample sizes or variances differ between groups. Instead of pooling the variances, Welch‚Äôs method uses the individual sample variances to compute the standard error and an approximate degrees of freedom, denoted \\(\\nu\\). The confidence interval is thus given by:\n\n\\[\n\\bar{x} - \\bar{y} \\pm t_{\\nu, \\alpha/2} \\cdot \\sqrt{ \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y} }\n\\] with degrees of freedom approximated by: \\[\n\\nu \\approx \\frac{ \\left( \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y} \\right)^2 }{ \\frac{(s_x^2 / n_x)^2}{n_x - 1} + \\frac{(s_y^2 / n_y)^2}{n_y - 1} }\n\\] This method is more robust and does not assume equal population variances, making it the preferred choice in most small-sample scenarios with unequal spread.\nThe different cases are summarized in Table¬†21.3.\n\n\nTable¬†21.3: Confidence interval formulas for the difference between two means given different sample sizes and under different variance assumptions.\n\n\n\n\n\n\n\n\n\nSample Size & Variance Assumptions\nDistribution\nDegrees of Freedom (\\(\\nu\\))\nFormula\n\n\n\n\n\\(n_x, n_y \\geq 30\\), \\(\\sigma_x, \\sigma_y\\) known\nStandard normal \\(Z\\)\n\n\n\\(\\bar{x} - \\bar{y} \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{\\sigma_x^2}{n_x} + \\frac{\\sigma_y^2}{n_y} }\\)\n\n\n\n\\(n_x, n_y \\geq 30\\), \\(\\sigma_x, \\sigma_y\\) unknown\nStandard normal \\(Z\\)\n\n\n\\(\\bar{x} - \\bar{y} \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y} }\\)\n\n\n\n\\(n_x, n_y &lt; 30\\), \\(s_x = s_y\\)\n\nPooled \\(t\\)-distribution\n\\(n_x + n_y - 2\\)\n\\(\\bar{x} - \\bar{y} \\pm t_{\\nu, \\alpha/2} \\cdot \\sqrt{ s_p^2 \\left( \\frac{1}{n_x} + \\frac{1}{n_y} \\right) }\\)\n\n\n\n\\(n_x, n_y &lt; 30\\), \\(s_x \\neq s_y\\)\n\nWelch‚Äôs \\(t\\)-distribution\n\\(\\displaystyle \\frac{\\left( \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y} \\right)^2}{\\frac{(s_x^2 / n_x)^2}{n_x - 1} + \\frac{(s_y^2 / n_y)^2}{n_y - 1}}\\)\n\\(\\bar{x} - \\bar{y} \\pm t_{\\nu, \\alpha/2} \\cdot \\sqrt{ \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y} }\\)\n\n\n\n\n\n\nExample 21.4: Confidence Interval for the Difference in Means\nTwo independent samples were taken from two different populations:\n\nSample 1: \\(n_x = 51\\), \\(\\bar{x} = 14.3\\), \\(s_x = 3.18\\)\n\nSample 2: \\(n_y = 52\\), \\(\\bar{y} = 12.6\\), \\(s_y = 3.5\\)\n\n\nConstruct a 95% confidence interval for the difference in population means, \\(\\mu_x - \\mu_y\\).\nSince both sample sizes are greater than 30, and population variances are unknown, we can use the standard normal approximation with sample variances substituted in. That is, we use the formula: \\[\n\\bar{x} - \\bar{y} \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y} }\n\\]\nwhere \\(z_{0.025} = 1.96\\) for a 95% confidence level. We plug in the values: \\[\n\\bar{x} - \\bar{y} = 14.3 - 12.6 = 1.7\n\\] \\[\n\\begin{split}\n\\text{Standard error} & = \\sqrt{ \\frac{3.18^2}{51} + \\frac{3.5^2}{52} } \\\\ & \\approx \\sqrt{ \\frac{10.1124}{51} + \\frac{12.25}{52} }  \\\\ & \\approx \\sqrt{0.1983 + 0.2356}  \\\\ & \\approx \\sqrt{0.4339} \\\\ & \\approx 0.6588\n\\end{split}\n\\] and calculate the margin of error as: \\[\n1.96 \\cdot 0.6588 \\approx 1.29\n\\] So the confidence interval is: \\[\n1.7 \\pm 1.29 = [0.41, 2.99]\n\\]\nExample 21.5: Confidence Interval for the Difference in Means\nWe are given two independent random samples from normally distributed populations with equal but unknown variances:\n\n\n\n\n\n\n\n\nGroup\nSample Size\nMean\nStandard Deviation\n\n\n\nPopulation 1\n\\(n_x = 11\\)\n\\(\\bar{x} = 1.23\\)\n\n\\(s_{x}\\) = \\(0.23\\)\n\n\n\nPopulation 2\n\\(n_y =13\\)\n\\(\\bar{y} = 1.18\\)\n\\(s_y= 0.27\\)\n\n\n\nWe are to compute a 95% confidence interval for the difference in population means: \\(\\mu_x - \\mu_y\\).\nSince \\(n_x = 11\\) and \\(n_y = 13\\) are both less than 30, and the population variances are assumed equal but unknown, we use the pooled \\(t\\)-distribution approach. The formula to use is the following: \\[\n\\bar{x} - \\bar{y} \\pm t_{\\nu, \\alpha/2} \\cdot \\sqrt{ s_p^2 \\left( \\frac{1}{n_x} + \\frac{1}{n_y} \\right) }\n\\]\nThe pooled sample variance \\(s_p^2\\) is computed as: \\[\ns_p^2 = \\frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}\n= \\frac{(10)(0.23^2) + (12)(0.27^2)}{22} = 0.0638\n\\] and the degrees of freedom are given by \\[\n\\nu = n_x + n_y - 2 = 11 + 13 - 2 = 22\n\\] At the 95% confidence level we have that (Appendix B): \\[\nt_{22,\\ 0.025} = 2.074\n\\] We substitute values in the formula above: \\[\\begin{split}\n0.05 \\pm 2.074 \\cdot \\sqrt{0.0638 \\left( \\frac{1}{11} + \\frac{1}{13} \\right)}\n& = 0.05 \\pm 2.074 \\cdot \\sqrt{0.0638 \\cdot 0.1709}\n\\\\ & = 0.05 \\pm 2.074 \\cdot 0.1045\n\\\\ &\\approx 0.05 \\pm 0.217\n\\end{split}\n\\] So the 95% confidence interval is: \\[\n[-0.167,\\ 0.267]\n\\] The 95% confidence interval for the difference in population means is \\([-0.167,\\ 0.267]\\). This means we are 95% confident that the true difference \\(\\mu_x - \\mu_y\\) lies somewhere between \\(-0.167\\) and \\(0.267\\). Since this interval includes values both below and above zero, the observed difference in sample means may be due to sampling variability rather than a clear difference between the populations.\nCase 2: Paired Samples\nThe second case for two group comparisons, is when we have a single sample from a population, but we take two measurements on each individual in the sample. This means we no longer have two independent samples, but instead we have paired observations.\nPaired data, that is, two measurements taken on the same individuals or on matched units is different from having two independent samples. Examples include:\n\nMeasuring blood pressure before and after a treatment on the same patient.\nComparing performance on two tests taken by the same student.\nTesting two teaching methods on the same group of students. Because the observations are not independent, we must take the dependency into account.\n\nAs before, we are interested in constructing a confidence interval for the difference in means based on these paired data. Instead of comparing two separate means though, we analyze the difference within each pair defined as: \\[\nd_i = x_i - y_i\n\\] Now let:\n\n\n\\(\\bar{d}\\) be the mean of the differences,\n\n\n\\(s_d\\) the standard deviation of the differences,\n\n\n\\(n\\) the number of pairs. Then, the confidence interval for the mean difference \\(\\mu_d\\) is: \\[\n\\bar{d} \\pm t_{n - 1, \\alpha/2} \\cdot \\frac{s_d}{\\sqrt{n}}\n\\]\n\n\nThis formula is based on the one-sample \\(t\\)-distribution with \\(n - 1\\) degrees of freedom.\n\n\n\n\n\n\nWhen to Use This Method\n\n\n\nUse the paired \\(t\\)-method when:\n\nThe same subject is measured twice (e.g., before and after),\nThe data is naturally paired (e.g., matched cases),\nThe differences \\(d_i\\) are approximately normally distributed.\n\n\n\nSuppose we are studying the effect of a blood pressure treatment. For each individual in our sample, we measure blood pressure before and after treatment as shown in the table below:\n\n\nIndividual\nAfter (\\(x\\))\nBefore (\\(y\\))\nDifference (\\(d = x - y\\))\n\n\n\n1\n\\(x_1\\)\n\\(y_1\\)\n\\(d_1 = x_1 - y_1\\)\n\n\n2\n\\(x_2\\)\n\\(y_2\\)\n\\(d_2 = x_2 - y_2\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(n\\)\n\\(x_n\\)\n\\(y_n\\)\n\\(d_n = x_n - y_n\\)\n\n\n\nThese \\(d_1, d_2, \\dots, d_n\\) form a sample from a population of differences with population mean \\(\\mu_d\\) and variance \\(\\sigma_d^2\\). We estimate the population mean difference \\(\\mu_d\\) using the sample mean of the differences: \\[\n\\bar{d} = \\frac{1}{n} \\sum_{i=1}^n d_i\n\\] This is an unbiased estimator, since: \\[\nE(\\bar{d}) = \\mu_d \\quad \\text{and} \\quad \\text{Var}(\\bar{d}) = \\frac{\\sigma_d^2}{n}\n\\] The sample variance of the differences is: \\[\ns_d^2 = \\frac{1}{n - 1} \\sum_{i=1}^n (d_i - \\bar{d})^2\n\\] and the estimated standard error is: \\[\n\\text{SE} = \\frac{s_d}{\\sqrt{n}}\n\\]\nThere are (again) two scenarios for constructing a confidence interval:\n\nLarge sample siez (that is \\(n\\geq 30\\))\nWhen the sample size is large (regardless of the population distribution), the confidence interval is based on the standard normal distribution: \\[\n\\bar{d} \\pm z_{\\alpha/2} \\cdot \\frac{s_d}{\\sqrt{n}}\n\\]\nSmall sample size and population of differences is normally distributed\nWhen \\(n &lt; 30\\) and we assume normality, we use the \\(t\\)-distribution so the confeidence interval is given by: \\[\n\\bar{d} \\pm t_{\\nu,\\alpha/2} \\cdot \\frac{s_d}{\\sqrt{n}}, \\quad \\nu = n - 1\n\\]\n\n\nNote: In both cases, we assume the population variance \\(\\sigma_d^2\\) is unknown, which is typically the case in practice.\n\nThe different scenarios are summarized in Table¬†21.4.\n\n\nTable¬†21.4: Confidence interval formulas for paired-sample mean differences, depending on sample size and assumptions about the distribution of the population differences.\n\n\n\n\n\n\n\n\nConditions\nVariance Assumptions\nFormula\n\n\n\n\n\\(n \\geq 30\\), any population distribution\n\n\\(\\sigma_d^2\\) known\n\\(\\bar{d} \\pm z_{\\alpha/2} \\left( \\frac{\\sigma_d}{\\sqrt{n}} \\right)\\)\n\n\n\n\n\\(\\sigma_d^2\\) unknown\n\\(\\bar{d} \\pm z_{\\alpha/2} \\left( \\frac{s_d}{\\sqrt{n}} \\right)\\)\n\n\n\n\\(n &lt; 30\\), population of differences is normal\n\n\\(\\sigma_d^2\\) known\n\\(\\bar{d} \\pm z_{\\alpha/2} \\left( \\frac{\\sigma_d}{\\sqrt{n}} \\right)\\)\n\n\n\n\n\\(\\sigma_d^2\\) unknown\n\\(\\bar{d} \\pm t_{\\nu,\\alpha/2} \\left( \\frac{s_d}{\\sqrt{n}} \\right)\\)\n\n\n\n\\(n &lt; 30\\), population of differences is not normal\n‚Äî\nConfidence interval cannot be calculated\n\n\n\n\n\n\nExample 21.6: Confidence Interval for Paired Differences\nWe have a sample of 6 workers from a normally distributed population. Each worker performs the same task using Method A and Method B, and the time taken in minutes is recorded for both methods:\n\n\n\\(X\\) = time using Method A\n\n\n\\(Y\\) = time using Method B\n\nWe are to compute a 95% confidence interval for the average difference in time (Method A ‚àí Method B).\nLet \\(d = x - y\\) be the difference for each individual:\n\n\n\n\n\n\n\n\n\n\nPerson\n\\(x\\)\n\\(y\\)\n\\(d = x - y\\)\n\\(d - \\bar{d}\\)\n\\((d - \\bar{d})^2\\)\n\n\n\n1\n6.0\n5.4\n0.6\n0.3\n0.09\n\n\n2\n5.0\n5.2\n-0.2\n-0.5\n0.25\n\n\n3\n7.0\n6.5\n0.5\n0.2\n0.04\n\n\n4\n6.2\n5.9\n0.3\n0.0\n0.00\n\n\n5\n6.0\n6.0\n0.0\n-0.3\n0.09\n\n\n6\n6.4\n5.8\n0.6\n0.3\n0.09\n\n\nTotal\n\n\n1.8\n\n0.56\n\n\n\nNow we can compute the sample statistics:\n\nMean difference: \\(\\bar{d} = \\frac{1.8}{6} = 0.3\\)\n\nVariance: \\(s_d^2 = \\frac{0.56}{5} = 0.112\\)\n\nStandard deviation: \\(s_d = \\sqrt{0.112} = 0.335\\)\n\n\nWe note that \\(n &lt; 30\\), \\(\\sigma^2\\) is unknown, and we have a normally distributed population. Therefore, a 95% confidence interval for \\(\\mu_d\\) is calculated as follows: \\[\n\\bar{d} \\pm t_{\\nu, \\alpha/2} \\cdot \\frac{s_d}{\\sqrt{n}}\n\\] Since \\(n = 6\\), degrees of freedom \\(\\nu = 5\\), and \\(\\alpha = 0.025\\), we use (see Appendix B): \\[\nt_{5, 0.025} = 2.571\n\\] Substitute values in the confidence interval formula: \\[\n0.3 \\pm 2.571 \\cdot \\frac{0.335}{\\sqrt{6}} = 0.3 \\pm 0.35\n\\] So the 95% confidence interval is: \\[\n[-0.05,\\ 0.65]\n\\] Since the interval includes 0, we cannot rule out that the two methods are equally effective. With 95% confidence, the average difference in time could be zero.\n\n21.4.4 Confidence Intervals for Differences in Population Proportions\nWhen comparing two independent populations on a binary outcome (such as success/failure), we are often interested in estimating the difference between their population proportions, \\(p_x - p_y\\). If both samples are large enough, we can use the normal approximation to construct a confidence interval for this difference:\n\\[\n(\\hat{p}_x - \\hat{p}_y) \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{\\hat{p}_x (1 - \\hat{p}_x)}{n_x} + \\frac{\\hat{p}_y (1 - \\hat{p}_y)}{n_y} }\n\\]\nThis interval provides a plausible range of values for the true difference between the proportions in the two populations. If the confidence interval includes zero, it suggests that the observed difference might be due to random sampling variability, and there may be no real difference between the groups.\n\n\n\n\n\n\nWarning\n\n\n\nSmall Sample Sizes: If either sample is small, specifically, if \\(n \\cdot \\hat{p} &lt; 5\\) or \\(n \\cdot (1 - \\hat{p}) &lt; 5\\), the normal approximation may not be appropriate.\n\n\nExample 21.7: Confidence Interval for the Difference Between Two Proportions\nWe want to estimate the difference in support for a political party between two populations.\n\nLet \\(p_x\\) = proportion in population 1 who support the party\n\nLet \\(p_y\\) = proportion in population 2 who support the party\n\nWe take a simple random sample of:\n\n\n\\(n_x = 150\\) from population 1, with \\(\\hat{p}_x = 0.36\\)\n\n\n\\(n_y = 250\\) from population 2, with \\(\\hat{p}_y = 0.27\\)\n\n\nWe are to construct a 95% confidence interval for \\(p_x - p_y\\). Since the sample sizes are large, we use the standard normal approximation for the confidence interval: \\[\n\\hat{p}_x - \\hat{p}_y \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{ \\hat{p}_x (1 - \\hat{p}_x) }{n_x} + \\frac{ \\hat{p}_y (1 - \\hat{p}_y) }{n_y} }\n\\] With \\(z_{\\alpha/2} = z_{0.025} = 1.96\\), we compute:\n\\[\n0.36 - 0.27 \\pm 1.96 \\cdot \\sqrt{ \\frac{0.36(1 - 0.36)}{150} + \\frac{0.27(1 - 0.27)}{250} }\n\\] \\[\n\\begin{split} 0.09 \\pm 1.96 \\cdot \\sqrt{ \\frac{0.2304}{150} + \\frac{0.1971}{250} }\n& = 0.09 \\pm 1.96 \\cdot \\sqrt{0.001536 + 0.0007884}\n\\\\ & = 0.09 \\pm 1.96 \\cdot 0.0406\n\\\\ &= 0.09 \\pm 0.0796\n\\end{split}\n\\] So the 95% confidence interval is: \\[\n[0.0104,\\ 0.1696]\n\\] We estimate that the difference in support between the two populations is between 1.0% and 17.0%, with population 1 showing more support. Since the entire interval is above 0, this suggests a real difference in proportions between the populations.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "inferential/estimation.html#exercises",
    "href": "inferential/estimation.html#exercises",
    "title": "21¬† Estimation",
    "section": "Exercises",
    "text": "Exercises\n\nA random sample of 120 families was drawn from a population of approximately 5000 families. The number of children in each selected family was recorded. The sample yielded \\(\\bar{x} = 1.28\\) (mean number of children) and \\(s = 1.10\\) (sample standard deviation). Assuming the sample is drawn using simple random sampling, calculate a 99% confidence interval for the population mean \\(\\mu\\), the average number of children per family.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are given:\n\n\\(\\bar{x} = 1.28\\)\n\\(s = 1.10\\)\n\\(n = 120\\)\nConfidence level: \\(99\\% \\Rightarrow \\alpha = 0.01 \\Rightarrow \\alpha/2 = 0.005\\)\n\n\n\\(z_{\\alpha/2} = 2.58\\) (from the standard normal table)\n\nSince the sample is large (\\(n = 120\\)), the Central Limit Theorem applies, and we can use the normal distribution.\nThe standard error is:\n\\[\nSE = \\frac{s}{\\sqrt{n}} = \\frac{1.10}{\\sqrt{120}} \\approx 0.1004\n\\]\nThen the confidence interval is:\n\\[\n\\bar{x} \\pm z_{\\alpha/2} \\cdot SE = 1.28 \\pm 2.58 \\cdot 0.1004 \\approx 1.28 \\pm 0.26\n\\]\nFinal interval:\n\\[\n[1.02,\\ 1.54]\n\\]\nInterpretation: We are 99% confident that the true mean number of children per family in the population lies between 1.02 and 1.54.\n\n\n\n\nIn a small town with 8820 households, a sample of 200 households is taken. In the sample, 60 households have a smart home system installed. Construct a 95% confidence interval for the proportion of households in the entire town that have a smart home system.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are given:\n\n\\(n = 200\\)\n\\(x = 60\\)\n\\(\\hat{p} = \\frac{60}{200} = 0.30\\)\n\n\\(z_{\\alpha/2} = 1.96\\) for a 95% confidence level\n\nThe standard error is calculated as:\n\\[\nSE = \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = \\sqrt{\\frac{0.30(1 - 0.30)}{200}} = \\sqrt{\\frac{0.21}{200}} \\approx 0.0324\n\\]\nThe confidence interval is:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\cdot SE = 0.30 \\pm 1.96 \\cdot 0.0324 \\approx 0.30 \\pm 0.0635\n\\]\nSo the 95% confidence interval is approximately:\n\\[\n[0.24, 0.36]\n\\]\nTo interpret this in terms of number of households:\n\n\\(0.24 \\cdot 8820 \\approx 2117\\)\n\\(0.36 \\cdot 8820 \\approx 3175\\)\n\nWe can say, with 95% confidence, that roughly 2100 and 3200 households in the town have a smart home system installed.\n\n\n\n\nA car manufacturer wants to compare the average fuel efficiency (in liters per 100 km) between two models of hybrid vehicles. Two random samples were taken:\n\n\n\n\n\n\n\n\n\nModel\nSample Size\nMean\nStandard Deviation\n\n\n\nHybrid A\n15\n\\(4.8\\)\n\\(0.5\\)\n\n\nHybrid B\n12\n\\(5.1\\)\n\\(0.6\\)\n\n\n\nAssume that fuel efficiency is normally distributed, and the population variances are equal but unknown. Construct a 95% confidence interval for the difference in mean fuel efficiency between the two models. What can you say about the results in terms of the difference in fuel efficiency?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe use the pooled \\(t\\)-distribution approach since sample sizes are small and equal variances are assumed. The pooled variance is given by: \\[\n\\begin{split}\ns_p^2 = \\frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}\n& = \\frac{(14)(0.5^2) + (11)(0.6^2)}{25}\n\\\\ & = \\frac{3.5 + 3.96}{25} \\\\ & = 0.3384\n\\end{split}\n\\] and we have degrees of freedom equal to \\[\n\\nu = n_x + n_y - 2 = 15 + 12 - 2 = 25\n\\] yielding the critical \\(t\\)-value \\[\nt_{25,\\ 0.025} = 2.060 .\n\\]\nThe 95% confidence interval to use is given by \\[\n\\bar{x} - \\bar{y} \\pm t_{\\nu, \\alpha/2} \\cdot \\sqrt{s_p^2 \\left( \\frac{1}{n_x} + \\frac{1}{n_y} \\right)}\n\\] and with substituted values we get: \\[\n\\begin{split}\n4.8 - 5.1 \\pm 2.060 \\cdot \\sqrt{0.3384 \\left( \\frac{1}{15} + \\frac{1}{12} \\right)}\n& = -0.3 \\pm 2.060 \\cdot \\sqrt{0.3384 \\cdot 0.1528}\n\\\\ &= -0.3 \\pm 2.060 \\cdot 0.2273\n\\\\ &= -0.3 \\pm 0.468\n\\end{split}\n\\] \\[\n\\implies [-0.768,\\ 0.168]\n\\] Since this interval includes zero, the observed difference in sample means may be due to sampling variability rather than a clear difference between the two hybrid models.\n\n\n\n\nA pedagogical study aimed to compare the learning abilities of two age groups of children. Large random samples were taken from each population. The goal is to estimate the difference in mean learning ability using a 99% confidence interval. The sample summary is shown below:\n\n\n\nGroup\nSample Size\nMean\nStandard Deviation\n\n\n\nGroup 1\n89\n42\n6.1\n\n\nGroup 2\n73\n30\n4.5\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSince both samples are large and population variances are unknown, we use the standard normal \\(z\\)-distribution with the formula:\n\\[\n\\bar{x} - \\bar{y} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y}}\n\\] Given from sample data is the following:\n\n\n\\(\\bar{x} = 42\\), \\(s_x = 6.1\\), \\(n_x = 89\\)\n\n\n\\(\\bar{y} = 30\\), \\(s_y = 4.5\\), \\(n_y = 73\\)\n\n\\(z_{\\alpha/2} = z_{0.005} = 2.58\\)\n\nWe compute the sample statistics: \\[\n\\bar{x} - \\bar{y} = 42 - 30 = 12\n\\] \\[\nSE = \\sqrt{ \\frac{6.1^2}{89} + \\frac{4.5^2}{73} } = \\sqrt{ \\frac{37.21}{89} + \\frac{20.25}{73} } \\approx \\sqrt{0.418 + 0.277} \\approx \\sqrt{0.695} \\approx 0.834\n\\] Next, we can compute the confidence interval \\[\n12 \\pm 2.58 \\cdot 0.834 = 12 \\pm 2.15\n\\] So the 99% confidence interval is: \\[\n[9.85,\\ 14.15]\n\\] Since this interval does not include zero, we can conclude that there is likely a meaningful difference in learning ability between the two groups.\n\n\n\n\nAt a school, students were randomly divided into two groups for English instruction. Group 1 had access to a language laboratory, while Group 2 received only traditional classroom instruction. After the instruction was completed, the goal was to examine whether there was any difference in the effectiveness of the two teaching methods. To do this, a 90% confidence interval was constructed to estimate the difference in average language proficiency between the two groups (populations). A random sample of students from each group was selected to complete a standardized language test. The investigation yielded the following results:\n\nGroup 1: \\(\\bar{x} = 42.4\\), \\(s_x^2 = 66\\), \\(n_x = 10\\)\n\nGroup 2: \\(\\bar{y} = 46.6\\), \\(s_y^2 = 54\\), \\(n_y = 12\\)\n\n\nConstruct a 90% confidence interval for \\(\\mu_x - \\mu_y\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe assumptions are as follows:\n\nTwo independent random samples\n\nSmall sample sizes (\\(n_x = 10\\), \\(n_y = 12\\))\n\nAssume normal populations with equal variances\n\n\\(\\implies\\) Unknown population variances, use pooled \\(t\\)-distribution\nCompute the pooled variance: \\[\ns_p^2 = \\frac{(n_x - 1)s_x^2 + (n_y - 1)s_y^2}{n_x + n_y - 2}\n= \\frac{(9)(66) + (11)(54)}{20} = 59.4\n\\] The degrees of freedom are given by \\[\n\\nu = n_x + n_y - 2 = 10 + 12 - 2 = 20\n\\] and the critical \\(t\\) value for 90% confidence, \\(\\alpha = 0.10\\) and \\(\\alpha/2 = 0.05\\) is given by \\[\nt_{20,\\,0.05} = 1.725\n\\]\nWe can now compute the confidence interval: \\[\n\\bar{x} - \\bar{y} \\pm t_{\\nu, \\alpha/2} \\cdot \\sqrt{s_p^2 \\left( \\frac{1}{n_x} + \\frac{1}{n_y} \\right)}\n= -4.2 \\pm 1.725 \\cdot \\sqrt{59.4 \\left( \\frac{1}{10} + \\frac{1}{12} \\right)}\n= -4.2 \\pm 5.7\n\\] \\[\n\\implies [-9.9,\\ 1.5]\n\\]\nThus, we estimate that the average English knowledge in the lab group is between 9.9 points lower and 1.5 points higher than that of the traditional group. Since the interval includes zero, the observed difference could be due to random variation in the samples, and we cannot confidently say that one teaching method leads to higher average performance than the other.\n\n\n\n\nA new medication is believed to reduce fever. To test its effect, researchers measured the body temperature of 8 patients before and one hour after taking the medication.\n\n\n\nPerson\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\nBefore (¬∞C)\n38.2\n38.4\n38.5\n38.9\n39.0\n39.0\n39.3\n39.7\n\n\nAfter (¬∞C)\n37.2\n37.2\n38.8\n38.1\n38.2\n39.6\n38.2\n38.6\n\n\n\nConstruct a 95% confidence interval for the mean temperature reduction due to the medication.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis is a case of paired observations (before vs.¬†after on the same individuals), so we compute the differences: \\[\nd_i = \\text{Before} - \\text{After}\n\\]\n\n\nPerson\n\\(d_i\\)\n\n\n\n1\n1.0\n\n\n2\n1.2\n\n\n3\n-0.3\n\n\n4\n0.8\n\n\n5\n0.8\n\n\n6\n-0.6\n\n\n7\n1.1\n\n\n8\n1.1\n\n\n\n\nSample mean of differences: \\(\\bar{d} = 0.6375\\)\n\nSample standard deviation: \\(s_d = 0.6907\\)\n\nSample size: \\(n = 8\\)\n\nDegrees of freedom: \\(\\nu = 7\\)\n\nCritical \\(t\\)-value at 95%: \\(t_{7, 0.025} = 2.365\\)\n\n\nThe confidence interval is given by \\[\n\\bar{d} \\pm t_{\\nu, \\alpha/2} \\cdot \\frac{s_d}{\\sqrt{n}} = 0.6375 \\pm 2.365 \\cdot \\frac{0.6907}{\\sqrt{8}} \\approx 0.6375 \\pm 0.58\n\\] So the 95% confidence interval is: \\[\n[0.06,\\ 1.21]\n\\] We estimate that the medication reduces fever by between 0.06 and 1.21¬∞C on average. Since the interval does not include 0, we have evidence that the medication is likely effective in lowering body temperature.\n\n\n\n\nA survey is conducted to compare the support for a new vaccine in two regions. In region A, 120 out of 200 people support the vaccine. In region B, 135 out of 250 support it. Construct a 95% confidence interval for the difference in population proportions, \\(p_A - p_B\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are given:\n\n\\(\\hat{p}_A = \\frac{120}{200} = 0.60\\)\n\\(\\hat{p}_B = \\frac{135}{250} = 0.54\\)\n\\(n_A = 200,\\quad n_B = 250\\)\n\n\\(z_{\\alpha/2} = 1.96\\) for 95% confidence We use the formula: \\[\n\\hat{p}_A - \\hat{p}_B \\pm z_{\\alpha/2} \\cdot \\sqrt{ \\frac{ \\hat{p}_A (1 - \\hat{p}_A) }{n_A} + \\frac{ \\hat{p}_B (1 - \\hat{p}_B) }{n_B} }\n\\] Substitute: \\[\n0.60 - 0.54 \\pm 1.96 \\cdot \\sqrt{ \\frac{0.60 \\cdot 0.40}{200} + \\frac{0.54 \\cdot 0.46}{250} }\n\\] \\[ \\begin{split}\n& = 0.06 \\pm 1.96 \\cdot \\sqrt{0.0012 + 0.0009936}\n\\\\ & = 0.06 \\pm 1.96 \\cdot \\sqrt{0.0021936}\n\\\\ &= 0.06 \\pm 1.96 \\cdot 0.0468\n\\\\ &= 0.06 \\pm 0.0917\n\\end{split}\n\\] So the 95% confidence interval is: \\[\n[-0.0317,\\ 0.1517]\n\\] The interval ranges from approximately ‚àí3.2% to 15.2%. Since the interval includes 0, we cannot conclude that there is a meaningful difference in vaccine support between the two regions based on this sample.\n\n\n\n\n\nA university wants to compare the average weekly study hours between psychology and engineering students. Random samples yield the following results:\n\n\n\nPsychology: \\(n_1 = 18\\), \\(\\bar{x}_1 = 24.3\\), \\(s_1 = 4.1\\)\n\n\nEngineering: \\(n_2 = 16\\), \\(\\bar{x}_2 = 27.8\\), \\(s_2 = 5.6\\)\n\n\nConstruct a 95% confidence interval for the difference in mean study hours, assuming the population variances are not equal.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe use Welch‚Äôs t-interval for independent samples with unequal variances. The point estimate for the difference in means is given by \\[\n\\bar{x}_1 - \\bar{x}_2 = 24.3 - 27.8 = -3.5\n\\] and the standard error is given by \\[\n\\begin{split}SE & = \\sqrt{ \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} }\n\\\\ &= \\sqrt{ \\frac{4.1^2}{18} + \\frac{5.6^2}{16} }\n\\\\ &= \\sqrt{ \\frac{16.81}{18} + \\frac{31.36}{16} }\n\\\\ & = \\sqrt{0.934 + 1.96} = \\sqrt{2.894} \\approx 1.702\n\\end{split}\n\\]\nWe find the correct degrees of freedom using Welch-Satterthwaite approximation: \\[\n\\nu \\approx \\frac{ \\left( \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2 }\n{ \\frac{ \\left( \\frac{s_1^2}{n_1} \\right)^2 }{n_1 - 1} + \\frac{ \\left( \\frac{s_2^2}{n_2} \\right)^2 }{n_2 - 1} }\n= \\frac{(0.934 + 1.96)^2}{\\frac{0.934^2}{17} + \\frac{1.96^2}{15}} \\approx \\frac{8.38}{0.0513 + 0.256} \\approx 25.1\n\\] Thus, we use \\(t_{25} \\approx 2.060\\) for 95% confidence. The confidence interval is then given by \\[\n-3.5 \\pm 2.060 \\cdot 1.702 = -3.5 \\pm 3.508\n\\implies [-7.01,\\ 0.01]\n\\] The 95% confidence interval for the difference in study hours ranges from ‚àí7.01 to 0.01 hours. Since the interval includes zero, we cannot conclude that there is a difference in average study hours between the two majors.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html",
    "href": "inferential/hyp-test.html",
    "title": "22¬† Hypothesis Testing",
    "section": "",
    "text": "22.1 What Is Hypothesis Testing?\nIn the previous chapter, we used confidence intervals to estimate an unknown population parameter such as the mean (\\(\\mu\\)) or proportion (\\(p\\)), based on a random sample. Confidence intervals provide a range of plausible values for that parameter.\nWhile confidence intervals focus on estimation, hypothesis testing addresses decision-making: it allows us to test specific claims about a population parameter using sample data. In fact, these two methods are closely related; we can often reach the same conclusions using either approach. We return to this in more detail later in this chapter.\nHypothesis testing is a formal method used to evaluate two competing statements (called hypotheses) about a population parameter:\nWe use data from a sample to decide whether there is sufficient evidence to reject the null hypothesis in favor of the alternative. The null hypothesis (\\(H_0\\)) is assumed to be true unless the evidence from the sample strongly contradicts it. It plays the role of a ‚Äúpresumption of innocence.‚Äù The alternative hypothesis (\\(H_1\\)) is what we hope to support, but only if we have enough evidence to doubt \\(H_0\\).\nWe never prove the alternative hypothesis directly; we can only reject \\(H_0\\) if the evidence is strong enough, just like a jury does not prove guilt, but rather rejects the assumption of innocence when the evidence demands it. Rejecting \\(H_0\\) only indicates that the data are inconsistent with \\(H_0\\) under the assumed conditions.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#what-is-hypothesis-testing",
    "href": "inferential/hyp-test.html#what-is-hypothesis-testing",
    "title": "22¬† Hypothesis Testing",
    "section": "",
    "text": "Null hypothesis (\\(H_0\\)): The default or status quo assumption.\n\nAlternative hypothesis (\\(H_1\\) or \\(H_a\\)): A competing claim that we seek evidence for.\n\n\n\nExample 22.1: Bottled Water Production\nA company bottles 500 ml of spring water per bottle. To ensure customer trust, they need to verify that the filling process remains accurate. Let\n\\[\n\\mu = \\text{true average amount of water per bottle}\n\\]\nWe want to test whether the bottling machine is still calibrated correctly:\n\\(H_0\\): \\(\\mu = 500\\) (machine is accurate)\n\\(H_1\\): \\(\\mu \\neq 500\\) (machine is underfilling or overfilling)\nThat is, the alternative hypothesis says: ‚ÄúThe machine does not have the correct precision.‚Äù\nExample 22.2: Political Party Support\nIn a political opinion poll, 14% of the selected individuals say they support Party A. We know that in the most recent election, Party A received 12% of the votes. Has the proportion of A-supporters in the population increased since the election?\n\\(H_0\\): \\(P = 0.12\\) (The proportion is unchanged)\n\\(H_1\\): \\(P &gt; 0.12\\) (The proportion has increased)\nShould we reject \\(H_0\\) or not?\n\nIf we consider the high sample value to be explainable by chance (assuming \\(H_0\\) is true), we stick with \\(H_0\\).\nIf we consider the sample proportion to be too high to be reasonably explained by chance, we reject \\(H_0\\).\n\nWe can never be 100% certain that we are making the correct decision. Statistical hypothesis testing involves using specific decision rules to determine when we should reject \\(H_0\\) (and when we should retain \\(H_0\\)). These decision rules are designed so that we have a certain level of control over the risk of making an incorrect decision.\nTo understand the reasoning behind hypothesis testing, it can be helpful to draw an analogy from the legal system. Imagine a courtroom trial where the task is to determine whether the defendant is guilty or not. A key question in this context is: on whom does the burden of proof lie?\nJust as in most legal systems, where a person is presumed innocent until proven guilty, hypothesis testing begins with a similar assumption. The null hypothesis, denoted \\(H_0\\), plays the role of ‚Äúinnocence‚Äù: it is the claim we initially assume to be true. The alternative hypothesis, denoted \\(H_1\\), corresponds to the prosecution‚Äôs claim: it challenges the status quo and must be supported by strong evidence.\nThere is an asymmetry in how we treat the null hypothesis (\\(H_0\\)) and the alternative hypothesis (\\(H_1\\)) in statistical hypothesis testing. We typically choose \\(H_0\\) to be the hypothesis that we hold on to as long as possible. It is the default assumption, often representing ‚Äúno change,‚Äù ‚Äúno effect,‚Äù or ‚Äúno difference.‚Äù On the other hand, \\(H_1\\) is usually the more bold and interesting hypothesis from an applied perspective.\nWe require particularly strong evidence from the observed data to reject \\(H_0\\). The burden of proof lies with the party advocating for \\(H_1\\). Before diving into how to best use information from the sample, we ask ourselves: how confident must we be that the accused is guilty before reaching a guilty verdict? Similarly, how confident must we be that the null hypothesis is incorrect before deciding to believe in the alternative hypothesis?\nIf we reach that level of confidence, we say that we reject the null hypothesis (or accept the alternative hypothesis). The degree of confidence required depends on the context, but typically, we want to be quite certain that the assumption in the null hypothesis is incorrect. This is because the decision to reject the null hypothesis, and instead believe in the alternative, often comes with serious consequences.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#classical-hypothesis-testing",
    "href": "inferential/hyp-test.html#classical-hypothesis-testing",
    "title": "22¬† Hypothesis Testing",
    "section": "\n22.2 Classical Hypothesis Testing",
    "text": "22.2 Classical Hypothesis Testing\nThe classical approach to hypothesis testing involves the following six main steps:\nStep 1. Hypotheses\nBegin by formulating the null hypothesis (\\(H_0\\)) and the alternative hypothesis (\\(H_1\\)).\nExamples of hypotheses about population means:\n\n\\(H_0: \\mu = \\mu_0\\); \\(H_1: \\mu \\ne \\mu_0\\)(Simple null hypothesis; two-sided alternative)\n\\(H_0: \\mu \\le \\mu_0\\); \\(H_1: \\mu &gt; \\mu_0\\)(Composite null hypothesis; one-sided alternative)\n\nExamples of hypotheses about population proportions:\n\n\\(H_0: p = p_0\\); \\(H_1: p \\ne p_0\\)(Simple null hypothesis; two-sided alternative)\n\\(H_0: p = p_0\\); \\(H_1: p &gt; p_0\\)(Simple null hypothesis; one-sided alternative)\nStep 2. Significance Level\nChoose a significance level \\(\\alpha\\), which represents the probability (or risk) of rejecting the null hypothesis \\(H_0\\) when it is actually true.\nA common choice is \\(\\alpha = 0.05\\), which implies that the hypothesis test is conducted at the 5% level. This means that there is a 5% chance of making a Type I error, that is rejecting a true null hypothesis. In other words, if the null hypothesis is true, then on average, 1 in every 20 tests will incorrectly reject it. If we want to be more cautious about rejecting a correct null hypothesis, we use a smaller \\(\\alpha\\), such as \\(\\alpha = 0.01\\).\nStep 3. Test Statistic\nSpecify which test statistic will be used. A test statistic is a quantity calculated from the sample data and its value forms the basis of our decision (see step 5).\nThe choice of test statistic depends on:\n\nWhether the sample is large or not.\nWhether the population is normally distributed or not.\nWhether the population variance is known or not.\n\nWe‚Äôll return to these different cases in more detail below.\nStep 4: Decision Rule\nSpecify the rejection region (the critical region), such that \\(H_0\\) is rejected if the test statistic falls within this region. In summary, the form of the critical region is determined by:\n\n\nThe form of the alternative hypothesis:\n\n\n\\(H_1: \\mu \\neq \\mu_0\\) ‚Üí two-tailed test ‚Üí rejection region in both tails.\n\n\\(H_1: \\mu &gt; \\mu_0\\) ‚Üí one-tailed test ‚Üí rejection region in the right tail.\n\n\\(H_1: \\mu &lt; \\mu_0\\) ‚Üí one-tailed test ‚Üí rejection region in the left tail.\n\n\nThe significance level \\(\\alpha\\).\n\nAlternative hypotheses of the forms \\(&gt;\\) and \\(&lt;\\) are called one-sided, while those using \\(\\neq\\) are called two-sided. Figure¬†22.1 illustrates the decision framework of hypothesis testing three panels:\n\nLeft: Depicts a two-tailed test, where both tails of the distribution represent critical regions. The dashed lines mark the critical values at \\(z = \\pm z_{\\alpha/2}\\). Each tail has an area of \\(\\alpha/2\\), and the null hypothesis is rejected if the test statistic lies in either shaded tail. The central blue segment indicates the non-rejection region.\nRight: Represents a one-sided test with the alternative hypothesis \\(H_1: \\mu &gt; \\mu_0\\). The right tail is shaded red, indicating the critical region with area \\(\\alpha\\). The test statistic must fall in this region to reject \\(H_0\\).\nMiddle: Shows the critical region in the left tail of the distribution, representing a one-sided test with the alternative hypothesis \\(H_1: \\mu &lt; \\mu_0\\). The red-shaded area corresponds to the significance level \\(\\alpha\\), and any test statistic falling in this region leads to rejection of the null hypothesis \\(H_0\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.1: The decision framework of hypothesis testing for two-tailed and one-tailed tests.\n\n\n\n\n\n\n\n\nErrors and Decision Framework\n\n\n\nWhen making a decision, one either makes a correct choice or one of two types of errors. Just as there is a risk that an innocent person may be wrongly convicted, there is also a risk that a guilty person may go free.\nUsing probability theory, we can to some extent determine the risk of making incorrect decisions.\n\nA Type I error occurs when we incorrectly reject the null hypothesis (\\(H_0\\)) even though it is true. The risk of making a Type I error is called the significance level of the test and is denoted by the Greek letter \\(\\alpha\\).\nA Type II error occurs when we incorrectly fail to reject the null hypothesis, even though it is false. The risk of this error is denoted by the Greek letter \\(\\beta\\).\n\nA diagram describing the possible outcomes of hypothesis testing is shown below:\n\n\n\n\n\n\n\nReality\n\n\\(H_0\\) is true\n\n\\(H_0\\) is false\n\n\n\nDecision\n\n\n\n\nDo not reject \\(H_0\\)\n\nCorrect decision\nType II error (incorrect decision)\n\n\nReject \\(H_0\\)\n\nType I error (incorrect decision)\nCorrect decision\n\n\n\nIn classical hypothesis testing, we primarily control the probability of making a Type I error. This is done by setting the significance level \\(\\alpha\\) to a predefined low value (commonly \\(\\alpha = 0.01\\), \\(0.05\\), or \\(0.10\\)).\n\\[\n\\alpha = \\text{Significance level of the test} = P(\\text{Reject } H_0 \\mid H_0 \\text{ is true})\n\\]\nAfter setting the acceptable level for Type I errors, we then aim to reduce the probability of Type II errors (\\(\\beta\\)) by choosing a sufficiently large sample size.\n\n\nOnce the hypotheses have been formulated, the appropriate test statistic selected and decision rules specified, we proceed with the final steps of the classical hypothesis testing procedure:\nStep 5: Observation\nWe calculate the value of the test statistic using the data obtained from the sample. This computation allows us to compare the observed value with the theoretical distribution under the null hypothesis. This value is what we refere to as our observed value.\nStep 6: Conclusion\nBased on the value of the test statistic (our observed value), we make our decision based on the decision rule:\n\nIf the value falls outside the critical boundaries (i.e.¬†outside the non-rejection region), we reject the null hypothesis \\(H_0\\). This means that we have obtained a result that is statistically significant at the chosen significance level \\(\\alpha\\).\nIf the value falls within the non-rejection region, we do not reject \\(H_0\\). In this case, the result is said to be not statistically significant.\n\nIn essence, these final steps guide us in deciding whether the sample data provides enough evidence to conclude that the null hypothesis is unlikely to be true, given the selected confidence level.\n\n\n\n\n\n\nNote\n\n\n\nA non-significant result does not mean that we can conclude the null hypothesis (\\(H_0\\)) is true. It simply indicates that the alternative hypothesis (\\(H_1\\)) does not present strong enough evidence against \\(H_0\\) in this particular case.\nThere may be many other potential null hypotheses that would also not be rejected. Therefore, failing to reject \\(H_0\\) is not the same as accepting \\(H_0\\) as true.\nIn other words, we use the terms ‚Äòreject‚Äô and ‚Äòfail to reject‚Äô to summarize the possible outcomes of a hypothesis test",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "chi2.html",
    "href": "chi2.html",
    "title": "Chi Square Tests",
    "section": "",
    "text": "[1] 2",
    "crumbs": [
      "Chi Square Tests"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "Regression Analysis",
    "section": "",
    "text": "Simple Linear Regression\nMultiple Linear Regression\nOLS estimation\nGauss Markov Theorem\nModel Assumptions and Diagnostics\nDummy variables and Interaction Terms\nEndogeneity and IV estimation\n\n\n\n[1] 2",
    "crumbs": [
      "Regression Analysis"
    ]
  },
  {
    "objectID": "appendix/normal-table.html",
    "href": "appendix/normal-table.html",
    "title": "Appendix A: The Standard Normal Distribution Table",
    "section": "",
    "text": "Standard Normal Cumulative Probabilities: \\(\\Phi(z) = P(Z \\leq z)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nz\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\n0.08\n0.09\n\n\n\n0.0\n0.5000\n0.5040\n0.5080\n0.5120\n0.5160\n0.5199\n0.5239\n0.5279\n0.5319\n0.5359\n\n\n0.1\n0.5398\n0.5438\n0.5478\n0.5517\n0.5557\n0.5596\n0.5636\n0.5675\n0.5714\n0.5753\n\n\n0.2\n0.5793\n0.5832\n0.5871\n0.5910\n0.5948\n0.5987\n0.6026\n0.6064\n0.6103\n0.6141\n\n\n0.3\n0.6179\n0.6217\n0.6255\n0.6293\n0.6331\n0.6368\n0.6406\n0.6443\n0.6480\n0.6517\n\n\n0.4\n0.6554\n0.6591\n0.6628\n0.6664\n0.6700\n0.6736\n0.6772\n0.6808\n0.6844\n0.6879\n\n\n0.5\n0.6915\n0.6950\n0.6985\n0.7019\n0.7054\n0.7088\n0.7123\n0.7157\n0.7190\n0.7224\n\n\n0.6\n0.7257\n0.7291\n0.7324\n0.7357\n0.7389\n0.7422\n0.7454\n0.7486\n0.7517\n0.7549\n\n\n0.7\n0.7580\n0.7611\n0.7642\n0.7673\n0.7704\n0.7734\n0.7764\n0.7794\n0.7823\n0.7852\n\n\n0.8\n0.7881\n0.7910\n0.7939\n0.7967\n0.7995\n0.8023\n0.8051\n0.8078\n0.8106\n0.8133\n\n\n0.9\n0.8159\n0.8186\n0.8212\n0.8238\n0.8264\n0.8289\n0.8315\n0.8340\n0.8365\n0.8389\n\n\n1.0\n0.8413\n0.8438\n0.8461\n0.8485\n0.8508\n0.8531\n0.8554\n0.8577\n0.8599\n0.8621\n\n\n1.1\n0.8643\n0.8665\n0.8686\n0.8708\n0.8729\n0.8749\n0.8770\n0.8790\n0.8810\n0.8830\n\n\n1.2\n0.8849\n0.8869\n0.8888\n0.8907\n0.8925\n0.8944\n0.8962\n0.8980\n0.8997\n0.9015\n\n\n1.3\n0.9032\n0.9049\n0.9066\n0.9082\n0.9099\n0.9115\n0.9131\n0.9147\n0.9162\n0.9177\n\n\n1.4\n0.9192\n0.9207\n0.9222\n0.9236\n0.9251\n0.9265\n0.9279\n0.9292\n0.9306\n0.9319\n\n\n1.5\n0.9332\n0.9345\n0.9357\n0.9370\n0.9382\n0.9394\n0.9406\n0.9418\n0.9429\n0.9441\n\n\n1.6\n0.9452\n0.9463\n0.9474\n0.9484\n0.9495\n0.9505\n0.9515\n0.9525\n0.9535\n0.9545\n\n\n1.7\n0.9554\n0.9564\n0.9573\n0.9582\n0.9591\n0.9599\n0.9608\n0.9616\n0.9625\n0.9633\n\n\n1.8\n0.9641\n0.9649\n0.9656\n0.9664\n0.9671\n0.9678\n0.9686\n0.9693\n0.9699\n0.9706\n\n\n1.9\n0.9713\n0.9719\n0.9726\n0.9732\n0.9738\n0.9744\n0.9750\n0.9756\n0.9761\n0.9767\n\n\n2.0\n0.9772\n0.9778\n0.9783\n0.9788\n0.9793\n0.9798\n0.9803\n0.9808\n0.9812\n0.9817\n\n\n2.1\n0.9821\n0.9826\n0.9830\n0.9834\n0.9838\n0.9842\n0.9846\n0.9850\n0.9854\n0.9857\n\n\n2.2\n0.9861\n0.9864\n0.9868\n0.9871\n0.9875\n0.9878\n0.9881\n0.9884\n0.9887\n0.9890\n\n\n2.3\n0.9893\n0.9896\n0.9898\n0.9901\n0.9904\n0.9906\n0.9909\n0.9911\n0.9913\n0.9916\n\n\n2.4\n0.9918\n0.9920\n0.9922\n0.9925\n0.9927\n0.9929\n0.9931\n0.9932\n0.9934\n0.9936\n\n\n2.5\n0.9938\n0.9940\n0.9941\n0.9943\n0.9945\n0.9946\n0.9948\n0.9949\n0.9951\n0.9952\n\n\n2.6\n0.9953\n0.9955\n0.9956\n0.9957\n0.9959\n0.9960\n0.9961\n0.9962\n0.9963\n0.9964\n\n\n2.7\n0.9965\n0.9966\n0.9967\n0.9968\n0.9969\n0.9970\n0.9971\n0.9972\n0.9973\n0.9974\n\n\n2.8\n0.9974\n0.9975\n0.9976\n0.9977\n0.9977\n0.9978\n0.9979\n0.9979\n0.9980\n0.9981\n\n\n2.9\n0.9981\n0.9982\n0.9982\n0.9983\n0.9984\n0.9984\n0.9985\n0.9985\n0.9986\n0.9986\n\n\n3.0\n0.9987\n0.9987\n0.9987\n0.9988\n0.9988\n0.9989\n0.9989\n0.9989\n0.9990\n0.9990",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>The Standard Normal Distribution Table</span>"
    ]
  },
  {
    "objectID": "appendix/t-table.html",
    "href": "appendix/t-table.html",
    "title": "Appendix B: The \\(t\\) Distribution Table",
    "section": "",
    "text": "One-sided critical t-values for the Student‚Äôs t-distribution: P(T &gt; tŒΩ, Œ±) = Œ±. The last row shows the corresponding standard normal (z) values as degrees of freedom ŒΩ ‚Üí ‚àû.\n\nŒΩ\nŒ± = 0.1\nŒ± = 0.05\nŒ± = 0.025\nŒ± = 0.01\nŒ± = 0.005\n\n\n\n1\n3.078\n6.314\n12.706\n31.821\n63.657\n\n\n2\n1.886\n2.920\n4.303\n6.965\n9.925\n\n\n3\n1.638\n2.353\n3.182\n4.541\n5.841\n\n\n4\n1.533\n2.132\n2.776\n3.747\n4.604\n\n\n5\n1.476\n2.015\n2.571\n3.365\n4.032\n\n\n6\n1.440\n1.943\n2.447\n3.143\n3.707\n\n\n7\n1.415\n1.895\n2.365\n2.998\n3.499\n\n\n8\n1.397\n1.860\n2.306\n2.896\n3.355\n\n\n9\n1.383\n1.833\n2.262\n2.821\n3.250\n\n\n10\n1.372\n1.812\n2.228\n2.764\n3.169\n\n\n11\n1.363\n1.796\n2.201\n2.718\n3.106\n\n\n12\n1.356\n1.782\n2.179\n2.681\n3.055\n\n\n13\n1.350\n1.771\n2.160\n2.650\n3.012\n\n\n14\n1.345\n1.761\n2.145\n2.624\n2.977\n\n\n15\n1.341\n1.753\n2.131\n2.602\n2.947\n\n\n16\n1.337\n1.746\n2.120\n2.583\n2.921\n\n\n17\n1.333\n1.740\n2.110\n2.567\n2.898\n\n\n18\n1.330\n1.734\n2.101\n2.552\n2.878\n\n\n19\n1.328\n1.729\n2.093\n2.539\n2.861\n\n\n20\n1.325\n1.725\n2.086\n2.528\n2.845\n\n\n21\n1.323\n1.721\n2.080\n2.518\n2.831\n\n\n22\n1.321\n1.717\n2.074\n2.508\n2.819\n\n\n23\n1.319\n1.714\n2.069\n2.500\n2.807\n\n\n24\n1.318\n1.711\n2.064\n2.492\n2.797\n\n\n25\n1.316\n1.708\n2.060\n2.485\n2.787\n\n\n26\n1.315\n1.706\n2.056\n2.479\n2.779\n\n\n27\n1.314\n1.703\n2.052\n2.473\n2.771\n\n\n28\n1.313\n1.701\n2.048\n2.467\n2.763\n\n\n29\n1.311\n1.699\n2.045\n2.462\n2.756\n\n\n30\n1.310\n1.697\n2.042\n2.457\n2.750\n\n\n100\n1.290\n1.660\n1.984\n2.364\n2.626\n\n\n500\n1.283\n1.648\n1.965\n2.334\n2.586\n\n\n‚àû\n1.282\n1.645\n1.960\n2.326\n2.576",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>The $t$ Distribution Table</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#hypothesis-testoing-for-a-population-mean",
    "href": "inferential/hyp-test.html#hypothesis-testoing-for-a-population-mean",
    "title": "\n22¬† Hypothesis Testing\n",
    "section": "\n22.3 Hypothesis Testoing for a Population Mean",
    "text": "22.3 Hypothesis Testoing for a Population Mean\n\n22.3.1 Two-Sided Test\nJust as with confidence intervals, different cases must be considered when conducting hypothesis tests:\n\nIs the sample size large or small?\nIs the population normally distributed?\nIs the population variance known?\n\nWe begin with a foundational example: suppose we draw a sample of size \\(n\\) from a normally distributed population where the mean \\(\\mu\\) is unknown but the variance \\(\\sigma^2\\) is known. We conduct a two-sided hypothesis test at a significance level \\(\\alpha = 0.05\\), walking through the six steps of hypothesis testing.\n1. State the Hypotheses\nWe want to test whether the population mean equals some hypothesized value \\(\\mu_0\\). The hypotheses are:\n\\[\nH_0: \\mu = \\mu_0 \\\\\nH_1: \\mu \\ne \\mu_0\n\\]\nThis is a two-sided test, as we are considering deviations in both directions from \\(\\mu_0\\).\n2. Set the Significance Level\nWe choose a significance level of:\n\\[\n\\alpha = 0.05\n\\]\nThis indicates we are willing to accept a 5% chance of rejecting the null hypothesis if it is actually true.\n3. Choose the Test Statistic\nSince the population is normally distributed and the population standard deviation \\(\\sigma\\) is known, we use the standard normal \\(Z\\) statistic:\n\\[\nZ = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n\\]\nUnder \\(H_0\\), the statistic follows the standard normal distribution:\n\\[\nZ \\sim N(0, 1)\n\\]\n4. Decision Rule\nFor a two-sided test with \\(\\alpha = 0.05\\), the critical values are:\n\\[\nz_{\\alpha/2} = \\pm 1.96\n\\]\nThe decision rule is:\n\nReject \\(H_0\\) if \\(|z_{\\text{obs}}| &gt; 1.96\\)\n\nOtherwise, do not reject \\(H_0\\)\n\n\nThe critical regions for this test is visualized in Figure¬†22.2, where we see the threshold for rejecting \\(H_0\\) in both directions when testing for a deviation from a hypothesized population mean.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.2: Visual representation of a two-sided hypothesis test at significance level \\(\\alpha  = 0.05\\). The standard normal curve is split into two critical regions (shaded red), each representing \\(\\alpha‚ÅÑ2 = 0.025\\) in the tails, where the null hypothesis is rejected. The non-rejection region (shaded blue) lies between the critical values ‚àí1.96 and 1.96. If the test statistic falls within this central interval, we do not reject the null hypothesis.\n\n\n5. Calculate the Test Statistic\nCompute the observed value of the test statistic:\n\\[\nz_{\\text{obs}} = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n\\]\n6. Draw a Conclusion\nCompare \\(z_{\\text{obs}}\\) to the critical values:\n\nIf \\(|z_{\\text{obs}}| &gt; 1.96\\), reject \\(H_0\\)\n\nOtherwise, fail to reject \\(H_0\\)\n\n\nThis tells us whether the sample provides strong enough evidence to conclude that the population mean differs from \\(\\mu_0\\).\n\n\n\n\n\n\nNote: Choosing Critical Values for a Hypothesis Test\n\n\n\nA reasonable starting point in hypothesis testing is that we should reject the null hypothesis (\\(H_0\\)) if we observe a sample mean \\(\\bar{x}\\) that is ‚Äúfar‚Äù from the expected value \\(\\mu_0\\) under \\(H_0\\).\nIn practical terms, \\(\\bar{x}\\) being far from \\(\\mu_0\\) means that the test statistic \\(Z\\) takes on a value far from 0; either in the positive or negative direction. Therefore, we decide to reject \\(H_0\\) if \\(Z\\) falls outside a specified range: specifically, outside the interval \\([-c, c]\\), where \\(c\\) is a positive constant that we determine based on the desired significance level \\(\\alpha\\).\nTo define this cutoff \\(c\\), we choose it so that the total probability of \\(Z\\) falling outside the interval (i.e., the two tails) equals the chosen significance level \\(\\alpha\\). For example, with \\(\\alpha = 0.05\\), we solve:\n\\[\nP(|Z| &gt; c \\mid H_0 \\text{ true}) = 0.05\n\\]\nSince the distribution of \\(Z\\) under the null hypothesis is standard normal \\(N(0, 1)\\), we find:\n\\[\nP(|Z| &gt; 1.96 \\mid H_0 \\text{ true}) = 0.05\n\\]\nThus, we set \\(c = 1.96\\) for a two-sided test at the 5% significance level. Our final decision rule becomes:\n\nReject \\(H_0\\) if the computed test statistic \\(Z\\) falls outside the interval \\([-1.96,\\ 1.96]\\). Otherwise, we fail to reject \\(H_0\\).\n\n\n\n\n22.3.2 One-Sided Test",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#hypothesis-testing-for-a-population-mean",
    "href": "inferential/hyp-test.html#hypothesis-testing-for-a-population-mean",
    "title": "22¬† Hypothesis Testing",
    "section": "\n22.3 Hypothesis Testing for a Population Mean",
    "text": "22.3 Hypothesis Testing for a Population Mean\nJust as with confidence intervals, different cases must be considered when conducting hypothesis tests:\n\nIs the sample size large or small?\nIs the population normally distributed?\nIs the population variance known?\n\n\n22.3.1 Two-Sided Hypothesis Tests\nWe begin with an example: suppose we draw a sample of size \\(n\\) from a normally distributed population where the mean \\(\\mu\\) is unknown but the variance \\(\\sigma^2\\) is known. We conduct a two-sided hypothesis test at a significance level \\(\\alpha = 0.05\\), walking through the six steps of hypothesis testing.\n1. Hypotheses\nWe want to test whether the population mean equals some hypothesized value \\(\\mu_0\\). The hypotheses are:\n\\[\nH_0: \\mu = \\mu_0 \\\\\nH_1: \\mu \\ne \\mu_0\n\\]\nThis is a two-sided test, as we are considering deviations in both directions from \\(\\mu_0\\).\n2. Significance Level\nWe choose a significance level of:\n\\[\n\\alpha = 0.05\n\\]\nThis indicates we are willing to accept a 5% chance of rejecting the null hypothesis if it is actually true.\n3. Test Statistic\nSince the population is normally distributed and the population standard deviation \\(\\sigma\\) is known, we use the standard normal \\(Z\\) statistic:\n\\[\nZ = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n\\]\nUnder \\(H_0\\), the statistic follows the standard normal distribution:\n\\[\nZ \\sim N(0, 1)\n\\]\n4. Decision Rule\nFor a two-sided test with \\(\\alpha = 0.05\\), the critical values are:\n\\[\nz_{\\alpha/2} = \\pm 1.96\n\\]\nThe decision rule is:\n\nReject \\(H_0\\) if \\(|z_{\\text{obs}}| &gt; 1.96\\)\n\nOtherwise, do not reject \\(H_0\\)\n\n\nThe critical regions for this test is visualized in Figure¬†22.2, where we see the threshold for rejecting \\(H_0\\) in both directions when testing for a deviation from a hypothesized population mean.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.2: Visual representation of a two-sided hypothesis test at significance level \\(\\alpha  = 0.05\\). The standard normal curve is split into two critical regions (shaded red), each representing \\(\\alpha‚ÅÑ2 = 0.025\\) in the tails, where the null hypothesis is rejected. The non-rejection region (shaded blue) lies between the critical values ‚àí1.96 and 1.96. If the test statistic falls within this central interval, we do not reject the null hypothesis.\n\n\n5. Observation\nCompute the observed value of the test statistic:\n\\[\nz_{\\text{obs}} = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\n\\]\n6. Conclusion\nCompare \\(z_{\\text{obs}}\\) to the critical values:\n\nIf \\(|z_{\\text{obs}}| &gt; 1.96\\), reject \\(H_0\\)\n\nOtherwise, fail to reject \\(H_0\\)\n\n\nThis tells us whether the sample provides strong enough evidence to conclude that the population mean differs from \\(\\mu_0\\).\n\n\n\n\n\n\nNote: Choosing Critical Values for a Hypothesis Test\n\n\n\nA reasonable starting point in hypothesis testing is that we should reject the null hypothesis (\\(H_0\\)) if we observe a sample mean \\(\\bar{x}\\) that is ‚Äúfar‚Äù from the expected value \\(\\mu_0\\) under \\(H_0\\).\nIn practical terms, \\(\\bar{x}\\) being far from \\(\\mu_0\\) means that the test statistic \\(Z\\) takes on a value far from 0; either in the positive or negative direction. Therefore, we decide to reject \\(H_0\\) if \\(Z\\) falls outside a specified range: specifically, outside the interval \\([-c, c]\\), where \\(c\\) is a positive constant that we determine based on the desired significance level \\(\\alpha\\).\nTo define this cutoff \\(c\\), we choose it so that the total probability of \\(Z\\) falling outside the interval (i.e., the two tails) equals the chosen significance level \\(\\alpha\\). For example, with \\(\\alpha = 0.05\\), we solve:\n\\[\nP(|Z| &gt; c \\mid H_0 \\text{ true}) = 0.05\n\\]\nSince the distribution of \\(Z\\) under the null hypothesis is standard normal \\(N(0, 1)\\), we find:\n\\[\nP(|Z| &gt; 1.96 \\mid H_0 \\text{ true}) = 0.05\n\\]\nThus, we set \\(c = 1.96\\) for a two-sided test at the 5% significance level. Our final decision rule becomes:\n\nReject \\(H_0\\) if the computed test statistic \\(Z\\) falls outside the interval \\([-1.96,\\ 1.96]\\). Otherwise, we fail to reject \\(H_0\\).\n\n\n\n\n22.3.2 One-Sided Hypothesis Tests\nIn some situations, we are not interested in detecting any difference from the null value, but specifically a greater or smaller value. In such cases, we use a one-sided alternative hypothesis. The structure of the test depends on the direction specified in the alternative.\nTesting if the mean is greater than a specified value\nWe want to test the hypotheses:\n\\[\nH_0: \\mu = \\mu_0 \\quad \\text{vs.} \\quad H_1: \\mu &gt; \\mu_0\n\\]\nIn this case, we are interested in large values of the sample mean \\(\\bar{x}\\) as evidence against \\(H_0\\). The rejection region lies in the right tail of the standard normal distribution.\nFor a significance level \\(\\alpha = 0.05\\), the critical value is:\n\\[\nz_\\alpha = 1.645\n\\]\nWe reject the null hypothesis if:\n\\[\nz_{\\text{obs}} &gt; 1.645\n\\]\nThis corresponds to the idea that an unusually high observed value of \\(\\bar{x}\\) supports the alternative that the true mean is greater than \\(\\mu_0\\).\nTesting if the mean is less than a specified value\nNow suppose we want to test:\n\\[\nH_0: \\mu = \\mu_0 \\quad \\text{vs.} \\quad H_1: \\mu &lt; \\mu_0\n\\]\nHere, we are interested in small values of the sample mean as evidence against \\(H_0\\). The rejection region lies in the left tail of the standard normal distribution.\nFor \\(\\alpha = 0.05\\), the critical value becomes:\n\\[\nz_\\alpha = -1.645\n\\]\nWe reject the null hypothesis if:\n\\[\nz_{\\text{obs}} &lt; -1.645\n\\]\nThis reflects the logic that low values of \\(\\bar{x}\\) support the alternative that the true mean is less than \\(\\mu_0\\).\nThe critical regions for these one-sided tests are visualized in Figure¬†22.3, where we see the threshold for rejecting \\(H_0\\) in either directions when testing for a deviation from a hypothesized population mean.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.3: Visual comparison of one-sided hypothesis tests using the standard normal distribution. The left plot shows a right-tailed test, with the rejection region in the upper tail (for testing \\(H_0: \\mu = \\mu_0\\) vs.¬†\\(H_1: \\mu &gt; \\mu_0\\)). The right plot illustrates a left-tailed test, where the rejection region lies in the lower tail (for testing \\(H_0: \\mu = \\mu_0\\) vs.¬†\\(H_1: \\mu &lt; \\mu_0\\)).\n\n\n\n22.3.3 Hypothesis Testing with Unknown Variance\nUp until now, we have assumed that the population is normally distributed and that the population variance \\(\\sigma^2\\) is known. But what if the population variance is unknown or if the sample size is small?\nIn such cases, we no longer use the standard normal distribution (\\(Z\\)). Instead, we use the Student‚Äôs \\(t\\)-distribution, which accounts for the additional uncertainty introduced by estimating the population standard deviation from the sample.\nThe test statistic is then defined as:\n\\[\nt = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\n\\]\nwhere:\n\n\n\\(\\bar{X}\\) is the sample mean,\n\n\\(\\mu_0\\) is the value of the population mean under the null hypothesis,\n\n\\(s\\) is the sample standard deviation,\n\n\\(n\\) is the sample size.\n\nUnder the null hypothesis \\(H_0\\), this test statistic follows a \\(t\\)-distribution with \\(n - 1\\) degrees of freedom.\nThis approach is particularly crucial when the sample size is small (\\(n &lt; 30\\)), and the population variance cannot be assumed to be known. The \\(t\\)-distribution is wider than the normal distribution, which reflects greater uncertainty in small samples. As \\(n\\) increases, the \\(t\\)-distribution approaches the standard normal distribution (see Chapter 21).\nSummary: Hypothesis Tests for a Population Mean\nWhen testing hypotheses about a population mean, the choice of test statistic depends on the sample size, whether the population standard deviation is known, and the shape of the population distribution. These different cases for a test of the population mean are shown in Table¬†22.1.\n\n\nTable¬†22.1: Summary of test statistics and distributions used for hypothesis testing of a population mean (\\(\\mu\\)), depending on sample size, knowledge of the population variance, and the assumption of normality. When the population standard deviation is unknown and the sample size is small, the \\(t\\)-distribution is used with \\(n - 1\\) degrees of freedom. Note that these are the distributions assumed given \\(H_0\\) true.\n\n\n\n\n\n\n\n\nConditions\nTest Statistic\nDistribution\n\n\n\n\n\\(n \\geq 30\\), \\(\\sigma^2\\) known\n\\(Z = \\dfrac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}\\)\nStandard Normal (\\(Z\\))\n\n\n\n\\(n \\geq 30\\), \\(\\sigma^2\\) unknown\n\\(Z = \\dfrac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\\)\nStandard Normal (\\(Z\\))\n\n\n\n\\(n &lt; 30\\), \\(\\sigma^2\\) known, normal population\n\\(Z = \\dfrac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}\\)\nStandard Normal (\\(Z\\))\n\n\n\n\\(n &lt; 30\\), \\(\\sigma^2\\) unknown, normal population\n\\(t = \\dfrac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\\)\n\n\\(t\\) with \\(n-1\\) df\n\n\n\n\n\n\nExample 22.1: Hypothesis Testing for a Mean\nWe are given a sample of \\(n = 16\\) observations from a normally distributed population with a known standard deviation \\(\\sigma = 16\\). The sample mean is \\(\\bar{x} = 743\\). We want to test at the 5% significance level whether the population mean differs from 750, i.e., whether \\(\\mu \\ne 750\\).\n\nStep 1: Hypotheses \\[\nH_0: \\mu = 750\n\\] \\[\nH_1: \\mu \\ne 750\n\\] This is a two-sided test.\nStep 2: Significance Level\nWe use a significance level of: \\[\n\\alpha = 0.05\n\\]\nStep 3: Test Statistic\nSince \\(\\sigma\\) is known and the population is normally distributed, we use the standard normal test statistic (see Table¬†22.1): \\[\nZ = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}} \\sim N(0,1)\n\\]\nStep 4: Decision Rule\nBecause this is a two-tailed test, the critical values are: \\[\nz_{\\alpha/2} = \\pm 1.96\n\\] We reject \\(H_0\\) if: \\[\n|z| &gt; 1.96\n\\]\nStep 5: Observation\nWe use the sample data to compute our observed value: \\[\nZ = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}} = \\frac{743 - 750}{16 / \\sqrt{16}} = \\frac{-7}{4} = -1.75\n\\]\nStep 6: Conclusion\nSince the observed test statistic is \\(z = -1.75\\) and: \\[\n|-1.75| &lt; 1.96\n\\] we fail to reject the null hypothesis. There is not enough evidence at the 5% level to conclude that the population mean differs from 750.\n\nThis test is visualized in Figure¬†22.4.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.4: The two-tailed test in Example 22.1 using the \\(Z\\)-distribution.\n\n\nExample 22.2: Hypothesis Test for a Mean\nWe are given a random sample of size \\(n = 15\\) drawn from a normally distributed population with unknown standard deviation. The sample has a mean \\(\\bar{x} = 24.1\\) and a sample standard deviation \\(s = 2\\). We want to test, at the 1% significance level, whether the population mean \\(\\mu\\) is less than 25.\n\nStep 1: Hypotheses\nWe are conducting a one-sided (left-tailed) test: \\[\nH_0: \\mu = 25\n\\] \\[\nH_1: \\mu &lt; 25\n\\]\nStep 2: Significance Level\nWe choose a significance level of \\(\\alpha = 0.01\\).\nStep 3: Test Statistic\nSince \\(\\sigma\\) is unknown and \\(n\\) is small, we use the \\(t\\)-distribution (see Table¬†22.1): \\[\nt = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}  \\sim t(n-1)\n\\]\nStep 4: Decision Rule\nWith \\(n - 1 = 14\\) degrees of freedom and \\(\\alpha = 0.01\\) (one-tailed), we find the critical value: \\[\nt_{14, 0.01} = -2.624\n\\] We reject \\(H_0\\) if \\(t_{\\text{obs}} &lt; -2.624\\).\nStep 5: Observation\nWe use the sample data to compute our observed value: \\[\nt = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}} = \\frac{24.1 - 25}{2 / \\sqrt{15}} \\approx -1.743\n\\]\nStep 5: Conclusion Since \\(t_{\\text{obs}} = -1.743\\) is greater than \\(-2.624\\) (in the non-rejection region), we do not reject the null hypothesis. We fail to reject \\(H_0\\). The sample does not provide sufficient evidence at the 1% significance level to conclude that the population mean is less than 25. See Figure¬†22.5 for an illustration of this one-tailed test.\n\n\nNote: Because the test statistic does not fall in the rejection region, the observed sample mean can be explained by random sampling variation if the true mean were 25.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.5: The one-tailed test in Example 22.2 using the \\(t\\)-distribution.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#hypothesis-testing-for-a-population-mean-with-unknown-variance",
    "href": "inferential/hyp-test.html#hypothesis-testing-for-a-population-mean-with-unknown-variance",
    "title": "\n22¬† Hypothesis Testing\n",
    "section": "\n22.4 Hypothesis Testing for a Population Mean with Unknown Variance",
    "text": "22.4 Hypothesis Testing for a Population Mean with Unknown Variance\nUp until now, we have assumed that the population is normally distributed and that the population variance \\(\\sigma^2\\) is known. But what if the population variance is unknown or if the sample size is small?\nIn such cases, we no longer use the standard normal distribution (\\(Z\\)). Instead, we use the Student‚Äôs \\(t\\)-distribution, which accounts for the additional uncertainty introduced by estimating the population standard deviation from the sample.\nThe test statistic is then defined as:\n\\[\nt = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\n\\]\nwhere:\n\n\n\\(\\bar{X}\\) is the sample mean,\n\n\\(\\mu_0\\) is the value of the population mean under the null hypothesis,\n\n\\(s\\) is the sample standard deviation,\n\n\\(n\\) is the sample size.\n\nUnder the null hypothesis \\(H_0\\), this test statistic follows a \\(t\\)-distribution with \\(n - 1\\) degrees of freedom.\nThis approach is particularly crucial when the sample size is small (\\(n &lt; 30\\)), and the population variance cannot be assumed to be known. The \\(t\\)-distribution is wider than the normal distribution, which reflects greater uncertainty in small samples. As \\(n\\) increases, the \\(t\\)-distribution approaches the standard normal distribution.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#hypothesis-testing-for-a-population-proportion",
    "href": "inferential/hyp-test.html#hypothesis-testing-for-a-population-proportion",
    "title": "22¬† Hypothesis Testing",
    "section": "\n22.4 Hypothesis Testing for a Population Proportion",
    "text": "22.4 Hypothesis Testing for a Population Proportion\nIn this section, we test hypotheses about a population proportion \\(p\\) based on data from a single sample. The hypotheses can be formulated as:\n\n\n\\(H_0: p = p_0\\) (null hypothesis)\n\n\\(H_1\\): one of the following alternative hypotheses:\n\n\n\\(p \\neq p_0\\) (two-tailed)\n\n\\(p &gt; p_0\\) (right-tailed)\n\n\\(p &lt; p_0\\) (left-tailed)\n\n\n\nHere, \\(p\\) is the unknown population proportion, and \\(p_0\\) is a specified numerical value.\nWe ask: Is the observed sample proportion \\(\\hat{p}\\) far enough from \\(p_0\\) to justify rejecting the null hypothesis \\(H_0\\)? Or is the observed deviation consistent with sampling variation?\nIf the sample size is sufficiently large, we use the test statistic: \\[\nZ = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1 - p_0)}{n}}}\n\\] Under the null hypothesis \\(H_0\\), this statistic is approximately standard normal: \\[\nZ \\sim N(0, 1)\n\\] For a common significance level \\(\\alpha = 0.05\\), the decision rules are as follows:\n\n\n\n\n\n\n\nAlternative Hypothesis\nReject \\(H_0\\) if‚Ä¶\nCritical Value (\\(z_c\\))\n\n\n\n\\(p \\neq p_0\\)\n\\(|z_{obs}| &gt; z_c\\)\n\\(z_c = 1.96\\)\n\n\n\\(p &gt; p_0\\)\n\\(z_{obs} &gt; z_c\\)\n\\(z_c = 1.645\\)\n\n\n\\(p &lt; p_0\\)\n\\(z_{obs} &lt; -z_c\\)\n\\(z_c = -1.645\\)\n\n\n\n\nThe critical values change with the chosen significance level. For other \\(\\alpha\\), adjust \\(z_c\\) accordingly.\n\nExample 22.3: Hypothesis Test for a Population Proportion\nIn a random sample of \\(n = 1200\\) individuals, 625 report a particular opinion. Do the sample data support the claim that more than half of the population shares this opinion? We will test this at a significance level of \\(\\alpha = 0.05\\).\n\nStep 1: Hypotheses\nThis is a one-sided test:\nNull hypothesis: \\(H_0: p = 0.5\\)\nAlternative hypothesis: \\(H_1: p &gt; 0.5\\)\nStep 2: Significance Level We use \\(\\alpha = 0.05\\).\n\nStep 3: Test Statistic\nBecause the sample size is large, we use the normal approximation. The test statistic is: \\[\nZ = \\frac{\\hat{p} - p_0}{\\sqrt{ \\frac{p_0(1 - p_0)}{n} }}\n\\] where:\n\n\\(\\hat{p} = \\frac{625}{1200} = 0.521\\)\n\\(p_0 = 0.5\\)\n\\(n = 1200\\)\n\n\nStep 4: Decision Rule\nFor a one-sided test at the 5% level, we reject \\(H_0\\) if: \\[\nz_{\\text{obs}} &gt; 1.645\n\\]\nStep 5: Observation\nSubstitute the values into the formula for test statistic: \\[\nz_{\\text{obs}} = \\frac{0.521 - 0.5}{\\sqrt{ \\frac{0.5(1 - 0.5)}{1200} }} = \\frac{0.021}{0.0144} \\approx 1.45\n\\]\nStep 6: Conclusion\nSince \\(z_{\\text{obs}} = 1.45\\) is less than the critical value 1.645, we fail to reject the null hypothesis. This means that the sample does not provide sufficient evidence to support the claim that more than half of the population holds this opinion at the 5% level. The test is visualize in Figure¬†22.6.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.6: The one-tailed test for population proportion in Example 22.3.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#hypothesis-testing-with-p-values",
    "href": "inferential/hyp-test.html#hypothesis-testing-with-p-values",
    "title": "22¬† Hypothesis Testing",
    "section": "\n22.5 Hypothesis Testing with \\(p\\)-Values",
    "text": "22.5 Hypothesis Testing with \\(p\\)-Values\nIn hypothesis testing, once the test statistic has been calculated, the next step is to decide whether to reject the null hypothesis. This decision traditionally depends on whether the test statistic falls within the critical region defined by a chosen significance level (\\(\\alpha\\)). However, this binary decision does not reveal how unusual or extreme the observed result actually is under the assumption that the null hypothesis is true.\nTo provide a more nuanced view, we use what is known as the \\(p\\)-value. The \\(p\\)-value answers the question:\n\nIf the null hypothesis were true, what is the probability of obtaining a result at least as extreme as the one observed?\n\nIn this sense, the \\(p\\)-value is a measure of how compatible the observed data are with the null hypothesis. A small \\(p\\)-value indicates that such an extreme outcome would be unlikely if the null hypothesis were true, thereby providing evidence against it.\nThe smaller the \\(p\\)-value, the stronger the evidence against the null hypothesis in favor of the alternative. This value can also be thought of as a kind of post hoc significance threshold:\n\nThe \\(p\\)-value is the lowest significance level at which the null hypothesis would be rejected based on the observed data.\n\nInstead of comparing the test statistic to a critical value, statistical software typically reports the \\(p\\)-value directly. This allows researchers and readers to interpret the strength of the evidence themselves, depending on the context and the significance level they consider appropriate.\nIn practical terms, if a researcher has set a significance level of 0.05 before conducting the test, and the calculated \\(p\\)-value is below this threshold, the null hypothesis would be rejected. If the \\(p\\)-value is greater, the null hypothesis is not rejected. The \\(p\\)-value thus becomes a central element in statistical inference, guiding conclusions with more granularity than a simple yes-or-no decision.\nLet‚Äôs consider an example: suppose we are conducting a hypothesis test at the 5% level using the alternative hypothesis: \\[\nH_1: \\mu &gt; \\mu_0\n\\] and the sample results yield a \\(p\\)-value of 3%. We perform this test at a significance level of \\(\\alpha = 0.05\\), i.e., a 5% threshold for rejecting the null hypothesis.\nThe \\(p\\)-value here tells us that the probability (under the assumption that the null hypothesis is true) of obtaining a result at least as extreme as the one observed is 3%. Since this is less than 5%, we reject the null hypothesis.\nThis decision is based on comparing the \\(p\\)-value to the critical value threshold. The critical region begins at the so-called critical point, the value on the distribution where the area under the curve to the right equals \\(\\alpha = 0.05\\).\nBecause the \\(p\\)-value corresponds to an area of only 3% under the curve to the right of our observed test statistic, and 3% is less than 5%, the observed value lies beyond the critical point and thus falls in the rejection region. This interpretation means the result is statistically significant at the 5% level. This is visualized in Figure¬†22.7.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.7: The shaded red region represents the critical region corresponding to a significance level of \\(\\alpha\\) and critical value of z[c]. The blue point indicates the observed test statistic z[obs]. The purple shaded area indicates the \\(p\\)-value region. Since \\(p\\)-value \\(&lt;  \\alpha\\), the null hypothesis is rejected.\n\n\nFor this example, the \\(p\\)-value is given as \\[P (Z&gt;z_{obs}|H_0 \\text{ true} ) = 1‚àí\\Phi(z_{obs}) =0 .03\\] where \\(\\Phi\\) is the cumulative distribution function (CDF) of the standard normal distribution. Thus, the p-value is the probability (under the null hypothesis \\(H_0\\)) of obtaining a value of \\(Z\\) at least as extreme as the observed value \\(z_{obs}\\).\nSuppose we want to test whether a population mean is equal to a specific value. Our hypotheses are:\n\nNull hypothesis: \\(H_0: \\mu = \\mu_0\\)\n\nAlternative hypothesis: \\(H_1: \\mu \\neq \\mu_0\\)\n\n\nIn this case, we are interested in detecting whether the mean is either significantly larger or smaller than the hypothesized value, that is a two-tailed test. To determine how surprising our result is under the assumption that \\(H_0\\) is true, we can calculate the \\(p\\)-value. This is the probability of obtaining a \\(Z\\) value that is at least as extreme as the observed value, in either direction.\nThe formula for the \\(p\\)-value then becomes: \\[\np\\text{-value} = 2 \\left[1 - \\Phi\\left(|z_{\\text{obs}}|\\right)\\right]\n\\]\nwhere \\(\\Phi\\) is the cumulative distribution function (CDF) of the standard normal distribution, and \\(|z_{\\text{obs}}|\\) is the absolute value of our observed test statistic. This is shown in Figure¬†22.8.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.8: Visualization of a two-tailed \\(p\\)-value. The shaded purple regions in both tails represent the \\(p\\)-value, corresponding to the probability (under the null hypothesis) of observing a test statistic as extreme or more extreme than the observed value z[obs]. The dashed vertical lines indicate the observed test statistic in both directions. Since this is a two-sided test, both tails are included in the calculation of the \\(p\\)-value.\n\n\nExample 22.4: Hypothesis Testing Using the \\(p\\)-value\nWe have a random sample of \\(n = 70\\) observations from a population with unknown distribution and unknown variance. From the sample, we obtain:\n\nSample mean: \\(\\bar{x} = 14100\\)\n\nSample standard deviation: \\(s = 1900\\)\n\n\nWe want to test whether the population mean \\(\\mu\\) is greater than 13500, using the \\(p\\)-value method.\n\nHypotheses \\[\nH_0: \\mu = 13500 \\\\\nH_1: \\mu &gt; 13500\n\\]\nTest Statistic\nSince the population variance \\(\\sigma^2\\) is unknown but the sample is large, we use the standardized test statistic: \\[\nZ = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\n\\]\nObservation \\[\nz_{\\text{obs}} = \\frac{14100 - 13500}{1900 / \\sqrt{70}} = 2.64\n\\] Specifying a significance level or a formal decision rule isn‚Äôt necessary here, since the \\(p\\)-value alone provides sufficient information to determine whether the null hypothesis should be rejected. We therefore compute the \\(p\\)-value as the next step.\n\\(p\\)-value\nUnder the null hypothesis, \\(Z \\sim N(0, 1)\\). The \\(p\\)-value is the probability of obtaining a value as extreme or more extreme than the observed value when \\(H_0\\) is true (see Appendix A): \\[\n\\text{p-value} = P(Z &gt; 2.64) = 1 - \\Phi(2.64) = 1 - 0.9959 = 0.0041\n\\] See Figure¬†22.9 for an illustration of this \\(p\\)-value.\nConclusion As long as the significance level \\(\\alpha &gt; 0.0041\\), we reject the null hypothesis. Thus, we reject \\(H_0\\) at the 1% level of significance. In fact, we would reject it at any significance level above 0.41%, but not below. There is strong evidence in favor of \\(H_1\\); that the population mean is greater than 13500.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.9: An illustration of the test in Example 22.4, where the \\(p\\)-value is equal to 0.0041.\n\n\nExample 22.5: Two-Sided Hypothesis Test with \\(p\\)-value\nWe use the same setup as in Example 22.4, but this time we test against the two-sided alternative: \\[\nH_1: \\mu \\neq 13,\\!500\n\\] This means that both very high and very low values of the test statistic \\(Z\\) are considered evidence against the null hypothesis \\(H_0\\). We observe: \\[\nz_{\\text{obs}} = 2.64\n\\] The \\(p\\)-value is now calculated as:\n\\[\n\\begin{split}\np\\text{-value} & = P(Z &gt; z_{\\text{obs}} \\mid H_0) + P(Z &lt; -z_{\\text{obs}} \\mid H_0)\n\\\\ & = 2 \\cdot [1 - \\Phi(2.64)] = 2 \\cdot (1 - 0.9959) = 0.0082\n\\end{split}\n\\] We multiply by 2 because in a two-sided test, extreme outcomes in both directions (greater than or less than the hypothesized value) are considered equally inconsistent with the null hypothesis. Therefore, we calculate the probability of observing a test statistic at least as extreme as \\(|z_{\\text{obs}}|\\) in either tail of the distribution, as shown in Figure¬†22.10.\nSince the \\(p\\)-value is 0.0082, we would reject the null hypothesis at a 1% significance level. In fact, we would reject it at any significance level down to 0.82%, but not below that. This provides strong evidence in favor of the alternative hypothesis \\(H_1\\) over the null hypothesis \\(H_0\\).\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†22.10: Visualization of a two-tailed \\(p\\)-value in Example 22.5.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#hypothesis-testing-and-confidence-intervals",
    "href": "inferential/hyp-test.html#hypothesis-testing-and-confidence-intervals",
    "title": "22¬† Hypothesis Testing",
    "section": "\n22.6 Hypothesis Testing and Confidence Intervals",
    "text": "22.6 Hypothesis Testing and Confidence Intervals\nWhen we are testing a hypothesis such as \\[\nH_0 : \\mu = \\mu_0\n\\] against the two-sided alternative hypothesis \\[\nH_1 : \\mu \\ne \\mu_0,\n\\] we can use a confidence interval for the population mean $ instead of computing a test statistic directly. The key relationship is:\n\nThe null hypothesis \\(H_0\\) is rejected at significance level \\(\\alpha\\) if and only if the \\(100(1 - \\alpha)\\%\\) confidence interval for \\(\\mu\\) does not include the value \\(\\mu_0\\).\n\nInstead of calculating the value of a test statistic, we can construct a 95% confidence interval for \\(\\mu\\) and check whether the value \\(\\mu_0\\) lies within this interval or not (Significance level = 5%).\nSuppose we are given a 95% confidence interval for the population mean as \\(64.8 &lt; \\mu &lt; 67.3\\). We want to test the null hypothesis: \\[\nH_0: \\mu = 65 \\quad\n\\] against \\[\nH_1: \\mu \\ne 65\n\\] Since the hypothesized value 65 lies inside the confidence interval, we fail to reject the null hypothesis. In other words, the data do not provide sufficient evidence to suggest that the population mean differs from 65 at the 5% significance level.\nTo state this more generally:\n\nA 95% confidence interval contains all values of \\(\\mu\\) that would not be rejected in a two-sided test at the 5% significance level.\nA 99% confidence interval contains all values of \\(\\mu\\) that would not be rejected at the 1% level.\nA 99.9% confidence interval corresponds to a 0.1% significance level.\nand so on‚Ä¶\n\nThis shows how confidence intervals and hypothesis testing are closely related; they are essentially two sides of the same inferential coin.\n\n\n\n\n\n\nNote: when working with proportions\n\n\n\nWhile the above equivalence between hypothesis tests and confidence intervals holds well for means, it is not exact for proportions or differences in proportions. This is because confidence intervals for proportions use the sample proportion \\(\\hat{p}\\) in the standard error: \\[\n\\hat{p} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nand hypothesis tests for a proportion use the null proportion \\(P_0\\) in the test statistic: \\[\nZ = \\frac{\\hat{p} - p_0}{\\sqrt{ \\frac{p_0(1 - p_0)}{n} }}\n\\]\nThus, confidence intervals and hypothesis testing may give slightly different results in these cases, especially with small samples.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "inferential/hyp-test.html#when-working-with-proportions",
    "href": "inferential/hyp-test.html#when-working-with-proportions",
    "title": "22¬† Hypothesis Testing",
    "section": "\n22.7 When working with proportions",
    "text": "22.7 When working with proportions\nWhile this equivalence holds well for means, it is not exact for proportions or differences in proportions. This is because confidence intervals for proportions use the sample proportion \\(\\hat{p}\\) in the standard error: \\[\n\\hat{p} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nand hypothesis tests for a proportion use the null proportion \\(P_0\\) in the test statistic: \\[\nZ = \\frac{\\hat{p} - p_0}{\\sqrt{ \\frac{p_0(1 - p_0)}{n} }}\n\\]\nThus, confidence intervals and hypothesis testing may give slightly different results in these cases, especially with small samples.",
    "crumbs": [
      "Inferential Statistics",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  }
]