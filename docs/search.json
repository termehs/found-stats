[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Foundational Statistics",
    "section": "",
    "text": "Welcome\nThis book is work in progress.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "introduction/what-is-stats.html",
    "href": "introduction/what-is-stats.html",
    "title": "1¬† What is Statistics?",
    "section": "",
    "text": "1.1 Descriptive Statistics\nStatistics is all about making informed decisions in an uncertain world. Imagine you‚Äôre a detective piecing together clues (data) to solve a case (hypothesis testing). But instead of clear-cut evidence, you get noisy, incomplete, and sometimes misleading information.\nAt its core, statistics is the science of changing your mind under uncertainty‚Äî not because you‚Äôre indecisive, but because data has the power to prove you wrong! Making decisions without data is like guessing the weather based on your mood. Data helps us navigate randomness, update our beliefs, and make smarter choices based on evidence rather than gut feeling. You‚Äôre basically saying, we don‚Äôt know everything, but let‚Äôs make the best of what we‚Äôve got.\nUsing statistical terminology (in parenthesis) we can sunmmarize as following: Making decisions based on facts means having information about all the facts (parameters) . But most of the time we don‚Äôt have all the information, and what we know comes (sample) is often different than what we wish we knew (population). So we guess (estimate) under uncertainty.\nThe uncertainty comes from the fact that the world is messy, unpredictable, and full of unknowns. No data is perfect, randomness exist everywhere. Further to this, even if we collect tons of data, there‚Äôs always some level of error. Instead of making absolute claims, statistics helps us express how confident we are in our conclusions using quantified uncertainty. Just remember that there is no magic formula that turns uncertainty into certainty, we cannot escape it!\nStatistics has two main branches, descriptive statistics and inferential statistics, each tackling uncertainty differently.\nThis is like taking a selfie of your data. It summarizes and reports what‚Äôs there, showing us things like averages, spreads, and patterns. Think of it as data gossip ‚Äî who‚Äôs the biggest, smallest, most popular, or way off in the corner doing their own thing (yes, outliers, I‚Äôm looking at you!).\nFor example, a histogram or boxplot can reveal whether our data is skewed, normally distributed, or hiding some unexpected surprises. Without descriptive analysis, we risk making assumptions that could lead to misleading conclusions‚Äîkind of like blindly trusting a GPS without checking if the road exists!",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>What is Statistics?</span>"
    ]
  },
  {
    "objectID": "introduction/what-is-stats.html#inferential-statistics",
    "href": "introduction/what-is-stats.html#inferential-statistics",
    "title": "1¬† What is Statistics?",
    "section": "1.2 Inferential Statistics",
    "text": "1.2 Inferential Statistics\nInstead of just describing what we see, we here aim to gain insight or make predictions about the big picture based on a small sample. It‚Äôs like tasting one donut from the box and guessing if the whole batch is good üç©.\nConsider you have a hypothesis you wish to test (alternative hypothesis). Using data collected, you express the rules of the game through probabilities, distributions, and statistical models. This helps create a ‚Äútoy model‚Äù of the world based on your hypothesis. The null hypothesis is then the ‚Äúdefault world,‚Äù and your working hypothesis is literally everything else. You pretend you know how things work, and then check if reality agrees with you (hypothesis testing). Then you ask the big question: Does our data make the null hypothesis look completely ridiculous? If yes, we might just reject it and revise the null world accordingly.\nStatistics isn‚Äôt about finding the ultimate truth, but about making the best possible decisions with the information available. We estimate, test, and adjust‚Äîbecause in the end, being less wrong is the best we can do. In the words of the famous statistician George Box: ‚ÄúAll models are wrong, but some are useful‚Äù.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>What is Statistics?</span>"
    ]
  },
  {
    "objectID": "introduction/what-is-stats.html#statistical-analysis-the-process",
    "href": "introduction/what-is-stats.html#statistical-analysis-the-process",
    "title": "1¬† What is Statistics?",
    "section": "1.3 Statistical Analysis: The Process",
    "text": "1.3 Statistical Analysis: The Process\nThe diagram in Figure¬†1.1 represents the pipeline of statistical analysis, outlining the key steps in drawing insights from data:\n\nData Collection ‚Äì A sample is selected from the population to be used for the analysis and posed research questions.\nDescriptive Statistics ‚Äì The sample is analyzed to summarize patterns and trends.\nProbability Modeling ‚Äì Statistical methods establish connections between the sample and population.\nInference ‚Äì Findings from the sample are generalized to make conclusions about the population.\n\n\n\n\n\n\n\n\nFigure¬†1.1: The main branches of Statistics, together with associations between them.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>What is Statistics?</span>"
    ]
  },
  {
    "objectID": "introduction/intro-math.html",
    "href": "introduction/intro-math.html",
    "title": "2¬† The Unavoidable Math",
    "section": "",
    "text": "2.1 The Sum and The Product\nWhile some math concepts fall into the ‚Äúnice to know but not always necessary‚Äù category, others are inescapable. Whether you‚Äôre designing a survey, analyzing data, or just trying to make sense of numbers, a basic grasp of algebra, probability, and statistics is essential. Understanding fractions, percentages, and averages helps interpret results, while probability is crucial for assessing uncertainty and making predictions. Basic algebra sneaks in when solving equations or working with formulas, and statistical measures like mean, median, and standard deviation provide insight into data patterns. Even if math isn‚Äôt your favorite subject, these core concepts will save you from misinterpretations, bad decisions, and the embarrassment of wildly inaccurate estimates. So, let‚Äôs tackle the unavoidable math‚Äîquick, painless, and as useful as possible!\nWe write the sum of \\(n\\) numbers denoted \\(x_1,x_2,\\ldots,x_n\\) as \\[\\sum_{i=1}^n x_i = x_1 +x_2 + \\cdots + x_n \\] This is read as the sum of \\(x_i\\) where \\(i\\) goes from 1 to \\(n\\). The letter \\(i\\) is called the summation index and can be chosen to be any other letter.\nSimilarly, the product of \\(n\\) numbers denoted \\(x_1,x_2,\\ldots,x_n\\) is written as \\[\\prod_{i=1}^n x_i = x_1 \\times x_2 \\times  \\cdots \\times x_n \\].",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Unavoidable Math</span>"
    ]
  },
  {
    "objectID": "introduction/intro-math.html#the-sum-and-the-product",
    "href": "introduction/intro-math.html#the-sum-and-the-product",
    "title": "2¬† The Unavoidable Math",
    "section": "",
    "text": "2.1.1 Example\nAssume 5 values on \\(x\\) denoted \\(x_1,x_2,x_3,x_4,x_5\\). How can we write the sum of the squared difference of each of these values to their mean value \\(\\overline{x}\\)? \\[(x_1-\\overline{x})^2 + (x_2-\\overline{x})^2 + (x_3-\\overline{x})^2 + (x_4-\\overline{x})^2 + (x_1-\\overline{x})^5 \\]\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\\[\\sum_{i=1}^n (x_i-\\overline{x})^2\\]",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Unavoidable Math</span>"
    ]
  },
  {
    "objectID": "introduction/intro-math.html#combinatorics",
    "href": "introduction/intro-math.html#combinatorics",
    "title": "2¬† The Unavoidable Math",
    "section": "2.2 Combinatorics",
    "text": "2.2 Combinatorics\nThe next couple of mathematical concepts covered here are closely linked to the theory of probability which we will cover later in this book.\nCombinatorics studies different ways to count, arrange, and select objects. Essentially combinatorics helps answer questions like:\n\nIn how many ways can we arrange a set of items?\nIn how many ways can we select a group of objects?\n\nWhat are the possible ways to distribute objects into groups?\n\nThe following concepts help answer these questions.\n\n2.2.1 Counting Principles\nCombinatorics is built on two fundamental counting rules:\n\nMultiplication Principle: also known as The rule of product, is a basic counting principle. Assume that you have to perform \\(k\\) tasks in turn (one after the other). The first task can be performed in \\(n_1\\) different ways, the second in \\(n_2\\) different ways, etc. The number of possible ways to perform the \\(k\\) tasks in turn is given by \\[n_1 \\times n_2 \\times  \\cdots \\times n_k\\]\nAddition Principle: If we have mutually exclusive choices, the total number of ways they can happen is the sum of the ways each event can occur; \\(n_1 + n_2 \\cdots +  n_k\\).\n\n\nExamples\n\nIf a restaurant has 3 appetizers and 4 main courses, the total number of different meal combinations is:\n\\[3 \\times 4 = 12 \\]\nA person needs to travel from City A to City B and has the following options:\n\nBy Car: 3 different routes\n\nBy Train: 2 available train services\n\nBy Plane: 1 direct flight\nSince a person can only take one mode of transport, the number of ways to travel is: \\[3 + 2 + 1 = 6 \\]",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Unavoidable Math</span>"
    ]
  },
  {
    "objectID": "introduction/intro-math.html#permutations",
    "href": "introduction/intro-math.html#permutations",
    "title": "2¬† The Unavoidable Math",
    "section": "2.3 Permutations",
    "text": "2.3 Permutations\nPermutations refers to the mathematical calculation of the number of ways a particular set can be arranged, i.e.¬†order matters. An arrangement of \\(n\\) different objects in a specific order is called a permutation of the objects. The number of permutations that can be formed from \\(n\\) different objects is \\[n! = n\\cdot (n-1)\\cdot (n-2) \\cdots 2\\cdot 1 \\].\nIf we have \\(n\\) distinct objects and want to arrange \\(r\\) of them in a specific order, the number of ways to do so is given by the permutation formula:\n\\[ P(n,r) = \\frac{n!}{(n - r)!} \\]\nwhere:\n\n\\(n!\\) (n factorial) represents the total number of ways to arrange \\(n\\) items.\n\n\\((n - r)!\\) accounts for the unselected objects.\n\n\n\n\n\n\n\nNote\n\n\n\n\\[ 0!=1 \\]\n\n\n\nExample 2.1\nIn how many different ways can we permute the three objects \\(A\\), \\(B\\) and \\(C\\)? The asnwer is \\[3! = 3 \\cdot 2 \\cdot 1 = 6\\] namely: \\(ABC,\\  ACB, \\ BAC, \\ BCA,\\  CAB, \\ CBA\\)\n\n\n2.3.1 Combinations\nGenerally, a combination refers to a selection of objects where order does not matter. If we have \\(n\\) distinct objects and want to select \\(r\\) of them, the number of ways to do so is given by the combination formula:\n\\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n - r)!} \\]\nwhere:\n\n\\(n!\\) (read as n-factorial) represents the total number of ways to arrange \\(n\\) items.\n\n\\(r!\\) accounts for the fact that order does not matter.\n\n\\((n - r)!\\) accounts for the unselected objects.\n\n\nExample 2.2\nChoosing 3 students from a class of 10 for a group project means there are \\[ C(10,3) = \\frac{10!}{3!(10-3)!} = \\frac{10!}{3!7!} = \\frac{10 \\times 9 \\times 8}{3 \\times 2 \\times 1} = 120\\]\ndifferent combinations.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>The Unavoidable Math</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html",
    "href": "introduction/intro-surveys.html",
    "title": "3¬† Surveys: Key Concepts",
    "section": "",
    "text": "3.1 Census vs.¬†Sample Surveys\nSurveys are a fundamental method of gathering information in various fields, including business, social sciences, and policy making. They help us understand populations without needing to examine every individual within them.\nThe population refers to the complete set of elements (individuals, objects, or units) relevant to the study. The definition of a population can vary based on the research objective and can be finite (e.g., employees in a company) or infinite (e.g., potential customers in a market). A sample is a selected subset of the population. (inlcude figure)\nA census (or total survey) involves collecting data from every individual in a given population. This is common in national population counts but is often impractical for other types of research due to cost and time constraints. Instead, most studies rely on sample surveys which aim to generalize findings from the sample to the entire population with reasonable accuracy. The size of the sample (sample size) plays a crucial role in determining the reliability of the conclusions drawn.\nOne way to understand sampling is through the urn metaphor (Figure¬†3.1): Imagine an urn filled with different-colored balls representing different individuals in a population. Drawing balls at random with/without replacement simulates the process of selecting a sample from a population, emphasizing the role of randomness in reducing bias.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html#census-vs.-sample-surveys",
    "href": "introduction/intro-surveys.html#census-vs.-sample-surveys",
    "title": "3¬† Surveys: Key Concepts",
    "section": "",
    "text": "Figure¬†3.1: The urn metaphor.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html#characteristics-of-a-population",
    "href": "introduction/intro-surveys.html#characteristics-of-a-population",
    "title": "3¬† Surveys: Key Concepts",
    "section": "3.2 Characteristics of a Population",
    "text": "3.2 Characteristics of a Population\nEach individual in a population has measurable attributes, such as height, weight, income, or opinions. When measuring a particular characteristic, we can calculate various population metrics such as:\n\nMean (average), e.g., the average height of individuals in a population.\nProportion, e.g., the percentage of women in a population.\nTotal values, e.g., the total number of items owned by a group.\nCounts of specific attributes, e.g., the number of people with a particular qualification.\n\nThe main challenge in survey research is determining how accurately a sample represents the entire population. Statistical methods help estimate key characteristics of a population based on sample data.\nThese population characteristics are fixed parameters values which are usually unknown. Common parameters are the mean (\\(\\mu\\)) representing the true average of a characteristic in the population, or the proportion (\\(p\\)) representing the fraction of the population with a certain attribute.\nSince parameters cannot always be measured directly, they are estimated using sample statistics. For example, the sample mean (\\(\\bar{x}\\)) based on sampled observations \\(x_1,x_2,\\ldots, x_n\\) is used to estimate the population mean (\\(\\mu\\)). (include figure)\nTo distinguish between parameters and estimates, Greek letters are typically used for population parameters, while Latin letters are used for sample estimates. We will however avoid using already taken parameters, for example \\(\\pi\\) is not here used for population parameter as this already has a value assigned to it. In such cases we use the Latin letter to indicate the parameter and a ‚Äòhat‚Äô over the letter indicate the sample estimate (that is \\(\\hat{p}\\)).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html#types-of-surveys",
    "href": "introduction/intro-surveys.html#types-of-surveys",
    "title": "3¬† Surveys: Key Concepts",
    "section": "3.3 Types of Surveys",
    "text": "3.3 Types of Surveys\nThe method chosen for collecting data in a survey plays a crucial role in determining the accuracy and reliability of the results. Broadly, survey research can be classified into experimental and non-experimental approaches, each serving different research purposes.\n\n3.3.1 Experimental Surveys\nExperimental surveys are designed to explore causal relationships between variables.Here, researchers have control over certain conditions, manipulating one or more variables while keeping others constant to observe the effects. A key feature of experimental surveys is randomization, where participants are randomly assigned to different groups to eliminate bias. By ensuring that external factors do not influence the results, researchers can draw strong conclusions about cause and effect.\nOne common application of experimental surveys is in medical research, where clinical trials are conducted to test the effectiveness of a new drug. In such cases, patients might be randomly assigned to either a treatment group receiving the drug or a control group receiving a placebo. The outcomes are then compared to determine the drug‚Äôs efficacy. Similarly, in marketing, companies may experiment with different advertising strategies by exposing randomly selected groups to different promotional campaigns and then measuring their purchasing behavior.\nWhile experimental surveys provide strong evidence of causal relationships, they do have some limitations. They tend to be resource-intensive, requiring significant time and financial investment. Furthermore, ethical considerations may restrict certain types of experiments, especially in cases where withholding treatment or intervention from a control group could have serious consequences. Another challenge is that controlled settings may not fully capture real-world complexities, making it difficult to generalize findings beyond the experimental conditions.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/intro-surveys.html#non-experimental-surveys-observing-trends-and-patterns",
    "href": "introduction/intro-surveys.html#non-experimental-surveys-observing-trends-and-patterns",
    "title": "3¬† Surveys: Key Concepts",
    "section": "3.4 Non-Experimental Surveys: Observing Trends and Patterns",
    "text": "3.4 Non-Experimental Surveys: Observing Trends and Patterns\nUnlike experimental surveys, non-experimental surveys focus on observing and describing characteristics, trends, and relationships within a population without direct intervention. These surveys are widely used in fields such as social sciences, market research, and public policy analysis, where the goal is often to collect descriptive data rather than establish causality.\nOne of the most common types of non-experimental surveys is the cross-sectional survey, which captures data from a population at a single point in time. This method is frequently used in opinion polls, customer satisfaction studies, and demographic research. For example, a company might conduct a survey to understand consumer preferences for a new product just before its launch. Because cross-sectional surveys are quick and cost-effective, they are widely used.\nFor studies that require tracking changes over time, researchers may turn to longitudinal surveys, which collect data from the same subjects at multiple intervals. Longitudinal surveys are especially useful for understanding long-term trends, such as how consumer behavior evolves over the years or how health outcomes change in response to lifestyle choices. In a panel study, the same individuals are followed over time, whereas in a cohort study, a specific group‚Äîsuch as people born in a particular year‚Äîis tracked to observe changes as they age. These methods are valuable in policy research, where understanding the long-term effects of interventions, such as educational reforms or public health initiatives, is critical.\nSome non-experimental surveys rely on observational data, where researchers study behaviors and interactions without directly questioning participants. Observational studies often aim to identify associations and generate hypotheses for further research. This method is commonly used in consumer behavior research. For example, a supermarket might analyze shopping patterns by tracking how customers navigate store aisles without them being aware of the observation. Another example is web tracking which is a modern form of observational research where companies monitor users‚Äô online activities to analyze behavior, predict preferences, and personalize experiences. Unlike traditional observational studies, which are typically conducted with ethical oversight and clear participant consent, the presented examples often operates in the background without users‚Äô full awareness or control. Thus, while observational studies provide authentic behavioral insights, they raise ethical concerns about privacy and cannot establish direct cause-and-effect relationships.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Surveys: Key Concepts</span>"
    ]
  },
  {
    "objectID": "introduction/variable-class.html",
    "href": "introduction/variable-class.html",
    "title": "4¬† Variable Classification",
    "section": "",
    "text": "4.1 Types of Variables\nA variable is a property that can vary between different units in a population. Understanding the classification of variables is fundamental to selecting appropriate statistical methods and interpreting results accurately. The nature of a variable will for example determine:\nTo facilitate analysis, we focus on measurable variables, which are broadly categorized into quantitative and qualitative types. There are further sub-classes for each of these main classes, as shown in Figure¬†4.1 and exemplified further in the following.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Variable Classification</span>"
    ]
  },
  {
    "objectID": "introduction/variable-class.html#types-of-variables",
    "href": "introduction/variable-class.html#types-of-variables",
    "title": "4¬† Variable Classification",
    "section": "",
    "text": "graph TD;\n    A(Variable) --&gt; B(Qualitative);\n    A(Variable) --&gt; C(Quantitative);\n    C --&gt; D(Discrete);\n    C --&gt; E(Continuous);\n\n\n\n\n\n\n\n\nFigure¬†4.1: Variable classification.\n\n\n\n\n4.1.1 Quantitative (Numerical)\nThese variables are represented by numbers and can be measured. Depending on the type of numbers a variable takes, it can be classified as discrete or continuous.\nDiscrete variables take specific, distinct values and cannot be subdivided (natural, integer, or rational numbers). Think of these as variables holding countable values. Examples include number of children in a family, number of goals ina football match, and number of sales transactions per day.\nContinuous variables can take any value within a given range of values within an interval and can be infinitely divided (real numbers). Examples include hegiht, weight, stock price and distance.\n\n\n4.1.2 Qualitative (Categorical) Variables\nThese variables represent data that can be divided into distinct groups or categories. These values do not have a natural numerical order (except for ordinal variables) and must be coded into numerical values for statistical analysis. Examples include political affiliation, blood type, movie genre and social media platform.\nA special case of qualitative variables that take only two possible values, so called dichotomous or binary variable. Examples include smoking status (Smoker/Non-smoker) and COVID-19 test result (positive/negative).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Variable Classification</span>"
    ]
  },
  {
    "objectID": "introduction/variable-class.html#levels-of-measurement",
    "href": "introduction/variable-class.html#levels-of-measurement",
    "title": "4¬† Variable Classification",
    "section": "4.2 Levels of Measurement",
    "text": "4.2 Levels of Measurement\nThe characteristics of collected data allow us to classify them into four different measurement levels. These levels determine the statistical operations that can be performed. Table¬†4.1 summarizes the different measurement levels described in the following.\nNominal scale categorizes data without any inherent order. For example, there is no inherent ordering in the variable eye color (blue, brown, green), gender or nationality. You can only distinguish between the values nominal variables take.\nOrdinal scale is when data can be ranked in a meaningful order, but differences between values are not necessarily equal or meaningful, for example when looking at the variable fruit preference ranking or customer satisfaction levels (low, medium, high). In other words, interval lengths between one variable value and another are not of the same length.\nInterval scale is similar to the ordinal scale but with equal intervals between values. However, it lacks a true zero point. Examples include Temperature in Celsius and calendar years (the year 2000 is 100 years after 1900, but the year 0 does not represent the ‚Äúbeginning of time‚Äù).\nFinally, ratio scale has all of the above properties but also a natural zero point, allowing meaningful calculations of differences and ratios. Examples here include salary, distance traveled, height, and weight.\n\n\n\nTable¬†4.1: Summary of measurement levels.\n\n\n\nSummary of measurement levels.\n\n\n\n\n\n\n\n\n\n\n\nDistinguish\nRank\nEqual Step Length\nAbsolute Zero Point\nExample\n\n\n\n\nNominal\nYes\nNo\nNo\nNo\ngender, city, religion\n\n\nOrdinal\nYes\nYes\nNo\nNo\ngrades, preference, customer satisfaction ratings\n\n\nInterval\nYes\nYes\nYes\nNo\ntemperature in Celsius. credit scores, calender years\n\n\nRatio\nYes\nYes\nYes\nYes\nlength, weight, time, salary",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Variable Classification</span>"
    ]
  },
  {
    "objectID": "introduction/variable-class.html#types-of-numbers",
    "href": "introduction/variable-class.html#types-of-numbers",
    "title": "4¬† Variable Classification",
    "section": "4.3 Types of Numbers",
    "text": "4.3 Types of Numbers\nUnderstanding the nature of numbers is crucial when classifying variables because it directly influences statistical analysis, measurement accuracy, and the interpretation of data. The classification of numbers into natural, whole, integer, rational, irrational, and real numbers helps in determining which mathematical operations and statistical techniques are valid for a given data set:\n\nNatural Numbers: \\(0, 1, 2, 3, \\ldots\\)\nIntegers: \\(\\dots , -3, -2, -1, 0, 1, 2, 3, \\ldots\\)\nRational Numbers: Numbers that can be expressed as a fraction \\(\\frac{a}{b}\\) , where \\(a\\) and \\(b\\) are integers. Examples include:\n\n\\(-14 = \\frac{-14}{1}\\)\n\\(\\frac{3}{4} = 0.75\\)\n\\(\\frac{2}{7} = 0.285714285714 \\dots\\)\n\nReal Numbers: Non-repeating decimal numbers, such as:\n\n\\(\\pi = 3.14159265358979 \\dots\\)\n\n\nFor example you cannot calculate an average zip code (nominal) or say that ‚Äúa temperature of 20¬∞C is twice as hot as 10¬∞C‚Äù (interval), but you can say ‚Äúa person earning ‚Ç¨50,000 earns twice as much as someone earning ‚Ç¨25,000‚Äù (ratio). An another example, you cannot consider the mean of a categorical variable like ‚Äúfavorite color,‚Äù but you can analyze the frequency distribution.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Variable Classification</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html",
    "href": "descriptive-stats/describe-data.html",
    "title": "5¬† Describing a Dataset",
    "section": "",
    "text": "5.1 Describing Qualitative Variables\nDescriptive statistics is the foundation of data analysis, helping us summarize, visualize, and interpret data before diving into deeper statistical methods. This section explores how to describe datasets using tables, charts, and frequency distributions for both qualitative and quantitative variables.\nBefore analyzing data, it‚Äôs essential to understand its nature. The choice of tables, charts, or summary statistics depends on:\nQualitative (categorical) variables represent data grouped into distinct categories, such as gender, marital status, or election participation. These variables are best summarized using frequency tables and graphs such as bar charts and pie charts.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html#describing-qualitative-variables",
    "href": "descriptive-stats/describe-data.html#describing-qualitative-variables",
    "title": "5¬† Describing a Dataset",
    "section": "",
    "text": "5.1.1 Frequency Tables for Qualitative Data\nA frequency table lists the categories of a variable along with their corresponding counts (absolute frequency) and percentages (relative frequency). Assume we surveyed 300 people about their favorite hot beverage and found that 60% prefer coffee and 40% prefer tea. This preference distribution, also presented in the table below, will be used as a running example in the following.\n\n\n\nPreference\nCount (\\(f_i\\))\nPercentage (\\(f_i\\) in %)\n\n\n\n\nTea\n120\n40%\n\n\nCoffee\n180\n60%\n\n\nTotal\n300\n100%\n\n\n\nThe relative frequency is calculated as:\n\\[\\frac{120}{300} \\times 100 = 40\\%\\]\nand shown in the third column.\n\n\n5.1.2 Pie Chart\nPie charts are one of the most commonly used tools for representing categorical data in a simple, visual format. They break down a whole into proportional slices, making it easy to see relative differences between categories at a glance. Whether you‚Äôre comparing sales across different product categories, analyzing survey responses, or breaking down a budget, a well-made pie chart provides an intuitive way to present proportions.\nEach slice represents a category‚Äôs percentage of the total, with the entire pie equaling 100%. The size of each slice is determined by the proportion of the category it represents. For example, if 60% of survey respondents prefer coffee over tea, that category would take up 60% of the pie chart, or 60% of 360¬∞, that is \\(0.60 √ó 360¬∞ = 216¬∞\\) of the full circle. Pie charts are particularly effective when comparing a few distinct categories but lose clarity when too many slices are included.\n\n\n\n\n\n\n\n\n\nWhile a standard pie chart is a great way to visualize data, 3D pie charts are the dark side of data visualization. They may look fancy, but they distort proportions, making it difficult to accurately compare slice sizes. Due to the perspective effect, some slices appear larger or smaller than they actually are, leading to misleading interpretations. In short: if you want your data to be clear and not just flashy, stick to 2D pies - your audience will thank you.\n\n\n5.1.3 Bar Chart\nBar charts are a great way to visualize qualitative data, making it easy to compare different categories. Each category is represented by a bar, with the height corresponding to its frequency or percentage. For example, a bar chart would clearly display the difference between coffee and tea lovers, making it easy to interpret at a glance. Unlike pie charts, bar charts work well even when multiple categories are involved, ensuring your audience can quickly grasp the data - without any risk of 3D chart-induced confusion!\n\n\n\n\n\n\n\n\n\n\n\n5.1.4 Contingency Tables\nWhen we have observations on two qualitative variables, we can create two separate frequency tables. However, if we want to study the relationship between the two variables, we use a contingency table.\nA contingency table organizes paired observations, showing the frequency distribution across the two categorical variables.\nFor example, consider the following data where individuals are classified into two groups based on their marital status (Married (M) or Not Married (NM)) and their voting behavior (Voted (1) or Did Not Vote (0)). This results in four possible outcome combinations:\n\n(M, 0) - Married, Did Not Vote\n(M, 1) - Married, Voted\n(NM, 0) - Not Married, Did Not Vote\n(NM, 1) - Not Married, Voted\n\nAssume the first four observations are: (G, 0), (EG, 1), (G, 1), (G, 1) Which we create the following table over:\n\n\n\n\n0 (Did Not Vote)\n1 (Voted)\n\n\n\n\nM (Married)\n‚úîÔ∏è\n‚úîÔ∏è‚úîÔ∏è\n\n\nNM (Not Married)\n\n‚úîÔ∏è\n\n\n\nOnce all observations have been recorded, we can create the following contingency table:\n\n\n\n\nDid Not Vote\nVoted\nTotal\n\n\n\n\nMarried\n54\n1496\n1550\n\n\nNot Married\n85\n628\n713\n\n\nTotal\n139\n2124\n2263\n\n\n\nThis table displays the distribution of voting behavior by marital status, where we can analyze differences between the groups.\n\nMarginal Distributions\nA marginal distribution summarizes the totals for each row and column in a contingency table. This helps us understand the overall distribution of each variable separately.\nFor example, the absolute and relative marginal distributions for marital status is shown below:\n\n\n\nMarital Status\nCount\nPercentage (%)\n\n\n\n\nMarried\n1550\n68.5%\n\n\nNot Married\n713\n31.5%\n\n\nTotal\n2263\n100%\n\n\n\nSimilarly, the absolute and relative marginal distributions for voting behvaior is shown below:\n\n\n\nVoting Behavior\nCount\nPercentage (%)\n\n\n\n\nDid Not Vote\n139\n6.1%\n\n\nVoted\n2124\n93.9%\n\n\nTotal\n2263\n100%\n\n\n\nThese tables summarize how many people are in each category without considering the second variable.\n\n\nConditional Distributions\nTo compare voting behavior between married and non-married individuals, we calculate row percentages.\n\n\n\n\nDid Not Vote (%)\nVoted (%)\nTotal (%)\n\n\n\n\nMarried\n3.5%\n96.5%\n100%\n\n\nNot Married\n11.9%\n88.1%\n100%\n\n\n\nThis table shows the conditional distribution of voting behavior, given marital status.\n\nAmong married individuals, 1496 √ó 100 = 0.965= 96.5% voted while 54 √ó 100 = 0.035 =3.5% did not.\nAmong non-married individuals, 88.1% voted, while 11.9% did not.\n\nBy comparing these row percentages, we can see that married individuals were more likely to vote compared to non-married individuals. We have calculated the percentages horizontally but compare the percentage values in the vertical columns. We can also compute column percentages instead of row percentages if needed.\nTo determine whether a relationship exists between voting behavior and marital status, we compare conditional distributions. Since the voting percentages differ between married and non-married groups, we conclude that marital status influences voting behavior. If the two variables were independent, the percentages in the columns would be nearly the same. The fact that they differ suggests an association between the two variables.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html#describing-quantitative-variables",
    "href": "descriptive-stats/describe-data.html#describing-quantitative-variables",
    "title": "5¬† Describing a Dataset",
    "section": "5.2 Describing Quantitative Variables",
    "text": "5.2 Describing Quantitative Variables\nUnlike qualitative data, which can be subjective and harder to categorize, quantitative data enables direct comparisons, making it easier to identify patterns, test hypotheses, and make data-driven decisions.\nQuantitative variables are numeric and can be either discrete (specific values, such as test scores) or continuous (measured on a scale, such as weight). These variables are best summarized using frequency tables, histograms, and cumulative distributions.\n\n5.2.1 Frequency and Cumulative Frequency Tables\n\nExample 5.1: Mathematics Grade\nWe begin by examining a discrete variable with a small number of observations. Assume the mathematics grades (ranging from 1-5) of 25 students are:\n5 4 1 4 4 3 2 3 3 3 4 2 3 1 3 3 5 4 2 2 2 4 3 5 3\nWhen data is presented in this way, it is referred to as ungrouped data. Let:\n\n\\(x_i\\) = observed values, where \\(i = 1, \\ldots , n\\)\n\\(f_i\\) = frequency of the \\(i\\)-th variable value, where \\(i = 1, 2, \\ldots, k\\).\n\nFor our example here, \\(n = 25\\) (total observations) and \\(k = 5\\) (five distinct values of the variable ‚ÄúMathematics Grades‚Äù).\nLet‚Äôs summarize this data by counting how many we have in each grade category:\n\n\n\nGrade (\\(x_i\\))\nCount\nFrequency (\\(f_i\\))\n\n\n\n\n1\n‚úîÔ∏è‚úîÔ∏è\n2\n\n\n2\n‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è\n5\n\n\n3\n‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úî\n9\n\n\n4\n‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è\n6\n\n\n5\n‚úîÔ∏è‚úîÔ∏è‚úîÔ∏è\n3\n\n\nTotal\n\n25\n\n\n\nThe sum of all frequencies equals the total number of observations: \\(\\sum_{i=1}^{k} f_i = n\\).\nWe have created a frequency table by grouping the data into categories which can be visualized using a bar chart:\n\n\n\n\n\n\n\n\n\nThe cumulative frequency tells us how many observations are less than or equal to a given value.\n\n\n\n\n\n\n\n\nScore (\\(x_i\\))\nAbsolute Frequency (\\(f_i\\))\nCumulative Frequency (\\(F_i\\))\n\n\n\n\n1\n2\n2\n\n\n2\n5\n7\n\n\n3\n9\n16\n\n\n4\n6\n22\n\n\n5\n3\n25\n\n\n\nCumulative frequencies are often displayed using a cumulative step graph:",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html#histograms",
    "href": "descriptive-stats/describe-data.html#histograms",
    "title": "5¬† Describing a Dataset",
    "section": "5.3 Histograms",
    "text": "5.3 Histograms\nWhen dealing with a continuous variable or a discrete variable with many values, it is common to create class intervals and then display frequencies in a frequency table or graph.\n\nExample 5.2: Candy Bar Weights\n\n\n\n\n\nWe have observed 40 candy bars of a specific brand and recorded their weighs which are given in the following in ascending order:\n20.5 20.7 20.8 21.0 21.0 21.4 21.5 22.0 22.1 22.5\n22.6 22.6 22.7 22.7 22.9 22.9 23.1 23.3 23.4 23.5\n23.6 23.6 23.6 23.9 24.1 24.3 24.5 24.5 24.8 24.8\n24.9 24.9 25.1 25.1 25.2 25.6 25.8 25.9 26.1 26.7\nSince weight is a continuous variable, we must group the observations into classes. We choose five class intervals, each with a width of 1.3 grams, starting from 20.4 grams:\n\nClass 1: 20.4 - 21.6\nClass 2: 21.7 - 22.9\nClass 3: 23.0 - 24.2\nClass 4: 24.3 - 25.5\nClass 5: 25.6 - 26.9\n\nWe can then create a frequency table as before:\n\n\n\nWeight Range (grams)\nFrequency (\\(f_i\\))\n\n\n\n\n20.4 - 21.6\n7\n\n\n21.7 - 22.9\n9\n\n\n23.0 - 24.2\n9\n\n\n24.3 - 25.5\n10\n\n\n25.6 - 26.9\n5\n\n\nTotal\n40\n\n\n\nWe then can visualize the frequency distribution using a histogram:\n\n\n\n\n\n\n\n\n\nGenerally, A histogram represents continuous data by grouping values into intervals, with bar heights corresponding to frequencies.\nTo determine how many observations fall below a given value, we calculate the cumulative frequencies as before and visualize using a step chart.\n\n\n\n\n\n\n\n\n\n\nWeight Range (grams)\nAbsolute Frequency (fi)\nCumulative Frequency (Fi)\nRelative Frequency (%)\nCumulative Relative Frequency (%)\n\n\n\n\n20.4 - 21.6\n7\n7\n17.5\n17.5\n\n\n21.7 - 22.9\n9\n16\n22.5\n40.0\n\n\n23.0 - 24.2\n9\n25\n22.5\n62.5\n\n\n24.3 - 25.5\n10\n35\n25.0\n87.5\n\n\n25.6 - 26.9\n5\n40\n12.5\n100\n\n\nTotal\n40\n40\n100%\n100%",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/describe-data.html#stem-and-leaf-plot",
    "href": "descriptive-stats/describe-data.html#stem-and-leaf-plot",
    "title": "5¬† Describing a Dataset",
    "section": "5.4 Stem-and-Leaf Plot",
    "text": "5.4 Stem-and-Leaf Plot\nA Stem-and-leaf plot is a compact way to display numerical data while preserving individual values. It organizes data into stems (representing the leading digits) and leaves (the following digits), providing a good display of the distribution.\nFor example, in the dataset of candy bar weights, a stem-and-leaf plot can show whether weights cluster around a certain value and help identify any inconsistencies. This is shown in the follwing.\nWe split each value from our candy bar weight dataset into - Stem (e.g., 20, 21, 22, etc.) - Leaf (the decimal part, such as .1, .2, .3, etc.)\nThe Stem-and-Leaf Table is then given as:\n\n\n\nStem\nLeaf\n\n\n\n\n20\n5 7 8\n\n\n21\n0 0 4 5\n\n\n22\n0 1 5 6 6 7 7 9 9\n\n\n23\n1 3 4 5 6 6 6 9\n\n\n24\n1 3 5 5 8 8 9 9\n\n\n25\n1 1 2 6 8 9\n\n\n26\n1 7\n\n\n\nIf you tilt your head to the right or rotate the table 90¬∞ you get a fairly good view on the distribution of the data. The distribution appears fairly symmetric, with a slight skew toward the higher weights. Overall, the data is well distributed across the entire range, but there is a higher density of observations between 22.0 g and 24.9 g, indicating that the most frequent range appears to be 22 to 24 grams, with many values concentrated in these stems. The least frequent weights occur at the lower (20-21 g) and higher (25-26 g) ends. In a quality control one might check this distribution and note whether a large amount of candy bars end up in the tails of the distribution, thus indicating inconsistent production of candy bars.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Describing a Dataset</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html",
    "href": "descriptive-stats/central-measures.html",
    "title": "6¬† Measures of Central Tendency",
    "section": "",
    "text": "Example 6.1: Income\nMeasures of central tendency are numerical indicators that describe a ‚Äútypical‚Äù observation within a data set. These measures help summarize data and provide insight into the distribution. The three most commonly used central measures are:\nWe will use the follwing running example in this chapter.\nWe have income data (in thousands of ‚Ç¨) for 18 individuals:\nWe will in the following show how we compute each of the shown measure of central tendency in the follwing.\nWe will see that for this example, the median income is the most representative value, as it is less affected by high-income extreme values.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html#arithmetic-mean",
    "href": "descriptive-stats/central-measures.html#arithmetic-mean",
    "title": "6¬† Measures of Central Tendency",
    "section": "6.1 Arithmetic Mean",
    "text": "6.1 Arithmetic Mean\nThe mean is calculated by summing all values and dividing by the number of observations. It is often used as a measure of central tendency because it incorporates all data points, making it a valuable summary statistic. However, the mean is sensitive to outliers, meaning that extreme values can pull it higher or lower, potentially misrepresenting the typical value in a skewed distribution. Despite this, in normally distributed data, the mean is a reliable and widely used indicator of the data set‚Äôs center.\nThe mean is calculated differently depending on whether we are working with an entire population or a sample: For a population, the mean (\\(\\mu\\), just a fancy Greek way of saying ‚Äúthe mean of \\(X\\)‚Äù) is given by: \\[\n\\mu = \\frac{\\sum_{i=1}^{N} x_i}{N}\n\\]\nwhere \\(N\\) is the population size. For a sample, the mean (\\(\\bar{x}\\)) is an estimate of \\(\\mu\\) and is calculated as: \\[\n\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n\\] where \\(n\\) is the sample size.\n\nExample 6.1: Income\nThe mean income is: \\[\\bar{x} = \\frac{20 + 22 + 24 + 24 + \\cdots + 85 + 90}{18} = 44.7 \\] Thus, the mean income is 44 700 ‚Ç¨.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html#median",
    "href": "descriptive-stats/central-measures.html#median",
    "title": "6¬† Measures of Central Tendency",
    "section": "6.2 Median",
    "text": "6.2 Median\nThe median is the middle value of a dataset when arranged in ascending order. It represents the point where half of the observations are below and half are above, making it a useful measure of central tendency for skewed distributions. Unlike the mean, the median is not affected by outliers, making it a more robust indicator of typical values in cases where extreme values exist. For example, in income data, the median often provides a better reflection of the typical salary than the mean, which can be skewed by very high incomes. If there is an even number of observations, the median is the average of the two middle values. The median position is found using: \\[\n\\frac{n + 1}{2}\n\\]\n\nExample 6.1: Income\nFor our sorted income data we get that the median is located at the position \\[\n\\frac{19}{2} = 9.5\n\\] The median is then the average of the 9th and 10th values (40 and 44):** \\[\n\\frac{40 + 44}{2} =42\n\\] Thus, the median income is 42 000 ‚Ç¨.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html#mode",
    "href": "descriptive-stats/central-measures.html#mode",
    "title": "6¬† Measures of Central Tendency",
    "section": "6.3 Mode",
    "text": "6.3 Mode\nThe mode is the most frequently occurring value in a data set. A data set can have one mode (unimodal), multiple modes (multimodal), or no mode at all if all values are unique. The mode is particularly useful for categorical data, such as identifying the most popular product in a sales dataset or the most common salary range in a workforce. In a histogram, the mode corresponds to the peak of the distribution, highlighting where data points concentrate the most.\n\nExample 6.1: Income\nThe most frequently occurring values in the income example is 24.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/central-measures.html#which-measure-should-you-choose",
    "href": "descriptive-stats/central-measures.html#which-measure-should-you-choose",
    "title": "6¬† Measures of Central Tendency",
    "section": "6.4 Which Measure Should You Choose?",
    "text": "6.4 Which Measure Should You Choose?\nThe appropriate measure of central tendency depends on the data type:\n\n\n\nData Type\nSuitable Measure(s)\n\n\n\n\nNominal Data (categories)\nMode\n\n\nOrdinal Data (ranked categories)\nMode, Median\n\n\nInterval Data (e.g., temperature)\nMode, Median, Mean\n\n\nRatio Data (e.g., income, weight)\nMode, Median, Mean\n\n\n\nWhen deciding between the mean and median, the mean is preferred for normally distributed data without outliers, while the median is better suited for skewed distributions or data sets with extreme values since it is not influenced by outliers. The mode, while useful for categorical and multimodal data, may not always provide meaningful insights in numerical data sets.\nIn our example, the median income (42 thousand euros) is a better representation of a ‚Äútypical‚Äù income than the mean (44.7 thousand euros) due to high-income values skewing the mean upward.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Measures of Central Tendency</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html",
    "href": "descriptive-stats/dispersion-measures.html",
    "title": "7¬† Measures of Dispersion",
    "section": "",
    "text": "Example: Test Scores\nWhile measures of central tendency, such as the mean or median, provide valuable insight into the typical value in a data set, they often do not tell the whole story. Two data sets can have the same mean but exhibit vastly different distributions. This is where measures of dispersion become crucial, as they describe the spread or variability in a data set.\nMeasures of dispersion quantify how much the observations in a data set differ from each other. They help answer questions such as:\nDispersion measures require numerical data and are essential for understanding the reliability and consistency of a data set.\nConsider two sets of scores from two different groups of students. Each data set contains eight observations, representing the scores students received on a test:\nData A\nData B\nBoth data sets have the same mean: \\[\\bar{x}_A = \\frac{4 + 4 + 5 + 5 + 5 + 6 + 6 + 7}{8} = 5.25\\] \\[\\bar{x}_B = \\frac{0+1+4+5+6+7+8+11}{8} = 5.25\\]\nHowever, data set B has a much wider spread of values, ranging from 0 to 11, while data set A is more compact, with values between 4 and 7. The greater spread in data set B suggests higher variability in scores, meaning individual performances were less consistent compared to data set A. In contrast, data set A shows more uniform performance, suggesting students‚Äô scores were relatively close to each other. The two data set distributions are visualized below:\nSeveral statistical measures help quantify dispersion in a dataset, some of which are covered in the following.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#quartiles-and-percentiles",
    "href": "descriptive-stats/dispersion-measures.html#quartiles-and-percentiles",
    "title": "7¬† Measures of Dispersion",
    "section": "7.1 Quartiles and Percentiles",
    "text": "7.1 Quartiles and Percentiles\nQuartiles and percentiles divide data into sections, helping us understand the distribution more effectively. The most commonly used quartiles are the first quartile (Q1), median (Q2), and third quartile (Q3).\n\nFirst Quartile (Q1) - 25th Percentile\nThe first quartile (Q1) marks the value below which 25% of the observations fall. It helps us understand the lower range of the dataset and is computed as: \\[\nQ1 = \\text{value at position } 0.25(n+1)\n\\] where \\(n\\) is the total number of observations.\n\n\nSecond Quartile (Q2) ‚Äì 50th Percentile (Median)\nThe second quartile (Q2) is simply the median, dividing the dataset into two equal halves. This is calculated as: \\[\nQ2 = \\text{value at position } 0.50(n+1)\n\\] Since 50% of values are below this point, the median represents the central value in the distribution.\n\n\nThird Quartile (Q3) - 75th Percentile\nThe third quartile (Q3) is the value below which 75% of the observations fall. This is particularly useful for understanding the upper range of the dataset and is calculated as: \\[\nQ3 = \\text{value at position } 0.75(n+1)\n\\]\nQuartiles provide valuable information about how data is spread across different sections. They allow us to:\n\nIdentify skewness: If Q1 and Q3 are unevenly spaced around Q2 (the median), the data may be skewed.\nDetect outliers: Any value that is significantly lower than Q1 or higher than Q3 can be considered an outlier.\nCalculate the Interquartile Range (\\(IQR\\)), which is the difference between Q3 and Q1, providing a robust measure of spread that is less sensitive to extreme values (not to be confused with range which is the difference between minimum and maximum observation values \\(x_{max}-x_{min}\\)).\nCalculate the Quartile Deviation which is another measure that is robust against extreme values and defined as half the difference between the third quartile (Q3) and the first quartile (Q1): \\[\\frac{Q3-Q1}{2} .\\]",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#five-number-summary-and-boxplot",
    "href": "descriptive-stats/dispersion-measures.html#five-number-summary-and-boxplot",
    "title": "7¬† Measures of Dispersion",
    "section": "7.2 Five-Number Summary and Boxplot",
    "text": "7.2 Five-Number Summary and Boxplot\nA Five-Number Summary is a set of five descriptive statistics that provide insights into the distribution of a data set. These include:\n\nMinimum ‚Äì The smallest observed value.\nFirst Quartile (Q1) ‚Äì The 25th percentile, below which 25% of the data falls.\nSecond Quartile (Median, Q2) ‚Äì The 50th percentile, the middle value of the data set.\nThird Quartile (Q3) ‚Äì The 75th percentile, below which 75% of the data falls.\nMaximum ‚Äì The largest observed value.\n\nThe Five-Number Summary helps in constructing a boxplot, which visually represents the spread and skewness of the data, as well as potential outliers. An example is shown in Figure¬†7.1.\nThe boxplot visually represents the distribution and spread of the data using the five-number summary. The minimum and maximum values mark the range of the data, while the first quartile (Q1), median (Q2), and third quartile (Q3) divide the data into four equal parts. The interquartile range (IQR), which spans from Q1 to Q3, highlights the middle 50% of the data, giving insights into variability.\nThe median (Q2) represents the central value, while outliers (if any) are shown as red points beyond the whiskers of the box. This boxplot effectively summarizes the data set, making it easy to identify skewness, dispersion, and potential outliers at a glance.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.1: Boxplot with labels for each component of the Five-Number Summary\n\n\n\n\nExample: Test Scores\nWe compute the Five-Number Summary for the two datasets, A and B, representing test scores.\nData A\n4 4 5 5 5 6 6 7\nData B\n0 1 4 5 6 7 8 11\n1 and 5: The range is the difference between the maximum and minimum values (thus allowig us to see the minimum and maximum as well):\n\nA: (7 - 4 = 3)\nB: (11 - 0 = 11)\n\n2: The first quartile is found at position:\n\\[\nQ1 = 0.25(n+1) = 0.25(9) = 2.25\n\\]\n\nA: \\(Q1 = 4 + 0.25(5-4) = 4.25\\)\nB: \\(Q1 = 1 + 0.25(4-1) = 1.75\\)\n\n3: The median is found at position:\n\\[\nQ2 = 0.50(n+1) = 0.50(9) = 4.5\n\\]\n\nA: \\(Q2 = 5\\)\nB: \\(Q2 = 5.5\\)\n\n4: The third quartile is found at position:\n\\[\nQ3 = 0.75(n+1) = 0.75(9) = 6.75\n\\]\n\nA: \\(Q3 = 6 + 0.75(6-6) = 6\\)\nB: \\(Q3 = 7 + 0.75(8-7) = 7.75\\)\n\nFinal Five-Number Summaries\n\n\n\nDataset\nMinimum\nQ1\nMedian (Q2)\nQ3\nMaximum\n\n\n\n\nA\n4\n4.25\n5\n6\n7\n\n\nB\n0\n1.75\n5.5\n7.75\n11\n\n\n\nTo better understand the distribution of the two datasets, we use a boxplot to visualize the Five-Number Summary.\n\n\n\n\n\n\n\n\n\nThe boxplot visually highlights key aspects of dispersion, skewness, and potential outliers. In our example:\n\nDataset A has a smaller range (3) and is more compact.\nDataset B has a wider range (11), indicating greater variability in scores.\n\nBy using these descriptive statistics, we can better interpret datasets and make informed comparisons in various fields, including education, business, and research.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#variance-and-standard-deviation",
    "href": "descriptive-stats/dispersion-measures.html#variance-and-standard-deviation",
    "title": "7¬† Measures of Dispersion",
    "section": "7.3 Variance and Standard Deviation",
    "text": "7.3 Variance and Standard Deviation\nWhen analyzing data, calculating the mean provides insight into the average value of a dataset. However, to understand how spread out the data is, we need to measure its variability. This is where variance and standard deviation become essential.\nVariance quantifies the average squared deviation of each data point from the mean. It provides a measure of how much the data points differ from the central value. For an entire population, the variance (\\(\\sigma^2\\)) is calculated as: \\[\nœÉ^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\n\\] where:\n\n\\(N\\) = total number of data points in the population,\n\\(x_i\\) = individual data points,\n\\(\\mu\\) = population mean.\n\nWhen working with a sample instead of an entire population, we use the sample variance (\\(s^2\\)): \\[\ns^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\n\\] where:\n\n\\(n\\) = sample size,\n\\(x_i\\) = individual data points,\n\\(\\bar{x}\\)= sample mean.\n\nThe denominator \\((n-1)\\) instead of \\(n\\) accounts for the loss of one degree of freedom, making it an unbiased estimator of population variance (we‚Äôll return to this later).\nAn alternative formula for calculating sample variance can be found by noting that the sum of all deviations from the mean is zero: \\(\\sum_{i=1}^{n} x_i = n\\bar{x}\\) so that we get \\[\n\\sum_{i=1}^{n} x_i \\bar{x} = \\bar{x} \\sum_{i=1}^{n} x_i = n \\bar{x}^2.\n\\] Substituting this back into original equation yields: \\[\ns^2 = \\frac{\\sum_{i=1}^{n} x_i^2 - 2n\\bar{x}^2 + n\\bar{x}^2}{n-1}\n= \\frac{\\sum_{i=1}^{n} x_i^2 - n\\bar{x}^2}{n-1}\n\\] Rewriting using summation notation: \\[\ns^2 = \\frac{n \\sum_{i=1}^{n} x_i^2 - (\\sum_{i=1}^{n} x_i)^2}{n(n-1)}\n\\] This formulation simplifies calculations by hand when working with moderately large data sets.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#standard-deviation",
    "href": "descriptive-stats/dispersion-measures.html#standard-deviation",
    "title": "7¬† Measures of Dispersion",
    "section": "7.4 Standard Deviation",
    "text": "7.4 Standard Deviation\nThe standard deviation is the square root of variance, bringing it back to the same units as the data, for example if measuring weight in kg, standard deviation is in kg as well. Thus, it is better to use when you need an intuitive, practical measure of data spread in real-world scenarios.\nFor a population, the standard deviation (\\(\\sigma\\)) is: \\[\n\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}}\n\\] For a sample, the standard deviation (\\(s\\)) is: \\[\ns = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}}\n\\] which can also be rewritten as: \\[\ns = \\sqrt{\\frac{n \\sum_{i=1}^{n} x_i^2 - (\\sum_{i=1}^{n} x_i)^2}{n(n-1)}}\n\\] following the alternative variance formula shown above.\nTo better understand the concept of standard deviation, we visualize the distribution of a data set in Figure¬†7.2 where the mean (blue) and standard deviation bands (red) are overlayed.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.2: Histogram of data set of 100 0bservations with standard deviation bands included.\n\n\n\n\nExample: Test Scores\nReturning to our example on test scores, we previously calculated the sample mean as \\(\\bar{x} = 5.25\\). Now, we compute the variance (\\(s^2\\)) for each data set: \\[\ns^2_A = \\frac{(4‚àí5.25)^2 + (4‚àí5.25)^2 + \\dots + (7‚àí5.25)^2}{8-1}  \\approx 1.074\n\\] \\[\ns^2_B = \\frac{(0‚àí5.25)^2 + (1‚àí5.25)^2 + \\dots + (11‚àí5.25)^2}{8-1} \\approx 13.071\n\\]\nThe standard deviation (\\(s\\)) is then simply the square root of the variance: \\[\ns_A = \\sqrt{1.071} \\approx 1.035\n\\] and \\[\ns_B = \\sqrt{13.071} \\approx 3.615\n\\] We see that for data set A, the standard deviation is 1.035, indicating that most scores are relatively close to the mean (5.25), while for data set B, the standard deviation is 3.615, suggesting a wider spread of scores and greater variability. This comparison shows that data set B has a significantly higher variability than data set A, meaning the scores are more dispersed from the average.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#the-empirical-rule",
    "href": "descriptive-stats/dispersion-measures.html#the-empirical-rule",
    "title": "7¬† Measures of Dispersion",
    "section": "7.5 The Empirical Rule",
    "text": "7.5 The Empirical Rule\nThe Empirical Rule, also known as the 68-95-99.7 Rule, describes how data is distributed in a normal (bell-shaped) distribution. It states that for a large population following a normal distribution:\n\nApproximately 68% of all observations lie within one standard deviation from the mean (\\(\\mu ¬± 1\\sigma\\)).\nApproximately 95% of all observations lie within two standard deviations from the mean (\\(\\mu ¬± 2\\sigma\\)).\nNearly all observations (99.7%) lie within three standard deviations from the mean (\\(\\mu ¬± 3\\sigma\\)).\n\nThis rule helps us understand the probability of an observation falling within a given range and is widely used in quality control, finance, and science to assess variability and expected outcomes. It is particularly useful when analyzing data distributions. If data follows a normal distribution most values cluster around the mean, and extreme values are rare. This also means that outliers can be identified if they fall beyond 3 standard deviations from the mean.\nThe empricial rule is visualized in Figure¬†7.3 showing the percentages of data falling within each standard deviation range.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.3: The Empirical Rule: Normal Distribution.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "descriptive-stats/dispersion-measures.html#covariance-and-correlation",
    "href": "descriptive-stats/dispersion-measures.html#covariance-and-correlation",
    "title": "7¬† Measures of Dispersion",
    "section": "7.6 Covariance and Correlation",
    "text": "7.6 Covariance and Correlation\nWhen analyzing data, it is often important to understand the relationship between two variables. Measures such as covariance and correlation help quantify the degree to which two variables change together, allowing us to assess their association.\nCovariance measures the direction of the linear relationship between two variables, \\(X\\) and \\(Y\\). It tells us whether an increase in one variable is associated with an increase or decrease in the other. For an entire population, the covariance is calculated as: \\[\nCov(X, Y) = \\sigma_{xy} = \\frac{\\sum_{i=1}^{N} (x_i - \\mu_x)(y_i - \\mu_y)}{N}\n\\] where:\n\n\\(N\\) = total number of observations,\n\\(x_i, y_i\\) = individual data points,\n\\(\\mu_x \\mu_y\\) = means of \\(X\\) and \\(Y\\).\n\nFor a sample, we estimate covariance using: \\[\nCov(X, Y) = s_{xy} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{n - 1}\n\\] where:\n\n\\(n\\) = sample size,\n\\(\\bar{x} ,\\bar{y}\\) = sample means of \\(X\\) and \\(Y\\).\n\nHow do we interpret the covariance?\n\nIf we have positive covariance it means that when \\(X\\) increases, then \\(Y\\) also tends to increase (e.g., study time and exam scores).\nIf we have negative covariance it means that when \\(X\\) increases, then \\(Y\\) tends to decrease (e.g., speed and time taken to reach a destination).\nIf we have near zero covariance, then this indicates no significant linear relationship between \\(X\\) and \\(Y\\) (note however that it does not detect patterns where variables are related in a non-linear way e.g., quadratic or exponential relationships).\n\nOne limitation of covariance is that it depends on the units of measurement (same as for variance), making it difficult to interpret. This is where correlation comes in as it standardizes covariance by adjusting for the scales of the variables, providing a dimensionless measure that is easier to interpret. The population correlation (\\(\\rho\\)) is given by \\[\n\\rho = \\frac{Cov(X, Y)}{\\sigma_x \\sigma_y}\n\\] where \\(\\sigma_x,\\sigma_y\\) are the standard deviations of \\(X\\) and \\(Y\\). The sample correlation (\\(r\\)) \\[\nr = \\frac{Cov(X, Y)}{s_x s_y}\n\\] where \\(s_x, s_y\\) are the sample standard deviations. Correlation values fall within the range -1 to 1, with the following interpretations (we use sample correlation as example):\n\n\\(r = 1\\): perfect positive correlation; \\(X\\) and \\(Y\\) move together exactly in a straight line.\n\\(0.8 \\leq r &lt; 1\\): strong positive correlation; \\(X\\) and \\(Y\\) tend to increase together.\n\\(0.5 \\leq r &lt; 0.8\\): moderate positive correlation; \\(X\\) and \\(Y\\) show a noticeable increasing relationship.\n\\(0 &lt; r &lt; 0.5\\): weak positive correlation; \\(X\\) and \\(Y\\) tend to increase together, but with variability.\n\\(r = 0\\): no linear relationship; \\(X\\) and \\(Y\\) are not linearly related (but might be non-linearly associated).\n\\(-0.5 &lt; r &lt; 0\\): weak negative correlation; as \\(X\\) increases, \\(Y\\) tends to decrease slightly.\n\\(-0.8 &lt; r \\leq -0.5\\): moderate negative correlation; \\(X\\) and \\(Y\\) shown an inverse relationship.\n\\(-1 ‚â§ r ‚â§ -0.8\\): strong negative correlation; \\(X\\) and \\(Y\\) move in opposite directions strongly.\n\\(r = -1\\): perfect negative correlation; \\(X\\) and \\(Y\\) move in exactly opposite directions in a straight line.\n\nA few examples are shown in Figure¬†7.4.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.4: Simulated data showing different correlations.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Measures of Dispersion</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html",
    "href": "prob-theory/prob-concepts.html",
    "title": "8¬† Probability Concepts",
    "section": "",
    "text": "8.1 Random Experiments\nWe now focus on the middle part of Figure¬†8.1, where we transition from simply summarizing data to drawing broader conclusions. Probability theory serves as the bridge between descriptive statistics, which tells us ‚Äúhow it is,‚Äù and inferential statistics, which helps us predict ‚Äúhow it will be.‚Äù By understanding why certain patterns appear in our sample data and combining that with probabilistic assumptions, we can move toward generalizing from the sample to the entire population.\nProbability theory is the branch of mathematics that deals with random experiments, where the outcome of each trial is uncertain and cannot be determined in advance. These experiments can be repeated under similar conditions, but due to inherent randomness, different trials may produce different results. No matter how hard you stare at a die before rolling, you won‚Äôt magically force it to land on a 6 (unless you‚Äôre a magician‚Ä¶ or cheating).\nA random experiment is an event or process that, when performed, leads to one of several possible outcomes, but the exact outcome is not known beforehand. The key characteristic of a random experiment is that even though individual outcomes are unpredictable, patterns may emerge when the experiment is repeated multiple times. This allows us to quantify uncertainty and make probabilistic predictions.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html#random-experiments",
    "href": "prob-theory/prob-concepts.html#random-experiments",
    "title": "8¬† Probability Concepts",
    "section": "",
    "text": "8.1.1 Properties of Random Experiments\n\nUncertainty in Individual Outcomes: The result of a single trial is unpredictable. You never really know what‚Äôs coming (just like your WiFi signal when you really need it).\nReproducibility Under Similar Conditions: The experiment can be performed multiple times under the same setup but the result may change every time (kind of like baking‚Äîyou follow the same recipe, yet somehow, things go wrong).\nPatterns in the Long Run: While single outcomes are uncertain, probability theory helps reveal long-term statistical regularities. In other words, while each trial is a mystery, repeat something enough times, and trends start to emerge (like realizing your cat will always knock things off the table).\n\nExamples of random experiments include:\n\nRolling a die (What number will appear: 1, 2, 3, 4, 5, or 6?)\nDrawing a lottery ticket (Win or no win?)\nRandom sampling from a population (Who will be selected?)\nFertilization of an egg (Boy or girl?)\nRadioactive decay (Number of particles decayed in a given time?)\nManufacturing of a product (Defective or non-defective?)\n\nWhile randomness may seem chaotic, probability theory helps us bring order to the madness. It allows us to assign mathematical probabilities to outcomes, making it possible to predict patterns, measure risk, and, if you‚Äôre lucky, win at poker.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html#outcomes-sample-space-and-events",
    "href": "prob-theory/prob-concepts.html#outcomes-sample-space-and-events",
    "title": "8¬† Probability Concepts",
    "section": "8.2 Outcomes, Sample Space and Events",
    "text": "8.2 Outcomes, Sample Space and Events\nThe result of a random experiment is called an outcome, and the set of all possible outcomes is known as the sample space, denoted as \\(\\Omega\\). A couple of examples are shown below:\nExperiment: Rolling a six-sided die\nSample Space: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\)\nExperiment: Flipping a coin twice\nSample Space: \\(\\Omega = \\{\\text{heads, tails}), (\\text{heads, heads}), (\\text{tails, heads}), (\\text{tails, tails})\\}\\)\nIn probability theory, we are often more interested in the characteristics of outcomes rather than the individual outcomes themselves. An event is a collection of outcomes that share a common feature, allowing us to analyze probabilities more efficiently and identify meaningful patterns within the data. Events are typically denoted by uppercase letters such as \\(A, B, C, \\ldots\\) and are formally defined as subsets of the sample space \\(\\Omega\\) Each event is characterized by the set of outcomes for which it occurs, meaning that an event is said to happen if and only if at least one of its associated outcomes is observed.\nConsider the follwing example. In a standard six-sided die roll üé≤, the sample space is given by: \\[\n\\Omega =\\{1, 2, 3, 4, 5, 6\\}\n\\]\nDifferent events can be defined as subsets of the sample space:\n\n\n\nEvent\nSubset of Sample Space\n\n\n\n\n\\(A\\) = Rolling an odd number\n\\(A = \\{1, 3, 5\\}\\)\n\n\n\\(B\\) = Rolling at most three\n\\(B = \\{1, 2, 3\\}\\)\n\n\n\\(C\\) = Rolling a six\n\\(C = \\{6\\}\\)\n\n\n\\(D\\) = Not rolling a six\n\\(D = \\{1, 2, 3, 4, 5\\}\\)\n\n\n\\(E\\) = Rolling a seven\n\\(E = \\emptyset\\) (empty set)\n\n\n\nIn this table, event \\(E\\) represents an impossible event since rolling a seven is not possible with a six-sided die, making its subset the empty set \\(\\emptyset\\).\n\nExample 8.1\nImagine randomly selecting a person from a lecture room. The sample space consists of all individuals present in the room. However, we are often more interested in certain characteristics rather than the specific individuals themselves.\nLet‚Äôs define the following events:\n\n\\(A\\) = The selected person wears glasses\n\n\\(B\\) = The selected person cycled to the university\n\nEach event consists of all outcomes where the selected individual satisfies the given condition. Suppose the randomly chosen person is Alex. If Alex wears glasses, then event \\(A\\) has occurred. If Alex also cycled to the university, then both events \\(A\\) and \\(B\\) have occurred simultaneously.\nNote that we here only considered one random experiment. In many real-world situations, random experiments are repeated multiple times instead of occurring just once. In such cases, each possible sample drawn represents an individual outcome.\nFor example, suppose we randomly select three students from the lecture room and ask them: ‚ÄúDid you cycle to today‚Äôs lecture?‚Äù.\nIf we let \\(Y\\) represent ‚ÄúYes‚Äù and \\(N\\) represent ‚ÄúNo‚Äù, the sample space consists of all possible sequences of answers: \\[\n\\Omega = \\{YYY, YYN, YNY, NYY, YNN, NYN, NNY, NNN\\}\n\\]\nand each outcome represents a specific combination of answers from the three selected students.\nRather than focusing on individual outcomes, we may be interested in how many of the selected students cycled to the lecture. This allows us to define events based on counts. For example, let‚Äôs define:\n\n\\(B_2\\) = Exactly two students cycled to the lecture\n\nThis event consists of all sequences where two of the three selected students answered ‚ÄúYes‚Äù, i.e.¬†\\[\nB_2 = \\{YYN, YNY, NYY\\}\n\\] Similarly, we can define:\n\n\\(B_0\\) = No students cycled to the lecture\n\n\\(B_1\\) = Exactly one student cycled to the lecture\n\n\\(B_3\\) = All three students cycled to the lecture\n\nSince one and only one of these events must occur, they are considered:\n\nExhaustive ‚Äì Together, they cover the entire sample space.\n\nMutually Exclusive ‚Äì No two of these events can occur at the same time.\n\nBy structuring probability problems in this way, we can analyze patterns in data and make probability calculations more intuitive.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html#venn-diagram",
    "href": "prob-theory/prob-concepts.html#venn-diagram",
    "title": "8¬† Probability Concepts",
    "section": "8.3 Venn Diagram",
    "text": "8.3 Venn Diagram\nProbability theory frequently utilizes conecpts from set theory to describe relationships between events. Venn diagrams provide a visual representation of these concepts and illustrate how different events relate to one another within the sample space. By using set operations, we can define and show new events effectively.\nThe sample space \\(\\Omega\\) is often represented as a rectangle, where individual outcomes may be shown as dots inside. However, for simplicity, the dots are usually omitted (and sometimes even the rectangle is omitted).\nAn event is typically represented as a circle within the rectangle. If multiple events are considered, their circles may overlap, reflecting cases where both events can occur simultaneously.\nReturning to our previous example, imagine we again randomly select a student from a lecture hall. We define the following events:\n\n\\(A\\) = The selected student wears glasses\n\\(B\\) = The selected student cycled to the university\n\nThese events can be visualized in a Venn diagram, where each event is a circle, as shown in Figure¬†8.2. Their overlap represents students who meet both conditions. These is called the intersection of events \\(A\\) and \\(B\\) and is one of three interesting areas that are of particular interest. We will cover each fo these in the following with reference to Figure¬†8.3 below.\n\n\n\n\n\n\n\nFigure¬†8.2: Events \\(A\\) and \\(B\\) in sample space \\(\\Omega\\).\n\n\n\n\n\n8.3.1 The Intersection of Events\nHere we look for outcomes that belong to both events \\(A\\) and \\(B\\). The intersection of two events \\(A\\) and \\(B\\) is denoted as: \\[A \\cap B\\]\nand represents the set of all outcomes where both events occur simultaneously. This is shown in top-left diagram of Figure¬†8.3.\n\nExample 8.2\nConsider a standard six-sided die where the sample space is: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) Define the following events:\n\n\\(A\\) = Rolling an odd number; \\(A = \\{1, 3, 5\\}\\)\n\\(B\\) = Rolling a number that is at most 3; \\(B = \\{1, 2, 3\\}\\)\n\nThe intersection of \\(A\\) and \\(B\\) includes only the numbers that appear in both sets: \\[\nA \\cap B = \\{1, 3\\}\n\\] Thus, the intersection contains only the numbers 1 and 3, since these are the only values present in both events.\n\n\n\n8.3.2 The Union of Events\nWe now look for outcomes that belong to at least one of the two events \\(A\\) and \\(B\\). The union of events, denoted as: \\[ A \\cup B \\] and represents the event that either \\(A\\), \\(B\\), or both occur. This is shown in bottom-left diagram of Figure¬†8.3.\n\nExample 8.3\nConsider a standard six-sided die where the sample space is: \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) Define the following events:\n\n\\(A\\) = Rolling an odd number; \\(A = \\{1, 3, 5\\}\\)\n\\(B\\) = Rolling a number that is at most 3; \\(B = \\{1, 2, 3\\}\\)\n\nThe union of \\(A\\) and \\(B\\) includes all outcomes that belong to either event or both:\n\\[A \\cup B = \\{1, 2, 3, 5\\}\\]\nThus, the union contains the numbers 1, 2, 3, and 5, since at least one of the events \\(A\\) or \\(B\\) includes each of these numbers.\n\n\n\n8.3.3 Complement of an Event\nFor every event \\(A\\), there exists a complement event, which consists of all outcomes that do not belong to event \\(A\\).\nThe complement of \\(A\\) is denoted as: \\[ \\overline{A} \\] and represents the event that \\(A\\) does not occur. This is shown in bottom-right diagram of Figure¬†8.3.\n\nExample 8.4\nConsider rolling a standard six-sided die, where the sample space is: \\[S=\\{1,2,3,4,5,6\\}\\] Define the following event:\n\n\\(A\\) = Rolling an odd number; \\(A=\\{1,3,5\\}\\)\n\nThe complement of \\(A\\) consists of all outcomes not included in \\(A\\): \\[\\overline{A}=\\{2,4,6\\}\\] Thus, the complement of rolling an odd number is rolling an even number.\n\n\n\n8.3.4 Mutually Exclusive Events\nIn some cases, events \\(A\\) and \\(B\\) do not share any outcomes. Such events are called disjoint events, meaning they cannot occur simultaneously. Mathematically, this is written as: \\[A \\cap B = \\emptyset\\] where \\(\\emptyset\\) represents the empty set, meaning a set with no elements. This is shown in top-right diagram of Figure¬†8.3.\n\nExample 8.4\nConsider rolling a standard six-sided die, where the sample space is: \\[S=\\{1,2,3,4,5,6\\}\\]\nDefine the following events:\n\n\\(A\\) = Rolling an odd number; \\(A=\\{1,3,5\\}\\)\n\\(B\\) = Rolling an even number; \\(B=\\{2,4,6\\}\\)\n\nSince \\(A\\) and \\(B\\) do not have any numbers in common, we conclude: \\[A \\cap B = \\emptyset\\]\nThus, rolling an odd number and rolling an even number are mutually exclusive events.\n\n\n\n\n\n\n\nFigure¬†8.3: The intersection of events \\(A\\) and \\(B\\) (top-left), mutually exhaustive events (top-right), the union of events \\(A\\) and \\(B\\) (bottom-left) and the complement of event \\(A\\) (bottom-right).",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-concepts.html#exercises",
    "href": "prob-theory/prob-concepts.html#exercises",
    "title": "8¬† Probability Concepts",
    "section": "Exercises",
    "text": "Exercises\nLet the sample space be: \\[\\Omega = {1,2,3,4,5,6} \\] Define the following events:\n\n\\(A\\) = ‚ÄúOdd numbers‚Äù; \\(A = {1,3,5}\\)\n\\(B\\) = ‚ÄúAt most three‚Äù; \\(B = {1,2,3}\\)\n\nDraw Venn diagrams to verify that the following statements hold:\n\n\\(\\overline{A \\cup B} = {4,6}\\)\n\\(\\overline{A} \\cap \\overline{B} = {4,6}\\)\n\\(A \\cup \\overline{A} = {1,2,3,4,5,6} = \\Omega\\)\n\\(A \\cap \\overline{A} = \\emptyset\\)",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Probability Concepts</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html",
    "href": "prob-theory/what-is-prob.html",
    "title": "9¬† What is Probability?",
    "section": "",
    "text": "9.1 Fundamental Assumptions of Probability\nNow that we have explored fundamental probability concepts, such as unions, intersections, complements, and mutually exclusive events, we can use these ideas to formally define probability itself.\nUsing the relationships between events that we have discussed, we can also establish the formal rules of probability and see how these concepts help in calculating probabilities for different types of events.\nProbability theory provides a framework for modeling randomness and quantifying uncertainty. At its core, it relies on three fundamental assumptions that define how probabilities are assigned to different outcomes in a random experiment.\n\\[P(O_1) + P(O_2) + \\dots + P(O_n) = \\sum_{i=1}^{n} P(O_i) = 1\\]\nThese fundamental principles form the backbone of probability theory, ensuring a structured and consistent way to reason about uncertain events. By defining probabilities within these constraints, we can build models that capture real-world randomness and variability in a mathematically rigorous way.\nThe probability of an event \\(A\\), denoted as \\(P(A)\\), is determined by summing the probabilities of all individual outcomes that make up \\(A\\): \\[ P(A) = \\sum_{O_i \\in A} P(O_i) \\]\nThis rule ensures that if an event consists of multiple possible outcomes, its probability is found by adding up the probabilities of each contributing outcome.\nSince probability values must be assigned consistently, we require a formal system that ensures logical coherence in probability calculations. This leads us to Kolmogorov axioms, which form the foundation of modern probability theory.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#fundamental-assumptions-of-probability",
    "href": "prob-theory/what-is-prob.html#fundamental-assumptions-of-probability",
    "title": "9¬† What is Probability?",
    "section": "",
    "text": "First, every probability calculation begins with a random experiment that has a well-defined sample space, denoted as \\(\\Omega = \\{O_1, O_2, \\dots, O_n\\}\\). This sample space represents all possible outcomes of the experiment, ensuring that every event of interest is accounted for.\nSecond, once the sample space is established, each outcome \\(O_i\\) is assigned a probability \\(P(O_i)\\) for \\(i = 1,2,\\ldots, n\\), representing the likelihood of that specific event occurring. These probabilities must follow\n\n\nnon-negativity, meaning that probabilities must always fall within the range \\(0 \\leq P(O_i) \\leq 1\\) for all outcomes. This ensures that an event can never have a negative probability, and the probability of a certain event is at most 1.\n\nand the total probability principle, stating that the sum of all assigned probabilities must equal 1:",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#kolmogorovs-axioms",
    "href": "prob-theory/what-is-prob.html#kolmogorovs-axioms",
    "title": "9¬† What is Probability?",
    "section": "9.2 Kolmogorov‚Äôs Axioms",
    "text": "9.2 Kolmogorov‚Äôs Axioms\nTo maintain consistency in probability assignments, Andrey Kolmogorov formulated three fundamental axioms:\n\nNon-Negativity: The probability of any event \\(A\\) is always greater than or equal to zero:\n\\[P(A) \\geq 0\\]\nThis ensures that probabilities are never negative.\nTotal Probability: The probability of the entire sample space \\(\\Omega\\) (i.e., the event that some outcome must occur) is exactly 1:\n\\[P(\\Omega) = 1\\]\nThis guarantees that probability is correctly distributed among all possible outcomes.\nAdditivity for Mutually Exclusive Events: If two events \\(A\\) and \\(B\\) cannot occur at the same time (i.e., they are mutually exclusive), then the probability of either occurring is the sum of their individual probabilities:\n\\[P(A \\cup B) = P(A) + P(B)\\]\nThis principle extends to any finite or countable number of mutually exclusive events. If \\(A_1, A_2, \\dots, A_k\\) are pairwise disjoint events, then the probability of their union is the sum of their individual probabilities: \\[P(A_1 \\cup A_2 \\cup \\dots \\cup A_k) = P(A_1) + P(A_2) + \\dots + P(A_k)\\]\n\nThese axioms are not just abstract rules; they provide the backbone for all probability calculations, from simple games of chance to risk assessments in finance, medicine, and machine learning. By defining probability through outcome summation and enforcing consistency through these axioms, we build a powerful and reliable framework for understanding and modeling uncertainty, thus allowing for meaningful calculations and predictions about uncertain events.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#defining-probability",
    "href": "prob-theory/what-is-prob.html#defining-probability",
    "title": "9¬† What is Probability?",
    "section": "9.3 Defining Probability",
    "text": "9.3 Defining Probability\nThe probability of an event \\(A\\), denoted as \\(P(A)\\), is a measure of how likely it is that the event will occur. Different interpretations of probability exist, leading to various probability definitions.\n\n9.3.1 The Classical Definition\nThe classical definition of probability, derived from basic counting principles, states that if a random experiment has \\(N\\) possible outcomes, and exactly \\(N_A\\) of these correspond to event \\(A\\) occurring, then the probability of \\(A\\) is given by: \\[P(A) = \\frac{N_A}{N}\\] This is known as a theoretical probability assignment, as it assumes that all outcomes are equally likely.\n\n\n9.3.2 The Frequentist Definition\nAn alternative way to define probability is through relative frequency. In the frequentist interpretation, the probability of an event \\(A\\) is understood as the proportion of times \\(A\\) occurs in a very long sequence of repeated random experiments. This can be expressed mathematically as: \\[P(A) \\approx \\frac{n_A}{n}\\] where:\n\n\\(n_A\\) is the number of times event \\(A\\) occurs.\n\\(n\\) is the total number of trials.\n\nAs the number of trials \\(n\\) increases, the relative frequency of event \\(A\\) stabilizes and approaches its probability \\(P(A)\\), aligning with the classical probability definition. In other words, if we repeat an experiment an extremely large number of times, the empirical probability we observe will converge toward a fixed value. This phenomenon is known as the stability of relative frequencies and serves as the empirical foundation of probability theory. It explains why probabilities can be estimated by repeated experimentation, as observed frequencies tend to settle around a fixed value over a large number of trials. AN example of this is shown below in Example 9.1.\nThis probability defintion is known as the empirical probability assignment, meaning that probabilities are assigned based on observed data rather than theoretical assumptions.\n\n\n9.3.3 The Subjective Definition\nAnother way to interpret probability is through subjective probability, where probability is understood as a*measure of personal belief in the occurrence of an event. Formally, the probability of an event \\(A\\) in this interpretation is given by:\n\\[P(A) = \\text{a measure of how strongly a person believes that } A \\text{ will occur}\\] For example, one might estimate the probability of rain tomorrow as 30%, or believe that the chance of Germany winning the next Eurovision Song Contest is 70%. These probabilities are not derived from mathematical models or repeated experiments but instead reflect an individual‚Äôs degree of confidence in a given outcome.\nThis approach known as the subjective probability assignment is commonly used in decision-making under uncertainty, such as betting, economics, and risk assessment, where probabilities are assigned based on available information, intuition, or expert judgment rather than empirical frequency or formal statistical models.\n\nExample 9.1: Stability of Relative Frequencies\nHow many sixes can we expect if we roll a die 10 times? 1000 times? 10,000 times?\nLet event \\(A\\) represent rolling a six when tossing a fair die. The theoretical probability of rolling a six is:\n\\[P(A) = \\frac{1}{6} \\approx 0.167\\]\nThis suggests that in 10 rolls, we should expect approximately 1 to 2 sixes.\nTo illustrate this, nine people each rolled a die 10 times, producing the following results for the number of sixes obtained: \\(1, 3, 1, 2, 2, 5, 4, 0, 2\\)\nIn total, there were 90 rolls, with a total of: \\(1+3+1+2+2+5+4+0+2 = 20\\) occurrences of a six. The relative frequency of rolling a six in this experiment was: \\[\\frac{n_A}{n} = \\frac{20}{90} = 0.22\\]\nWhat happens if we roll the die many more times? Using a computer simulation, the die was rolled 1000, 10 000 and 100 000 times, resulting in 140, 1726, and 16 745 sixes. The results are summarized in Table¬†9.1.\n\n\n\nTable¬†9.1: Summary of rolling a fair six-sided die multiple times, showing how the relative frequency of rolling a six approaches the theoretical probability 0.167 (16.7%) as the number of trials increases.\n\n\n\n\n\nNumber of üé≤ Rolls\nNumber of Sixes\nRelative Frequency\n\n\n\n\n10\n2\n0.20 (20%)\n\n\n90\n20\n0.22 (22%)\n\n\n1,000\n140\n0.14 (14%)\n\n\n10,000\n1,726\n0.173 (17.3%)\n\n\n100,000\n16,745\n0.167 (16.75%)\n\n\n\n\n\n\nAs the number of trials increases, the observed relative frequency tends to stabilize around the theoretical probability. This illustrates the law of large numbers, which states that the empirical probability of an event converges to its theoretical probability as the number of trials increases. We‚Äôll return to this later on.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#uniform-probabilitis",
    "href": "prob-theory/what-is-prob.html#uniform-probabilitis",
    "title": "9¬† What is Probability?",
    "section": "9.4 Uniform Probabilitis",
    "text": "9.4 Uniform Probabilitis\nIn many practical situations, it is reasonable to assume that all outcomes of a random experiment are equally likely. This is known as a uniform probability model.\nFor an experiment where each outcome occurs with equal probability, the probability of an event \\(A\\) can be calculated as:\n\\[P(A) = \\frac{N_A}{N}\\]\nwhere:\n\n\\(N\\) is the total number of possible outcomes.\n\\(N_A\\) is the number of favorable outcomes (i.e., outcomes where event \\(A\\) occurs).\n\nThis applies to all situations where each outcome has the same probability of occurring.\n\nExample 9.2: Rolling Two Dice üé≤üé≤\nConsider rolling two fair six-sided dice. Since each die has six faces, there are a total of:\n\\[6 \\times 6 = 36\\]\npossible outcomes, all of which are assumed to be equally likely. This is illustrated below where each star represents a possible combination of each roll of the two dice:\n\n\n\n\n\n\n\n\n\nWhat is the probability of rolling two sixes?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nDefine event \\(A\\) as the event of rolling a six on both dice. Since there is only one way to get this outcome \\((6,6)\\) among the 36 possible outcomes, the probability of \\(A\\) is: \\[P(A) = \\frac{1}{36} \\]\nThus, the likelihood of rolling double sixes in a single roll is 1 in 36, or approximately 2.78%.\nBelow in Table¬†9.2, all possible outcome combinations and their corresponding probaiblitis are given. The probability of rolling double sixes in a single roll is given the last row of this table.\n\n\n\nTable¬†9.2: The probability distribution of sums when rolling two six-sided dice.\n\n\n\n\n\nSum\nNumber of Outcomes\nProbability\n\n\n\n\n2\n1\n1/36 (2.78%)\n\n\n3\n2\n2/36 (5.56%)\n\n\n4\n3\n3/36 (8.33%)\n\n\n5\n4\n4/36 (11.11%)\n\n\n6\n5\n5/36 (13.89%)\n\n\n7\n6\n6/36 (16.67%)\n\n\n8\n5\n5/36 (13.89%)\n\n\n9\n4\n4/36 (11.11%)\n\n\n10\n3\n3/36 (8.33%)\n\n\n11\n2\n2/36 (5.56%)\n\n\n12\n1\n1/36 (2.78%)",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/what-is-prob.html#exercises",
    "href": "prob-theory/what-is-prob.html#exercises",
    "title": "9¬† What is Probability?",
    "section": "Exercises",
    "text": "Exercises\n\nConsider rolling two fair six-sided dice. What is the probability of rolling doubles (both dice show the same number)?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFrom earlier we know that the dice rolling follows a uniform probability model with \\(6 \\times 6 = 36\\) total possible outcomes.\nThe event ‚ÄòDoubles‚Äô occur when both dice show the same number:\n(1,1), (2,2), (3,3), (4,4), (5,5), (6,6), implying we have 6 outcomes of interest and the probability of this event is given by \\[P(\\text{doubles}) = \\frac{6}{36} = \\frac{1}{6} \\approx 0.167 \\text{ (16.7\\%)} \\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>What is Probability?</span>"
    ]
  },
  {
    "objectID": "prob-theory/count-rules.html",
    "href": "prob-theory/count-rules.html",
    "title": "10¬† Counting Rules",
    "section": "",
    "text": "10.1 With/Without Replacement? Order Matters or Not?\nNow that we have established the definition of probability, the next step is to determine how to count the number of possible outcomes in a structured way.\nIn many probability problems, we need to calculate the likelihood of an event occurring based on the number of favorable outcomes relative to the total number of possible outcomes. However, when dealing with large or complex sample spaces, manually listing all possible outcomes is impractical.\nTo efficiently compute probabilities, we rely on counting rules from combinatorics, which provide systematic methods to count possible outcomes. These include (see Chapter 2):\nOne key distinction in counting problems is whether selection is with or without replacement.\nAnother important factor is whether the order of selection matters when counting possibilities.\nBy understanding whether we are dealing with replacement or no replacement and ordered or unordered selection, we can use combinatorial techniques to systematically count possible outcomes in probability problems.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Counting Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/count-rules.html#withwithout-replacement-order-matters-or-not",
    "href": "prob-theory/count-rules.html#withwithout-replacement-order-matters-or-not",
    "title": "10¬† Counting Rules",
    "section": "",
    "text": "If a ball is drawn from an urn and returned before the next draw, then every selection remains independent, and the number of available choices does not change. This is known as drawing with replacement. For example, if an urn contains six balls, each ball has a \\(1/6\\) probability of being chosen, and this probability remains the same for every draw.\nIn contrast, drawing without replacement means that once a ball is selected, it is not returned to the urn. This affects the probability of subsequent draws. A common example is a lottery draw, where seven winning numbers are selected from a total of 35 balls. Since each number can only appear once, this is an example of drawing without replacement.\n\n\n\nIn some cases, order does matter. For example, imagine that a company requires employees to create five-letter security codes using the letters A, B, C, D, and E. Here the order of the letters celarly matters since password ABCDE is different from password ACBDE. This means the number of possible passwords availbale to choose from is determined by permutations, where order plays a role.\nIn other cases, order does not matter. Returning to the lottery example, suppose the machine selects the balls in the order 1,2,3,4,5,6,7. This sequence represents the same lottery result as if the balls had been drawn in the order 7,6,5,4,3,2,1. Since the order of selection does not change the outcome, this scenario follows combinations, where only the chosen numbers matter, not their sequence.\n\n\n\n10.1.1 Drawing with Replacement, Order Matters\n\nExample 9.3: PIN Code Generation\nConsider a four-digit PIN code, where each digit can be any number from 0 to 9. Since each digit is chosen independently and can be repeated, every unique sequence forms a distinct PIN code.\nThis is an example of permutations with repetition, where the total number of possible PIN codes is given by: \\[N^n\\] where:\n\n\\(N\\) is the number of available choices for each digit (10 digits: 0‚Äì9).\n\\(n\\) is the number of digits in the PIN code (4-digit code). Applying the formula: \\[10^4 = 10,000 \\]\n\nThis means there are 10,000 unique PIN codes that can be generated under these conditions.\n\n\nExample 9.4: Vehicle Registration Numbers in Sweden\nHow many possible vehicle registration numbers exist in Sweden? In Swedish license plates, a registration number consists of three letters followed by three digits. Since letters and digits can be repeated, this follows the rule of permutations with repetition.\nTo calculate the total number of possible license plates, we consider:\n\nThe first three characters are letters, chosen from 26 available options.\n\nThe last three characters are digits, chosen from 10 available options (0‚Äì9).\n\nUsing the multiplication principle, the total number of possible registration numbers is:\n\\[ 26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3 = 17,576,000 \\]\nThis means that Sweden can issue up to 17.58 million unique vehicle registration numbers under this system. The formaula is generally written as \\(N_1^{n_1} \\times N_2^{n_2}\\) where:\n\n\\(N_1 = 26\\) (number of available letters), \\(n_1 = 3\\) (three letters chosen).\n\n\\(N_2 = 10\\) (number of available digits), \\(n_2 = 3\\) (three digits chosen).\n\n\n\n\n10.1.2 Drawing with Replacement, Ignoring Order\n\nExample 9.5: Selecting Ice Cream Flavors üç¶\nImagine an ice cream shop that offers six different flavors. A customer selects three scoops of ice cream, where:\n\nThe same flavor can be chosen multiple times (replacement).\n\nThe order of the scoops does not matter‚Äî choosing (vanilla, chocolate, vanilla) is the same as (chocolate, vanilla, vanilla).\n\nSince order is ignored, but repetition is allowed, we calculate the number of possible selections using combinations with replacement, given by the formula: \\[\\binom{N + n - 1}{n} = \\frac{(N + n - 1)!}{n!(N - 1)!} \\]\nwhere:\n\n\\(N = 6\\) (number of available flavors).\n\n\\(n = 3\\) (number of scoops selected).\n\nApplying the formula:\n\\[ \\binom{6+3-1}{3} = \\binom{8}{3} = \\frac{8!}{3!(5!)} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56 \\]\nThus, there are 56 different ways to choose three scoops of ice cream when order does not matter, but flavors can be repeated.\n\n\n\n10.1.3 Drawing without Replacement, Order Matters\n\nExample 9.6: Finalist Selection in ESC üé§üé∂\nIn the semi-final rounds of the Eurovision Song Contest, five countries have reached the last stage. The final ranking must be determined, where each country is assigned a unique position from 1st place to 5th place.\nSince the order of ranking is important, we need to determine how many different ways the top five positions can be arranged. This follows the permutation rule, as once a country‚Äôs submission is assigned a position, it cannot be placed elsewhere. The total number of possible rankings is calculated as: \\[5 \\times 4 \\times 3 \\times 2 \\times 1 = 5! = 120 \\]\nThus, there are 120 possible ways to assign the final rankings to the five finalists.\nThis follows the principle of permutations without replacement, meaning that each finalist is placed in a unique ranking, and no two countries can hold the same position.\n\n\n\n10.1.4 Drawing without Replacement, Ignoring Order\n\nExample 9.7: Poker Hands üé¥\nIn a standard game of five-card poker, a player is dealt five random cards from a standard deck of 52 playing cards. Since:\n\nThe order of the cards does not matter (a hand with A‚ô† K‚ô† Q‚ô† J‚ô† 10‚ô† is the same regardless of the order drawn).\nCards are drawn without replacement (once a card is drawn, it cannot be selected again), we calculate the total number of different poker hands using combinations without replacement: \\[\\binom{52}{5} = \\frac{52!}{(52-5)!5!} = \\frac{52 \\times 51 \\times 50 \\times 49 \\times 48}{5!} = 2 598 960 \\]\nThus, there are 2 598 960 unique five-card poker hands in a standard deck.\n\nWhat is the probability of getting a flush on the first draw?\nA flush in poker means that all five cards in the hand belong to the same suit (‚ô†, ‚ô•, ‚ô¶, or ‚ô£). We define event \\(A\\) as the event of being dealt a flush directly, meaning that all five cards in the hand belong to the same suit (‚ô†, ‚ô•, ‚ô¶, or ‚ô£).\nTo compute the probability \\(A\\), consider that:\n\nIf we focus on only hearts, there are 13 hearts in the deck, and we need to choose 5 of them: \\[\\binom{13}{5} = \\frac{13!}{(13-5)!5!} = 1287 \\]\nThe same calculation applies for the other three suits (spades, diamonds, and clubs), so the total number of flush hands is: \\[4 \\times 1287 = 5148 \\]\n\nSince all poker hands are equally likely, the probability of being dealt a flush is: \\[P(A) = \\frac{5148}{2598960} \\approx 0.00198\\]\nThis means that the probability of being dealt a flush on the first draw is approximately 0.198%.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Counting Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/count-rules.html#exercises",
    "href": "prob-theory/count-rules.html#exercises",
    "title": "10¬† Counting Rules",
    "section": "Exercises",
    "text": "Exercises\n\nA full house in poker consists of three cards of one rank and two cards of another (e.g., Q‚ô† Q‚ô• Q‚ô¶ 7‚ô£ 7‚ô¶). What is the probability of getting a full house on the first draw?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSince the order does not matter, and cards are drawn without replacement, we use combinations to determine the number of possible full house hands.\nSelecting one of 13 ranks for the three-of-a-kind: \\(\\binom{13}{1} = 13\\). Choosing three suits out of four for that rank: \\(\\binom{4}{3} = 4\\).\nTotal ways to select the three-of-a-kind: \\[13 \\times 4 = 52 \\]\nSelecting one of 12 remaining ranks for the pair: \\(\\binom{12}{1} = 12\\). Choosing two suits out of four for that rank: \\(\\binom{4}{2} = 6\\). Total ways to select the pair: \\[12 \\times 6 = 72 \\]\nMultiplying both parts together we get: \\[52 \\times 72 = 3 744 \\]\nThus, there are 3 744 unique full house hands in a standard deck.\nSince we already know that there are 2 598 960 total poker hands, the probability of being dealt a full house is (defined as event \\(A\\)):\n\\[P(A) = \\frac{3744}{2598960} \\approx 0.00144\\]\nThis means the probability of being dealt a full house on the first draw is 0.144%.\n\n\n\n\nA teacher randomly arranges 6 students in a line for a class photo. Each student is assigned a unique position.\n\n\n\nHow many different ways can the 6 students be arranged in a line?\nWhat is the probability that a specific student (A) is in the first position?\nWhat is the probability that student A is first and student B is second in the lineup?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nThere are \\(P(6,6) = 6! = 6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1 = 720\\) different ways to arrange the students in a line (see Chapter 2 exercises for more details)\nSince all arrangements are equally likely, student A can be in any of the 6 positions. If we fix A in the first position, the remaining 5 students can be arranged freely: \\[5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\]\nThe probability of A being first is then given by \\[P(A)  = \\frac{120}{720} = \\frac{1}{6} \\approx 0.167 \\text{ (16.7\\%)}\\]\nIf A is fixed in the first position, there are 5 students remaining. If B is fixed in the second position, there are 4 students left to be arranged: \\[4! = 4 \\times 3 \\times 2 \\times 1 = 24\\]\nThe probability of A being first and B being second is then given by: \\[P(B) = \\frac{24}{720} = \\frac{1}{30} \\approx 0.0333 \\text{ (3.33\\%)}\\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Counting Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html",
    "href": "prob-theory/prob-rules.html",
    "title": "\n11¬† Probability Rules\n",
    "section": "",
    "text": "11.1 The Complement Rule\nWhile some probabilities can be determined directly from counting outcomes, others require probability rules that help us break down complex situations. Several fundamental rules govern probability calculations, ensuring consistency and logical reasoning:\nWe‚Äôll cover these in more details and examples in the following.\nhe complement rule states that if an event \\(A\\) has probability \\(P(A)\\), then the probability that \\(A\\) does not occur is:\\[P(\\overline{A}) = 1 - P(A)\\]\nThis rule is particularly useful when calculating the probability of ‚Äúat least one‚Äù occurrences by considering the opposite event. See Figure¬†11.1.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#the-complement-rule",
    "href": "prob-theory/prob-rules.html#the-complement-rule",
    "title": "\n11¬† Probability Rules\n",
    "section": "",
    "text": "Figure¬†11.1: The complement of event \\(A\\).\n\n\n\nExample 11.1: Deck of Cards\nDetermine the probability of drawing a ‚ô¶ (diamond), ‚ô• (heart), or ‚ô† (spade) when randomly selecting a card from a standard deck of 52 cards.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe sample space consists of all 52 cards, so: \\(\\Omega = \\{1, 2, 3, \\dots, 52\\}\\)\nLet \\(A\\) be the event of drawing a ‚ô¶, ‚ô•, or ‚ô†. The complement of \\(A\\), denoted as \\(\\overline{A}\\), is the event of drawing a ‚ô£ (club). Since there are 13 clubs in a deck, the probability of \\(\\overline{A}\\) is:\\[P(\\overline{A}) = \\frac{13}{52}\\]\nUsing the complement rule we get that: \\[P(A) = 1 - P(\\overline{A}) = 1 - \\frac{13}{52} = \\frac{39}{52} = \\frac{3}{4}\\] Thus, the probability of drawing a ‚ô¶, ‚ô•, or ‚ô† is 3/4 (75%).",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#the-addition-rule",
    "href": "prob-theory/prob-rules.html#the-addition-rule",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.2 The Addition Rule",
    "text": "11.2 The Addition Rule\nThe addition rule helps compute the probability of the union of two events (see Figure¬†11.2):\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\n\n\n\n\nFigure¬†11.2: The union of events \\(A\\) and \\(B\\).\n\n\n\nIf \\(A\\) and \\(B\\) are mutually exclusive (disjoint), then it follows that \\[P(A \\cup B) = P(A) + P(B)\\] since there is no intersection between the two events.\nExample 11.2: Dice Roll üé≤\nDetermine the probability of rolling an even number or a number greater than three when rolling a fair six-sided die.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe sample space consists of all possible outcomes of a die roll:\\[\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\]\nDefine the events:\n\n\n\\(A\\) = rolling an even number: \\(A = \\{2, 4, 6\\}\\)\n\n\n\\(B\\) = rolling a number greater than three: \\(B = \\{4, 5, 6\\}\\)\n\nThe intersection of these events (\\(A \\cap B\\)) = numbers that are both even and greater than three: \\[A \\cap B = \\{4, 6\\}\\]\n\n\nThe probabilities are \\[P(A) = \\frac{3}{6}, \\quad P(B) = \\frac{3}{6}, \\quad P(A \\cap B) = \\frac{2}{6}\\]\nUsing the addition rule \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\] we get that \\[P(A \\cup B) = \\frac{3}{6} + \\frac{3}{6} - \\frac{2}{6} = \\frac{4}{6} \\]\nThus, the probability of rolling either an even number or a number greater than three is \\(\\frac{4}{6}\\) or approximately 0.667 (66.7%).\n\n\n\nExample 11.2: Product Defects\nIn the manufacturing process of a product, two types of defects, \\(A\\) and \\(B\\), can occur. Sometimes both defects appear together. We are given the probabilities:\\[P(A) = 0.01, \\quad P(B) = 0.02, \\quad P(A \\cap B) = 0.005\\]\na. Determine the probability that a product has at least one of the two defects.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are looking for the union of the events \\(A\\) and \\(B\\): \\[P (A \\cup  B) = 0.01 + 0.02 ‚àí 0.005 = 0.025 = 2.5\\%\\]\n\n\n\n\nWhat is the probability that a product will be defect-free?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are looking for the complement of the union of the events \\(A\\) and \\(B\\): \\[P (\\overline{A \\cup B}) = 1 ‚àí P (A \\cup B) = 1 ‚àí 0.025 = 0.975 = 97.5\\%\\]\n\n\n\n\nWhat is the probability that a product will have exactly one defect?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are looking for the shaded area in Figure¬†11.3 which is given by \\[P(A \\cup  B) ‚àí P (A \\cap B) = 0.025 ‚àí 0.005 = 0.02 = 2\\%\\]\n\n\n\n\n\n\nFigure¬†11.3: The area shaded corresponds to exactly one defect.\n\n\n\n\n\n\n\n11.2.1 The Union of Three or More Events\nTo compute the probability of the union of three events \\(A\\), \\(B\\), and \\(C\\) as shown in Figure¬†11.4 we use the generalized addition rule:\n\\(\\qquad \\qquad \\qquad  P(A \\cup B \\cup C) = P(A) + P(B) + P(C)\\)\n\\[\\quad \\qquad \\qquad  - P(A \\cap B) - P(A \\cap C) - P(B \\cap C)\\]\n\\[+P(A \\cap B \\cap C)\\]\nThis formula ensures that overlapping probabilities are not double-counted when summing individual event probabilities.\n\n\n\n\n\n\nFigure¬†11.4: The union of three events.\n\n\n\nTo generalize it even further for \\(n\\) events \\(A_1, A_2, \\ldots, A_n\\), the probability of their union follows the principle of inclusion-exclusion:\n\\(P\\left(\\bigcup_{i=1}^{n} A_i \\right) =\n\\sum_{i=1}^{n} P(A_i) -\n\\sum_{1 \\leq i &lt; j \\leq n} P(A_i \\cap A_j)\\)\n\\[\n\\qquad + \\sum_{1 \\leq i &lt; j &lt; k \\leq n} P(A_i \\cap A_j \\cap A_k)\n- \\dots + (-1)^{n+1} P(A_1 \\cap A_2 \\cap \\dots \\cap A_n)  \n\\] This pattern continues, alternating between adding and subtracting intersections of increasing size.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#conditional-probability",
    "href": "prob-theory/prob-rules.html#conditional-probability",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.3 Conditional Probability",
    "text": "11.3 Conditional Probability\nImagine you‚Äôre waiting for a pizza delivery. Normally, the probability of the delivery driver being on time (event \\(B\\)) might not be great. But then you receive a text message saying, ‚ÄúYour order is on the way!‚Äù (event \\(A\\) has occurred). Now that you have extra information, your estimate of \\(P(B)\\) should change, right? That‚Äôs the essence of conditional probability; updating what we know when we gain new insight.\nWe originally wanted to find the probability of \\(B\\) happening, i.e., \\(P(B)\\). But now we‚Äôve been given a game-changing update: \\(A\\) has happened. That means our world is now limited to the subset of outcomes where \\(A\\) is true. In other words, we‚Äôre no longer looking at the whole sample space \\(\\Omega\\) - our new reality is just \\(A\\)!\nSo, the updated probability of \\(B\\) given that \\(A\\) has occurred, the so called conditional probability of \\(B\\) given \\(A\\), written as \\(P(B \\mid A)\\), is calculated using:\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)}\n\\]\nwhere \\(P(A) &gt; 0\\) (because if \\(A\\) didn‚Äôt happen, there‚Äôs no reason to update anything). This formula quantifies how the probability of \\(B\\) changes when we have additional information that \\(A\\) has occurred.\nConditional probability is like getting insider information:\n\nDid your team win the game? If they were leading at halftime, the probability changes.\n\nIs your package arriving today? If it was shipped yesterday, chances are better.\n\nAre you likely to pass your exam? If you‚Äôve studied, your odds are much higher!\n\nExample 11.3: Conditional Probability\nWe are given a population of individuals where:\n\n40% are men\n\n60% are women\n\nFurthermore, we know that:\n\n28% of the population are smokers, of which 8% are male and 20% are female\n\nA person is randomly selected from the population.\nWe are interested in finding the following conditional probabilities:\n\nWhat is the probability that the person is a smoker, given that the person is male?\nWhat is the probability that the person is a smoker, given that the person is female?\nWhat is the probability that the person is female, given that the person is a smoker?\n\nWe define the following events:\n\n\n\\(A\\): the person is a woman\n\n\n\\(\\bar{A}\\): the person is a man\n\n\n\\(B\\): the person is a smoker\n\n\n\\(\\bar{B}\\): the person is a non-smoker\n\nand the probabilities given for the events:\n\n\\(P(A) = 0.6\\)\n\\(P(\\bar{A}) = 0.4\\)\n\\(P(B) = 0.28\\)\n\\(P(\\bar{B}) = 0.72\\)\n\\(P(A \\cap B) = 0.20\\)\n\\(P(\\bar{A} \\cap B) = 0.08\\)\n\nTo help us calculate conditional probabilities, we construct a contingency table that shows joint and marginal probabilities. We fill in the parts given to us:\n\n\n\nWoman (\\(A\\))\nMan (\\(\\bar{A}\\))\nTotal\n\n\n\nSmoker (\\(B\\))\n0.20\n0.08\n0.28\n\n\nNon-smoker (\\(\\bar{B}\\))\n?\n?\n0.72\n\n\nTotal\n0.60\n0.40\n1.00\n\n\n\nTo fill in the remaining cells, we use subtraction: \\[P(A \\cap \\bar{B}) = P(A) - P(A \\cap B) = 0.60 - 0.20 = 0.40\\] \\[P(\\bar{A} \\cap \\bar{B}) = P(\\bar{A}) - P(\\bar{A} \\cap B) = 0.40 - 0.08 = 0.32\\]\nThe complete table is then given below:\n\n\n\n\n\n\n\n\n\nWoman (\\(A\\))\nMan (\\(\\bar{A}\\))\nTotal\n\n\n\nSmoker (\\(B\\))\n0.20\n0.08\n0.28\n\n\nNon-smoker (\\(\\bar{B}\\))\n0.40\n0.32\n0.72\n\n\nTotal\n0.60\n0.40\n1.00\n\n\n\nWith the help of this table, and the equation for conditional probability above, we can now find the asked probabilities (a)‚Äì(c).\n\n\n\n\n\n\nSolution (a)\n\n\n\n\n\n\nSmoker given man:\\[P(B \\mid \\bar{A}) = \\frac{P(B \\cap \\bar{A})}{P(\\bar{A})}\n= \\frac{0.08}{0.40} = 0.2\\] So, the probability that a person is a smoker given that he is a man is 20%.\n\n\n\n\n\n\n\n\n\n\nSolution (b)\n\n\n\n\n\nSmoker given woman: \\[\n   P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{0.20}{0.60} = \\frac{1}{3} \\approx 0.333\n\\]\n\n\n\n\n\n\n\n\n\nSolution (c)\n\n\n\n\n\nWoman given smoker: \\[\n   P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{0.20}{0.28} \\approx 0.714\n\\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "rv-probdists.html",
    "href": "rv-probdists.html",
    "title": "Random Variables and Probability Distributions",
    "section": "",
    "text": "Discrete random variables and distributions\nContinuous random variables and distributons\nMultivariate Random Variables\n\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Random Variables and Probability Distributions"
    ]
  },
  {
    "objectID": "sampling-dists.html",
    "href": "sampling-dists.html",
    "title": "Sampling and Sampling Distributions",
    "section": "",
    "text": "Sampling Distribution for a sample mean\nSampling Distribution for a sample proportion\nCentral Limit Theorem\n\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Sampling and Sampling Distributions"
    ]
  },
  {
    "objectID": "inference.html",
    "href": "inference.html",
    "title": "Inferential Statistics",
    "section": "",
    "text": "Estimation: point and interval estimation\nHypothesis testing for a sample mean and sample proportion\nHypothesis testing with confidence intervals\nHypothesis testing for the difference of two means or proportions\n\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Inferential Statistics"
    ]
  },
  {
    "objectID": "chi2.html",
    "href": "chi2.html",
    "title": "Chi Square Tests",
    "section": "",
    "text": "1 + 1\n\n[1] 2",
    "crumbs": [
      "Chi Square Tests"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "Regression Analysis",
    "section": "",
    "text": "Simple Linear Regression\nMultiple Linear Regression\nOLS estimation\nGauss Markov Theorem\nModel Assumptions and Diagnostics\nDummy variables and Interaction Terms\nEndogeneity and IV estimation\n\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Regression Analysis"
    ]
  },
  {
    "objectID": "slr.html",
    "href": "slr.html",
    "title": "\n12¬† Simple Linear Regression\n",
    "section": "",
    "text": "1 + 1\n\n[1] 2",
    "crumbs": [
      "Regression Analysis",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Summary"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#solution-c",
    "href": "prob-theory/prob-rules.html#solution-c",
    "title": "11¬† Probability Rules",
    "section": "11.4 Solution (c)",
    "text": "11.4 Solution (c)\nWoman given smoker: \\[\n   P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{0.20}{0.28} \\approx 0.714\n\\] :::",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#the-multiplication-rule",
    "href": "prob-theory/prob-rules.html#the-multiplication-rule",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.4 The Multiplication Rule",
    "text": "11.4 The Multiplication Rule\nFrom the definition of conditional probability, we can derive what is known as the multiplication rule.\nFor two events \\(A\\) and \\(B\\), the following holds:\\[\nP(A \\cap B) = P(A) \\cdot P(B \\mid A)\n\\]\nThis rule is particularly useful when determining the joint probability of two events that are not independent.\nExample 11.4: Defective Items\nConsider a batch of 100 items, out of which 5 are defective.\nWe randomly select one item from the 100. Then, without replacing the first, we randomly select another from the remaining 99 items.\nWe want to find the probability that both selected items are defective.\nDefine the events:\n\n\n\\(A\\): ‚ÄúThe first selected item is defective‚Äù\n\n\n\\(B\\): ‚ÄúThe second selected item is defective‚Äù\n\nWe are interested in computing \\(P(A \\cap B)\\) and we know that \\(P(A) = \\frac{5}{100}\\) and \\(P(B \\mid A) = \\frac{4}{99}\\) (since one defective item has been removed, 4 defective remain out of 99 items.) Now we apply the multiplication rule: \\[P(A \\cap B) = P(A) \\cdot P(B \\mid A) = \\frac{5}{100} \\cdot \\frac{4}{99} = \\frac{20}{9900} = \\frac{1}{495}\\] Alternatively, we could have used combinatorics to solve the problem. Can you see how?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe want the probability of choosing 2 defective items out of 5, from a total of 100:\n\\[P(\\text{both defective}) = \\frac{\\binom{5}{2} \\cdot \\binom{95}{0}}{\\binom{100}{2}} = \\frac{10 \\cdot 1}{4950} = \\frac{1}{495}\\]\nSo, both the multiplication rule and combinatorics give us the same result: the probability is \\(\\frac{1}{495}\\)",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#example-defective-items",
    "href": "prob-theory/prob-rules.html#example-defective-items",
    "title": "11¬† Probability Rules",
    "section": "11.5 Example: Defective Items",
    "text": "11.5 Example: Defective Items\nConsider a batch of 100 items, out of which 5 are defective.\nWe randomly select one item from the 100. Then, without replacing the first, we randomly select another from the remaining 99 items.\nWe want to find the probability that both selected items are defective.\nDefine the events: - \\(A\\): ‚ÄúThe first selected item is defective‚Äù\n- \\(B\\): ‚ÄúThe second selected item is defective‚Äù\nWe are interested in computing \\(P(A \\cap B)\\) and we know that \\(P(A) = \\frac{5}{100}\\) and \\(P(B \\mid A) = \\frac{4}{99}\\) (since one defective item has been removed, 4 defective remain out of 99 items.) Now we apply the multiplication rule: \\[P(A \\cap B) = P(A) \\cdot P(B \\mid A) = \\frac{5}{100} \\cdot \\frac{4}{99} = \\frac{20}{9900} = \\frac{1}{495}\\] Alternatively, we could have used combinatorics to solve the problem. Can you see how?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe want the probability of choosing 2 defective items out of 5, from a total of 100:\n\\[P(\\text{both defective}) = \\frac{\\binom{5}{2} \\cdot \\binom{95}{0}}{\\binom{100}{2}} = \\frac{10 \\cdot 1}{4950} = \\frac{1}{495}\\]\nSo, both the multiplication rule and combinatorics give us the same result: the probability is \\(\\frac{1}{495}\\)",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#independence",
    "href": "prob-theory/prob-rules.html#independence",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.5 Independence",
    "text": "11.5 Independence\nTwo events \\(A\\) and \\(B\\) are said to be independent if:\n\\[P(A \\cap B) = P(A) \\cdot P(B)\\]\nThis also implies:\n\\[P(A \\mid B) = P(A \\mid \\bar{B}) = P(A)\\]\nIn other words, knowing that \\(B\\) has occurred (or not) tells us nothing about whether \\(A\\) will happen. This follows from the definition of conditional probability:\n\\[P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(A) \\cdot P(B)}{P(B)} = P(A)\\]\n\nIntuition: If you‚Äôre flipping a coin, the result of the second flip doesn‚Äôt care what happened on the first flip!\n\nExample 11.5: Rolling Dice üé≤\nLet‚Äôs roll a standard die twice.\n\nLet \\(A\\) be ‚Äúgetting a 6 on the first roll‚Äù\nLet \\(B\\) be ‚Äúgetting a 6 on the second roll‚Äù\n\nThese events are independent, because one roll doesn‚Äôt affect the other. This means that \\[P(A) = \\frac{1}{6} \\ \\textrm{ and } \\ P(B) = \\frac{1}{6}\\]\nTherefore: \\[P(\\text{6 on both rolls}) = P(A \\cap B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36}\\] Note that if \\(A\\) and \\(B\\) are independent, then the following events are also indepndent:\n\n\n\\(A\\) and \\(\\bar{B}\\)\n\n\n\\(\\bar{A}\\) and \\(B\\)\n\n\n\\(\\bar{A}\\) and \\(\\bar{B}\\)\n\n\nIn other words, independence spreads across complements!\nLet‚Äôs calculate the probability of not getting a 6 in either roll.\n\n\n\\(\\bar{A}\\): Not getting a 6 on the first roll with probability \\(P(\\bar{A}) = \\frac{5}{6}\\)\n\n\n\\(\\bar{B}\\): Not getting a 6 on the second roll with probability \\(P(\\bar{B}) = \\frac{5}{6}\\)\n\n\nSince they are independent events, the probability of their intersection is given by\n\\[P(\\bar{A} \\cap \\bar{B}) = \\frac{5}{6} \\cdot \\frac{5}{6} = \\frac{25}{36}\\]\n\n\n\n\n\n\nNote\n\n\n\nDon‚Äôt confuse independence with mutual exclusivity ‚Äî they‚Äôre very different! Exercises 1 and 2 below illlutrate this.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#exercises",
    "href": "prob-theory/prob-rules.html#exercises",
    "title": "\n11¬† Probability Rules\n",
    "section": "Exercises",
    "text": "Exercises\n\nThe probability of two events \\(A\\) and \\(B\\) are given by \\(P(A) = 0.5\\) and \\(P(B) = 0.2\\). What‚Äôs \\(P(A \\cap B)\\) if\n\n\n\\(A\\) and \\(B\\) are mutually exclusive events\n\\(A\\) and \\(B\\) are independent events\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nIf \\(A\\) and \\(B\\) can‚Äôt happen together, then \\(P(A \\cap B) = \\emptyset = 0\\).\nIf \\(A\\) and \\(B\\) are independent, then \\(P(A \\cap B) = P(A) \\cdot P(B) = 0.5 \\cdot 0.2 = 0.1\\).\n\n\n\n\n\nThe probability of two events \\(A\\) and \\(B\\) are given by \\(P(A) = 0.5\\) and \\(P(B) = 0.2\\). What is \\(P(A \\cup B)\\), the probability that at least one happens, if\n\n\n\\(A\\) and \\(B\\) are mutually exclusive events\n\\(A\\) and \\(B\\) are independent events\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nIf \\(A\\) and \\(B\\) are mutually exclusive events, then \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B) = 0.5 + 0.2 - 0 = 0.7\\).\nIf \\(A\\) and \\(B\\) are independent, then \\(P(A \\cup B) = 0.5 + 0.2 - 0.1 = 0.6\\).\n\n\n\n\n\nAssume we know the following: \\(P(A) = 0.6\\), \\(P(A \\mid B) = 0.75\\), \\(P(B \\mid A) = 0.5\\). What is the probability that \\(B\\) will happen?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFind \\(P(A \\cap B)\\) using the conditional probability rule:\n\\[P(A \\cap B) = P(A) \\cdot P(B \\mid A) = 0.6 \\cdot 0.5 = 0.3\\]\nThen use the definition of conditional probability:\n\\[P(B) = \\frac{P(A \\cap B)}{P(A \\mid B)} = \\frac{0.3}{0.75} = 0.4\\]\n\n\n\n\nAnna and Bob go downhill skiing. The probability that Anna falls is \\(1/2\\), while the probability that Bob falls is \\(1/3\\). The probability that both fall is \\(1/4\\). What is the probability that both make it safely down the slope?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet:\n\n\n\\(A\\) = Anna falls\n\n\\(B\\) = Bob falls\n\nWe want the probability that both Anna and Bob make it down the slope safely \\[P(\\bar{A} \\cap \\bar{B}) = P(\\overline{A \\cup B}) =  1 - P(A \\cup B)\\]\n\\[P(\\bar{A} \\cap \\bar{B})  = 1 - P(A \\cup B)\n= 1 - [P(A) + P(B) - P(A \\cap B)] \\] \\[ = 1 - \\left(\\frac{1}{2} + \\frac{1}{3} - \\frac{1}{4}\\right) = \\frac{5}{12}\\]\n\n\n\n\nA tech company has found that:\n\n\n40% of its users are premium members (\\(P(M) = 0.4\\))\n80% of premium users log in daily (\\(P(D \\mid M) = 0.8\\))\n\nWhat is the probability that a randomly chosen user is a premium member who logs in daily?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUsing the mnultiplication rule, we get that\n\\[\nP(M \\cap D) = P(M) \\cdot P(D \\mid M)\n\\]\nSubstitute the values:\n\\[\nP(M \\cap D) = 0.4 \\cdot 0.8 = 0.32\n\\]\nThus 32% of users are both premium and daily-active.\n\n\n\n\nIn a survey of 300 students:\n\n\n180 said they drink coffee\n\n150 said they drink tea\n\n60 said they drink both coffee and tea\n\nWhat is the probability that a randomly chosen student drinks coffee (\\(C\\)) or tea (\\(T\\))?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are seeking \\(P(C \\cup T)\\): the probability that a student drinks coffee OR tea. We can use the addition rule:\n\\[\nP(C \\cup T) = P(C) + P(T) - P(C \\cap T)\n\\]\nFirst we convert counts into probabilities:\n\n\n\\(P(C) = \\frac{180}{300} = 0.6\\)\n\n\n\\(P(T) = \\frac{150}{300} = 0.5\\)\n\n\\(P(C \\cap T) = \\frac{60}{300} = 0.2\\)\n\nThen apply the rule:\n\\[\nP(C \\cup T) = 0.6 + 0.5 - 0.2 = 0.9\n\\]\nThus 90% of students drink either coffee, tea, or both.\n\n\n\n\nA machine learning model classifies emails as spam or not spam. Based on past data we know the following:\n\n\n10% of all emails are actually spam: \\(P(S) = 0.10\\)\n\n90% of emails are not spam: \\(P(\\bar{S}) = 0.90\\)\n\nThe model correctly detects spam 95% of the time: \\(P(D \\mid S) = 0.95\\)\n\nThe model incorrectly flags 5% of non-spam as spam: \\(P(D \\mid \\bar{S}) = 0.05\\)\n\n\nYou receive an email that was flagged by the model as spam (i.e., it was detected as spam).\nWhat is the probability that it is actually spam?\nThat is, compute \\(P(S \\mid D)\\), where:\n\n\n\\(S\\): Email is spam\n\n\\(D\\): Email was detected as spam by the filter\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe apply Bayes‚Äô Theorem: \\[\nP(S \\mid D) = \\frac{P(S) \\cdot P(D \\mid S)}{P(S) \\cdot P(D \\mid S) + P(\\bar{S}) \\cdot P(D \\mid \\bar{S})}\n\\]\nPlug in the values to get\n\nNumerator: \\(0.10 \\cdot 0.95 = 0.095\\)\n\nDenominator: \\(0.10 \\cdot 0.95 + 0.90 \\cdot 0.05 = 0.095 + 0.045 = 0.14\\)\n\n\nThus: \\[\nP(S \\mid D) = \\frac{0.095}{0.14} \\approx 0.679\n\\] There is a 67.9% chance the email is actually spam.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#the-law-of-total-probability",
    "href": "prob-theory/prob-rules.html#the-law-of-total-probability",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.6 The Law of Total Probability",
    "text": "11.6 The Law of Total Probability\nSometimes, we want to calculate the probability of a complex event \\(B\\), but it‚Äôs hard to compute directly. However, we might know the conditional probabilities of \\(B\\) given simpler events: \\(P(B \\mid A_1), P(B \\mid A_2), ..., P(B \\mid A_k)\\)\nIf \\(A_1, A_2, ..., A_k\\) are:\n\n\nmutually exclusive: \\(A_i \\cap A_j = \\emptyset\\) for \\(i \\ne j\\)\n\n\ncollectively exhaustive: \\(A_1 \\cup A_2 \\cup \\dots \\cup A_k = S\\)\n\n\nThen we can piece things together with the Law of Total Probability.\nLet \\(A_1, A_2, ..., A_k\\) be mutually exclusive and collectively exhaustive events. Then:\n\\[\nP(B) = \\sum_{i=1}^{k} P(A_i) \\cdot P(B \\mid A_i)\n\\]\nWe break down \\(B\\) based on each case \\(A_i\\), multiply by the probability of that case, then add them all up. Think of it like calculating total outcomes across different ‚Äúpaths‚Äù or scenarios. This is illustrated in Figure¬†11.5 for \\(k=7\\).\n\n\n\n\n\n\nFigure¬†11.5: Venn diagram of the law of total. probability\n\n\n\nExample 11.6: Picking Pupils\nThere are 3 school classes:\n\nClass 1: 10 boys, 10 girls\n\nClass 2: 8 boys, 12 girls\n\nClass 3: 6 boys, 14 girls\n\nA class is chosen at random, then a pupil is picked randomly from that class. What‚Äôs the probability the pupil is a girl?\nTo solve this, we define the following events:\n\n\n\\(A_1\\) = Class 1\n\n\n\\(A_2\\) = Class 2\n\n\n\\(A_3\\) = Class 3\n\n\n\\(B\\) = Student is a girl\n\nSince all classes are equally likely we get the following: \\[P(A_1) = P(A_2) = P(A_3) = \\frac{1}{3}\\]\\[P(B \\mid A_1) = \\frac{10}{20} = 0.5\\] \\[P(B \\mid A_2) = \\frac{12}{20} = 0.6\\] \\[P(B \\mid A_3) = \\frac{14}{20} = 0.7\\]\nNow we apply the law of total probability:\n\\[\nP(B) = \\frac{1}{3} \\cdot 0.5 + \\frac{1}{3} \\cdot 0.6 + \\frac{1}{3} \\cdot 0.7 = \\frac{0.5 + 0.6 + 0.7}{3} = \\frac{1.8}{3} = 0.6\n\\]\nThus, there‚Äôs a 60% chance the selected pupil is a girl.\nExample 11.7: Drawing Balls ‚ö´‚ö™\nYou can also illustrate the law of total probability using tree diagrams, which is used in this example. Assume draw two balls without replacement from a box of 7 black and 10 white balls.\nThe tree below illustrates the four possible outcomes of the two draws, along with their probabilities.\n\n\n\nTree\nStart\nStartA\nAP(A) = 7/17Start-&gt;A\n7/17Abar\nAÃÑP(AÃÑ) = 10/17Start-&gt;Abar\n10/17AB\nBP(B|A) = 6/16A-&gt;AB\n6/16ABarB\nBÃÑP(BÃÑ|A) = 10/16A-&gt;ABarB\n10/16AbarB\nBP(B|AÃÑ) = 7/16Abar-&gt;AbarB\n7/16AbarBarB\nBÃÑP(BÃÑ|AÃÑ) = 9/16Abar-&gt;AbarBarB\n9/16AB_lbl\nP(A)¬∑P(B|A)ABarB_lbl\nP(A)¬∑P(BÃÑ|A)AbarB_lbl\nP(AÃÑ)¬∑P(B|AÃÑ)AbarBarB_lbl\nP(AÃÑ)¬∑P(BÃÑ|AÃÑ)\n\n\n\nWe clarify each step now. Let:\n\n\n\\(A\\) = First ball is black\n\n\n\\(\\bar{A}\\) = First ball is white\n\n\n\\(B\\) = Second ball is black\n\nWe want to compute \\(P(B)\\) using total probability. First, we calculate each part:\n\\[P(A) = \\frac{7}{17}\\] since 7 out of 17 are black, and the complement is thus \\[P(\\bar{A}) = \\frac{10}{17}\\]\nIf the first is black we have that \\(P(B \\mid A) = \\frac{6}{16}\\), and one black is removed. If the first is white \\(P(B \\mid \\bar{A}) = \\frac{7}{16}\\), and all black balls are still there.\nNow apply the law of total probability:\n\\[\nP(B) = P(A) \\cdot P(B \\mid A) + P(\\bar{A}) \\cdot P(B \\mid \\bar{A})\n\\]\n\\[\nP(B) = \\frac{7}{17} \\cdot \\frac{6}{16} + \\frac{10}{17} \\cdot \\frac{7}{16}\n\\]\nSome simplifying leads to: \\[\nP(B) = \\frac{42}{272} + \\frac{70}{272} = \\frac{112}{272} = \\frac{7}{17}\n\\]\nThe probability of the second ball being black is again \\(\\frac{7}{17}\\); the same as the original proportion of black balls!",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#example-2-tree-diagram-drawing-balls",
    "href": "prob-theory/prob-rules.html#example-2-tree-diagram-drawing-balls",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.7 Example 2: Tree Diagram ‚Äì Drawing Balls",
    "text": "11.7 Example 2: Tree Diagram ‚Äì Drawing Balls\nWe draw two balls without replacement from a box of 7 black and 10 white balls.\nThis tree illustrates the four possible outcomes of the two draws, along with their probabilities.\n\nYou can also\n\n\nTree\nStart\n1st BallA\n1st BlackP(A) = 7/17Start-&gt;A\n7/17notA\n1st WhiteP(¬¨A) = 10/17Start-&gt;notA\n10/17A_B\n2nd BlackP(B|A) = 6/16A-&gt;A_B\n6/16A_notB\n2nd WhiteP(¬¨B|A) = 10/16A-&gt;A_notB\n10/16notA_B\n2nd BlackP(B|¬¨A) = 7/16notA-&gt;notA_B\n7/16notA_notB\n2nd WhiteP(¬¨B|¬¨A) = 9/16notA-&gt;notA_notB\n9/16",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#understanding-bayes-theorem",
    "href": "prob-theory/prob-rules.html#understanding-bayes-theorem",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.7 üìò Understanding Bayes‚Äô Theorem",
    "text": "11.7 üìò Understanding Bayes‚Äô Theorem\nBayes‚Äô Theorem is a fundamental tool in probability theory, especially when we want to reverse the direction of a conditional probability. Suppose we have a collection of events \\(A_1, A_2, ..., A_n\\) that are mutually exclusive‚Äîno two can happen at the same time‚Äîand together cover the entire sample space. That means one and only one of these events will occur.\nNow assume we know the probability of each of these events, \\(P(A_1), P(A_2), ..., P(A_n)\\), and we also know the conditional probabilities of another event \\(B\\) given each \\(A_i\\), that is, \\(P(B \\mid A_1), ..., P(B \\mid A_n)\\). Our goal is to compute the probability that \\(A_i\\) is true given that \\(B\\) has occurred, written as \\(P(A_i \\mid B)\\).\nBayes‚Äô Theorem gives us exactly this:\n\\[\nP(A_i \\mid B) = \\frac{P(A_i) \\cdot P(B \\mid A_i)}{P(B)}\n\\]\nThe denominator, \\(P(B)\\), is calculated using the law of total probability:\n\\[\nP(B) = \\sum_{i=1}^{k} P(A_i) \\cdot P(B \\mid A_i)\n\\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#a-medical-scenario-genetics-and-thumb-length",
    "href": "prob-theory/prob-rules.html#a-medical-scenario-genetics-and-thumb-length",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.8 üß¨ A Medical Scenario: Genetics and Thumb Length",
    "text": "11.8 üß¨ A Medical Scenario: Genetics and Thumb Length\nImagine a person may or may not carry a certain gene that causes a disease to develop before the age of 40. However, we cannot directly observe whether someone carries the gene. What we can observe is whether they have long thumbs‚Äîa trait which appears more often in people who do have the gene.\nLet us define the events as follows:\\(A\\) is the event that the person has the gene (and will eventually develop the disease), and \\(\\bar{A}\\) is the event that they do not. Let \\(B\\) be the event that the person has long thumbs, and \\(\\bar{B}\\) that they have short thumbs.\nWe are given the following probabilities:\nThe probability that someone carries the gene is \\(P(A) = 0.01\\). Among those who carry the gene, 90% have long thumbs, so \\(P(B \\mid A) = 0.9\\). For those who do not carry the gene, 40% have long thumbs, meaning \\(P(B \\mid \\bar{A}) = 0.4\\).\nNow, imagine someone is 16 years old and notices they have long thumbs. What is the probability that they carry the gene for the disease?",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#solving-with-bayes-theorem",
    "href": "prob-theory/prob-rules.html#solving-with-bayes-theorem",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.9 ‚úçÔ∏è Solving with Bayes‚Äô Theorem",
    "text": "11.9 ‚úçÔ∏è Solving with Bayes‚Äô Theorem\nWe want to compute \\(P(A \\mid B)\\), the probability that someone has the gene, given they have long thumbs. Using Bayes‚Äô Theorem, we write:\n\\[\nP(A \\mid B) = \\frac{P(A) \\cdot P(B \\mid A)}{P(A) \\cdot P(B \\mid A) + P(\\bar{A}) \\cdot P(B \\mid \\bar{A})}\n\\]\nSubstituting the known values:\n\n\\(P(A) \\cdot P(B \\mid A) = 0.01 \\cdot 0.9 = 0.009\\)\n\\(P(\\bar{A}) \\cdot P(B \\mid \\bar{A}) = 0.99 \\cdot 0.4 = 0.396\\)\n\\(P(B) = 0.009 + 0.396 = 0.405\\)\n\nThus,\n\\[\nP(A \\mid B) = \\frac{0.009}{0.405} \\approx 0.0222\n\\]\nThis tells us that the probability a person with long thumbs carries the disease gene is about 2.2%.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#a-puzzle-finding-a-bathroom-in-a-strange-house",
    "href": "prob-theory/prob-rules.html#a-puzzle-finding-a-bathroom-in-a-strange-house",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.10 üö™ A Puzzle: Finding a Bathroom in a Strange House",
    "text": "11.10 üö™ A Puzzle: Finding a Bathroom in a Strange House\nNow let‚Äôs turn to a more lighthearted but equally instructive example.\nImagine you are at a party in a large, unfamiliar house. You‚Äôre searching for the bathroom, which we‚Äôll call \\(T\\). You see three doors in front of you, each leading to a different room: \\(R_1\\), \\(R_2\\), and \\(R_3\\). You don‚Äôt know which one to pick, so you choose randomly.\nOnce inside one of these rooms, you find several doors. In room \\(R_1\\), there are two more doors, one of which leads to the bathroom. In \\(R_2\\), there are four doors, again only one of which leads to \\(T\\). In \\(R_3\\), three doors are present, and two of them lead to \\(T\\).\nYou may only move forward‚Äîthat is, you pick one of the three initial rooms and then try one of its doors.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#what-is-the-probability-that-you-reach-the-bathroom",
    "href": "prob-theory/prob-rules.html#what-is-the-probability-that-you-reach-the-bathroom",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.11 üí° What is the probability that you reach the bathroom?",
    "text": "11.11 üí° What is the probability that you reach the bathroom?\nSince you choose one of the three rooms at random, the probability of entering any specific room is \\(1/3\\). Given the room, the conditional probabilities of finding the bathroom are:\n\n\n\\(P(T \\mid R_1) = 1/2\\)\n\n\n\\(P(T \\mid R_2) = 1/4\\)\n\n\\(P(T \\mid R_3) = 2/3\\)\n\nUsing the law of total probability, we compute:\n\\[\nP(T) = \\frac{1}{3} \\cdot \\frac{1}{2} + \\frac{1}{3} \\cdot \\frac{1}{4} + \\frac{1}{3} \\cdot \\frac{2}{3}\n= \\frac{1}{6} + \\frac{1}{12} + \\frac{2}{9}\n= \\frac{6}{36} + \\frac{3}{36} + \\frac{8}{36} = \\frac{17}{36} \\approx 0.472\n\\]\nSo you have approximately a 47.2% chance of finding the bathroom.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#you-found-the-bathroom-but-which-room-did-you-use",
    "href": "prob-theory/prob-rules.html#you-found-the-bathroom-but-which-room-did-you-use",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.12 üß≠ You Found the Bathroom ‚Äî But Which Room Did You Use?",
    "text": "11.12 üß≠ You Found the Bathroom ‚Äî But Which Room Did You Use?\nLet‚Äôs now suppose you did find the bathroom but forgot which room you entered first. What‚Äôs the probability you entered through room \\(R_2\\)?\nThis is another great application of Bayes‚Äô Theorem. We now want \\(P(R_2 \\mid T)\\), the probability that you passed through \\(R_2\\) given that you found the bathroom.\nAccording to Bayes‚Äô Theorem:\n\\[\nP(R_2 \\mid T) = \\frac{P(R_2) \\cdot P(T \\mid R_2)}{P(T)} = \\frac{\\frac{1}{3} \\cdot \\frac{1}{4}}{\\frac{17}{36}} = \\frac{1}{12} \\cdot \\frac{36}{17} = \\frac{3}{17} \\approx 0.176\n\\]\nSo there‚Äôs about a 17.6% chance that your successful journey to the bathroom started through \\(R_2\\).",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#bayes-theorem",
    "href": "prob-theory/prob-rules.html#bayes-theorem",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.7 Bayes‚Äô Theorem",
    "text": "11.7 Bayes‚Äô Theorem\nBayes‚Äô Theorem is a fundamental tool in probability theory, especially when we want to reverse the direction of a conditional probability. Suppose we have a collection of events \\(A_1, A_2, ..., A_n\\) that are mutually exclusive; no two can happen at the same time, and together these events cover the entire sample space. That means one and only one of these events will occur.\nNow assume we know the probability of each of these events, \\(P(A_1), P(A_2), ..., P(A_n)\\), and we also know the conditional probabilities of another event \\(B\\) given each \\(A_i\\), that is, \\(P(B \\mid A_1), ..., P(B \\mid A_n)\\). Our goal is to compute the probability that \\(A_i\\) is true given that \\(B\\) has occurred, written as \\(P(A_i \\mid B)\\).\nBayes‚Äô Theorem gives us exactly this:\n\\[\nP(A_i \\mid B) = \\frac{P(A_i) \\cdot P(B \\mid A_i)}{P(B)}\n\\]\nThe denominator, \\(P(B)\\), is calculated using the law of total probability:\n\\[\nP(B) = \\sum_{i=1}^{k} P(A_i) \\cdot P(B \\mid A_i)\n\\]\nExample 11.8: Genetics and Thumb Length\nImagine a person may or may not carry a certain gene that causes a disease to develop before the age of 40. However, we cannot directly observe whether someone carries the gene. What we can observe is whether they have long thumbs; a trait which appears more often in people who do have the gene.\nLet us define the events as follows:\\(A\\) is the event that the person has the gene (and will eventually develop the disease), and \\(\\bar{A}\\) is the event that they do not. Let \\(B\\) be the event that the person has long thumbs, and \\(\\bar{B}\\) that they have short thumbs.\nWe are given the following probabilities:\nThe probability that someone carries the gene is \\(P(A) = 0.01\\). Among those who carry the gene, 90% have long thumbs, so \\(P(B \\mid A) = 0.9\\). For those who do not carry the gene, 40% have long thumbs, meaning \\(P(B \\mid \\bar{A}) = 0.4\\).\nNow, imagine someone is 16 years old and notices they have long thumbs. What is the probability that they carry the gene for the disease?\nWe want to compute \\(P(A \\mid B)\\), the probability that someone has the gene, given they have long thumbs. Using Bayes‚Äô Theorem, we write:\n\\[\nP(A \\mid B) = \\frac{P(A) \\cdot P(B \\mid A)}{P(A) \\cdot P(B \\mid A) + P(\\bar{A}) \\cdot P(B \\mid \\bar{A})}\n\\]\nSubstituting the known values:\n\n\\(P(A) \\cdot P(B \\mid A) = 0.01 \\cdot 0.9 = 0.009\\)\n\\(P(\\bar{A}) \\cdot P(B \\mid \\bar{A}) = 0.99 \\cdot 0.4 = 0.396\\)\n\\(P(B) = 0.009 + 0.396 = 0.405\\)\n\nThus,\n\\[\nP(A \\mid B) = \\frac{0.009}{0.405} \\approx 0.0222\n\\]\nThis tells us that the probability a person with long thumbs carries the disease gene is about 2.2%.\nExample 11.9: FInding the Toilet\nNow let‚Äôs turn to a more lighthearted but equally instructive example. Imagine you are at a party in a large, unfamiliar house. You‚Äôre searching for the toilet, which we‚Äôll call \\(T\\). You see three doors in front of you, each leading to a different room: \\(R_1\\), \\(R_2\\), and \\(R_3\\). You don‚Äôt know which one to pick, so you choose randomly.\nOnce inside one of these rooms, you find several doors. In room \\(R_1\\), there are two more doors, one of which leads to the bathroom. In \\(R_2\\), there are four doors, again only one of which leads to \\(T\\). In \\(R_3\\), three doors are present, and two of them lead to \\(T\\).\nYou may only move forward, that is, you pick one of the three initial rooms and then try one of its doors.\n\nWhat is the probability that you reach the bathroom?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSince you choose one of the three rooms at random, the probability of entering any specific room is \\(1/3\\). Given the room, the conditional probabilities of finding the bathroom are:\n\n\n\\(P(T \\mid R_1) = 1/2\\)\n\n\n\\(P(T \\mid R_2) = 1/4\\)\n\n\\(P(T \\mid R_3) = 2/3\\)\n\nUsing the law of total probability, we compute:\n\\[\nP(T) = \\frac{1}{3} \\cdot \\frac{1}{2} + \\frac{1}{3} \\cdot \\frac{1}{4} + \\frac{1}{3} \\cdot \\frac{2}{3}\n= \\frac{1}{6} + \\frac{1}{12} + \\frac{2}{9}\n= \\frac{6}{36} + \\frac{3}{36} + \\frac{8}{36} = \\frac{17}{36} \\approx 0.472\n\\]\nSo you have approximately a 47.2% chance of finding the bathroom.\n\n\n\n\nYou found the bathroom, but which room did you use?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet‚Äôs now suppose you did find the bathroom but forgot which room you entered first. What‚Äôs the probability you entered through say room \\(R_2\\)?\nThis is another great application of Bayes‚Äô Theorem. We now want \\(P(R_2 \\mid T)\\), the probability that you passed through \\(R_2\\) given that you found the bathroom.\nAccording to Bayes‚Äô Theorem:\n\\[\nP(R_2 \\mid T) = \\frac{P(R_2) \\cdot P(T \\mid R_2)}{P(T)} = \\frac{\\frac{1}{3} \\cdot \\frac{1}{4}}{\\frac{17}{36}} = \\frac{1}{12} \\cdot \\frac{36}{17} = \\frac{3}{17} \\approx 0.176\n\\]\nSo there‚Äôs about a 17.6% chance that your successful journey to the bathroom started through \\(R_2\\). Similarly: \\[\nP(R_1 \\mid T) =  \\frac{P(R_1) \\cdot P(T \\mid R_1)}{P(T)} = \\frac{\\frac{1}{3} \\cdot \\frac{1}{2}}{\\frac{17}{36}} = \\frac{1}{6} \\cdot \\frac{36}{17} = \\frac{6}{17} \\approx 0.353\n\\] and \\[\nP(R_3 \\mid T) = \\frac{P(R_3) \\cdot P(T \\mid R_3)}{P(T)} = \\frac{\\frac{1}{3} \\cdot \\frac{2}{3}}{\\frac{17}{36}} = \\frac{2}{9} \\cdot \\frac{36}{17} = \\frac{8}{17} \\approx 0.471\n\\]",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "prob-theory/prob-rules.html#bayes-theorem-1",
    "href": "prob-theory/prob-rules.html#bayes-theorem-1",
    "title": "\n11¬† Probability Rules\n",
    "section": "\n11.9 Bayes‚Äô Theorem",
    "text": "11.9 Bayes‚Äô Theorem\nWe want to compute \\(P(A \\mid B)\\), the probability that someone has the gene, given they have long thumbs. Using Bayes‚Äô Theorem, we write:\n\\[\nP(A \\mid B) = \\frac{P(A) \\cdot P(B \\mid A)}{P(A) \\cdot P(B \\mid A) + P(\\bar{A}) \\cdot P(B \\mid \\bar{A})}\n\\]\nSubstituting the known values:\n\n\\(P(A) \\cdot P(B \\mid A) = 0.01 \\cdot 0.9 = 0.009\\)\n\\(P(\\bar{A}) \\cdot P(B \\mid \\bar{A}) = 0.99 \\cdot 0.4 = 0.396\\)\n\\(P(B) = 0.009 + 0.396 = 0.405\\)\n\nThus,\n\\[\nP(A \\mid B) = \\frac{0.009}{0.405} \\approx 0.0222\n\\]\nThis tells us that the probability a person with long thumbs carries the disease gene is about 2.2%.",
    "crumbs": [
      "Probability Theory",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Probability Rules</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html",
    "href": "rvs-probdists/random-variables.html",
    "title": "12¬† Random Variables",
    "section": "",
    "text": "12.1 What is a Random Variable?\nIn many real-world situations, from rolling a die to measuring rainfall, we deal with outcomes that are inherently uncertain. To make sense of this uncertainty, we use random variables: mathematical tools that assign numerical values to the outcomes of random processes. They allow us to translate chance into structure, giving us a way to analyze and predict patterns in uncertain environments.\nThis section introduces the concept of random variables and the probability distributions that describe their behavior. A probability distribution not only lists the possible values a random variable can take, but also tells us how likely each value is to occur. Whether the variable counts discrete outcomes or measures continuous quantities, understanding its distribution is key to interpreting the role of randomness in data, decisions, and models.\nIn statistics, sampling should always be done randomly. This means that before the sampling occurs, we do not know who will be selected; it‚Äôs a random experiment where all individuals in the population are possible outcomes.\nTo introduce the idea of a random variable (also called a stochastic variable), imagine a small population of six individuals: Anna, Bob, Carol, David, Erin, Finn. This is shown in Figure¬†12.1 (a).\nWe are not primarily interested in the individuals themselves, but in the values they hold on some variable. For example, suppose we want to study whether each person has a driver‚Äôs license. Let‚Äôs assign a value of 1 to those who have a license and 0 to those who don‚Äôt. Now, instead of thinking about names, our outcome space transforms into a set of 1‚Äôs and 0‚Äôs, depending on the presence or absence of a driver‚Äôs license. This is shown in Figure¬†12.1 (b).\nIn probability theory, we often want to describe a random experiment using a variable before the experiment is carried out. Because we do not know in advance what the outcome will be, we use a random variable to represent the result. This variable is typically denoted by a capital letter, such as \\(X\\), \\(Y\\), or \\(Z\\), often chosen from the end of the alphabet.\nFor example, we might define the variable \\(X\\) as:\n\\(X\\) = Number of people with a driver‚Äôs license\nThis variable can take on different values depending on who is selected during the sampling process. By grouping all individuals who share the same outcome value for our variable, we divide the outcome space into disjoint events. Suppose we define the event \\(A\\) as: ‚ÄúA randomly selected individual has a driver‚Äôs license.‚Äù\nThis allows us to split the outcome space into two distinct parts: those with \\(X = 1\\) (event \\(A\\)), and those with \\(X = 0\\) (event \\(\\bar{A}\\)), as shown in Figure¬†12.2.\nIf three of the six individuals in the population have a license, then the probability of selecting a person with a license is:\n\\[\nP(X = 1) = \\frac{3}{6} = 0.5\n\\]\nAnd the probability of selecting someone without a license is:\n\\[\nP(X = 0) = \\frac{3}{6} = 0.5\n\\]\nThis defines the probability distribution of the variable \\(X\\). Note that we can construct an infinite number of random variables for the same random experiment. For instance, if we use the same group of six people, we could define a new variable \\(X\\) to represent vaccination instead of license status. Then we would need to specify what values the variable takes (e.g., 1 = vaccinated, 0 = not vaccinated), define the corresponding event \\(A\\), and determine the resulting probability distribution for this new version of \\(X\\).\nOnce the random event has occurred and the experiment is completed, the stochastic variable will have assumed a specific value. At that point, we switch notation and use lowercase letters (such as \\(x\\), \\(y\\), or \\(z\\)) to refer to the observed values. We write \\(P(x) = P(X = x)\\), which defines the probability function for the variable \\(X\\). This function tells us the likelihood that \\(X\\) takes on specific values \\(x\\).\nIn summary, a random variable is a numerical variable whose value is determined by the outcome of a random experiment. Before the experiment is performed, we don‚Äôt know what value the variable will take, but we do know the set of possible values it may assume. Once the experiment is conducted, the variable takes on a definite value, and we can analyze its behavior using its probability distribution.\nWe use uppercase letters like \\(X\\) to denote random variables, and the corresponding lowercase letters (like \\(x\\)) to represent actual outcomes. Depending on the context, random variables may be discrete or continuous, and each has its own type of probability model.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#defining-the-variable",
    "href": "rvs-probdists/random-variables.html#defining-the-variable",
    "title": "12¬† Random Variables",
    "section": "12.2 ‚úçÔ∏è Defining the Variable",
    "text": "12.2 ‚úçÔ∏è Defining the Variable\nIn probability theory, we often want to describe a random experiment using a variable before the experiment is carried out. Because we do not know in advance what the outcome will be, we use a stochastic variable to represent the result. This variable is typically denoted by a capital letter, such as ( X ), ( Y ), or ( Z ), often chosen from the end of the alphabet.\nFor example, we might define the variable ( X ) as:\n\\[\nX = \\text{Number of people with a driver‚Äôs license}\n\\]\nThis variable can take on different values depending on who is selected during the sampling.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#interpreting-outcomes-through-variables",
    "href": "rvs-probdists/random-variables.html#interpreting-outcomes-through-variables",
    "title": "12¬† Random Variables",
    "section": "12.3 üß† Interpreting Outcomes Through Variables",
    "text": "12.3 üß† Interpreting Outcomes Through Variables\nBy grouping all individuals who share the same outcome value for our variable, we divide the outcome space into disjoint events. Suppose we define the event ( A ) as:\n‚ÄúA randomly selected individual has a driver‚Äôs license.‚Äù\nThis allows us to split the outcome space into two distinct parts: those with ( X = 1 ) (event ( A )) and those with ( X = 0 ) (event ( {A} )).\n\n\n\n\n\n\n\nFigure¬†12.2: Text.\n\n\n\n\nIf three of the six individuals in the population have a license, then the probability of selecting a person with a license is:\n\\[\nP(X = 1) = \\frac{3}{6} = 0.5\n\\]\nAnd the probability of selecting someone without a license is:\n\\[\nP(X = 0) = \\frac{3}{6} = 0.5\n\\]\nThis defines the probability distribution of the variable ( X ).",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#many-variables-one-experiment",
    "href": "rvs-probdists/random-variables.html#many-variables-one-experiment",
    "title": "12¬† Random Variables",
    "section": "12.2 üîÅ Many Variables, One Experiment",
    "text": "12.2 üîÅ Many Variables, One Experiment\nImportantly, we can define many different stochastic variables based on the same random experiment. For instance, if we use the same group of six people, we could define a new variable ( X ) to represent gender instead of license status. Then we would need to specify what values the variable takes (e.g., 1 = woman, 0 = man), define the corresponding event ( A ), and determine the resulting probability distribution for this new version of ( X ).",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#values-and-notation",
    "href": "rvs-probdists/random-variables.html#values-and-notation",
    "title": "12¬† Random Variables",
    "section": "12.2 üìè Values and Notation",
    "text": "12.2 üìè Values and Notation\nOnce the random event has occurred and the experiment is completed, the stochastic variable will have assumed a specific value. At that point, we switch notation and use lowercase letters (such as ( x ), ( y ), or ( z )) to refer to the observed values.\nWe often write ( P(x) = P(X = x) ), which defines the probability function for the variable ( X ). This function tells us the likelihood that ( X ) takes on the specific value ( x ).",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#a-concrete-example",
    "href": "rvs-probdists/random-variables.html#a-concrete-example",
    "title": "12¬† Random Variables",
    "section": "12.3 üßÆ A Concrete Example",
    "text": "12.3 üßÆ A Concrete Example\nLet‚Äôs say we define ( X ) as the number of dots (prickar) shown when rolling a standard six-sided die. Before the die is rolled, ( X ) is a stochastic variable representing the yet-unknown outcome. Once the die is rolled and shows, say, three dots, we would say that:\n\\[\nX = 3\n\\]\nor in observed-value notation:\n\\[\nx = 3\n\\]\nThis value is now fixed, and the randomness is gone ‚Äî the experiment has been performed.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#discrete-vs.-continuous-stochastic-variables",
    "href": "rvs-probdists/random-variables.html#discrete-vs.-continuous-stochastic-variables",
    "title": "12¬† Random Variables",
    "section": "12.4 üßÆ Discrete vs.¬†Continuous Stochastic Variables",
    "text": "12.4 üßÆ Discrete vs.¬†Continuous Stochastic Variables\nA discrete stochastic variable is one that can only take on a countable number of values. This might be a finite set, or it could be an infinite but countable one. Common examples include:\n\nThe number of dots shown when rolling a die\nThe sum of two dice rolls\nThe number of trials needed to roll a six\nThe number of girls in a randomly selected family with three children\n\nOn the other hand, a **",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#what-is-a-random-variable",
    "href": "rvs-probdists/random-variables.html#what-is-a-random-variable",
    "title": "12¬† Random Variables",
    "section": "",
    "text": "(a) Sample space with names.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Sample space with coded variable of interest.\n\n\n\n\n\n\n\nFigure¬†12.1: Random variables in sample space.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†12.2: Outcome space divided into disjoint events.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#discrete-vs.-continuous-random-variables",
    "href": "rvs-probdists/random-variables.html#discrete-vs.-continuous-random-variables",
    "title": "12¬† Random Variables",
    "section": "12.2 Discrete vs.¬†Continuous Random Variables",
    "text": "12.2 Discrete vs.¬†Continuous Random Variables\nA discrete stochastic variable is one that can only take on a countable number of values. This might be a finite set, or it could be an infinite but countable one. Common examples include:\n\nThe number of dots shown when rolling a die\nThe sum of two dice rolls\nThe number of trials needed to roll a six\nThe number of girls in a randomly selected family with three children\n\nOn the other hand, a continuous stochastic variable can take on any value within an interval of the real number line. These variables are useful for modeling quantities that are measured rather than counted. Some examples include:\n\nThe length of a randomly selected newborn child\nThe lifespan of a randomly chosen light bulb\nThe annual income of a randomly chosen household",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#summary",
    "href": "rvs-probdists/random-variables.html#summary",
    "title": "12¬† Random Variables",
    "section": "12.3 üîÅ Summary",
    "text": "12.3 üîÅ Summary\nA stochastic variable is a numerical variable whose value is determined by the outcome of a random experiment. Before the experiment is performed, we don‚Äôt know what value the variable will take, but we do know the set of possible values it may assume. Once the experiment is conducted, the variable takes on a definite value, and we can analyze its behavior using its probability distribution.\nWe use uppercase letters like ( X ) to denote stochastic variables, and the corresponding lowercase letters (like ( x )) to represent actual outcomes. Depending on the context, stochastic variables may be discrete or continuous, and each has its own type of probability model.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#exercises",
    "href": "rvs-probdists/random-variables.html#exercises",
    "title": "12¬† Random Variables",
    "section": "12.6 Exercises",
    "text": "12.6 Exercises\nFor each of the random variables below, decide whether it is discrete or continuous:\n\nThe number of books a student checked out from the library this week\n\nThe time (in minutes) it takes a person to run 5 kilometers\n\nThe number of heads in 10 coin tosses\n\nA person‚Äôs height (in centimeters)\n\nThe number of emails received in one day\n\nThe daily average temperature in a city (in ¬∞C)\n\nWhether a person owns a smartphone (yes = 1, no = 0)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDiscrete ‚Äì counts books, can only be whole numbers\n\nContinuous ‚Äì time can be measured with decimals (e.g., 23.75 minutes)\n\nDiscrete ‚Äì number of heads is a count between 0 and 10\n\nContinuous ‚Äì height is measurable and can take any value in a range\n\nDiscrete ‚Äì number of emails is countable\n\nContinuous ‚Äì temperature is measured on a continuous scale\n\nDiscrete ‚Äì binary variable (yes/no)\n\n\n\n\n\nTwo workers, Alice and Bob, work independently on a task. The time (in hours) it takes each of them to complete their part is modeled as discrete random variables:\n\\(X\\) is Alice‚Äôs completion time, with \\(\\mathbb{E}(X) = 5\\) and \\(\\mathbb{V}(X) = 1.5\\)\n\\(Y\\) is Bob‚Äôs completion time, with \\(\\mathbb{E}(Y) = 6\\) and \\(\\mathbb{V}(Y) = 2\\)\nAssume \\(X\\) and \\(Y\\) are independent. Now define:\n\n\\(T = X + Y\\) as the total time they spend\n\\(D = Y - X\\) as the difference between their times\n\nCompute \\(\\mathbb{E}(T)\\), \\(\\mathbb{V}(T)\\), \\(\\mathbb{E}(D)\\) and \\(\\mathbb{V}(D)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTotal time: \\(T = X + Y\\). Using linearity of expectation:\n\\[\n\\mathbb{E}(T) = \\mathbb{E}(X) + \\mathbb{E}(Y) = 5 + 6 = 11\n\\]\nSince \\(X\\) and \\(Y\\) are independent:\n\\[\n\\mathbb{V}(T) = \\mathbb{V}(X) + \\mathbb{V}(Y) = 1.5 + 2 = 3.5\n\\]\nTime difference: \\(D = Y - X\\). Again, using linearity:\n\\[\n\\mathbb{E}(D) = \\mathbb{E}(Y - X) = \\mathbb{E}(Y) - \\mathbb{E}(X) = 6 - 5 = 1\n\\]\nVariance of the difference (since \\(X\\) and \\(Y\\) are independent):\n\\[\n\\mathbb{V}(D) = \\mathbb{V}(Y) + \\mathbb{V}(X) = 2 + 1.5 = 3.5\n\\]",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#expected-value-and-variance",
    "href": "rvs-probdists/random-variables.html#expected-value-and-variance",
    "title": "12¬† Random Variables",
    "section": "12.3 Expected Value and Variance",
    "text": "12.3 Expected Value and Variance\nA random variable‚Äôs probability distribution can, much like an empirical data set, be described using measures of central tendency and spread.\nThe expected value of a random variable, often denoted as \\(\\mathbb{E}(X)\\) or \\(\\mu\\), represents the long-run average outcome of a random process if it were repeated many times. It‚Äôs a kind of ‚Äúcenter of gravity‚Äù for the distribution ‚Äî where the outcomes tend to balance out.\nWhile the expected value tells us the average, the variance of a random variable, denoted \\(\\mathbb{V}(X)\\), tells us how spread out the values are around the mean. A small variance means values cluster tightly around the mean; a large variance means they are more widely scattered.\nSo even if we don‚Äôt yet know the outcome of a random process, we can describe how it typically behaves: where it centers (expected value) and how much it varies (standard deviation). This way, we can summarize the behavior of randomness in both location and consistency ‚Äî a powerful way to make sense of uncertainty. We explore these concepts further in the next chapter.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html",
    "href": "rvs-probdists/discrete-dist.html",
    "title": "13¬† Discrete Probability Distributions",
    "section": "",
    "text": "13.1 Probability Mass Function (PMF)\nWhen dealing with discrete random variables, we are interested in how likely it is that the variable takes on specific values. This relationship, the link between possible values and their associated probabilities, is described by the probability distribution of the random variable.\nThe probability mass function (PMF) is a mathematical function that assigns a probability to each value the variable can take. In other words, the PMF is the mathematical expression of the probability distribution. The distribution is the overall concept; the PMF is the function that specifies the details.\nWe usually denote the PMF as \\(P(x)\\), where:\n\\[\nP(x) = P(X = x)\n\\] This gives the probability that the random variable \\(X\\) equals a specific value \\(x\\).\nFor the PMF to describe a valid distribution, it must satisfy two conditions:\nIf we know \\(P(x)\\) for all values \\(x\\) that \\(X\\) can take, we say we know the probability distribution of \\(X\\). We can present a probability distribution in several forms: as a table, a bar chart, or through a formula.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#probability-mass-function-pmf",
    "href": "rvs-probdists/discrete-dist.html#probability-mass-function-pmf",
    "title": "13¬† Discrete Probability Distributions",
    "section": "",
    "text": "Each probability must be between 0 and 1: \\[\n0 \\leq P(x) \\leq 1\n\\]\nThe total probability across all values must sum to 1: \\[\n\\sum_x P(x) = 1\n\\]\n\n\nExample 12.1: Coin Toss\nSuppose we toss a fair coin two times. Let the random variable \\(X\\) represent the number of heads observed. The sample space consists of four equally likely outcomes:\n\nHead, Head ‚Üí \\(X = 2\\)\n\nHead, Tail ‚Üí \\(X = 1\\)\n\nTail, Head ‚Üí \\(X = 1\\)\n\nTail, Tail ‚Üí \\(X = 0\\)\n\n\nEach of these outcomes has probability 0.25. From this, we can define the probability mass function (PMF) of \\(X\\) as:\n\\[\nP(x) =\n\\begin{cases}\n0.25 & \\text{if } x = 0 \\\\\n0.50 & \\text{if } x = 1 \\\\\n0.25 & \\text{if } x = 2 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nThe table below presents a representation of the PMF; showing the values of \\(P(x)\\) for each value in the support of \\(X\\):\n\n\nOutcomes\n\n\\(x\\) (Number of heads)\n\\(P(x)\\)\n\n\n\n(Tail, Tail)\n0\n0.25\n\n\n(Head, Tail), (Tail, Head)\n1\n0.50\n\n\n(Head, Head)\n2\n0.25\n\n\n\nWe can confirm that this satisfies the requirement:\n\\[\n\\sum_x P(x) = 0.25 + 0.5 + 0.25 = 1\n\\]\nThis confirms that \\(P(x)\\) defines a valid probability distribution.\nThis table is one way of representing the probability distribution of \\(X\\). Another way to represent it is by using bar plot:",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#cumualtive-distribution-function-cmf",
    "href": "rvs-probdists/discrete-dist.html#cumualtive-distribution-function-cmf",
    "title": "\n13¬† Discrete Probability Distributions\n",
    "section": "\n13.2 Cumualtive Distribution Function (CMF)",
    "text": "13.2 Cumualtive Distribution Function (CMF)",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#cumulative-distribution-function-cmf",
    "href": "rvs-probdists/discrete-dist.html#cumulative-distribution-function-cmf",
    "title": "\n13¬† Discrete Probability Distributions\n",
    "section": "\n13.2 Cumulative Distribution Function (CMF)",
    "text": "13.2 Cumulative Distribution Function (CMF)",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#t-he-cumulative-distribution-function-cdf",
    "href": "rvs-probdists/discrete-dist.html#t-he-cumulative-distribution-function-cdf",
    "title": "\n13¬† Discrete Probability Distributions\n",
    "section": "\n13.2 T he Cumulative Distribution Function (CDF)",
    "text": "13.2 T he Cumulative Distribution Function (CDF)\nFor a discrete random variable \\(X\\), we can describe its probability distribution not only using the probability mass function, but also through its cumulative distribution function, denoted \\(F(x)\\).\nThe CDF gives the probability that \\(X\\) takes on a value less than or equal to a given number \\(x\\):\n\\[\nF(x) = P(X \\leq x)\n\\]\nThis function grows step by step as we move through the possible values of \\(X\\), accumulating the total probability up to each point.\nExample 12.1: Coin Toss (continued)\nWe continue here with the example abive, where \\(X\\) is the number of heads in two tosses of a fair coin. The PMF and corresponding CDF values are:\n\n\n\\(x\\)\n\\(P(x)\\)\n\\(F(x)\\)\n\n\n\n0\n0.25\n0.25\n\n\n1\n0.50\n0.75\n\n\n2\n0.25\n1.00\n\n\n\nThe last value of \\(F(x)\\) must always equal 1, since the total probability must sum to 1.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#the-cumulative-distribution-function-cdf",
    "href": "rvs-probdists/discrete-dist.html#the-cumulative-distribution-function-cdf",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.2 The Cumulative Distribution Function (CDF)",
    "text": "13.2 The Cumulative Distribution Function (CDF)\nFor a discrete random variable \\(X\\), we can describe its probability distribution not only using the probability mass function, but also through its cumulative distribution function, denoted \\(F(x)\\).\nThe CDF gives the probability that \\(X\\) takes on a value less than or equal to a given number \\(x\\):\n\\[\nF(x) = P(X \\leq x)\n\\]\nThis function grows step by step as we move through the possible values of \\(X\\), accumulating the total probability up to each point.\nExample 12.1: Coin Toss (continued)\nWe continue here with the example abive, where \\(X\\) is the number of heads in two tosses of a fair coin. The PMF and corresponding CDF values are:\n\n\n\\(x\\)\n\\(P(x)\\)\n\\(F(x)\\)\n\n\n\n0\n0.25\n0.25\n\n\n1\n0.50\n0.75\n\n\n2\n0.25\n1.00\n\n\n\nThe last value of \\(F(x)\\) must always equal 1, since the total probability must sum to 1.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#expected-value-of-a-discrete-random-variable",
    "href": "rvs-probdists/discrete-dist.html#expected-value-of-a-discrete-random-variable",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.3 Expected Value of a Discrete Random Variable",
    "text": "13.3 Expected Value of a Discrete Random Variable\nJust like empirical data can be summarized with averages and standard deviations, a discrete probability distribution can also be described using corresponding statistical measures. These include measures of central tendency, such as the expected value, and measures of variability, such as the standard deviation.\nThe expected value plays the role of a mean or average. But because the possible outcomes may occur with different probabilities, we must take this into account by assigning more weight to more likely outcomes. This means the values are weighted by their associated probabilities.\nTo find the expected value of a discrete random variable, we do not simply average the outcomes. Instead, we compute a weighted average where the weights are given by the probability mass function.\nThe expected value of a discrete random variable \\(X\\) is denoted by \\(\\mathbb{E}(X)\\), where \\(\\mathbb{E}\\) stands for expectation. It is defined as:\n\\[\n\\mathbb{E}(X) = \\sum_{x} x \\cdot P(x) = \\mu_X\n\\]\nThis formula tells us to multiply each value \\(x\\) by its probability \\(P(x)\\) and then sum the results over all possible values of \\(X\\). The result, \\(\\mathbb{E}(X)\\), gives us the value we expect to observe on average in the long run, if we were to randomly select a value of \\(X\\) according to its probability distribution.\nThe expected value represents the ‚Äúcenter‚Äù of the distribution ‚Äî the point where the values balance, considering how often each one occurs. For example, if a random variable has most of its probability mass near 1, its expected value will be close to 1.\nIt‚Äôs important to note that expected value doesn‚Äôt predict what will happen* ‚Äî it predicts what happens on average. It‚Äôs like asking, ‚ÄúWhat would I get if the universe reran this scenario a million times?‚Äù\nExample 12.1: Coin Toss (continued)\nIf you revisit the coin-toss example where \\(X\\) counts the number of heads in two tosses, you would compute the expected value as:\n\\[\n\\mathbb{E}(X) = \\sum_{x} x \\cdot P(x) = 0 \\cdot 0.25 + 1 \\cdot 0.5 + 2 \\cdot 0.25 = 1\n\\]\nThis confirms that we expect to get 1 head on average when tossing a coin twice.\nExample 12.2: Lottery - A Risky Business\nLet‚Äôs say you‚Äôre eyeing a lottery with 100 tickets. Each ticket costs 1‚Ç¨, and you‚Äôre feeling lucky. The prize setup is:\n\nOne lucky winner gets 50‚Ç¨\n\nThree people win 10‚Ç¨\n\nFive folks get 2‚Ç¨\n\nAnd‚Ä¶ the remaining 91 get absolutely nothing\n\nLet‚Äôs define a random variable \\(X\\) as the payout of a randomly selected ticket.\nSo what values can \\(X\\) take?\n\\[\nX \\in \\{0, 2, 10, 50\\}\n\\]\nBut ‚Äî and here‚Äôs the key ‚Äî just averaging those values like this:\n\\[\n\\frac{0 + 2 + 10 + 50}{4} = 15.5\n\\]\n‚Ä¶makes no sense! That would only be correct if all outcomes were equally likely, which they‚Äôre definitely not. Most people walk away with nothing. So we need to weight each value by how often it actually happens.\nLet‚Äôs build a table to show how many tickets correspond to each prize:\n\n\nPayout (‚Ç¨)\nNumber of tickets\nProbability \\(P(x)\\)\n\n\n\n\n0\n91\n0.91\n\n\n2\n5\n0.05\n\n\n10\n3\n0.03\n\n\n50\n1\n0.01\n\n\n\nSo now we have a complete probability distribution for \\(X\\) which is visualized below:\n\n\n\n\n\n\n\n\nLet‚Äôs compute the expected value \\(\\mathbb{E}(X)\\) using the PMF:\n\\[\n\\mathbb{E}(X) = \\sum_x x \\cdot P(x) = 0 \\cdot 0.91 + 2 \\cdot 0.05 + 10 \\cdot 0.03 + 50 \\cdot 0.01 = 0.90\n\\]\nSo even though one person might win 50‚Ç¨, the average payout per ticket is just 90 cents. That means if you pay 1‚Ç¨ per ticket, you‚Äôre losing 10 cents on average.\nMost of the time, lottery isn‚Äôt just random ‚Äî it‚Äôs rigged (in favor of the organizers)",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#interpretation",
    "href": "rvs-probdists/discrete-dist.html#interpretation",
    "title": "\n13¬† Discrete Probability Distributions\n",
    "section": "\n13.4 üß† Interpretation",
    "text": "13.4 üß† Interpretation\nThe expected value represents the ‚Äúcenter‚Äù of the distribution ‚Äî the point where the values balance, considering how often each one occurs. For example, if a random variable has most of its probability mass near 1, its expected value will be close to 1.\nIt‚Äôs important to note that the expected value is not necessarily one of the actual outcomes of the variable. Rather, it is the average outcome when all values are considered together, weighted by how likely they are.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#example-reference",
    "href": "rvs-probdists/discrete-dist.html#example-reference",
    "title": "\n13¬† Discrete Probability Distributions\n",
    "section": "\n13.5 üìé Example Reference",
    "text": "13.5 üìé Example Reference\nIf you revisit the coin-toss example where \\(X\\) counts the number of heads in two tosses, you would compute the expected value as:\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.25 + 1 \\cdot 0.5 + 2 \\cdot 0.25 = 1\n\\]\nThis confirms that we expect to get 1 head on average when tossing a coin twice.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#show-it-with-r-optional",
    "href": "rvs-probdists/discrete-dist.html#show-it-with-r-optional",
    "title": "\n13¬† Discrete Probability Distributions\n",
    "section": "\n13.4 üìä Show It with R (Optional)",
    "text": "13.4 üìä Show It with R (Optional)",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#variance-and-standard-deviation-of-a-discrete-random-variable",
    "href": "rvs-probdists/discrete-dist.html#variance-and-standard-deviation-of-a-discrete-random-variable",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.4 Variance and Standard Deviation of a Discrete Random Variable",
    "text": "13.4 Variance and Standard Deviation of a Discrete Random Variable\nJust as sample variance measures the average squared deviation from the sample mean, the variance of a random variable measures the average squared deviation from its expected value, weighted by the probability mass function.\nLet \\(X\\) be a discrete random variable with expected value \\(\\mu_X = \\mathbb{E}(X)\\). The variance of \\(X\\) is defined as:\n\\[\n\\text{Var}(X) = \\mathbb{E}[(X - \\mu_X)^2] = \\sum_x (x - \\mu_X)^2 \\cdot P(x)\n\\]\nAlternatively, variance can also be calculated using:\n\\[\n\\text{Var}(X) = \\mathbb{E}(X^2) - (\\mathbb{E}(X))^2\n\\]\nThe standard deviation is the square root of the variance:\n\\[\n\\sigma_X = \\sqrt{\\text{Var}(X)}\n\\]\nThese measures provide information about how much variability there is in the possible values of \\(X\\).\nExample 12.1: Coin Toss (continued)\nConsider again the random variable \\(X =\\) number of heads in two tosses of a fair coin. We previously found the expected value:\n\\[\n\\mathbb{E}(X) = 1\n\\]\nWe now calculate the variance by constructing the following table:\n\n\n\\(x\\)\n\\(P(x)\\)\n\\((x - \\mu_X)^2\\)\n\\((x - \\mu_X)^2 \\cdot P(x)\\)\n\n\n\n0\n0.25\n1\n0.25\n\n\n1\n0.50\n0\n0\n\n\n2\n0.25\n1\n0.25\n\n\n\n\n\n0.50\n\n\n\nSo,\n\\[\n\\text{Var}(X) = 0.50 \\quad \\text{and} \\quad \\sigma_X = \\sqrt{0.50} \\approx 0.7071\n\\]\nThis tells us that the number of heads in two tosses typically deviates by about 0.71 from the expected value.\nExample 12.2: Lottery - A Risky Business\nLet \\(X\\) denote the payout from a randomly selected lottery ticket. From earlier, we know the expected value is:\n\\[\n\\mu_X = \\mathbb{E}(X) = 0.9\n\\]\nTo compute the variance, we first calculate the squared deviations from the mean for each possible payout:\n\n\n\\(x\\)\n\\(P(x)\\)\n\\((x - \\mu_X)^2\\)\n\n\n\n0\n0.91\n\\((0 - 0.9)^2 = 0.81\\)\n\n\n2\n0.05\n\\((2 - 0.9)^2 = 1.21\\)\n\n\n10\n0.03\n\\((10 - 0.9)^2 = 82.81\\)\n\n\n50\n0.01\n\\((50 - 0.9)^2 = 2410.81\\)\n\n\n\nNow multiply by probabilities:\n\\[\n\\text{Var}(X) = 0.91 \\cdot 0.81 + 0.05 \\cdot 1.21 + 0.03 \\cdot 82.81 + 0.01 \\cdot 2410.81 = 27.39\n\\]\nSo the standard deviation is:\n\\[\n\\sigma_X = \\sqrt{27.39} \\approx 5.23\n\\]\nSo in summary, the expected payout of 0.9‚Ç¨ indicated that on average, each ticket returns 90cents. However, no single ticket actually pays exactly 0.9‚Ç¨. This value is theoretical ‚Äî it describes the average over many repetitions.\nThe standard deviation of 5.23‚Ç¨ tells us that the actual payout from a randomly chosen ticket typically deviates from the expected value by about 5‚Ç¨. This large spread reflects the presence of a few large prizes and many losing tickets.\nAlthough the possibility of winning a large amount may seem appealing, the large variance masks the fact that the expected return is less than the ticket price, ensuring profit for the lottery organizers over time.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#linear-transformations-of-random-variables",
    "href": "rvs-probdists/random-variables.html#linear-transformations-of-random-variables",
    "title": "12¬† Random Variables",
    "section": "12.4 Linear Transformations of Random Variables",
    "text": "12.4 Linear Transformations of Random Variables\nSuppose we know the expected value and variance of a random variable \\(X\\), and we define a new variable \\(Y\\) as a linear transformation:\n\\[\nY = a + bX\n\\]\nWe are interested in how this affects the expectation and variance.\nThe following rules apply:\n\nThe expected value of \\(Y\\) is:\n\n\\[\n\\mathbb{E}(Y) = \\mathbb{E}(a + bX) = a + b\\mathbb{E}(X)\n\\]\n\nThe variance of \\(Y\\) is:\n\n\\[\n\\mathbb{V}(Y) = \\mathbb{V}(a + bX) = b^2 \\mathbb{V}(X)\n\\]\nAdding a constant (\\(a\\)) does not affect variability, but scaling by a constant (\\(b\\)) affects the spread by a factor of \\(b^2\\).\nIf \\(c\\) is a constant (i.e., not a random variable):\n\nThe expected value of a constant is the constant itself:\n\n\\[\n\\mathbb{E}(c) = c\n\\]\n\nThe variance of a constant is zero:\n\n\\[\n\\mathbb{V}(c) = 0\n\\]\nA constant has no variability ‚Äî it stays fixed.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#constants-and-their-behavior",
    "href": "rvs-probdists/random-variables.html#constants-and-their-behavior",
    "title": "12¬† Random Variables",
    "section": "12.5 üìé Constants and Their Behavior",
    "text": "12.5 üìé Constants and Their Behavior\nIf \\(c\\) is a constant (i.e., not a random variable):\n\nThe expected value of a constant is the constant itself:\n\n\\[\n\\mathbb{E}(c) = c\n\\]\n\nThe variance of a constant is zero:\n\n\\[\n\\mathbb{V}(c) = 0\n\\]\nA constant has no variability ‚Äî it stays fixed. ## Exercises For each of the random variables below, decide whether it is discrete or continuous:\n\nThe number of books a student checked out from the library this week\n\nThe time (in minutes) it takes a person to run 5 kilometers\n\nThe number of heads in 10 coin tosses\n\nA person‚Äôs height (in centimeters)\n\nThe number of emails received in one day\n\nThe daily average temperature in a city (in ¬∞C)\n\nWhether a person owns a smartphone (yes = 1, no = 0)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nDiscrete ‚Äì counts books, can only be whole numbers\n\nContinuous ‚Äì time can be measured with decimals (e.g., 23.75 minutes)\n\nDiscrete ‚Äì number of heads is a count between 0 and 10\n\nContinuous ‚Äì height is measurable and can take any value in a range\n\nDiscrete ‚Äì number of emails is countable\n\nContinuous ‚Äì temperature is measured on a continuous scale\n\nDiscrete ‚Äì binary variable (yes/no)",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#sec-rvrules",
    "href": "rvs-probdists/random-variables.html#sec-rvrules",
    "title": "12¬† Random Variables",
    "section": "12.4 Linear Transformations of Random Variables",
    "text": "12.4 Linear Transformations of Random Variables\nSuppose we know the expected value and variance of a random variable \\(X\\), and we define a new variable \\(Y\\) as a linear transformation. FOr example, maybe you‚Äôre adding a flat fee to a cost, or scaling everything up because of inflation.\nMathematically, you‚Äôve created:\n\\[\nY = a + bX\n\\]\nNow you‚Äôre probably wondering: How does this change the average and the spread?\n\\[\nY = a + bX\n\\]\nWe are interested in how this affects the expectation and variance. The following rules apply:\n\nThe expected value of \\(Y\\) is:\n\n\\[\n\\mathbb{E}(Y) = \\mathbb{E}(a + bX) = a + b\\mathbb{E}(X)\n\\]\n\nThe variance of \\(Y\\) is:\n\n\\[\n\\mathbb{V}(Y) = \\mathbb{V}(a + bX) = b^2 \\mathbb{V}(X)\n\\]\nAdding a constant (\\(a\\)) does not affect variability, but scaling by a constant (\\(b\\)) affects the spread by a factor of \\(b^2\\).\nIf \\(c\\) is a constant (i.e., not a random variable):\n\nThe expected value of a constant is the constant itself:\n\n\\[\n\\mathbb{E}(c) = c\n\\]\n\nThe variance of a constant is zero:\n\n\\[\n\\mathbb{V}(c) = 0\n\\]\nWhy zero variance? Because there‚Äôs nothing to vary ‚Äî it‚Äôs always the same.\nWe will see a practiccal example of these rukes of in the next chapter.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#first-mean-and-variance-of-x",
    "href": "rvs-probdists/discrete-dist.html#first-mean-and-variance-of-x",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n14.1 üìê First: Mean and Variance of \\(X\\)\n",
    "text": "14.1 üìê First: Mean and Variance of \\(X\\)\n\n(From earlier or via R):\n\\[\n\\mathbb{E}(X) = 11.9 \\quad \\text{and} \\quad \\mathbb{V}(X) = 1.29\n\\]",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#now-lets-talk-total-cost",
    "href": "rvs-probdists/discrete-dist.html#now-lets-talk-total-cost",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n14.2 üí∏ Now Let‚Äôs Talk Total Cost",
    "text": "14.2 üí∏ Now Let‚Äôs Talk Total Cost\nUsing the formulas:\n\n14.2.1 Expected value:\n\\[\n\\mathbb{E}(Y) = 25000 + 900 \\cdot \\mathbb{E}(X) = 25000 + 900 \\cdot 11.9 = 35710\n\\]\nSo, the expected total cost is ‚Ç¨35,710.\n\n14.2.2 Variance:\n\\[\n\\mathbb{V}(Y) = 900^2 \\cdot \\mathbb{V}(X) = 810000 \\cdot 1.29 = 1044900\n\\]\n\n14.2.3 Standard deviation:\n\\[\n\\sigma_Y = \\sqrt{1044900} \\approx 1022.20\n\\]\nThis means your final project cost typically wiggles about ‚Ç¨1,022 above or below that ‚Ç¨35,710 mean.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#when-you-want-things-to-be-standard",
    "href": "rvs-probdists/discrete-dist.html#when-you-want-things-to-be-standard",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n14.3 üîÅ When You Want Things to Be Standard",
    "text": "14.3 üîÅ When You Want Things to Be Standard\nSometimes, it‚Äôs helpful to turn your variable into something more neutral ‚Äî centered at 0, and scaled so it‚Äôs easier to compare with others.\nThat‚Äôs called standardizing.\nWe define a new variable:\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}\n\\]\nIt‚Äôs like saying: &gt; ‚ÄúHow many standard deviations away is this value from the mean?‚Äù",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#what-happens-to-z",
    "href": "rvs-probdists/discrete-dist.html#what-happens-to-z",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n14.4 üß† What Happens to ( Z )?",
    "text": "14.4 üß† What Happens to ( Z )?\nThis magic trick always works:\n\nIts mean becomes:\n\n\\[\n\\mathbb{E}(Z) = 0\n\\]\n\nIts variance becomes:\n\n\\[\n\\mathbb{V}(Z) = 1\n\\]\nNow \\(Z\\) is unit-free, centered, and scaled ‚Äî perfect for comparing things measured in different units (like grades, heights, or pizza preferences).",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#why-its-useful",
    "href": "rvs-probdists/discrete-dist.html#why-its-useful",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n14.5 üì¶ Why It‚Äôs Useful",
    "text": "14.5 üì¶ Why It‚Äôs Useful\nStandardizing is a go-to move in statistics because:\n\nYou get rid of units\nYou make different variables comparable\nYou lay the groundwork for working with standard distributions (like the famous normal curve)\n\nIt‚Äôs one of those simple ideas that opens the door to powerful techniques later on.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/random-variables.html#standardizing-a-random-variable",
    "href": "rvs-probdists/random-variables.html#standardizing-a-random-variable",
    "title": "12¬† Random Variables",
    "section": "12.5 Standardizing a Random Variable",
    "text": "12.5 Standardizing a Random Variable\nTo compare random variables on a common scale, we often standardize them. Given a random variable \\(X\\) with expected value \\(\\mu_X\\) and standard deviation \\(\\sigma_X\\), we define:\n\\[\nZ = \\frac{X - \\mu_X}{\\sigma_X}\n\\]\nThis transformation creates a standardized variable \\(Z\\) with mean derived as follows using the rules shown in Section 12.4.\n\\[\n\\mathbb{E}(Z) = \\mathbb{E}\\left( \\frac{X - \\mu_X}{\\sigma_X} \\right)\n\\]\nSince \\(\\frac{1}{\\sigma_X}\\) is a constant, we can factor it out:\n\\[\n\\mathbb{E}(Z) = \\frac{1}{\\sigma_X} \\cdot \\mathbb{E}(X - \\mu_X)\n\\]\nUsing the linearity of expectation:\n\\[\n\\mathbb{E}(X - \\mu_X) = \\mathbb{E}(X) - \\mu_X = \\mu_X - \\mu_X = 0\n\\]\nSo:\n\\[\n\\mathbb{E}(Z) = \\frac{1}{\\sigma_X} \\cdot 0 = 0\n\\]\nThus, the standardized variable \\(Z\\) has mean 0. \\[\n  \\mathbb{E}(Z) = 0\n\\]\nNow we derive the variance of \\(Z\\):\n\\[\n\\mathbb{V}(Z) = \\mathbb{V}\\left( \\frac{X - \\mu_X}{\\sigma_X} \\right)\n\\]\nWe apply the rule for scaling a random variable:\n\\[\n\\mathbb{V}\\left( \\frac{X - \\mu_X}{\\sigma_X} \\right) = \\left( \\frac{1}{\\sigma_X} \\right)^2 \\cdot \\mathbb{V}(X - \\mu_X)\n\\]\nSince subtracting a constant does not change variance:\n\\[\n\\mathbb{V}(X - \\mu_X) = \\mathbb{V}(X) = \\sigma_X^2\n\\]\nSo:\n\\[\n\\mathbb{V}(Z) = \\frac{1}{\\sigma_X^2} \\cdot \\sigma_X^2 = 1\n\\]\nThus, the standardized variable \\(Z\\) has variance 1.\n\\[\n  \\mathbb{V}(Z) = 1\n\\]\nTo summarize, by standardizing a random variable using\n\\[\nZ = \\frac{X - \\mu_X}{\\sigma_X}\n\\]\nwe obtained a new variable \\(Z\\) with the following properties:\n\n\\(\\mathbb{E}(Z) = 0\\)\n\\(\\mathbb{V}(Z) = 1\\)\n\nThis makes \\(Z\\) easier to work with and allows comparisons between different variables, regardless of their original scale or units.\nStandardized variables are especially useful when:\n\nComparing two variables measured in different units\nWorking with standard distributions (like the standard normal)\nSimplifying statistical formulas and derivations\n\nStandardization ensures that the new variable \\(Z\\) has no unit, zero mean, and unit variance ‚Äî a common baseline in probability and statistics.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#the-bernoulli-distribution",
    "href": "rvs-probdists/discrete-dist.html#the-bernoulli-distribution",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n14.1 The Bernoulli Distribution",
    "text": "14.1 The Bernoulli Distribution\nA random variable \\(X\\) has a Bernoulli distribution if it takes only two values: \\(0\\) and \\(1\\), with probabilities:\n\n\n\\(x\\)\n\\(P(x)\\)\n\n\n\n0\n\\(1 - P\\)\n\n\n1\n\\(P\\)\n\n\n\nThis distribution is written as:\n\\[\nX \\sim \\text{Bernoulli}(P)\n\\]\n\n14.1.1 Properties\n\nExpected value: \\(\\mathbb{E}(X) = P\\)\n\nVariance: \\(\\mathbb{V}(X) = P(1 - P)\\)",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#example-rolling-a-die",
    "href": "rvs-probdists/discrete-dist.html#example-rolling-a-die",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n15.1 üé≤ Example: Rolling a Die",
    "text": "15.1 üé≤ Example: Rolling a Die\nLet \\(X\\) be the indicator variable for the event ‚Äúrolling a six‚Äù on a fair die. Then:\n\\[\nX =\n\\begin{cases}\n1 & \\text{if we roll a six} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nHere, the probability of rolling a six is \\(P = \\frac{1}{6}\\), so:\n\n\\(X \\sim \\text{Bernoulli}(1/6)\\)\n\nExpected value:\n\\[\n\\mathbb{E}(X) = \\frac{1}{6}\n\\]\n\n\nVariance:\n\\[\n\\mathbb{V}(X) = \\frac{1}{6} \\left(1 - \\frac{1}{6} \\right) = \\frac{5}{36}\n\\]",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#summary",
    "href": "rvs-probdists/discrete-dist.html#summary",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n15.2 ‚úÖ Summary",
    "text": "15.2 ‚úÖ Summary\n\nStandardizing a variable produces a new variable with mean 0 and variance 1.\nBernoulli distributions describe binary outcomes (success/failure, yes/no).\nIndicator variables are Bernoulli-distributed and have expected value equal to the probability of the event.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#the-bernoulli-and-binomial-distribution",
    "href": "rvs-probdists/discrete-dist.html#the-bernoulli-and-binomial-distribution",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.6 The Bernoulli and Binomial Distribution",
    "text": "13.6 The Bernoulli and Binomial Distribution\nIn probability theory, many random variables arise in contexts that follow well-known and well-studied distributions. For example, a variable that takes the value 1 when an event occurs and 0 otherwise ‚Äî such as flipping a coin or checking if a customer buys a product ‚Äî follows a Bernoulli distribution. When this type of binary trial is repeated independently a fixed number of times, and we count the number of successes, the resulting variable follows a Binomial distribution. These distributions not only help us describe real-world phenomena succinctly but also allow us to use established formulas to compute probabilities, expectations, variances, and more.\nA random variable \\(X\\) is said to follow a Bernoulli distribution if it takes on only two possible values: \\(0\\) and \\(1\\). These values typically represent the outcomes of a binary trial ‚Äî such as failure or success ‚Äî with probabilities \\(1 - p\\) and \\(p\\) respectively. The distribution is written as:\n\\[\nX \\sim \\text{Bernoulli}(p)\n\\]\nThis means that \\(X = 1\\) with probability \\(p\\), and \\(X = 0\\) with probability \\(1 - p\\). The expected value of a Bernoulli variable is given by \\(\\mathbb{E}(X) = p\\), and the variance is \\(\\mathbb{V}(X) = p(1 - p)\\).\nA common use of Bernoulli variables is as indicator variables, which simply record whether or not a particular event occurs. For example, suppose \\(A\\) is an event. Then we define the indicator variable \\(X\\) as:\n\\[\nX =\n\\begin{cases}\n1 & \\text{if event } A \\text{ occurs} \\\\\n0 & \\text{if event } A \\text{ does not occur}\n\\end{cases}\n\\]\nIn this case, \\(X \\sim \\text{Bernoulli}(p)\\), where \\(p = P(A)\\). This also implies that \\(\\mathbb{E}(X) = P(A)\\). In other words, the expected value of an indicator variable is simply the probability of the event it represents.\nAs an example, consider rolling a fair six-sided die. Let \\(X\\) be the indicator variable for the event ‚Äúrolling a six.‚Äù Then:\n\\[\nX =\n\\begin{cases}\n1 & \\text{if we roll a six} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nSince the probability of rolling a six is \\(p = \\frac{1}{6}\\), we can say \\(X \\sim \\text{Bernoulli}(1/6)\\). The expected value of \\(X\\) is then \\(\\mathbb{E}(X) = \\frac{1}{6}\\), and the variance is:\n\\[\n\\mathbb{V}(X) = \\frac{1}{6} \\left(1 - \\frac{1}{6} \\right) = \\frac{5}{36}\n\\]\nThis illustrates how Bernoulli variables can model simple binary outcomes and provide useful measures like mean and variability.\nBernoulli variables are also the building blocks of the Binomial distribution. When a Bernoulli trial is repeated independently \\(n\\) times, and we define a variable \\(X\\) to count the number of times the event (success) occurs, then \\(X\\) follows a Binomial distribution. More precisely, if each trial has success probability \\(p\\), and the trials are independent, then\n\\[\nX \\sim \\text{Bin}(n, p).\n\\]\nIn this case, \\(X\\) can take values \\(x = 0, 1, 2, \\dots, n\\), and the probability mass function is given by the formula\n\\[\nP(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x},\n\\]\nwhere \\(\\binom{n}{x}\\) is the binomial coefficient, which counts the number of ways to choose \\(x\\) successes from \\(n\\) trials. The expected value and variance of a binomially distributed random variable are\n\\[\n\\mathbb{E}(X) = np \\quad \\text{and} \\quad \\mathbb{V}(X) = np(1 - p).\n\\]\nExample 12.4: Flipping a Coin 3 Times\nAs an example, consider tossing a fair coin three times and let \\(X\\) be the number of heads obtained. Each toss is a Bernoulli trial with \\(p = 0.5\\), and there are three independent trials, so\n\\[\nX \\sim \\text{Bin}(3, 0.5).\n\\]\nWe can compute the probabilities for each possible value of \\(X\\) using the binomial formula:\n\\[\nP(X = x) = \\binom{3}{x}(0.5)^x(1 - 0.5)^{3 - x}.\n\\]\nFor example, to compute the probability of getting no heads at all, that is \\(X = 0\\), we use the binomial formula: \\[\nP(X = 0) = \\binom{3}{0}(0.5)^0(1 - 0.5)^3 = 1 \\cdot 1 \\cdot 0.125 = 0.125.\n\\]\nHere, \\(\\binom{3}{0} = 3\\) means the number of ways we can draw exactly 0 heads in 3 tosses and the answer is exactly 1 since there is only one outcome correposndin to this: \\(\\{(T,T,T)\\}\\).\nFor \\(X = 2\\) however, which corresponds to getting exactly two heads, the calculation is:\n\\[\nP(X = 2) = \\binom{3}{2}(0.5)^2(1 - 0.5)^1 = 3 \\cdot 0.25 \\cdot 0.5 = 0.375.\n\\]\nHere, \\(\\binom{3}{2} = 3\\) reflects the number of different ways to get two heads and one tail in three tosses. The specific outcomes are: \\(\\{(H,H,T), (H,T,H), (T,H,H)\\}\\). Each of these outcomes has the same probability, and the binomial coefficient counts how many such arrangements contribute to the total.\nDoing this for all possible outcomes provides the results in the following table:\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(F(x) = P(X \\leq x)\\)\n\n\n\n0\n0.125\n0.125\n\n\n1\n0.375\n0.500\n\n\n2\n0.375\n0.875\n\n\n3\n0.125\n1.000\n\n\n\nWe can verify that the total probability sums to 1, as expected. This example illustrates how the binomial distribution models the number of successes in a fixed number of independent trials, and how it extends naturally from the simpler Bernoulli setting.\nExample 12.5: 12 Independent Trials with Binary Outcomes\nIn this example, we consider a sequence of 12 independent trials, where the probability of success on each trial is 0.8. Let \\(X\\) be the random variable representing the total number of successful trials.\nWe begin by identifying the distribution of \\(X\\). Since the trials are independent and each has the same probability of success, \\(X\\) follows a binomial distribution with parameters \\(n = 12\\) and \\(P = 0.8\\). We can write:\n\\[\nX \\sim \\text{Bin}(12, 0.8)\n\\]\nWe are asked to compute:\n\n\n\\(P(X = 10)\\)\n\n\\(P(X \\leq 10)\\)\n\nThe first is straightforward to compute using our binomial formula: \\[\n\\begin{split}\nP(X = 10) = \\binom{12}{10}(0.8)^{10}(0.2)^2 &  = \\frac{12!}{10!(12 - 10)!} (0.8)^{10}(0.2)^2 \\\\ &  =  66 \\cdot 0.1074 \\cdot 0.04 \\approx 66 \\cdot 0.004296 \\\\ &  = 0.2835\n\\end{split}\n\\]\nHowever, for the second task of computing \\(P(X \\leq 10)\\), it can be very tedious to compute the binomial formula 11 times and then add them. Here‚Äôs the trick! We consider the number of failures instead. Define \\(Y\\) as the number of unsuccessful trials. Then \\(Y = 12 - X\\), and it also follows a binomial distribution, but with with \\(p = 0.2\\), that is \\[\nY \\sim \\text{Bin}(12, 0.2)\n\\]\nSo the probability of exactly 10 successes is approximately 0.2835.\nHowever, because \\(p = 0.8 &gt; 0.5\\), we cannot use the standard binomial tables in the textbook, which only go up to \\(P = 0.5\\). To get around this, we consider the number of failures instead. Define \\(Y\\) as the number of unsuccessful trials. Then \\(Y = 12 - X\\), and it also follows a binomial distribution, but with \\(P = 0.2\\). So:\n\\[\nY \\sim \\text{Bin}(12, 0.2)\n\\]\nNow to compute \\(P(X \\leq 10)\\) we see that it corresponds to \\(P(Y \\geq 2)\\), since if \\(X \\leq 10\\), then the number of failures \\(Y \\geq 2\\).\nWe use the complement: \\[\n\\begin{split} P(X \\leq 10) = P(Y \\geq 2) &  = 1 - P(Y \\leq 1) =  \\\\ &\n= 1 - [P(Y = 0) + P(Y = 1)]\n\\end{split}\n\\]\nand use the binomial formula as before: \\[\nP(Y = 0) = \\binom{12}{0}(0.2)^0(0.8)^{12} = 1 \\cdot 1 \\cdot (0.8)^{12} \\approx 0.0687\n\\]\n\\[\nP(Y = 1) = \\binom{12}{1}(0.2)^1(0.8)^{11} = 12 \\cdot 0.2 \\cdot (0.8)^{11} \\approx 0.2062\n\\] Add these two probabilities \\[\nP(Y \\leq 1) = P(Y = 0) + P(Y = 1) \\approx 0.0687 + 0.2062 = 0.2749\n\\]\nand finally, subtract from 1 to get the desired result:\n\\[\nP(Y \\geq 2) = 1 - 0.2749 = 0.7251\n\\]\nSo, the probability that \\(Y\\) is greater than or equal to 2 is approximately 0.7251. This is the same probability as \\(X\\) being less than or equal to 10.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#rules-for-expectation-and-variance",
    "href": "rvs-probdists/discrete-dist.html#rules-for-expectation-and-variance",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.5 Rules for Expectation and Variance",
    "text": "13.5 Rules for Expectation and Variance\nRecall from previous chapter and section Section 12.4 that for any random variable \\(X\\), and constants \\(a\\) and \\(b\\), we always have that the expected value is given by \\[\n\\mathbb{E}(a + bX) = a + b\\mathbb{E}(X)\n\\] and the variance by \\[\n\\mathbb{V}(a + bX) = b^2 \\mathbb{V}(X).\n\\] Let‚Äôs look at an exmaple of this in the discrete case.\nExample 12.3: The Project Budget\nYou‚Äôre managing a project. The number of workdays to finish the project, denoted by random variabel \\(X\\), is a bit uncertain. Its distribution looks like this:\n\n\n\\(x\\)\n10\n11\n12\n13\n14\n\n\n\\(P(x)\\)\n0.1\n0.3\n0.3\n0.2\n0.1\n\n\nYou know a few things:\n\nFixed cost: ‚Ç¨25,000\n\nDaily cost: ‚Ç¨900\n\nSo the total cost denoted by \\(Y\\) is:\\[\nY = 25000 + 900X\n\\]\n\n\nLet‚Äôs use the rules above to find the expected value and variance of \\(Y\\).\nFirst we use similar technique as earlier to find\n\\[\n\\mathbb{E}(X) = 11.9 \\quad \\text{and} \\quad \\mathbb{V}(X) = 1.29\n\\]\nUsing the rules of linear transformation we then can find the expected value of \\(Y\\) \\[\n\\mathbb{E}(Y) = 25000 + 900 \\cdot \\mathbb{E}(X) = 25000 + 900 \\cdot 11.9 = 35710\n\\]\nand the variance of \\(Y\\) as\n\\[\n\\mathbb{V}(Y) = 900^2 \\cdot \\mathbb{V}(X) = 810000 \\cdot 1.29 = 1044900\n\\]\nFinally we find the standarc deviaiton as \\[\n\\sqrt{\\mathbb{V}(Y)} = \\sqrt{1044900} \\approx 1022.20\n\\]\nThis gives a total expected project cost of ‚Ç¨35,710, with a standard deviation of about ‚Ç¨1,022.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dist.html#exercises",
    "href": "rvs-probdists/discrete-dist.html#exercises",
    "title": "13¬† Discrete Probability Distributions",
    "section": "\n13.7 Exercises",
    "text": "13.7 Exercises\n\nLet \\(X\\) be a discrete random variable with the following probability distribution:\n\n\n\n\\(x\\)\n1\n2\n3\n4\n\n\n\\(P(x)\\)\n0.1\n0.3\n0.4\n0.2\n\n\n\nVerify that this is a valid probability distribution.\n\nCompute the expected value \\(\\mathbb{E}(X)\\).\n\nCompute the variance \\(\\mathbb{V}(X)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nValidity check We check that the sum of the probabilities is 1:\n\n\\[\n0.1 + 0.3 + 0.4 + 0.2 = 1.0\n\\]\n\nExpected value\n\n\\[\n\\mathbb{E}(X) = \\sum x \\cdot P(x) = 1 \\cdot 0.1 + 2 \\cdot 0.3 + 3 \\cdot 0.4 + 4 \\cdot 0.2 = 0.1 + 0.6 + 1.2 + 0.8 = 2.7\n\\]\n\nVariance\n\nWe first compute \\(\\mathbb{E}(X^2)\\): \\[\n\\mathbb{E}(X^2) = 1^2 \\cdot 0.1 + 2^2 \\cdot 0.3 + 3^2 \\cdot 0.4 + 4^2 \\cdot 0.2 = 0.1 + 1.2 + 3.6 + 3.2 = 8.1\n\\]\nThen:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - (\\mathbb{E}(X))^2 = 8.1 - (2.7)^2 = 8.1 - 7.29 = 0.81\n\\]\n\n\n\n\nSuppose a quality control inspector checks whether products are defective. Each item has a 10% chance of being defective, and tests are independent.\n\n\nLet \\(X\\) be a Bernoulli random variable indicating whether a single item is defective. What are the mean and variance of \\(X\\)?\nLet \\(Y \\sim \\text{Bin}(10, 0.1)\\) represent the number of defective items in a sample of 10. Compute:\n\n\n\n\\(\\mathbb{E}(Y)\\) and \\(\\mathbb{V}(Y)\\)\n\n\n\\(P(Y = 0)\\)\n\n\\(P(Y \\geq 2)\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\nBernoulli Variable \\(X\\): \\(X \\sim \\text{Bernoulli}(0.1)\\) \\[\\mathbb{E}(X) = 0.1\\]\n\\[\\mathbb{V}(X) = 0.1 \\cdot (1 - 0.1) = 0.09\\]\n\n\n\n\n\nBinomial Variable \\(Y\\): \\(Y \\sim \\text{Bin}(10, 0.1)\\)\n\\(\\mathbb{E}(Y) = 10 \\cdot 0.1 = 1\\)\n\\(\\mathbb{V}(Y) = 10 \\cdot 0.1 \\cdot 0.9 = 0.9\\)\n\n\\(P(Y = 0)\\)\n\n\\[\nP(Y = 0) = \\binom{10}{0}(0.1)^0(0.9)^{10} = 1 \\cdot 1 \\cdot (0.9)^{10} \\approx 0.3487\n\\]\n\n\n\\(P(Y \\geq 2)\\) We use the complement: \\[\nP(Y \\geq 2) = 1 - P(Y = 0) - P(Y = 1)\n\\] Already have \\(P(Y = 0) \\approx 0.3487\\). Now compute: \\[\nP(Y = 1) = \\binom{10}{1}(0.1)^1(0.9)^9 = 10 \\cdot 0.1 \\cdot (0.9)^9 \\approx 0.3874\n\\] Then: \\[\nP(Y \\geq 2) = 1 - 0.3487 - 0.3874 = 0.2639\n\\]",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html",
    "href": "rvs-probdists/discrete-dists.html",
    "title": "13¬† Discrete Probability Distributions",
    "section": "",
    "text": "13.1 Probability Mass Function (PMF)\nA discrete probability distribution describes how the values of a variable are associated with probabilities. It applies when a variable can take on a limited or countable set of values, like 0, 1, 2, and so on, and we know how likely each value is. Note that we use uppercase letter to denote random variables and lowercase letters for the values they take on.\nThe probability function \\(P(x)\\) assigns a probability to each possible value \\(x\\) that the variable can take. These probabilities must all lie between 0 and 1, and together they must sum to exactly 1.\nWe use the expected value, \\(\\mathbb{E}(X)\\), to summarize the typical or central value of the distribution. It gives us a sense of where the values tend to cluster. Think of it as a kind of weighted average, where more probable outcomes count more heavily in the calculation.\nThe variance, \\(\\mathbb{V}(X)\\), describes how much the values of the variable differ from this central value. A small variance means most values are close to the expected value, while a large variance means the values are more spread out.\nWhen dealing with discrete random variables, we are interested in how likely it is that the variable takes on specific values. This relationship, the link between possible values and their associated probabilities, is described by the probability distribution of the random variable.\nThe probability mass function (PMF) is a mathematical function that assigns a probability to each value the variable can take. In other words, the PMF is the mathematical expression of the probability distribution. The distribution is the overall concept; the PMF is the function that specifies the details.\nWe usually denote the PMF as \\(P(x)\\), where:\n\\[\nP(x) = P(X = x)\n\\] This gives the probability that the random variable \\(X\\) equals a specific value \\(x\\).\nFor the PMF to describe a valid distribution, it must satisfy two conditions:\nIf we know \\(P(x)\\) for all values \\(x\\) that \\(X\\) can take, we say we know the probability distribution of \\(X\\). We can present a probability distribution in several forms: as a table, a bar chart, or through a formula.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#probability-mass-function-pmf",
    "href": "rvs-probdists/discrete-dists.html#probability-mass-function-pmf",
    "title": "13¬† Discrete Probability Distributions",
    "section": "",
    "text": "Each probability must be between 0 and 1: \\[\n0 \\leq P(x) \\leq 1\n\\]\nThe total probability across all values must sum to 1: \\[\n\\sum_x P(x) = 1\n\\]\n\n\n\nExample 12.1: Coin Toss\nSuppose we toss a fair coin two times. Let the random variable \\(X\\) represent the number of heads observed. The sample space consists of four equally likely outcomes:\n\nHead, Head ‚Üí \\(X = 2\\)\nHead, Tail ‚Üí \\(X = 1\\)\nTail, Head ‚Üí \\(X = 1\\)\nTail, Tail ‚Üí \\(X = 0\\)\n\nEach of these outcomes has probability 0.25. From this, we can define the probability mass function (PMF) of \\(X\\) as:\n\\[\nP(x) =\n\\begin{cases}\n0.25 & \\text{if } x = 0 \\\\\n0.50 & \\text{if } x = 1 \\\\\n0.25 & \\text{if } x = 2 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nThe table below presents a representation of the PMF; showing the values of \\(P(x)\\) for each value in the support of \\(X\\):\n\n\n\nOutcomes\n\\(x\\) (Number of heads)\n\\(P(x)\\)\n\n\n\n\n(Tail, Tail)\n0\n0.25\n\n\n(Head, Tail), (Tail, Head)\n1\n0.50\n\n\n(Head, Head)\n2\n0.25\n\n\n\nWe can confirm that this satisfies the requirement:\n\\[\n\\sum_x P(x) = 0.25 + 0.5 + 0.25 = 1\n\\]\nThis confirms that \\(P(x)\\) defines a valid probability distribution.\nThis table is one way of representing the probability distribution of \\(X\\). Another way to represent it is by using bar plot:",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#the-cumulative-distribution-function-cdf",
    "href": "rvs-probdists/discrete-dists.html#the-cumulative-distribution-function-cdf",
    "title": "13¬† Discrete Probability Distributions",
    "section": "13.2 The Cumulative Distribution Function (CDF)",
    "text": "13.2 The Cumulative Distribution Function (CDF)\nFor a discrete random variable \\(X\\), we can describe its probability distribution not only using the probability mass function, but also through its cumulative distribution function, denoted \\(F(x)\\).\nThe CDF gives the probability that \\(X\\) takes on a value less than or equal to a given number \\(x\\):\n\\[\nF(x) = P(X \\leq x)\n\\]\nThis function grows step by step as we move through the possible values of \\(X\\), accumulating the total probability up to each point.\n\nExample 12.1: Coin Toss (continued)\nWe continue here with the example abive, where \\(X\\) is the number of heads in two tosses of a fair coin. The PMF and corresponding CDF values are:\n\n\n\n\\(x\\)\n\\(P(x)\\)\n\\(F(x)\\)\n\n\n\n\n0\n0.25\n0.25\n\n\n1\n0.50\n0.75\n\n\n2\n0.25\n1.00\n\n\n\nThe last value of \\(F(x)\\) must always equal 1, since the total probability must sum to 1.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#expected-value-of-a-discrete-random-variable",
    "href": "rvs-probdists/discrete-dists.html#expected-value-of-a-discrete-random-variable",
    "title": "13¬† Discrete Probability Distributions",
    "section": "13.3 Expected Value of a Discrete Random Variable",
    "text": "13.3 Expected Value of a Discrete Random Variable\nJust like empirical data can be summarized with averages and standard deviations, a discrete probability distribution can also be described using corresponding statistical measures. These include measures of central tendency, such as the expected value, and measures of variability, such as the standard deviation.\nThe expected value plays the role of a mean or average. But because the possible outcomes may occur with different probabilities, we must take this into account by assigning more weight to more likely outcomes. This means the values are weighted by their associated probabilities.\nTo find the expected value of a discrete random variable, we do not simply average the outcomes. Instead, we compute a weighted average where the weights are given by the probability mass function.\nThe expected value of a discrete random variable \\(X\\) is denoted by \\(\\mathbb{E}(X)\\), where \\(\\mathbb{E}\\) stands for expectation. It is defined as:\n\\[\n\\mathbb{E}(X) = \\sum_{x} x \\cdot P(x) = \\mu_X\n\\]\nThis formula tells us to multiply each value \\(x\\) by its probability \\(P(x)\\) and then sum the results over all possible values of \\(X\\). The result, \\(\\mathbb{E}(X)\\), gives us the value we expect to observe on average in the long run, if we were to randomly select a value of \\(X\\) according to its probability distribution.\nThe expected value represents the ‚Äúcenter‚Äù of the distribution ‚Äî the point where the values balance, considering how often each one occurs. For example, if a random variable has most of its probability mass near 1, its expected value will be close to 1.\nIt‚Äôs important to note that expected value doesn‚Äôt predict what will happen* ‚Äî it predicts what happens on average. It‚Äôs like asking, ‚ÄúWhat would I get if the universe reran this scenario a million times?‚Äù\n\nExample 12.1: Coin Toss (continued)\nIf you revisit the coin-toss example where \\(X\\) counts the number of heads in two tosses, you would compute the expected value as:\n\\[\n\\mathbb{E}(X) = \\sum_{x} x \\cdot P(x) = 0 \\cdot 0.25 + 1 \\cdot 0.5 + 2 \\cdot 0.25 = 1\n\\]\nThis confirms that we expect to get 1 head on average when tossing a coin twice.\n\n\nExample 12.2: Lottery - A Risky Business\nLet‚Äôs say you‚Äôre eyeing a lottery with 100 tickets. Each ticket costs 1‚Ç¨, and you‚Äôre feeling lucky. The prize setup is:\n\nOne lucky winner gets 50‚Ç¨\n\nThree people win 10‚Ç¨\n\nFive folks get 2‚Ç¨\n\nAnd‚Ä¶ the remaining 91 get absolutely nothing\n\nLet‚Äôs define a random variable \\(X\\) as the payout of a randomly selected ticket.\nSo what values can \\(X\\) take?\n\\[\nX \\in \\{0, 2, 10, 50\\}\n\\]\nBut ‚Äî and here‚Äôs the key ‚Äî just averaging those values like this:\n\\[\n\\frac{0 + 2 + 10 + 50}{4} = 15.5\n\\]\n‚Ä¶makes no sense! That would only be correct if all outcomes were equally likely, which they‚Äôre definitely not. Most people walk away with nothing. So we need to weight each value by how often it actually happens.\nLet‚Äôs build a table to show how many tickets correspond to each prize:\n\n\n\nPayout (‚Ç¨)\nNumber of tickets\nProbability \\(P(x)\\)\n\n\n\n\n0\n91\n0.91\n\n\n2\n5\n0.05\n\n\n10\n3\n0.03\n\n\n50\n1\n0.01\n\n\n\nSo now we have a complete probability distribution for \\(X\\) which is visualized below:\n\n\n\n\n\n\n\n\n\nLet‚Äôs compute the expected value \\(\\mathbb{E}(X)\\) using the PMF:\n\\[\n\\mathbb{E}(X) = \\sum_x x \\cdot P(x) = 0 \\cdot 0.91 + 2 \\cdot 0.05 + 10 \\cdot 0.03 + 50 \\cdot 0.01 = 0.90\n\\]\nSo even though one person might win 50‚Ç¨, the average payout per ticket is just 90 cents. That means if you pay 1‚Ç¨ per ticket, you‚Äôre losing 10 cents on average.\nMost of the time, lottery isn‚Äôt just random ‚Äî it‚Äôs rigged (in favor of the organizers)",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#variance-and-standard-deviation-of-a-discrete-random-variable",
    "href": "rvs-probdists/discrete-dists.html#variance-and-standard-deviation-of-a-discrete-random-variable",
    "title": "13¬† Discrete Probability Distributions",
    "section": "13.4 Variance and Standard Deviation of a Discrete Random Variable",
    "text": "13.4 Variance and Standard Deviation of a Discrete Random Variable\nJust as sample variance measures the average squared deviation from the sample mean, the variance of a random variable measures the average squared deviation from its expected value, weighted by the probability mass function.\nLet \\(X\\) be a discrete random variable with expected value \\(\\mu_X = \\mathbb{E}(X)\\). The variance of \\(X\\) is defined as:\n\\[\n\\text{Var}(X) = \\mathbb{E}[(X - \\mu_X)^2] = \\sum_x (x - \\mu_X)^2 \\cdot P(x)\n\\]\nAlternatively, variance can also be calculated using:\n\\[\n\\text{Var}(X) = \\mathbb{E}(X^2) - (\\mathbb{E}(X))^2\n\\]\nThe standard deviation is the square root of the variance:\n\\[\n\\sigma_X = \\sqrt{\\text{Var}(X)}\n\\]\nThese measures provide information about how much variability there is in the possible values of \\(X\\).\n\nExample 12.1: Coin Toss (continued)\nConsider again the random variable \\(X =\\) number of heads in two tosses of a fair coin. We previously found the expected value:\n\\[\n\\mathbb{E}(X) = 1\n\\]\nWe now calculate the variance by constructing the following table:\n\n\n\n\\(x\\)\n\\(P(x)\\)\n\\((x - \\mu_X)^2\\)\n\\((x - \\mu_X)^2 \\cdot P(x)\\)\n\n\n\n\n0\n0.25\n1\n0.25\n\n\n1\n0.50\n0\n0\n\n\n2\n0.25\n1\n0.25\n\n\n\n\n\n0.50\n\n\n\nSo,\n\\[\n\\text{Var}(X) = 0.50 \\quad \\text{and} \\quad \\sigma_X = \\sqrt{0.50} \\approx 0.7071\n\\]\nThis tells us that the number of heads in two tosses typically deviates by about 0.71 from the expected value.\n\n\nExample 12.2: Lottery - A Risky Business\nLet \\(X\\) denote the payout from a randomly selected lottery ticket. From earlier, we know the expected value is:\n\\[\n\\mu_X = \\mathbb{E}(X) = 0.9\n\\]\nTo compute the variance, we first calculate the squared deviations from the mean for each possible payout:\n\n\n\n\\(x\\)\n\\(P(x)\\)\n\\((x - \\mu_X)^2\\)\n\n\n\n\n0\n0.91\n\\((0 - 0.9)^2 = 0.81\\)\n\n\n2\n0.05\n\\((2 - 0.9)^2 = 1.21\\)\n\n\n10\n0.03\n\\((10 - 0.9)^2 = 82.81\\)\n\n\n50\n0.01\n\\((50 - 0.9)^2 = 2410.81\\)\n\n\n\nNow multiply by probabilities:\n\\[\n\\text{Var}(X) = 0.91 \\cdot 0.81 + 0.05 \\cdot 1.21 + 0.03 \\cdot 82.81 + 0.01 \\cdot 2410.81 = 27.39\n\\]\nSo the standard deviation is:\n\\[\n\\sigma_X = \\sqrt{27.39} \\approx 5.23\n\\]\nSo in summary, the expected payout of 0.9‚Ç¨ indicated that on average, each ticket returns 90cents. However, no single ticket actually pays exactly 0.9‚Ç¨. This value is theoretical ‚Äî it describes the average over many repetitions.\nThe standard deviation of 5.23‚Ç¨ tells us that the actual payout from a randomly chosen ticket typically deviates from the expected value by about 5‚Ç¨. This large spread reflects the presence of a few large prizes and many losing tickets.\nAlthough the possibility of winning a large amount may seem appealing, the large variance masks the fact that the expected return is less than the ticket price, ensuring profit for the lottery organizers over time.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#rules-for-expectation-and-variance",
    "href": "rvs-probdists/discrete-dists.html#rules-for-expectation-and-variance",
    "title": "13¬† Discrete Probability Distributions",
    "section": "13.5 Rules for Expectation and Variance",
    "text": "13.5 Rules for Expectation and Variance\nRecall from previous chapter and section Section 12.4 that for any random variable \\(X\\), and constants \\(a\\) and \\(b\\), we always have that the expected value is given by \\[\n\\mathbb{E}(a + bX) = a + b\\mathbb{E}(X)\n\\] and the variance by \\[\n\\mathbb{V}(a + bX) = b^2 \\mathbb{V}(X).\n\\] Let‚Äôs look at an exmaple of this in the discrete case.\n\nExample 12.3: The Project Budget\nYou‚Äôre managing a project. The number of workdays to finish the project, denoted by random variabel \\(X\\), is a bit uncertain. Its distribution looks like this:\n\n\n\n\\(x\\)\n10\n11\n12\n13\n14\n\n\n\n\n\\(P(x)\\)\n0.1\n0.3\n0.3\n0.2\n0.1\n\n\n\nYou know a few things:\n\nFixed cost: ‚Ç¨25,000\n\nDaily cost: ‚Ç¨900\n\nSo the total cost denoted by \\(Y\\) is:\n\\[\nY = 25000 + 900X\n\\]\n\nLet‚Äôs use the rules above to find the expected value and variance of \\(Y\\).\nFirst we use similar technique as earlier to find\n\\[\n\\mathbb{E}(X) = 11.9 \\quad \\text{and} \\quad \\mathbb{V}(X) = 1.29\n\\]\nUsing the rules of linear transformation we then can find the expected value of \\(Y\\) \\[\n\\mathbb{E}(Y) = 25000 + 900 \\cdot \\mathbb{E}(X) = 25000 + 900 \\cdot 11.9 = 35710\n\\]\nand the variance of \\(Y\\) as\n\\[\n\\mathbb{V}(Y) = 900^2 \\cdot \\mathbb{V}(X) = 810000 \\cdot 1.29 = 1044900\n\\]\nFinally we find the standarc deviaiton as \\[\n\\sqrt{\\mathbb{V}(Y)} = \\sqrt{1044900} \\approx 1022.20\n\\]\nThis gives a total expected project cost of ‚Ç¨35,710, with a standard deviation of about ‚Ç¨1,022.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#the-bernoulli-and-binomial-distribution",
    "href": "rvs-probdists/discrete-dists.html#the-bernoulli-and-binomial-distribution",
    "title": "13¬† Discrete Probability Distributions",
    "section": "13.6 The Bernoulli and Binomial Distribution",
    "text": "13.6 The Bernoulli and Binomial Distribution\nIn probability theory, many random variables arise in contexts that follow well-known and well-studied distributions. For example, a variable that takes the value 1 when an event occurs and 0 otherwise ‚Äî such as flipping a coin or checking if a customer buys a product ‚Äî follows a Bernoulli distribution. When this type of binary trial is repeated independently a fixed number of times, and we count the number of successes, the resulting variable follows a Binomial distribution. These distributions not only help us describe real-world phenomena succinctly but also allow us to use established formulas to compute probabilities, expectations, variances, and more.\nA random variable \\(X\\) is said to follow a Bernoulli distribution if it takes on only two possible values: \\(0\\) and \\(1\\). These values typically represent the outcomes of a binary trial ‚Äî such as failure or success ‚Äî with probabilities \\(1 - p\\) and \\(p\\) respectively. The distribution is written as:\n\\[\nX \\sim \\text{Bernoulli}(p)\n\\]\nThis means that \\(X = 1\\) with probability \\(p\\), and \\(X = 0\\) with probability \\(1 - p\\). The expected value of a Bernoulli variable is given by \\(\\mathbb{E}(X) = p\\), and the variance is \\(\\mathbb{V}(X) = p(1 - p)\\).\nA common use of Bernoulli variables is as indicator variables, which simply record whether or not a particular event occurs. For example, suppose \\(A\\) is an event. Then we define the indicator variable \\(X\\) as:\n\\[\nX =\n\\begin{cases}\n1 & \\text{if event } A \\text{ occurs} \\\\\n0 & \\text{if event } A \\text{ does not occur}\n\\end{cases}\n\\]\nIn this case, \\(X \\sim \\text{Bernoulli}(p)\\), where \\(p = P(A)\\). This also implies that \\(\\mathbb{E}(X) = P(A)\\). In other words, the expected value of an indicator variable is simply the probability of the event it represents.\nAs an example, consider rolling a fair six-sided die. Let \\(X\\) be the indicator variable for the event ‚Äúrolling a six.‚Äù Then:\n\\[\nX =\n\\begin{cases}\n1 & \\text{if we roll a six} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nSince the probability of rolling a six is \\(p = \\frac{1}{6}\\), we can say \\(X \\sim \\text{Bernoulli}(1/6)\\). The expected value of \\(X\\) is then \\(\\mathbb{E}(X) = \\frac{1}{6}\\), and the variance is:\n\\[\n\\mathbb{V}(X) = \\frac{1}{6} \\left(1 - \\frac{1}{6} \\right) = \\frac{5}{36}\n\\]\nThis illustrates how Bernoulli variables can model simple binary outcomes and provide useful measures like mean and variability.\nBernoulli variables are also the building blocks of the Binomial distribution. When a Bernoulli trial is repeated independently \\(n\\) times, and we define a variable \\(X\\) to count the number of times the event (success) occurs, then \\(X\\) follows a Binomial distribution. More precisely, if each trial has success probability \\(p\\), and the trials are independent, then\n\\[\nX \\sim \\text{Bin}(n, p).\n\\]\nIn this case, \\(X\\) can take values \\(x = 0, 1, 2, \\dots, n\\), and the probability mass function is given by the formula\n\\[\nP(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x},\n\\]\nwhere \\(\\binom{n}{x}\\) is the binomial coefficient, which counts the number of ways to choose \\(x\\) successes from \\(n\\) trials. The expected value and variance of a binomially distributed random variable are\n\\[\n\\mathbb{E}(X) = np \\quad \\text{and} \\quad \\mathbb{V}(X) = np(1 - p).\n\\]\n\nExample 12.4: Flipping a Coin 3 Times\nAs an example, consider tossing a fair coin three times and let \\(X\\) be the number of heads obtained. Each toss is a Bernoulli trial with \\(p = 0.5\\), and there are three independent trials, so\n\\[\nX \\sim \\text{Bin}(3, 0.5).\n\\]\nWe can compute the probabilities for each possible value of \\(X\\) using the binomial formula:\n\\[\nP(X = x) = \\binom{3}{x}(0.5)^x(1 - 0.5)^{3 - x}.\n\\]\nFor example, to compute the probability of getting no heads at all, that is \\(X = 0\\), we use the binomial formula: \\[\nP(X = 0) = \\binom{3}{0}(0.5)^0(1 - 0.5)^3 = 1 \\cdot 1 \\cdot 0.125 = 0.125.\n\\]\nHere, \\(\\binom{3}{0} = 3\\) means the number of ways we can draw exactly 0 heads in 3 tosses and the answer is exactly 1 since there is only one outcome correposndin to this: \\(\\{(T,T,T)\\}\\).\nFor \\(X = 2\\) however, which corresponds to getting exactly two heads, the calculation is:\n\\[\nP(X = 2) = \\binom{3}{2}(0.5)^2(1 - 0.5)^1 = 3 \\cdot 0.25 \\cdot 0.5 = 0.375.\n\\]\nHere, \\(\\binom{3}{2} = 3\\) reflects the number of different ways to get two heads and one tail in three tosses. The specific outcomes are: \\(\\{(H,H,T), (H,T,H), (T,H,H)\\}\\). Each of these outcomes has the same probability, and the binomial coefficient counts how many such arrangements contribute to the total.\nDoing this for all possible outcomes provides the results in the following table:\n\n\n\n\\(x\\)\n\\(P(X = x)\\)\n\\(F(x) = P(X \\leq x)\\)\n\n\n\n\n0\n0.125\n0.125\n\n\n1\n0.375\n0.500\n\n\n2\n0.375\n0.875\n\n\n3\n0.125\n1.000\n\n\n\nWe can verify that the total probability sums to 1, as expected. This example illustrates how the binomial distribution models the number of successes in a fixed number of independent trials, and how it extends naturally from the simpler Bernoulli setting.\n\n\nExample 12.5: 12 Independent Trials with Binary Outcomes\nIn this example, we consider a sequence of 12 independent trials, where the probability of success on each trial is 0.8. Let \\(X\\) be the random variable representing the total number of successful trials.\nWe begin by identifying the distribution of \\(X\\). Since the trials are independent and each has the same probability of success, \\(X\\) follows a binomial distribution with parameters \\(n = 12\\) and \\(P = 0.8\\). We can write:\n\\[\nX \\sim \\text{Bin}(12, 0.8)\n\\]\nWe are asked to compute:\n\n\\(P(X = 10)\\)\n\n\\(P(X \\leq 10)\\)\n\nThe first is straightforward to compute using our binomial formula: \\[\n\\begin{split}\nP(X = 10) = \\binom{12}{10}(0.8)^{10}(0.2)^2 &  = \\frac{12!}{10!(12 - 10)!} (0.8)^{10}(0.2)^2 \\\\ &  =  66 \\cdot 0.1074 \\cdot 0.04 \\approx 66 \\cdot 0.004296 \\\\ &  = 0.2835\n\\end{split}\n\\]\nHowever, for the second task of computing \\(P(X \\leq 10)\\), it can be very tedious to compute the binomial formula 11 times and then add them. Here‚Äôs the trick! We consider the number of failures instead. Define \\(Y\\) as the number of unsuccessful trials. Then \\(Y = 12 - X\\), and it also follows a binomial distribution, but with with \\(p = 0.2\\), that is \\[\nY \\sim \\text{Bin}(12, 0.2)\n\\]\nSo the probability of exactly 10 successes is approximately 0.2835.\nHowever, because \\(p = 0.8 &gt; 0.5\\), we cannot use the standard binomial tables in the textbook, which only go up to \\(P = 0.5\\). To get around this, we consider the number of failures instead. Define \\(Y\\) as the number of unsuccessful trials. Then \\(Y = 12 - X\\), and it also follows a binomial distribution, but with \\(P = 0.2\\). So:\n\\[\nY \\sim \\text{Bin}(12, 0.2)\n\\]\nNow to compute \\(P(X \\leq 10)\\) we see that it corresponds to \\(P(Y \\geq 2)\\), since if \\(X \\leq 10\\), then the number of failures \\(Y \\geq 2\\).\nWe use the complement: \\[\n\\begin{split} P(X \\leq 10) = P(Y \\geq 2) &  = 1 - P(Y \\leq 1) =  \\\\ &\n= 1 - [P(Y = 0) + P(Y = 1)]\n\\end{split}\n\\]\nand use the binomial formula as before: \\[\nP(Y = 0) = \\binom{12}{0}(0.2)^0(0.8)^{12} = 1 \\cdot 1 \\cdot (0.8)^{12} \\approx 0.0687\n\\]\n\\[\nP(Y = 1) = \\binom{12}{1}(0.2)^1(0.8)^{11} = 12 \\cdot 0.2 \\cdot (0.8)^{11} \\approx 0.2062\n\\] Add these two probabilities \\[\nP(Y \\leq 1) = P(Y = 0) + P(Y = 1) \\approx 0.0687 + 0.2062 = 0.2749\n\\]\nand finally, subtract from 1 to get the desired result:\n\\[\nP(Y \\geq 2) = 1 - 0.2749 = 0.7251\n\\]\nSo, the probability that \\(Y\\) is greater than or equal to 2 is approximately 0.7251. This is the same probability as \\(X\\) being less than or equal to 10.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/discrete-dists.html#exercises",
    "href": "rvs-probdists/discrete-dists.html#exercises",
    "title": "13¬† Discrete Probability Distributions",
    "section": "13.7 Exercises",
    "text": "13.7 Exercises\n\nLet \\(X\\) be a discrete random variable with the following probability distribution:\n\n\n\n\n\\(x\\)\n1\n2\n3\n4\n\n\n\n\n\\(P(x)\\)\n0.1\n0.3\n0.4\n0.2\n\n\n\n\nVerify that this is a valid probability distribution.\n\nCompute the expected value \\(\\mathbb{E}(X)\\).\n\nCompute the variance \\(\\mathbb{V}(X)\\).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nValidity check We check that the sum of the probabilities is 1:\n\n\\[\n0.1 + 0.3 + 0.4 + 0.2 = 1.0\n\\]\n\nExpected value\n\n\\[\n\\mathbb{E}(X) = \\sum x \\cdot P(x) = 1 \\cdot 0.1 + 2 \\cdot 0.3 + 3 \\cdot 0.4 + 4 \\cdot 0.2 = 0.1 + 0.6 + 1.2 + 0.8 = 2.7\n\\]\n\nVariance\n\nWe first compute \\(\\mathbb{E}(X^2)\\): \\[\n\\mathbb{E}(X^2) = 1^2 \\cdot 0.1 + 2^2 \\cdot 0.3 + 3^2 \\cdot 0.4 + 4^2 \\cdot 0.2 = 0.1 + 1.2 + 3.6 + 3.2 = 8.1\n\\]\nThen:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - (\\mathbb{E}(X))^2 = 8.1 - (2.7)^2 = 8.1 - 7.29 = 0.81\n\\]\n\n\n\n\nSuppose a quality control inspector checks whether products are defective. Each item has a 10% chance of being defective, and tests are independent.\n\n\nLet \\(X\\) be a Bernoulli random variable indicating whether a single item is defective. What are the mean and variance of \\(X\\)?\nLet \\(Y \\sim \\text{Bin}(10, 0.1)\\) represent the number of defective items in a sample of 10. Compute:\n\n\n\\(\\mathbb{E}(Y)\\) and \\(\\mathbb{V}(Y)\\)\n\n\\(P(Y = 0)\\)\n\n\\(P(Y \\geq 2)\\)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\nBernoulli Variable \\(X\\): \\(X \\sim \\text{Bernoulli}(0.1)\\) \\[\\mathbb{E}(X) = 0.1\\]\n\\[\\mathbb{V}(X) = 0.1 \\cdot (1 - 0.1) = 0.09\\]\n\n\n\n\n\nBinomial Variable \\(Y\\): \\(Y \\sim \\text{Bin}(10, 0.1)\\)\n\\(\\mathbb{E}(Y) = 10 \\cdot 0.1 = 1\\)\n\\(\\mathbb{V}(Y) = 10 \\cdot 0.1 \\cdot 0.9 = 0.9\\)\n\\(P(Y = 0)\\)\n\n\\[\nP(Y = 0) = \\binom{10}{0}(0.1)^0(0.9)^{10} = 1 \\cdot 1 \\cdot (0.9)^{10} \\approx 0.3487\n\\]\n\n\\(P(Y \\geq 2)\\) We use the complement: \\[\nP(Y \\geq 2) = 1 - P(Y = 0) - P(Y = 1)\n\\] Already have \\(P(Y = 0) \\approx 0.3487\\). Now compute: \\[\nP(Y = 1) = \\binom{10}{1}(0.1)^1(0.9)^9 = 10 \\cdot 0.1 \\cdot (0.9)^9 \\approx 0.3874\n\\] Then: \\[\nP(Y \\geq 2) = 1 - 0.3487 - 0.3874 = 0.2639\n\\]",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html",
    "href": "rvs-probdists/cont-dists.html",
    "title": "14¬† Continuous Probability Distributions",
    "section": "",
    "text": "14.1 Probability Density Function (PDF)\nUntil now, we have mainly worked with discrete random variables, meaning variables that can only take on a finite or countably infinite number of possible values. For instance, the number of heads when tossing coins or the number of defective items in a sample are all discrete.\nHowever, not all random phenomena can be described in this way. A continuous random variable is a variable that can take on any value within an interval on the real number line. Rather than jumping between isolated values, a continuous variable can assume an infinite continuum of possible outcomes.\nBecause a continuous random variable can take any value within an interval, it is practically impossible to guess the exact value that a randomly selected observation will have. In fact, the probability that the variable exactly equals any specific value is zero. Consequently, for continuous random variables, we do not measure probabilities at single points. Instead, we consider the probability that the variable falls within a given interval.\nTo handle continuous random variables, we develop continuous analogues of the probability mass functions used for discrete variables. These continuous probability distributions are described using probability density functions, which allow us to calculate the probability that the variable lies within a specified range.\nTo summarize visually:\nIn discrete settings, probabilities are assigned to individual points. For continuous random variables, we instead measure the ‚Äúarea under the curve‚Äù of the density function across an interval.\nAs we move forward, we will develop the tools needed to work with continuous distributions, starting with probability density functions and moving toward important continuous models such as the uniform and normal distributions.\nA continuous random variable can take on all possible values within some interval on the real number line. The interval may be bounded or extend to infinity in one or both directions.\nThe probability distribution of a continuous random variable \\(X\\) is described by a so-called probability density function \\(f(x)\\). The density function represents how the values of \\(X\\) are distributed across the real line.\nA typical shape of a probability density function might look like the following:\nIn contrast to discrete random variables, continuous variables do not assign positive probability to specific points. Instead, the probability that \\(X\\) falls within a particular interval \\([a, b]\\) is given by the area under the curve of the density function between \\(a\\) and \\(b\\):\n\\[\nP(a \\leq X \\leq b) = \\text{area under } f(x) \\text{ from } a \\text{ to } b\n\\]\nThe properties that every valid probability density function must satisfy are: - \\(f(x) \\geq 0\\) for all \\(x\\) (the function must be non-negative everywhere) - The total area under \\(f(x)\\) over the entire real line equals 1:\n\\[\n\\int_{-\\infty}^{\\infty} f(x) , dx = 1\n\\]\nThis ensures that the random variable must take on some value in the real numbers with total probability one.\nWe can also visually highlight the probability over a specific interval by shading the area between two points \\(a\\) and \\(b\\):\nIn this plot, the shaded area between \\(a = 3\\) and \\(b = 7\\) represents \\(P(3 \\leq X \\leq 7)\\); the probability that the random variable falls within this interval.\nThis concept, relating probabilities to areas under a curve, is a fundamental idea when working with continuous random variables, and it distinguishes them clearly from the discrete case where we sum probabilities at isolated points.\nWhen working with continuous random variables, we are always interested in the probability that a value falls within an interval, never at a single point. This is because the area under the curve at a single value is zero, which means:\n\\[\nP(X = a) = 0\n\\]\nWhether we specify the interval as open, closed, or half-open does not affect the probability. For example, the following expressions are all equivalent:\n\\[\nP(a \\leq X \\leq b) = P(a \\leq X &lt; b) = P(a &lt; X \\leq b) = P(a &lt; X &lt; b)\n\\]\nThey all describe the same shaded region under the curve between \\(a\\) and \\(b\\).\nFormally, the probability that \\(X\\) falls within an interval \\([a, b]\\) is given by integrating the probability density function:\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx\n\\]\nHowever, in this course, we do not require formal calculations using integrals.\nWe can work with the cumulative distribution function (CDF), which is defined as:\n\\[\nF(x) = P(X \\leq x)\n\\]\nThis function gives the total probability accumulated up to the value \\(x\\), that is, the area under the density curve from the lower bound of the distribution up to \\(x\\).\nUsing the CDF, we can express interval probabilities as the difference of cumulative values:\n\\[\nP(a \\leq X \\leq b) = P(X \\leq b) - P(X \\leq a) = F(b) - F(a)\n\\]\nThis relationship is especially useful when we don‚Äôt have access to the density function itself but can look up or compute values of the cumulative distribution. It also reinforces the idea that probability for continuous variables is tied to the area between two points, not the height at a point.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#expectation-and-variance-for-continuous-variables",
    "href": "rvs-probdists/cont-dists.html#expectation-and-variance-for-continuous-variables",
    "title": "14¬† Continuous Probability Distributions",
    "section": "\n14.2 Expectation and Variance for Continuous Variables",
    "text": "14.2 Expectation and Variance for Continuous Variables\nJust as we did with discrete random variables, we can define the expected value and variance for continuous random variables. These two quantities serve as important measures of central tendency and spread, respectively.\nThe expected value of a continuous random variable \\(X\\) with density function \\(f(x)\\) is given by:\n\\[\n\\mathbb{E}(X) = \\mu_X = \\int_{-\\infty}^{\\infty} x f(x) \\, dx\n\\]\nThis can be interpreted as a kind of weighted average, where the values of \\(x\\) are weighted by their relative likelihood ‚Äî in this case, the density function \\(f(x)\\).\nThe variance is defined as:\n\\[\n\\mathbb{V}(X) = \\sigma_X^2 = \\int_{-\\infty}^{\\infty} (x - \\mu)^2 f(x) \\, dx\n\\]\nJust like in the discrete case, this measures how spread out the values of \\(X\\) are around the mean \\(\\mu\\).\nIntuitively, the expected value can be thought of as the balance point of the distribution, the point at which the density function would balance perfectly if it were a physical object. The variance, as before, describes how tightly or widely the values of \\(X\\) tend to cluster around this center.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#the-normal-distribution",
    "href": "rvs-probdists/cont-dists.html#the-normal-distribution",
    "title": "14¬† Continuous Probability Distributions",
    "section": "\n14.3 The Normal Distribution",
    "text": "14.3 The Normal Distribution\nAmong all continuous probability distributions, none is more important or more widely used than the normal distribution. This may seem strange, since very few real-world quantities are exactly normally distributed. Nevertheless, the normal distribution plays a central role in probability theory and statistics, especially as a powerful approximation tool.\nMathematically, a random variable \\(X\\) is said to follow a normal distribution if its probability density function is given by:\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\, e^{- \\frac{1}{2} \\left( \\frac{x - \\mu}{\\sigma} \\right)^2}, \\quad \\text{for } -\\infty &lt; x &lt; \\infty\n\\]\nWe denote this by writing:\n\\[\nX \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\nHere, \\(\\mu\\) is the mean of the distribution, and \\(\\sigma^2\\) is the variance (with \\(\\sigma\\) being the standard deviation).\nThis density function has a characteristic bell shape: it is symmetric about the mean \\(\\mu\\), and the spread of the curve is determined by \\(\\sigma\\). The larger the value of \\(\\sigma\\), the more spread out the distribution becomes.\nDespite its somewhat complicated appearance, the normal distribution is incredibly useful because many phenomena in practice, especially sums and averages of random variables, tend to follow a distribution that closely resembles the normal. This fact is supported by the central limit theorem, which guarantees that under mild conditions, the sum of a large number of independent random variables tends toward a normal distribution, regardless of the original distributions. We will return to this in more details later.\nMoreover, the probabilities associated with the normal distribution have already been computed and tabulated. These tables allow us to quickly look up values without performing integrals manually, making the normal distribution not only powerful in theory but also very practical in application.\nIt is this combination of mathematical elegance, approximation power, and computational convenience that explains the normal distribution‚Äôs central role in both theoretical and applied statistics.\nLet us now look at a concrete example. Suppose \\(X\\) is a normally distributed random variable with mean \\(\\mu = 10\\) and standard deviation \\(\\sigma = 2\\):\n\\[\nX \\sim \\mathcal{N}(10, 2)\n\\]\nThe density function of \\(X\\) is bell-shaped and symmetric around the mean, with most of its probability mass concentrated within a few standard deviations from the center.\nBelow is the probability density function for this distribution:\n\n\n\n\n\n\n\n\nIn practice, there are a few key characteristics of the normal distribution that are particularly important to understand.\nFirst, the shape of the normal distribution is completely determined by two parameters: the mean \\(\\mu\\) and the standard deviation \\(\\sigma\\). These control the center and the spread of the distribution, respectively.\nThe sample space of a normal distribution is the entire real number line, meaning that the variable can take on any real value, both positive and negative.\nGraphically, the density function of a normal distribution always has the same bell-shaped curve, regardless of the specific values of \\(\\mu\\) and \\(\\sigma\\). The mean \\(\\mu\\) determines the central location of the curve, while the standard deviation \\(\\sigma\\) determines how wide or narrow the curve appears.\nA key feature of the normal distribution is that it is symmetric around the mean \\(\\mu\\). This symmetry implies that probabilities on either side of the mean are equal for equally sized intervals. In addition, as \\(x \\to \\pm\\infty\\), the density function \\(f(x)\\) approaches zero, meaning that extremely large or small values are increasingly unlikely, but not impossible.\nThe shape of a normal distribution is fully determined by its mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Changing either of these parameters modifies the appearance of the distribution in predictable ways. This is shown in Figure¬†14.1.\nIn (a), we compare two normal distributions with different means but the same standard deviation. This results in curves with identical shapes, but centered at different locations. Shifting \\(\\mu\\) translates the curve horizontally without altering its height or spread.\nIn (b), we hold the mean constant and vary the standard deviation. This causes the curve to either compress or stretch. A smaller \\(\\sigma\\) yields a sharper, narrower peak, while a larger \\(\\sigma\\) produces a flatter, wider distribution.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†14.1: Effects of changing parameters in the normal distribution (a) Changing the mean shifts the curve horizontally. (b) Changing the standard deviation alters the width and height of the curve\n\n\nBut first, we will learn how to calculate probabilities using normal distribution tables.\n\n14.3.1 Area under curve\nWhen using a normal distribution curve to model probability, the logic is as follows: we want to determine the probability that a randomly selected individual falls within a certain interval, say \\((a, b)\\). This is equivalent to finding the proportion of individuals in the population whose values lie between \\(a\\) and \\(b\\).\nIn a normal distribution, this probability corresponds to the area under the curve between \\(a\\) and \\(b\\). Since the total area under the entire curve is equal to 1 (or 100%), the shaded region gives us the desired probability.\nThis relationship between area and probability allows us to calculate how likely it is to observe values within specific ranges ‚Äî and by symmetry, how unusual values far from the mean are.\nLet us visualize this with the previouslt mentioned empirical rule in Figure¬†7.3, which summarizes how the area is distributed across standard deviations from the mean. This is shown in Figure¬†14.2.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†14.2: Empirical rule for the normal distribution. Shaded areas show typical probabilities for values within 1, 2, and 3 standard deviations of the mean.\n\n\nIn practice, the most important takeaway is this:\n\nApproximately 68% of values lie within one standard deviation from the mean (\\(\\mu \\pm \\sigma\\))\nAbout 95% lie within two standard deviations (\\(\\mu \\pm 2\\sigma\\))\nNearly 99.7% lie within three standard deviations (\\(\\mu \\pm 3\\sigma\\))\n\nThis is known as the empirical rule, and it forms the basis for many practical applications of the normal distribution. It also shows that values far from the mean are rare, making them candidates for being considered ‚Äúunusual‚Äù or outliers in statistical reasoning.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "appendix/normal-table.html",
    "href": "appendix/normal-table.html",
    "title": "Appendix A: Standard Normal Table",
    "section": "",
    "text": "Standard Normal Cumulative Probabilities: \\(P(Z \\leq z)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nz\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\n0.08\n0.09\n\n\n\n0.0\n0.500\n0.504\n0.508\n0.512\n0.516\n0.520\n0.524\n0.528\n0.532\n0.536\n\n\n0.1\n0.540\n0.544\n0.548\n0.552\n0.556\n0.560\n0.564\n0.567\n0.571\n0.575\n\n\n0.2\n0.579\n0.583\n0.587\n0.591\n0.595\n0.599\n0.603\n0.606\n0.610\n0.614\n\n\n0.3\n0.618\n0.622\n0.626\n0.629\n0.633\n0.637\n0.641\n0.644\n0.648\n0.652\n\n\n0.4\n0.655\n0.659\n0.663\n0.666\n0.670\n0.674\n0.677\n0.681\n0.684\n0.688\n\n\n0.5\n0.691\n0.695\n0.698\n0.702\n0.705\n0.709\n0.712\n0.716\n0.719\n0.722\n\n\n0.6\n0.726\n0.729\n0.732\n0.736\n0.739\n0.742\n0.745\n0.749\n0.752\n0.755\n\n\n0.7\n0.758\n0.761\n0.764\n0.767\n0.770\n0.773\n0.776\n0.779\n0.782\n0.785\n\n\n0.8\n0.788\n0.791\n0.794\n0.797\n0.800\n0.802\n0.805\n0.808\n0.811\n0.813\n\n\n0.9\n0.816\n0.819\n0.821\n0.824\n0.826\n0.829\n0.831\n0.834\n0.836\n0.839\n\n\n1.0\n0.841\n0.844\n0.846\n0.848\n0.851\n0.853\n0.855\n0.858\n0.860\n0.862\n\n\n1.1\n0.864\n0.867\n0.869\n0.871\n0.873\n0.875\n0.877\n0.879\n0.881\n0.883\n\n\n1.2\n0.885\n0.887\n0.889\n0.891\n0.893\n0.894\n0.896\n0.898\n0.900\n0.901\n\n\n1.3\n0.903\n0.905\n0.907\n0.908\n0.910\n0.911\n0.913\n0.915\n0.916\n0.918\n\n\n1.4\n0.919\n0.921\n0.922\n0.924\n0.925\n0.926\n0.928\n0.929\n0.931\n0.932\n\n\n1.5\n0.933\n0.934\n0.936\n0.937\n0.938\n0.939\n0.941\n0.942\n0.943\n0.944\n\n\n1.6\n0.945\n0.946\n0.947\n0.948\n0.949\n0.951\n0.952\n0.953\n0.954\n0.954\n\n\n1.7\n0.955\n0.956\n0.957\n0.958\n0.959\n0.960\n0.961\n0.962\n0.962\n0.963\n\n\n1.8\n0.964\n0.965\n0.966\n0.966\n0.967\n0.968\n0.969\n0.969\n0.970\n0.971\n\n\n1.9\n0.971\n0.972\n0.973\n0.973\n0.974\n0.974\n0.975\n0.976\n0.976\n0.977\n\n\n2.0\n0.977\n0.978\n0.978\n0.979\n0.979\n0.980\n0.980\n0.981\n0.981\n0.982\n\n\n2.1\n0.982\n0.983\n0.983\n0.983\n0.984\n0.984\n0.985\n0.985\n0.985\n0.986\n\n\n2.2\n0.986\n0.986\n0.987\n0.987\n0.987\n0.988\n0.988\n0.988\n0.989\n0.989\n\n\n2.3\n0.989\n0.990\n0.990\n0.990\n0.990\n0.991\n0.991\n0.991\n0.991\n0.992\n\n\n2.4\n0.992\n0.992\n0.992\n0.992\n0.993\n0.993\n0.993\n0.993\n0.993\n0.994\n\n\n2.5\n0.994\n0.994\n0.994\n0.994\n0.994\n0.995\n0.995\n0.995\n0.995\n0.995\n\n\n2.6\n0.995\n0.995\n0.996\n0.996\n0.996\n0.996\n0.996\n0.996\n0.996\n0.996\n\n\n2.7\n0.997\n0.997\n0.997\n0.997\n0.997\n0.997\n0.997\n0.997\n0.997\n0.997\n\n\n2.8\n0.997\n0.998\n0.998\n0.998\n0.998\n0.998\n0.998\n0.998\n0.998\n0.998\n\n\n2.9\n0.998\n0.998\n0.998\n0.998\n0.998\n0.998\n0.998\n0.999\n0.999\n0.999\n\n\n3.0\n0.999\n0.999\n0.999\n0.999\n0.999\n0.999\n0.999\n0.999\n0.999\n0.999",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Standard Normal Table</span>"
    ]
  },
  {
    "objectID": "rvs-probdists/cont-dists.html#the-standard-normal-distribution",
    "href": "rvs-probdists/cont-dists.html#the-standard-normal-distribution",
    "title": "14¬† Continuous Probability Distributions",
    "section": "\n14.4 The Standard Normal Distribution",
    "text": "14.4 The Standard Normal Distribution\nIn practice, the values for which we want to calculate probabilities do not always align with the specific values shown in a table. Fortunately, thanks to the properties of the normal distribution, we don‚Äôt need a separate table for every possible mean and standard deviation.\nInstead, we make use of a powerful idea: that any normal distribution can be converted into a standard normal distribution, and this makes calculating probabilities far simpler.\nThe standard normal distribution is the special case where the mean is 0 and the standard deviation is 1. That is:\n\\[\nZ \\sim \\mathcal{N}(0, 1)\n\\]\nThis is our reference distribution. Because it measures distances in units of standard deviation from the mean, we can interpret a value like \\(z = 1.5\\) as ‚Äú1.5 standard deviations above the mean‚Äù.\nSince the normal distribution is symmetric around the mean, values less than 0 represent outcomes below average, and values greater than 0 are above average.\nBy using the standard normal, we only need to consult a single probability table, shown in Appendix A, to find probabilities for a wide range of problems. The transformation is done through standardization, which we‚Äôll explore in the next section.\nWe denote the cumulative probability function of the standard normal by \\(F(z)\\) or \\(P(Z \\leq z)\\), and for values of \\(z\\) between 0.00 and 3.00, these values are commonly found in standard Z-tables.\nWe also use the symmetry of the normal curve:\n\\[\nP(Z \\leq -z) = 1 - P(Z \\leq z)\n\\]\nThis makes it easy to compute probabilities for both tails of the distribution.\nBelow is the standard normal curve:\n\n\n\n\n\n\n\n\nThe plot shows the familiar bell shape, now centered at 0. This is the foundation for calculating probabilities with normal distributions; we convert our variable to a Z-score and then read the probability directly from this reference distribution.",
    "crumbs": [
      "Random Variables and Probability Distributions",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  }
]