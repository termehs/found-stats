# Hypothesis Testing {#sec-hyptest}
In the previous chapter, we used **confidence intervals** to estimate an unknown population parameter such as the mean ($\mu$) or proportion ($p$), based on a random sample. Confidence intervals provide a range of plausible values for that parameter.

While confidence intervals focus on estimation, **hypothesis testing** addresses decision-making: it allows us to test specific claims about a population parameter using sample data.   In fact, these two methods are closely related; we can often reach the same conclusions using either approach. We return to this in more detail later in this chapter.


## What Is Hypothesis Testing?
Hypothesis testing is a formal method used to evaluate **two competing statements** (called hypotheses) about a population parameter:

- **Null hypothesis** ($H_0$): The default or status quo assumption.
- **Alternative hypothesis** ($H_1$ or $H_a$): A competing claim that we seek evidence for.

We use data from a sample to decide whether there is sufficient evidence to reject the null hypothesis in favor of the alternative. The null hypothesis ($H_0$) is assumed to be true unless the evidence from the sample strongly contradicts it. It plays the role of a "presumption of innocence." The alternative hypothesis ($H_1$) is what we hope to support, but only if we have enough evidence to doubt $H_0$.  


We never prove the alternative hypothesis directly; we can only reject $H_0$ if the evidence is strong enough, just like a jury does not prove guilt, but rather rejects the assumption of innocence when the evidence demands it. Rejecting $H_0$ only indicates that the data are inconsistent with $H_0$ under the assumed conditions.

#### Example 22.1: Bottled Water Production {.unnumbered}

A company bottles 500 ml of spring water per bottle. To ensure customer trust, they need to verify that the filling process remains accurate. Let

$$
\mu = \text{true average amount of water per bottle}
$$

We want to test whether the bottling machine is still calibrated correctly:

$H_0$: $\mu = 500$ (machine is accurate)

$H_1$: $\mu \neq 500$ (machine is underfilling or overfilling)


That is, the alternative hypothesis says: *"The machine does not have the correct precision."*

#### Example 22.2:  Political Party Support {.unnumbered}

In a political opinion poll, 14% of the selected individuals say they support Party A. We know that in the most recent election, Party A received 12% of the votes. Has the proportion of A-supporters in the population increased since the election?

$H_0$: $P = 0.12$ (The proportion is unchanged)  

$H_1$: $P > 0.12$ (The proportion has increased)

*Should we reject $H_0$ or not?*

- If we consider the high sample value to be explainable by chance (assuming $H_0$ is true), we stick with $H_0$. 
- If we consider the sample proportion to be too high to be reasonably explained by chance, we reject $H_0$.

We can never be 100% certain that we are making the correct decision. Statistical hypothesis testing involves using specific decision rules to determine when we should reject $H_0$ (and when we should retain $H_0$). These decision rules are designed so that we have a certain level of control over the risk of making an incorrect decision.

To understand the reasoning behind hypothesis testing, it can be helpful to draw an analogy from the legal system. Imagine a courtroom trial where the task is to determine whether the defendant is guilty or not. A key question in this context is: on whom does the burden of proof lie?

Just as in most legal systems, where a person is presumed innocent until proven guilty, hypothesis testing begins with a similar assumption. The **null hypothesis**, denoted $H_0$, plays the role of "innocence": it is the claim we initially assume to be true. The **alternative hypothesis**, denoted $H_1$, corresponds to the prosecution's claim: it challenges the status quo and must be supported by strong evidence.

There is an asymmetry in how we treat the null hypothesis ($H_0$) and the alternative hypothesis ($H_1$) in statistical hypothesis testing. We typically choose $H_0$ to be the hypothesis that we hold on to as long as possible. It is the default assumption, often representing "no change," "no effect," or "no difference." On the other hand, $H_1$ is usually the more bold and interesting hypothesis from an applied perspective.

We require particularly strong evidence from the observed data to reject $H_0$. The burden of proof lies with the party advocating for $H_1$. Before diving into how to best use information from the sample, we ask ourselves: how confident must we be that the accused is guilty before reaching a guilty verdict? Similarly, how confident must we be that the null hypothesis is incorrect before deciding to believe in the alternative hypothesis?

If we reach that level of confidence, we say that we reject the null hypothesis (or accept the alternative hypothesis). The degree of confidence required depends on the context, but typically, we want to be quite certain that the assumption in the null hypothesis is incorrect. This is because the decision to reject the null hypothesis, and instead believe in the alternative, often comes with serious consequences.



## Classical Hypothesis Testing  

The classical approach to hypothesis testing involves the following six main steps:

### Step 1. Hypotheses {.unnumbered}

Begin by formulating the null hypothesis ($H_0$) and the alternative hypothesis ($H_1$).

Examples of hypotheses about population means:

- $H_0: \mu = \mu_0$; $H_1: \mu \ne \mu_0$  
  *(Simple null hypothesis; two-sided alternative)*

- $H_0: \mu \le \mu_0$; $H_1: \mu > \mu_0$  
  *(Composite null hypothesis; one-sided alternative)*

Examples of hypotheses about population proportions:

- $H_0: p = p_0$; $H_1: p \ne p_0$  
  *(Simple null hypothesis; two-sided alternative)*

- $H_0: p = p_0$; $H_1: p > p_0$  
  *(Simple null hypothesis; one-sided alternative)*

### Step 2. Significance Level {.unnumbered}

Choose a significance level $\alpha$, which represents the probability (or risk) of rejecting the null hypothesis $H_0$ when it is actually true. 

A common choice is $\alpha = 0.05$, which implies that the hypothesis test is conducted at the 5% level.   This means that there is a 5% chance of making a **Type I error**, that is rejecting a true null hypothesis. In other words, if the null hypothesis is true, then on average, 1 in every 20 tests will incorrectly reject it. If we want to be more cautious about rejecting a correct null hypothesis, we use a smaller $\alpha$, such as $\alpha = 0.01$.



### Step 3. Test Statistic {.unnumbered}

Specify which test statistic will be used.   A **test statistic** is a quantity calculated from the sample data and its value forms the basis of our decision (see step 5).

The choice of test statistic depends on:

- Whether the sample is large or not.
- Whether the population is normally distributed or not.
- Whether the population variance is known or not.

We'll return to these different cases in more detail below.

### Step 4: Decision Rule  {.unnumbered}

Specify the **rejection region** (the critical region), such that $H_0$ is rejected if the test statistic falls within this region. In summary, the form of the **critical region** is determined by:

1. The form of the alternative hypothesis:

   - $H_1: \mu \neq \mu_0$ → two-tailed test → rejection region in both tails.
   - $H_1: \mu > \mu_0$ → one-tailed test → rejection region in the **right** tail.
   - $H_1: \mu < \mu_0$ → one-tailed test → rejection region in the **left** tail.

2. The significance level $\alpha$.

Alternative hypotheses of the forms $>$ and $<$ are called **one-sided**, while those using $\neq$ are called **two-sided**. @Fig-hyptest illustrates the decision framework of hypothesis testing  three panels: 

1.	Left: Depicts a two-tailed test, where both tails of the distribution represent critical regions. The dashed lines mark the critical values at $z = \pm z_{\alpha/2}$. Each tail has an area of $\alpha/2$, and the null hypothesis is rejected if the test statistic lies in either shaded tail. The central blue segment indicates the non-rejection region.  

2.	Right: Represents a one-sided test with the alternative hypothesis $H_1: \mu > \mu_0$. The right tail is shaded red, indicating the critical region with area $\alpha$. The test statistic must fall in this region to reject $H_0$.

3.	Middle: Shows the critical region in the left tail of the distribution, representing a one-sided test with the alternative hypothesis $H_1: \mu < \mu_0$. The red-shaded area corresponds to the significance level $\alpha$, and any test statistic falling in this region leads to rejection of the null hypothesis $H_0$.

::: {#fig-hyptest .center}

```{r}
#| warning: false
#| message: false
#| fig-width: 12
#| fig-height: 3
#| fig-align: center

library(ggplot2)
library(patchwork)

# Data for standard normal curve
x_vals <- seq(-4, 4, length.out = 1000)
df <- data.frame(x = x_vals, y = dnorm(x_vals))

# Define alpha level and critical values
alpha <- 0.05
crit_val <- qnorm(1 - alpha / 2)  # ≈ ±1.96

# Data for shaded critical regions
df_left <- subset(df, x <= -crit_val)
df_right <- subset(df, x >= crit_val)

# Find y-values at critical points
y_crit <- dnorm(crit_val)

# Base plot
p1 <- ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Shade the critical regions
  geom_area(data = df_left, fill = "red", alpha = 0.5) +
  geom_area(data = df_right, fill = "red", alpha = 0.5) +

  # Vertical lines at critical values that stop at the curve
  annotate("segment", x = -crit_val, xend = -crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +
  annotate("segment", x = crit_val, xend = crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +

  # Horizontal colored lines for critical and acceptance regions
  annotate("segment", x = -4, xend = -crit_val, y = 0, yend = 0, color = "red", linewidth = 2) +
  annotate("segment", x = -crit_val, xend = crit_val, y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +
  annotate("segment", x = crit_val, xend = 4, y = 0, yend = 0, color = "red", linewidth = 2) +

   # Arrows pointing into tails
  annotate("segment", x = -crit_val-0.6, xend = -crit_val-0.15, y = 0.07, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +
  annotate("segment", x = crit_val + 0.6, xend = crit_val + 0.15, y = 0.06, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +

  # Annotate regions
  annotate("text", x = 0, y = 0.44, label = "Two-sided alternative hypothesis", size = 5, fontface = "italic") +
  annotate("text", x = 0, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = -3.1, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = 3.1, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = -crit_val-0.7, y = 0.1, label = "α/2", color = "black", size = 4, vjust = 1.2) +
  annotate("text", x = crit_val+0.7, y = 0.09, label = "α/2", color = "black", size = 4, vjust = 1.2) +

  # Clean theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )

#  plot
p2 <- ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Shade the critical regions
  geom_area(data = df_right, fill = "red", alpha = 0.5) +

  # Vertical  lines at critical values that stop at the curve

  annotate("segment", x = crit_val, xend = crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +

  # Horizontal colored lines for critical and acceptance regions

  annotate("segment", x = -4, xend = crit_val, y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +
  annotate("segment", x = crit_val, xend = 4, y = 0, yend = 0, color = "red", linewidth = 2) +

   # Arrows pointing into tails
  annotate("segment", x = crit_val + 0.6, xend = crit_val + 0.15, y = 0.06, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +

  # Annotate regions
  annotate("text", x = 0, y = 0.44, label = "One-sided alternative hypothesis (>)", size = 5, fontface = "italic") +
  annotate("text", x = -0.5, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = 3.1, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = crit_val+0.7, y = 0.09, label = "α", color = "black", size = 4, vjust = 1.2) +

  # Clean theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )

# plot

p3 <- ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Shade the critical regions
  geom_area(data = df_left, fill = "red", alpha = 0.5) +

  # Vertical lines at critical values that stop at the curve
  annotate("segment", x = -crit_val, xend = -crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +


  # Horizontal colored lines for critical and acceptance regions
  annotate("segment", x = -4, xend = -crit_val, y = 0, yend = 0, color = "red", linewidth = 2) +
  annotate("segment", x = -crit_val, xend = 4 , y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +


   # Arrows pointing into tails
  annotate("segment", x = -crit_val-0.6, xend = -crit_val-0.15, y = 0.07, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +


  # Annotate regions
  annotate("text", x = 0, y = 0.44, label = "Two-sided alternative hypothesis (<)", size = 5, fontface = "italic") +
  annotate("text", x = 0.5, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = -3.1, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = -crit_val-0.7, y = 0.1, label = "α", color = "black", size = 4, vjust = 1.2) +
  # Clean theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )

p1+ p2+ p3
```
The decision framework of hypothesis testing for two-tailed and one-tailed tests.
:::

::: {.callout-note}
## Errors and Decision Framework
When making a decision, one either makes a correct choice or one of two types of errors. Just as there is a risk that an innocent person may be wrongly convicted, there is also a risk that a guilty person may go free.

Using probability theory, we can to some extent determine the risk of making incorrect decisions.

- A **Type I error** occurs when we incorrectly reject the null hypothesis ($H_0$) even though it is true. The risk of making a Type I error is called the **significance level** of the test and is denoted by the Greek letter $\alpha$.

- A **Type II error** occurs when we incorrectly fail to reject the null hypothesis, even though it is false. The risk of this error is denoted by the Greek letter $\beta$.

A diagram describing the possible outcomes of hypothesis testing is shown below:

| **Reality**      | $H_0$ is true              | $H_0$ is false             |
|------------------|----------------------------|----------------------------|
| **Decision**     |                            |                            |
| Do not reject $H_0$ | Correct decision           | Type II error (incorrect decision) |
| Reject $H_0$     | Type I error (incorrect decision) | Correct decision           |

In classical hypothesis testing, we primarily control the probability of making a Type I error. This is done by setting the significance level $\alpha$ to a predefined low value (commonly $\alpha = 0.01$, $0.05$, or $0.10$).

$$
\alpha = \text{Significance level of the test} = P(\text{Reject } H_0 \mid H_0 \text{ is true})
$$

After setting the acceptable level for Type I errors, we then aim to reduce the probability of Type II errors ($\beta$) by choosing a sufficiently large sample size.
:::


Once the hypotheses have been formulated, the appropriate test statistic selected and decision rules specified, we proceed with the final steps of the classical hypothesis testing procedure:

### Step 5: Observation {.unnumbered}

We calculate the value of the **test statistic** using the data obtained from the sample. This computation allows us to compare the observed value with the theoretical distribution *under the null hypothesis*. This value is what we refere to as our **observed value**.

### Step 6: Conclusion  {.unnumbered}

Based on the value of the test statistic (our observed value), we make our decision based on the decision rule:

- If the value falls **outside the critical boundaries** (i.e. outside the non-rejection region), we **reject the null hypothesis** $H_0$. This means that we have obtained a result that is statistically significant at the chosen significance level $\alpha$.

- If the value falls **within the non-rejection region**, we **do not reject** $H_0$. In this case, the result is said to be **not statistically significant**.

In essence, these final steps guide us in deciding whether the sample data provides enough evidence to conclude that the null hypothesis is unlikely to be true, given the selected confidence level.


::: {.callout-note}
## Note
A non-significant result does **not** mean that we can conclude the null hypothesis ($H_0$) is true. It simply indicates that the alternative hypothesis ($H_1$) does not present strong enough evidence against $H_0$ in this particular case.

There may be many other potential null hypotheses that would also not be rejected. Therefore, **failing to reject $H_0$ is not the same as accepting $H_0$ as true**.

In other words, we use the terms ‘*reject*’ and ‘*fail to reject*’ to summarize the possible outcomes of a hypothesis test
:::

## Hypothesis Testing for a Population Mean

Just as with confidence intervals, different cases must be considered when conducting hypothesis tests:

- Is the sample size large or small?
- Is the population normally distributed?
- Is the population variance known?


### Two-Sided Hypothesis Tests

We begin with an example: suppose we draw a sample of size $n$ from a **normally distributed population** where the mean $\mu$ is unknown but the **variance $\sigma^2$ is known**. We conduct a **two-sided hypothesis test** at a significance level $\alpha = 0.05$, walking through the six steps of hypothesis testing.

#### 1. Hypotheses {.unnumbered}

We want to test whether the population mean equals some hypothesized value $\mu_0$. The hypotheses are:

$$
H_0: \mu = \mu_0 \\
H_1: \mu \ne \mu_0
$$

This is a **two-sided test**, as we are considering deviations in both directions from $\mu_0$.

#### 2. Significance Level {.unnumbered}

We choose a significance level of:

$$
\alpha = 0.05
$$

This indicates we are willing to accept a 5% chance of rejecting the null hypothesis if it is actually true.

#### 3. Test Statistic {.unnumbered}

Since the population is normally distributed and the population standard deviation $\sigma$ is known, we use the **standard normal $Z$ statistic**:

$$
Z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}
$$

Under $H_0$, the statistic follows the standard normal distribution:

$$
Z \sim N(0, 1)
$$

#### 4. Decision Rule {.unnumbered}

For a two-sided test with $\alpha = 0.05$, the critical values are:

$$
z_{\alpha/2} = \pm 1.96
$$

The decision rule is:

- Reject $H_0$ if $|z_{\text{obs}}| > 1.96$
- Otherwise, do not reject $H_0$

The critical regions for this test is visualized in @fig-mean2side, where we see the threshold for rejecting $H_0$ in both directions when testing for a deviation from a hypothesized population mean.


::: {#fig-mean2side .center}

```{r}
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 10

ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Shade the critical regions
  geom_area(data = df_left, fill = "red", alpha = 0.5) +
  geom_area(data = df_right, fill = "red", alpha = 0.5) +

  # Vertical lines at critical values that stop at the curve
  annotate("segment", x = -crit_val, xend = -crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +
  annotate("segment", x = crit_val, xend = crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +

  # Horizontal colored lines for critical and acceptance regions
  annotate("segment", x = -4, xend = -crit_val, y = 0, yend = 0, color = "red", linewidth = 2) +
  annotate("segment", x = -crit_val, xend = crit_val, y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +
  annotate("segment", x = crit_val, xend = 4, y = 0, yend = 0, color = "red", linewidth = 2) +

   # Arrows pointing into tails
  annotate("segment", x = -crit_val-0.6, xend = -crit_val-0.15, y = 0.07, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +
  annotate("segment", x = crit_val + 0.6, xend = crit_val + 0.15, y = 0.06, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +

  # Annotate regions
  annotate("text", x = 0, y = 0.44, label = "Two-sided alternative hypothesis, α = 0.05 ", size = 5, fontface = "italic") +
  annotate("text", x = 0, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = -2.7, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = 2.7, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = -crit_val-0.7, y = 0.1, label = "α/2=0.025", color = "black", size = 4, vjust = 1.2) +
  annotate("text", x = crit_val+0.7, y = 0.09, label = "α/2=0.025", color = "black", size = 4, vjust = 1.2) +
   annotate("text", x = -crit_val, y = -0.02, label = "-1.96", color = "black", size = 4, vjust = 1.2) +
  annotate("text", x = crit_val, y = - 0.02 , label = "1.96", color = "black", size = 4, vjust = 1.2) +

  # Clean theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )


```
Visual representation of a two-sided hypothesis test at significance level $\alpha  = 0.05$. The standard normal curve is split into two critical regions (shaded red), each representing $\alpha⁄2 = 0.025$ in the tails, where the null hypothesis is rejected. The non-rejection region (shaded blue) lies between the critical values −1.96 and 1.96. If the test statistic falls within this central interval, we do not reject the null hypothesis. 
:::

#### 5. Observation {.unnumbered}

Compute the observed value of the test statistic:

$$
z_{\text{obs}} = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}
$$

#### 6. Conclusion {.unnumbered}

Compare $z_{\text{obs}}$ to the critical values:

- If $|z_{\text{obs}}| > 1.96$, **reject $H_0$**
- Otherwise, **fail to reject $H_0$**

This tells us whether the sample provides strong enough evidence to conclude that the population mean differs from $\mu_0$.


::: {.callout-note}
# Note: Choosing Critical Values for a Hypothesis Test
A reasonable starting point in hypothesis testing is that we should reject the null hypothesis ($H_0$) if we observe a sample mean $\bar{x}$ that is “far” from the expected value $\mu_0$ under $H_0$.

In practical terms, $\bar{x}$ being far from $\mu_0$ means that the test statistic $Z$ takes on a value far from 0; either in the positive or negative direction. Therefore, we decide to reject $H_0$ if $Z$ falls outside a specified range: specifically, outside the interval $[-c, c]$, where $c$ is a positive constant that we determine based on the desired significance level $\alpha$.


To define this cutoff $c$, we choose it so that the total probability of $Z$ falling outside the interval (i.e., the two tails) equals the chosen significance level $\alpha$. For example, with $\alpha = 0.05$, we solve:

$$
P(|Z| > c \mid H_0 \text{ true}) = 0.05
$$

Since the distribution of $Z$ under the null hypothesis is standard normal $N(0, 1)$, we find:

$$
P(|Z| > 1.96 \mid H_0 \text{ true}) = 0.05
$$

Thus, we set $c = 1.96$ for a two-sided test at the 5% significance level. Our final decision rule becomes:

> Reject $H_0$ if the computed test statistic $Z$ falls outside the interval $[-1.96,\ 1.96]$. Otherwise, we fail to reject $H_0$.

:::

### One-Sided Hypothesis Tests
In some situations, we are not interested in detecting any difference from the null value, but specifically a greater or smaller value. In such cases, we use a one-sided alternative hypothesis. The structure of the test depends on the direction specified in the alternative.

#### Testing if the mean is greater than a specified value {.unnumbered}

We want to test the hypotheses:

$$
H_0: \mu = \mu_0 \quad \text{vs.} \quad H_1: \mu > \mu_0
$$

In this case, we are interested in large values of the sample mean $\bar{x}$ as evidence against $H_0$. The rejection region lies in the right tail of the standard normal distribution.

For a significance level $\alpha = 0.05$, the critical value is:

$$
z_\alpha = 1.645
$$

We reject the null hypothesis if:

$$
z_{\text{obs}} > 1.645
$$

This corresponds to the idea that an unusually high observed value of $\bar{x}$ supports the alternative that the true mean is greater than $\mu_0$.



#### Testing if the mean is less than a specified value {.unnumbered}

Now suppose we want to test:

$$
H_0: \mu = \mu_0 \quad \text{vs.} \quad H_1: \mu < \mu_0
$$

Here, we are interested in small values of the sample mean as evidence against $H_0$. The rejection region lies in the left tail of the standard normal distribution.

For $\alpha = 0.05$, the critical value becomes:

$$
z_\alpha = -1.645
$$

We reject the null hypothesis if:

$$
z_{\text{obs}} < -1.645
$$

This reflects the logic that low values of $\bar{x}$ support the alternative that the true mean is less than $\mu_0$.

The critical regions for these one-sided tests are visualized in @fig-mean1side, where we see the threshold for rejecting $H_0$ in either directions when testing for a deviation from a hypothesized population mean.


::: {#fig-mean1side .center}

```{r}
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 12
p11 <- ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Shade the critical regions
  geom_area(data = df_right, fill = "red", alpha = 0.5) +

  # Vertical  lines at critical values that stop at the curve

  annotate("segment", x = crit_val, xend = crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +

  # Horizontal colored lines for critical and acceptance regions

  annotate("segment", x = -4, xend = crit_val, y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +
  annotate("segment", x = crit_val, xend = 4, y = 0, yend = 0, color = "red", linewidth = 2) +

   # Arrows pointing into tails
  annotate("segment", x = crit_val + 0.6, xend = crit_val + 0.15, y = 0.06, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +

  # Annotate regions
  annotate("text", x = 0, y = 0.44, label = "One-sided alternative hypothesis (>), α = 0.05 ", size = 5, fontface = "italic") +
  annotate("text", x = -0.5, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = 3.1, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = crit_val+0.7, y = 0.09, label = "α=0.05", color = "black", size = 4, vjust = 1.2) +
  annotate("text", x = crit_val, y = - 0.02 , label = "1.645", color = "black", size = 4, vjust = 1.2) +

  # Clean theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )

p22 <-  ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Shade the critical regions
  geom_area(data = df_left, fill = "red", alpha = 0.5) +

  # Vertical lines at critical values that stop at the curve
  annotate("segment", x = -crit_val, xend = -crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +

  # Horizontal colored lines for critical and acceptance regions
  annotate("segment", x = -4, xend = -crit_val, y = 0, yend = 0, color = "red", linewidth = 2) +
  annotate("segment", x = -crit_val, xend = 4 , y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +
   # Arrows pointing into tails
  annotate("segment", x = -crit_val-0.6, xend = -crit_val-0.15, y = 0.07, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +
  annotate("text", x = -crit_val, y = - 0.02 , label = "-1.645", color = "black", size = 4, vjust = 1.2) +
  # Annotate regions
  annotate("text", x = 0, y = 0.44, label = "Two-sided alternative hypothesis (<), α=0.05", size = 5, fontface = "italic") +
  annotate("text", x = 0.5, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = -3.1, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = -crit_val-0.7, y = 0.1, label = "α=0.05", color = "black", size = 4, vjust = 1.2) +
  
  # Clean theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )

p11 + p22

```
Visual comparison of one-sided hypothesis tests using the standard normal distribution. The left plot shows a right-tailed test, with the rejection region in the upper tail (for testing $H_0: \mu = \mu_0$ vs. $H_1: \mu > \mu_0$). The right plot illustrates a left-tailed test, where the rejection region lies in the lower tail (for testing $H_0: \mu = \mu_0$ vs. $H_1: \mu < \mu_0$). 
:::

### Hypothesis Testing with Unknown Variance

Up until now, we have assumed that the population is normally distributed and that the population variance $\sigma^2$ is known. But what if the population variance is **unknown** or if the sample size is **small**?

In such cases, we no longer use the standard normal distribution ($Z$). Instead, we use the **Student’s $t$-distribution**, which accounts for the additional uncertainty introduced by estimating the population standard deviation from the sample.

The test statistic is then defined as:

$$
t = \frac{\bar{X} - \mu_0}{s / \sqrt{n}}
$$

where:

- $\bar{X}$ is the sample mean,
- $\mu_0$ is the value of the population mean under the null hypothesis,
- $s$ is the sample standard deviation,
- $n$ is the sample size.

Under the null hypothesis $H_0$, this test statistic follows a **$t$-distribution** with $n - 1$ **degrees of freedom**.

This approach is particularly crucial when the sample size is small ($n < 30$), and the population variance cannot be assumed to be known. The $t$-distribution is wider than the normal distribution, which reflects greater uncertainty in small samples. As $n$ increases, the $t$-distribution approaches the standard normal distribution (see @sec-est).

#### Summary: Hypothesis Tests for a Population Mean  {.unnumbered}

When testing hypotheses about a population mean, the choice of test statistic depends on the sample size, whether the population standard deviation is known, and the shape of the population distribution. These different cases for a test of the population mean are shown in @tbl-testmean.

::: {#tbl-testmean}
| Conditions                                          | Test Statistic                          | Distribution            |
|----------------------------------------------------------------------------------------------------|---------------------------|------------------------------------------------------|
| $n \geq 30$, $\sigma^2$ known                      | $Z = \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}}$ | Standard Normal ($Z$)    |
| $n \geq 30$, $\sigma^2$ unknown                    | $Z = \dfrac{\bar{X} - \mu_0}{s / \sqrt{n}}$     | Standard Normal ($Z$)    |
| $n < 30$, $\sigma^2$ known, normal population      | $Z = \dfrac{\bar{X} - \mu_0}{\sigma / \sqrt{n}}$ | Standard Normal ($Z$)    |
| $n < 30$, $\sigma^2$ unknown, normal population    | $t = \dfrac{\bar{X} - \mu_0}{s / \sqrt{n}}$     | $t$ with $n-1$ df |

Summary of test statistics and distributions used for hypothesis testing of a population mean ($\mu$), depending on sample size, knowledge of the population variance, and the assumption of normality. When the population standard deviation is unknown and the sample size is small, the $t$-distribution is used with $n - 1$ degrees of freedom. Note that these are the distributions assumed given $H_0$ true.

:::



#### Example 22.1: Hypothesis Testing for a Mean {.unnumbered}

We are given a sample of $n = 16$ observations from a normally distributed population with a known standard deviation $\sigma = 16$. The sample mean is $\bar{x} = 743$. We want to test at the 5% significance level whether the population mean differs from 750, i.e., whether $\mu \ne 750$.

-  **Step 1: Hypotheses**
$$
H_0: \mu = 750
$$
$$
H_1: \mu \ne 750
$$
This is a two-sided test.

- **Step 2: Significance Level** \
We use a significance level of:
$$
\alpha = 0.05
$$

- **Step 3: Test Statistic** \
Since $\sigma$ is known and the population is normally distributed, we use the standard normal test statistic (see @tbl-testmean):
$$
Z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}} \sim N(0,1)
$$

- **Step 4: Decision Rule** \
Because this is a two-tailed test, the critical values are:
$$
z_{\alpha/2} = \pm 1.96
$$
We reject $H_0$ if:
$$
|z| > 1.96
$$

- **Step 5: Observation** \
We use the sample data to compute our observed value:
$$
Z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}} = \frac{743 - 750}{16 / \sqrt{16}} = \frac{-7}{4} = -1.75
$$

- **Step 6: Conclusion** \
Since the observed test statistic is $z = -1.75$ and:
$$
|-1.75| < 1.96
$$
we *fail to reject the null hypothesis*. There is not enough evidence at the 5% level to conclude that the population mean differs from 750.

This test is visualized in @fig-mean-ex.


::: {#fig-mean-ex .center}

```{r}
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 10

z_obs <- -1.75

ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +
  
  # Shade the critical regions
  geom_area(data = df_left, fill = "red", alpha = 0.5) +
  geom_area(data = df_right, fill = "red", alpha = 0.5) +


  # Vertical lines at critical values that stop at the curve
  annotate("segment", x = -crit_val, xend = -crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +
  annotate("segment", x = crit_val, xend = crit_val, y = 0, yend = y_crit, linetype = "solid", color = "black") +

  # Horizontal colored lines for critical and acceptance regions
  annotate("segment", x = -4, xend = -crit_val, y = 0, yend = 0, color = "red", linewidth = 2) +
  annotate("segment", x = -crit_val, xend = crit_val, y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +
  annotate("segment", x = crit_val, xend = 4, y = 0, yend = 0, color = "red", linewidth = 2) +

   # Arrows pointing into tails
  annotate("segment", x = -crit_val-0.6, xend = -crit_val-0.15, y = 0.07, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +
  annotate("segment", x = crit_val + 0.6, xend = crit_val + 0.15, y = 0.06, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +
    annotate("segment", x = -crit_val + 0.6, xend = -crit_val + 0.3, y = -0.05, yend = -0.015,
           arrow = arrow(length = unit(0.2, "cm")), color = "black") +

  # Annotate regions
  annotate("text", x = 0, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = -3.1, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = 3.1, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +
  annotate("text", x = -crit_val-0.7, y = 0.1, label = "α/2=0.025", color = "black", size = 4, vjust = 1.2) +
  annotate("text", x = crit_val+0.7, y = 0.09, label = "α/2=0.025", color = "black", size = 4, vjust = 1.2) +
   annotate("text", x = -crit_val, y = -0.02, label = "-1.96", color = "black", size = 4, vjust = 1.2) +
  annotate("text", x = crit_val, y = - 0.02 , label = "1.96", color = "black", size = 4, vjust = 1.2) +
  annotate("text", x = z_obs + 0.4, y = -0.08, label = "z-obs = -1.75", size = 4.2,  vjust = -0.4, fontface = "bold") +

      
  # point for observed value
  geom_point(x = z_obs, y =0, size = 4) +
  
  # Clean theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )

```
The two-tailed test in Example 22.1 using the $Z$-distribution.
:::

#### Example 22.2:  Hypothesis Test for a Mean {.unnumbered}
We are given a random sample of size $n = 15$ drawn from a normally distributed population with unknown standard deviation. The sample has a mean $\bar{x} = 24.1$ and a sample standard deviation $s = 2$. We want to test, at the 1% significance level, whether the population mean $\mu$ is less than 25.

- **Step 1: Hypotheses** \
We are conducting a one-sided (left-tailed) test:
$$
H_0: \mu = 25
$$
$$
H_1: \mu < 25
$$

- **Step 2: Significance Level** \
We choose a significance level of $\alpha = 0.01$.

- **Step 3: Test Statistic** \
Since $\sigma$ is unknown and $n$ is small, we use the $t$-distribution (see @tbl-testmean):
$$
t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}  \sim t(n-1)
$$

- **Step 4: Decision Rule** \
With $n - 1 = 14$ degrees of freedom and $\alpha = 0.01$ (one-tailed), we find the critical value:
$$
t_{14, 0.01} = -2.624
$$
We reject $H_0$ if $t_{\text{obs}} < -2.624$.


- **Step 5: Observation**\
We use the sample data to compute our observed value:
$$
t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} = \frac{24.1 - 25}{2 / \sqrt{15}} \approx -1.743
$$

- **Step 5: Conclusion**
Since $t_{\text{obs}} = -1.743$ is greater than $-2.624$ (in the non-rejection region), we do not reject the null hypothesis.  We fail to reject $H_0$. The sample does **not** provide sufficient evidence at the 1% significance level to conclude that the population mean is less than 25.
See @fig-mean-ex2 for an illustration of this one-tailed test.

> **Note:** Because the test statistic does not fall in the rejection region, the observed sample mean can be explained by random sampling variation if the true mean were 25.

::: {#fig-mean-ex2 .center}

```{r}
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 10

# Parameters
df <- 14
alpha <- 0.01
t_obs <- -1.743
crit_val <- qt(1 - alpha, df)
y_crit <- dt(crit_val, df)

# Data
x <- seq(-4, 4, length.out = 1000)
df_plot <- data.frame(x = x, y = dt(x, df))
df_left <- subset(df_plot, x <= -crit_val)

# Plot
ggplot(df_plot, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Shaded critical regions
  geom_area(data = df_left, fill = "red", alpha = 0.5) +

  # Vertical lines at critical values
  annotate("segment", x = -crit_val, xend = -crit_val, y = 0, yend = y_crit, color = "black") +


  # Horizontal lines
  annotate("segment", x = -4, xend = -crit_val, y = 0, yend = 0, color = "red", linewidth = 2) +
  annotate("segment", x = -crit_val, xend = 4, y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +


  # Arrows 
  annotate("segment", x = -crit_val-0.6, xend = -crit_val-0.3, y = 0.06, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +
  annotate("segment", x = -crit_val + 1.27, xend = -crit_val + 1.27, y = -0.06, yend =-0.02, arrow = arrow(length = unit(0.2, "cm")), color = "black") +

  # Region annotations
  annotate("text", x = 0, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = -3.45, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +


  # Label critical values
  annotate("text", x = -crit_val, y = -0.02, label = sprintf("-%.3f", crit_val), color = "black", size = 4) +
  annotate("text", x = -crit_val-0.7, y = 0.08, label = "α = 0.01", size = 4) +

  # Observed value
  geom_point(aes(x = t_obs + 0.4, y = 0), size = 4) +
  annotate("text", x = t_obs + 0.4, y = -0.08, label = "t-obs = -1.743", size = 4.2, fontface = "bold") +

  # Theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )
```
The one-tailed test in Example 22.2 using the $t$-distribution.
:::


## Hypothesis Testing for a Population Proportion
In this section, we test hypotheses about a **population proportion** $p$ based on data from a single sample. The hypotheses can be formulated as:

- $H_0: p = p_0$ (null hypothesis)
- $H_1$: one of the following alternative hypotheses:
  - $p \neq p_0$ (two-tailed)
  - $p > p_0$ (right-tailed)
  - $p < p_0$ (left-tailed)

Here, $p$ is the unknown population proportion, and $p_0$ is a specified numerical value.

We ask: Is the observed sample proportion $\hat{p}$ far enough from $p_0$ to justify rejecting the null hypothesis $H_0$? Or is the observed deviation consistent with sampling variation?

If the sample size is sufficiently large, we use the test statistic:
$$
Z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0(1 - p_0)}{n}}}
$$
Under the null hypothesis $H_0$, this statistic is approximately standard normal:
$$
Z \sim N(0, 1)
$$
For a common significance level $\alpha = 0.05$, the decision rules are as follows:

| Alternative Hypothesis | Reject $H_0$ if...            | Critical Value ($z_c$) |
|------------------------|--------------------------------|-------------------------|
| $p \neq p_0$           | $|z_{obs}| > z_c$              | $z_c = 1.96$            |
| $p > p_0$              | $z_{obs} > z_c$                | $z_c = 1.645$           |
| $p < p_0$              | $z_{obs} < -z_c$               | $z_c = -1.645$          |


> The critical values change with the chosen significance level. For other $\alpha$, adjust $z_c$ accordingly.

#### Example 22.3: Hypothesis Test for a Population Proportion {.unnumbered}
In a random sample of $n = 1200$ individuals, 625 report a particular opinion. Do the sample data support the claim that *more than half* of the population shares this opinion?
We will test this at a significance level of $\alpha = 0.05$.

- **Step 1: Hypotheses**\
This is a one-sided test:

- Null hypothesis: $H_0: p = 0.5$
- Alternative hypothesis: $H_1: p > 0.5$

- **Step 2: Significance Level**
We use $\alpha = 0.05$.

- **Step 3: Test Statistic**\
Because the sample size is large, we use the **normal approximation**. The test statistic is:
$$
Z = \frac{\hat{p} - p_0}{\sqrt{ \frac{p_0(1 - p_0)}{n} }}
$$
where:
  - $\hat{p} = \frac{625}{1200} = 0.521$
  - $p_0 = 0.5$
  - $n = 1200$

- **Step 4: Decision Rule**\
For a one-sided test at the 5% level, we reject $H_0$ if:
$$
z_{\text{obs}} > 1.645
$$

- **Step 5: Observation**\
Substitute the values into the formula for test statistic:
$$
z_{\text{obs}} = \frac{0.521 - 0.5}{\sqrt{ \frac{0.5(1 - 0.5)}{1200} }} = \frac{0.021}{0.0144} \approx 1.45
$$

- **Step 6: Conclusion**\
Since $z_{\text{obs}} = 1.45$ is less than the critical value 1.645, we fail to reject the null hypothesis. This means that the sample does not provide sufficient evidence to support the claim that more than half of the population holds this opinion at the 5% level. The test is visualize in @fig-prop-ex.


::: {#fig-prop-ex .center}

```{r}
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 10

# Parameters
alpha <- 0.05
z_obs <- 1.45
crit_val <- qnorm(1 - alpha)
y_crit <- dnorm(crit_val)

# Data for normal curve
x <- seq(-4, 4, length.out = 1000)
df_plot <- data.frame(x = x, y = dnorm(x))
df_right <- subset(df_plot, x >= crit_val)

# Plot
ggplot(df_plot, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Shaded critical region
  geom_area(data = df_right, fill = "red", alpha = 0.5) +

  # Vertical line at critical value
  annotate("segment", x = crit_val, xend = crit_val, y = 0, yend = y_crit, color = "black") +

  # Horizontal lines
  annotate("segment", x = crit_val, xend = 4, y = 0, yend = 0, color = "red", linewidth = 2) +
  annotate("segment", x = -4, xend = crit_val, y = 0, yend = 0, color = "deepskyblue3", linewidth = 2) +

  # Arrows
  annotate("segment", x = crit_val + 0.6, xend = crit_val + 0.3, y = 0.06, yend = 0.02,
           arrow = arrow(length = unit(0.18, "cm")), color = "black") +
  annotate("segment", x = crit_val - 0.7, xend = crit_val - 0.3, y = -0.05, yend = -0.017,
           arrow = arrow(length = unit(0.2, "cm")), color = "black") +

  # Region annotations
  annotate("text", x = 0, y = -0.03, label = "Non-rejection region", size = 4.2) +
  annotate("text", x = 2.5, y = -0.03, label = "Critical region", size = 3.8, color = "firebrick") +

  # Label critical value and alpha
  annotate("text", x = crit_val, y = -0.02, label = sprintf("%.3f", crit_val), color = "black", size = 4) +
  annotate("text", x = crit_val + 0.7, y = 0.08, label = "α = 0.05", size = 4) +

  # Observed z value
  geom_point(aes(x = z_obs, y = 0), size = 4) +
  annotate("text", x = z_obs-0.5, y = -0.06, label = "z-obs = 1.45", size = 4.2, fontface = "bold") +

  # Theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )

```
The one-tailed test for population proportion in Example 22.3.
:::

## Hypothesis Testing with $p$-Values
In hypothesis testing, once the test statistic has been calculated, the next step is to decide whether to reject the null hypothesis. This decision traditionally depends on whether the test statistic falls within the critical region defined by a chosen significance level ($\alpha$). However, this binary decision does not reveal how unusual or extreme the observed result actually is under the assumption that the null hypothesis is true.

To provide a more nuanced view, we use what is known as the **$p$-value**. The $p$-value answers the question: 

> *If the null hypothesis were true, what is the probability of obtaining a result at least as extreme as the one observed?* 

In this sense, the $p$-value is a measure of how compatible the observed data are with the null hypothesis. A small $p$-value indicates that such an extreme outcome would be unlikely if the null hypothesis were true, thereby providing evidence against it.

The smaller the $p$-value, the stronger the evidence against the null hypothesis in favor of the alternative. This value can also be thought of as a kind of post hoc significance threshold: 

> The $p$-value is the lowest significance level at which the null hypothesis would be rejected based on the observed data.

Instead of comparing the test statistic to a critical value, statistical software typically reports the $p$-value directly. This allows researchers and readers to interpret the strength of the evidence themselves, depending on the context and the significance level they consider appropriate.

In practical terms, if a researcher has set a significance level of 0.05 before conducting the test, and the calculated $p$-value is below this threshold, the null hypothesis would be rejected. If the $p$-value is greater, the null hypothesis is not rejected. The $p$-value thus becomes a central element in statistical inference, guiding conclusions with more granularity than a simple yes-or-no decision. 

Let's consider an example: suppose we are conducting a hypothesis test at the 5% level using the alternative hypothesis:
$$
H_1: \mu > \mu_0
$$
and the sample results yield a $p$-value of 3%. We perform this test at a significance level of $\alpha = 0.05$, i.e., a 5% threshold for rejecting the null hypothesis.

The $p$-value here tells us that the probability (under the assumption that the null hypothesis is true) of obtaining a result at least as extreme as the one observed is 3%. Since this is less than 5%, we reject the null hypothesis.

This decision is based on comparing the $p$-value to the critical value threshold. The critical region begins at the so-called critical point, the value on the distribution where the area under the curve to the right equals $\alpha = 0.05$.

Because the $p$-value corresponds to an area of only 3% under the curve to the right of our observed test statistic, and 3% is less than 5%, the observed value lies beyond the critical point and thus falls in the rejection region. This interpretation means the result is statistically significant at the 5% level. This is visualized in @fig-pval.


::: {#fig-pval .center}

```{r}
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 10
#| 
# Set values
zc <- 1.645         # critical value for alpha = 0.05 (right-tailed)
z_obs <- 1.88       # example observed z-value
alpha <- 0.05
p_value <- 1 - pnorm(z_obs)  # right-tail p-value

y_crit <- dnorm(zc)
y_obs <- dnorm(z_obs)

# Generate normal distribution
x_vals <- seq(-4, 4, length.out = 1000)
df <- data.frame(x = x_vals, y = dnorm(x_vals))

# Highlight critical region (α = 0.05)
df_crit <- subset(df, x >= zc)

# Highlight p-value region
df_pval <- subset(df, x >= z_obs)

ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black") +
  
  # Critical region
  geom_area(data = df_crit, aes(x = x, y = y), fill = "red", alpha = 0.6) +
  
  # P-value region
  geom_area(data = df_pval, aes(x = x, y = y), fill = "blue", alpha = 0.3) +
  
  # Vertical line at critical value
  annotate("segment", x = zc, xend = zc, y = -0.015, yend = y_crit, color = "red") +
  annotate("segment", x = z_obs, xend = z_obs, y = -0.015, yend = y_obs, color = "blue") +
  
    # Arrows
  annotate("segment", x = zc + 0.75, xend = zc + 0.4, y = 0.06, yend = 0.03,
           arrow = arrow(length = unit(0.2, "cm")), color = "purple4") +
  annotate("segment", x = zc - 0.4, xend = zc + 0.15, y = 0.06, yend = 0.03,
           arrow = arrow(length = unit(0.2, "cm")), color = "firebrick") +

  # Labels
  annotate("text", x = zc-0.2, y = -0.035, label = "z[c]", color = "red", vjust = -1.2) +
  annotate("text", x = z_obs+0.3, y = -0.035, label = "z[obs]", color = "blue", vjust = -1.2) +
  annotate("text", x = 2.8, y = 0.08, label = "p-value", color = "purple2",  size = 6) +
  annotate("text", x = 1.1, y = 0.07, label = "α", color = "red", size = 6) +
  annotate("segment", x = zc, xend = 4, y = 0, yend = 0, color = "red", linewidth = 2) +
  labs(x = "Z", y = NULL) +
  theme_void() +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.minor = element_blank())
```
The shaded red region represents the critical region corresponding to a significance level of $\alpha$ and critical value of z[c]. The blue point indicates the observed test statistic z[obs]. The purple shaded area indicates the $p$-value region. 
Since $p$-value $<  \alpha$, the null hypothesis is rejected.
:::

For this example, the $p$-value is given as
$$P (Z>z_{obs}|H_0 \text{ true} ) = 1−\Phi(z_{obs}) =0 .03$$
where $\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution. Thus, the *p*-value is the probability (under the null hypothesis $H_0$) of obtaining a value of $Z$ at least as extreme as the observed value $z_{obs}$.

Suppose we want to test whether a population mean is equal to a specific value. Our hypotheses are:

- Null hypothesis: $H_0: \mu = \mu_0$
- Alternative hypothesis: $H_1: \mu \neq \mu_0$

In this case, we are interested in detecting whether the mean is either significantly larger or smaller than the hypothesized value, that is a two-tailed test.  To determine how surprising our result is under the assumption that $H_0$ is true, we can calculate the $p$-value. This is the probability of obtaining a $Z$ value that is at least as extreme as the observed value, *in either direction*.

The formula for the $p$-value then becomes:
$$
p\text{-value} = 2 \left[1 - \Phi\left(|z_{\text{obs}}|\right)\right]
$$

where $\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution, and $|z_{\text{obs}}|$ is the absolute value of our observed test statistic. This is shown in @fig-pval2.

::: {#fig-pval2 .center}

```{r}
#| message: false
#| warning: false
#| fig-align: center
#| fig-height: 4
#| fig-width: 12

# Define observed z-value
z_obs <- 1.88

# Generate data
x_vals <- seq(-4, 4, length.out = 1000)
df <- data.frame(x = x_vals, y = dnorm(x_vals))

# Define data for shaded p-value regions
df_left <- subset(df, x <= -z_obs)
df_right <- subset(df, x >= z_obs)

# Plot
ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "black", linewidth = 0.7) +

  # Add shaded areas (with named fills for legend)
  geom_area(data = df_left, aes(x = x, y = y, fill = "p-value"), alpha = 0.5) +
  geom_area(data = df_right, aes(x = x, y = y, fill = "p-value"), alpha = 0.5) +

  # Vertical dashed lines at ±z_obs
  geom_vline(xintercept = c(-z_obs, z_obs), color = "purple2", linetype = "dotted") +

  # Labels
  annotate("text", x = -z_obs - 0.25, y = -0.02, label = "-z[obs]", size = 4.2) +
  annotate("text", x = z_obs + 0.23, y = -0.02, label = "z[obs]", size = 4.2) +

  # Fill legend
  scale_fill_manual(name = "", values = c("p-value" = "purple2")) +

  # Clean theme
  labs(x = NULL, y = NULL) +
  theme_void() +
  theme(
    legend.position = "top",
    legend.text = element_text(size = 12),
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank()
  )
```
Visualization of a two-tailed $p$-value. The shaded purple regions in both tails represent the $p$-value, corresponding to the probability (under the null hypothesis) of observing a test statistic as extreme or more extreme than the observed value z[obs]. The dashed vertical lines indicate the observed test statistic in both directions. Since this is a two-sided test, both tails are included in the calculation of the $p$-value.
:::
